云计算与虚拟化技术丛书
Mastering elasticsearch
Second Edition
深入理解
Elasticsearch
(原书第2版)
拉斐尔·酷奇( Rafat Kuc)
里B4导y
[美]
马雷克·罗戈任斯基( Marek Rogozinski)
著
张世武余洪淼商旦译
业出版社
cHina Machine Pres图书在版编目(CIP)数据
深入理解 Elasticsearch(原书第2版)/(美)拉斐尔·酷奇( Rafal Ku)等著;张世武
等译.一北京:机械工业出版社,2017.5
(云计算与虚拟化技术丛书)
书名原文: Mastering Elasticsearch, Second edition
ISBN978-7-111-56825-4
I.深…Ⅱ.①拉…②张…I.互联网络一情报检索IV.G254.928
中国版本图书馆CIP数据核字(2017)第087852号
本书版权登记号:图字:01-2016-6257
Rafat Kuc, Marek Rogozinski: Mastering Elasticsearch, Second Edition(ISBN: 978-1-78355-379-2)
Copyright c 2015 Packt Publishing. First published in the English language under the title Mastering
Elasticsearch, Second edition
All rights reserved
Chinese simplified language edition published by China Machine Press
Copyright o 2017 by China Machine Press
本书中文简体字版由 Packt Publishing授权机械工业出版社独家出版。未经出版者书面许可,不得以任何方式
复制或抄袭本书内容
深入理解 Elasticsearch(原书第2版)
出版发行:机械工业出版社(北京市西城区百万庄大街22号邮政編码:100037)
责任编辑:张梦玲
责任校对:殷虹
印刷:三河市宏图印务有限公司
版次:2017年5月第1版第1次印刷
开本:186mm×240mm1/16
印张:20
书号:ISBN978-7-111-56825-4
定价:79.00元
凡购本书,如有缺页、倒页、脱页,由本社发行部调换
客服热线:(010)8837942688361066
投稿热线:(010)88379604
购书热线:(010)683262948837964968995259读者信箱:hzit@hzbook.com
版权所有·侵权必究
封底无防伪标均为盜版
本书法律顾问:北京大成律师事务所韩光/邹晓东华章|T
HZBOOKS Information Technology
n列c lanslide:lw译者序
随着互联网时代的来临,人类面临着前所未有的信息过载问题。为了方便人们从海量信息
中快速精准地检索感兴趣的内容,Web搜索引擎应运而生。在互联网发展早期,数据量比较小,
单机索引就能支撑起一个完整应用。在这个时期, Apache Lucene凭借其精巧的代码设计、优
异的性能、丰富的查询接口,以及众多衍生搜索产品(如 Apache Solr、 Nutch等),在开源搜索
领域大放异彩。随着互联网的发展,数据量快速膨胀,此时对搜索引擎提出了分布式、准实时、
高容错、可扩展、易于交互等诸多进阶要求。基于 Lucene的简单二次开发已经不能满足日常搜
索需求, Elasticsearch的诞生很好地满足了上述大数据时代的搜索产品需求。
Elasticsearch是一款基于 Apache Lucene的开源搜索引擎产品,最早发布于2010年。之
后 Elasticsearch的开发团队成立了专门的商业公司,继续对其进行开发并提供服务和技术支持。
Elasticsearch具有开源、分布式、准实时、 RESTFul、便于二次开发等特点,代码实现精巧,系
统稳定可靠,已经被国内外众多知名组织和公司广泛采用。
本书内容丰富,不仅深入介绍了 Apache Lucene的评分机制、查询DSL、底层索引控制,
还详细介绍了 Elasticsearch的分布式索引机制、用户体验的改善、系统管理及性能优化,以及
自定义插件的开发。本书文笔优雅,辅以大量翔实的实例,能帮助读者快速提高 Elasticsearch
应用水平。需要提醒读者的是,本书的目标读者是 Elasticsearch的中高级用户,如果读者对
Elasticsearch的基础概念(如 Mapping、Type)缺乏了解的话,建议先阅读作者另一本针对初学
者的书《 Elasticsearch server》(目前已经出了第2版)。
相对于第1版,本书重新组织了多个章节的内容,删减了部分对读者来说意义不大的内容,
如 Java API的使用,突出了 Elasticsearch使用过程中的进阶技能,比如查询优化、用户体验改
善、 Elasticsearch节点集群管理等。
本书译文经过精心组织,结合了译者对 Elasticsearch的使用经验,并参考了IBM、微软、
百度、腾讯等众多知名企业的业界专业人士的意见。本书翻译团队由拥有丰富 Elasticsearch实
践经验的搜索算法专家、架构师和开发者组成。其中,张世武负责第3、5、6章的翻译和校对
工作,余洪淼负责第⑦、8、9章的翻译和校对,商旦负责第1、2、4章的翻译及全书校对。在本书翻译过程中,翻译团队经过多次讨论、审校,力求翻译准确、优雅。由于本书涉及很多新
概念,业界尚无统一术语,另外译者水平有限,难免会出现一些问题,欢迎广大读者及业内同
行批评指正。
翻译团队的所有成员在精力和时间都很有限的情况下,能够四个月如一日,顶着日常工作
和生活的压力,不计回报地通力合作,为一本书的翻译付出极大的热忱,实在难得。这里要感
谢翻译团队家人们的理解和默默支持,让我们一路走到今天。
在本书的翻译过程中,译者张世武得到所在单位成都数联铭品科技有限公司(BBD)的大
力支持。BBD是一家行业领先的金融大数据公司, Elasticsearch在BBD得到了广泛的应用。感
谢曾途、尹康、丁国栋、宋开发、刘荀、田志伟、何宏靖等领导对本书出版给予的关怀与支持。
技术部及兄弟部门同事提出了很多宝贵建议,感谢以下同事的支持:李想、王尧、丁明会、范东
来、刘世林、赵龙、王振宇、何耀、刘兆强、金涛、黄光虎、范从俊、许尧、张伟、邢杰、丁
永强、程柳航、何俊、唐国海、刘兴洋、苏印、刘俊杰、闫俊杰、张学锋、徐胜、吕司君、吴
德文、邹俊、何正开、刘龙均、郭羽凌、吴勇、杨熹岑、曾昌强、秦徳强、谭亚军、魏犇、席
爱龄、沈思丞、田曲、陈珊、胡馨月、申秋艳、马小思、高翔、葛相宇、唐斌、苏柏铔、魏林
玮、沈思成、韩远、夏阳、杨建蓉、孙健、蒲雪芹、何晓宁、薛双凯、张冬冬。
同样需要感谢机械工业岀版社的编辑团队,感谢他们提供的这次翻译机会。尤其需要感谢
张梦玲女土,没有她的督导和支持,本书很难如期翻译校对完毕。还要感谢出版社相关岗位的
工作人员,离开他们的支持,本书也无法很快与读者见面。
再次感谢
译者
2017年3月na dhe Gude?作者简介
Rafal Kuc是一个很有天赋的团队领袖以及软件开发人员。他现在担任 Sematext集团公司
的咨询专家及软件工程师,专注于开源技术,如 Apache Lucene、Solr、 Elasticsearch、 Hadoop
stack等。他拥有超过13年的软件研发经验,涉及领域广阔,从银行软件到电子商务产品,主
要侧重于Java平台。除此之外,他对能提高研发效率的任意工具或编程语言都抱有极高的热情。
同时他也是 solr. pl网站的创始人之一,该网站致力于帮助人们解决Solr、 Lucene相关问题。他
还是世界范围内各种会议热邀的演讲嘉宾,之前受邀出席过 Lucene eurocon、 Berlin Buzzwords、
Apache Con、 Lucene revolution、 DevOps Days等会议。
早在2002年Rafa就接触到 Lucene,一开始他并不喜欢这个开源产品,然而在2003年,当
他再次使用 Lucene时,他改变了自己的看法,并看到了搜索技术的巨大潜力。随后Solr诞生
了。Rafa于2010年开始使用 Elasticsearch。Rafa目前主要着眼于 Lucene、Solr、 Elasticsearch
和信息检索等方面的研究。
Rafa是《Solr3.1 Cookbook》一书及其后续版本《Solr40Co0 book》以及再版作品《Solr
Cookbook, Third Edition》的作者。他也是《 Elasticsearch Server》第1版和第2版、《 Mastering
Elasticsearch》第1版的作者,这些书均由 Packt Publishing出版。
随着 Elasticsearch的快速发展,我和 Marek考虑针对本书第1版做一次更新。这本
书并不适合所有读者,不过在第1版中我们没有做出足够的强调。我们把本书第1版作为
《 Elasticsearch Server》的升级版。本书第1版的定位也是如此:此刻你手捧的这本书是对
《 Elasticsearch Server, Second edition》的扩展和续作。正因为如此,本书可以聚焦在一些高级
主题上,比如如何选择恰当的查询方式、如何扩展 Elasticsearch、大量的评分细节和示例、过
滤器内部机制、新增的聚集器、不同文档关系处理方式的优劣对比,等等。期望在读完本书后,
读者能够更好地理解 Elasticsearch和 Apache Lucene底层架构的各种细节,这将有助于他们更方
便快捷地获取所需知识。
在此,我想感谢我的家庭,当我在电脑屏幕前全身心投入本书写作的那些日日夜夜里,他
们表现出极大的耐心,是我最坚强的后盾。同样也要感谢 Sematext所有的同事们,尤其是Otis,感谢他为我付出的时间,并让我深刻
认识到 Sematext是一个非常适合我的公司。
最后,非常诚挚地感谢 Elasticsearch、 Lucene项目的所有创建者和开发者,感谢他们杰出
的工作和对开源项目的热情。没有他们,就没有本书的诞生;没有他们,开源搜索引擎就不会
有现在的这种活力。
再次感谢你们
Rafal Kuc
Marek Rogozinski是一个有着超过10年经验的软件架构师和咨询师。其技术专长涉及基
于开源搜索引擎(如Solr、 Elasticsearch等)的解决方案及大数据分析技术( Hadoop、 HBase、
Twitter Storm等)。
他也是 solr. pl网站的联合创始人之一,该网站致力于提供Solr和 Lucene相关资讯和教
程。他同时也是 Packt Publishing出版的《 Elasticsearch server》第1版和第2版、《 Mastering
Elasticsearch》第1版的作者之一。
目前,他是 Zen card公司的首席技术官和主架构师。 Zen card公司提供实时处理和分析大
规模交易事务的相关工具,可自动化、匿名识别所有零售渠道(移动电子商务、电子商务、实体
店)的零售客户,给零售商提供客户留存和忠诚度运营的工具。
这已经是我们完成的第4本关于 Elasticsearch的书了。在编写本书时,我一再沉醉于
Elasticsearch的快速进化。我们一直在被标记为“试验中”和“正在开发中”的各种特性之间
求取平衡,也不得不冒着最终代码变更,甚至某些有趣的功能被废弃的风险写作相关内容。本
书第2版重写了很多内容,并引入不少 Elasticsearch的新特性。不过,这些更新也是有代价
的:我们剔除了一些对读者来说不是那么重要的信息。在本书中,我们还试图为读者介绍
些 Elasticsearch相关的扩展主题。不过请注意, Elasticsearch的完整生态系统和ELK开发栈
( Elasticsearch、 Logstash和 Kiana)或者 Hadoop集成,都需要精心撰写单独的书籍加以介绍
现在,致谢时间到了。
感谢 Elasticsearch、 Lucene及所有相关产品的创造者们。
同时也要感谢本书的出版团队。尤其是感谢帮助检查错误、校稿、消除表达歧义的伙伴们
非常感谢给我们留言评论和提出建设性意见的读者们。发现有人认可我们的工作令我感到非常
惊喜,并深受鼓舞。谢谢你们!
最后,感谢所有支持我和理解我写作的朋友们。
Marek rogozinski
e《 Mastering Elasticsearch》的中文版《深入理解 Elasticsearch》已由机械工业出版社出版,书号为978-7
112416-8,本书为《 Mastering Elasticsearch, Second edition》的中文版。—编辑注ut the davian?评审者简介
Huseyin Akdogan的软件职业生涯起源于 GwBasic编程语言。他先后掌握了 Quick Basic和
Visual basic语言,并用VB开发了许多应用程序。2000年,他迈入了Web和PHP的世界,后
来又穿插使用Java语言进行开发。从2005年起,他一边进行咨询和培训活动,一边继续使
用 Java ee技术开发企业应用程序。他擅长 JavaServer faces、 Spring Frameworks,以及诸如
NOSQL和 Elasticsearch等大数据技术。除此之外,他还在钻研其他大数据相关技术。
Julien Duponchelle是一位毕业于欧洲理工学院的法国工程师。他致力于开发提升IT团队工
作效率的各种工具,并在其职业生涯中贡献了多个开源软件项目。
自从他加入ETNA(一个法国IT职业教育学校)开始涉足教育领域起, Julien以首席支持工
程师的身份协助过好几个创业公司进行工作,并参与了多个重大项目的募资活动,包括Pixy和
Youboox。
感谢我的女友 Mailing,感谢她在我评审本书和开发其他开源项目的无数个夜晚的善意支持
和极大的耐心。
Julien Duponchelle
Marcelo ochoa现任教于阿根廷布宜诺斯艾利斯省中部国立大学精确科学与自然科学学院的
系统实验室,也是 Scots,com公司的CTO,该公司致力于提供基于Solr和 Oracle的准实时搜索
解决方案。在高校任职的同时,他也参与一些与 Oracle、大数据相关的外部项目。他参与过的
Oracle相关项目有 Oracle手册文档翻译、多媒体培训等。其技术背景涉及数据库、网络、Web、
Java等。在XML领域,他参与过 Apache Cocoon中的 DB Generator,开源项目 DBPrism、
DBPrism cms,基于 Oracle JVM Directory的 Lucene-Oracle集成方案, Restlet. org项目中的
Oracle XDB Restlet Adapter(一个能在基于数据库驻存的JVM内部生成本地 REST Web服务的
解决方案)等项目或模块的开发,并因此为业界所熟知。
从2006年开始,他参与了 Oracle ace计划,这是 Oracle公司官方推出的一个计划,旨
在认可和奖励 Oracle技术社区中技术娴熟并愿意分享他们的知识、经验的成员为该社区所做VIl
的贡献。
Marcelo ochoa还是《 Oracle Database Programming Using Java and Web Services》( Kuassi
Mensah,由 Digital Press出版)和《 Professional Xml databases》( Kevin williams,由Wrox
Press i出版)两书的合著者,同时也是 Packt出版社的多部书籍,如《 Apache Solr4 Cookbook》
《 Elasticsearch server》等的评审者。欢迎来到 Elasticsearch的世界并阅读本书第2版。通过阅读本书,我们将带领你接触
与 Elasticsearch紧密相关的各种话题。请注意,本书不是为初学者写的。笔者将本书作为
Elasticsearch Server, Second edition》的续作和姊妹篇。相对于《 Elasticsearch server》,本书
涵盖了很多新知识,不过你偶尔也可以在本书中发现一些引自《 Elasticsearch Server》的内容。
本书将探讨与 Elasticsearch和 Lucene相关的多个不同主题。首先,我们以介绍 Lucene和
Elasticsearch的基本概念作为开始,带领读者认识 Elasticsearch提供的众多查询方式。在这里,
将涉及和查询相关的不同主题,比如结果过滤以及如何为特定场景选择合适的查询方式。显然
Elasticsearch不仅仅只有查询功能。因此,本书还将介绍 Elasticsearch新加入的聚集功能,以及
众多能够赋予被索引数据意义的特性,并设法提供更佳的用户查询体验。
对大多数用户来说,查询和数据分析是 Elasticsearch最吸引人的部分,不过这些还不是我
们想要探索的全部内容。因此,本书在涉及索引架构时还会试图跟读者探讨一些额外话题,比
如如何选择合适的分片数和副本数,如何调整分片分配行为等。当谈论 Elasticsearch和 Lucene
之间的关系时,我们还将介绍不同的打分算法、算法之间的差异、如何选择合适的存储机制,
以及为什么需要做此选择。
最后,我们还将触及 Elasticsearch的管理功能,将探讨发现和恢复模块,以及对人类友好
的 Cat APlo Cat API可以帮助我们快速获取相关的运维信息,它的返回数据组织成一种大多数
人都易于阅读的格式,无需进行JSON解析。我们还将认识和使用部落节点,它能够为我们提供
在多个节点间联合查询的能力。
因为本书的书名,我们无法忽略与性能相关的话题,所以我们决定用整整一章来探讨性能。
我们谈论了文档取值及其相关改进,还介绍了垃圾回收器的工作方式,以及在垃圾回收器未能
如我们期望般工作时可以做些什么。最后,探讨了如何扩展 Elasticsearch以应对高索引量和查
询量的场景。
和本书第1版一样,我们决定以开发 Elasticsearch插件的话题作为本书结尾。我们将展示
如何构建 Apache Maven项目,并开发两个不同类型的插件——自定义REST操作插件和自定义分析插件。
假如你在读完某些主题后对其产生浓厚的兴趣,那么这本书就是适合你的。希望你在读完
后能够喜欢这本书。
本书主要内容
第1章先介绍 Apache Lucene的工作方式,再介绍 Elasticsearch的基本概念,并演示
Elasticsearch内部是如何工作的。
第2章描述 Lucene评分过程,为什么要进行查询改写,什么是查询模板以及如何使用查询
模板。除此之外,还介绍了过滤器的使用,以及如何为特定场景选择合适的查询方式。
第3章描述了查询二次评分、多匹配控制,并介绍了用于做查询分析的各种聚合类型。
关键词项聚合和最优词项聚合可以根据所含内容片段对文档进行归类。除此之外,还介绍
了 Elasticsearch的 parent-child文档关系处理,并提供了在 Elasticsearch中使用脚本的相
关知识。
第4章覆盖了有关用户体验提升的相关话题。本章介绍了查询建议( suggester),它能帮助
修正查询中的拼写错误并构建高效的自动完成( autocomplete)机制。除此之外,通过实际的案
例展示如何通过使用不同查询类型和 Elasticsearch的其他功能来提高查询相关性。
第5章介绍了以下技术:如何选择合适的分片及副本数,路由是如何工作的,索引分片机
制是如何工作的以及如何影响分片行为。同时介绍了什么是查询执行偏好,以及它是如何影响
查询执行的。
第6章描述如何修改 Lucene评分以及如何选择备用的评分算法。本章也介绍了
Elasticsearch的准实时搜索和索引,事务日志的使用,理解索引的段合并,以及如何调整段合并
来适应应用场景。在本章最后,还将介绍 Elasticsearch的缓存机制和请求打断器,以避免出现
内存用尽的故障
第7章介绍了什么是发现、网关、恢复模块,如何配置这些模块,以及有哪些令人心烦的疑
难点。还介绍了什么是 Cat API,如何把数据备份到各种云服务上(比如亚马逊的AWS和微软的
Azure),以及如何从云服务上恢复数据。最后还介绍了如何使用部落节点进行联盟搜索。
第8章覆盖了与 Elasticsearch性能相关的各种主题,从使用文档取值来优化字段数据
缓存的内存使用,到JVM垃圾回收器的工作原理,再到查询基准测试,最后到如何扩展
Elasticsearch以适应更高的索引量和查询量场景。
第9章通过演示如何开发你自己的REST操作插件和查询语言分析插件来介绍 Elasticsearch
的插件开发。XI
阅读本书的必备资源
本书写作时采用了 Elasticsearch的14x版本,所有的范例代码应该能在该版本下正常运
行。除此之外,读者需要一个能发送HTTP请求的命令行工具,例如curl,该工具在绝大多数操
作系统上是可用的。请记住,本书的所有范例都使用了curl。如果读者想使用其他工具,请注意
检査请求的格式,以保证你所选择的工具能正确解析它。
除此之外,为了运行第9章的范例,需要读者的机器上已安装了JDK,并且需要一个编辑
器来开发相关代码(或者类似 Eclipse的 Java IDE)。另外,还要求使用 Apache Maven进行代码
的管理与构建。
本书的目标读者
本书的目标读者是那些对 Elasticsearch基本概念已经很熟悉但是又想深入了解其本身,同
时也对 Apache Lucene、JVM垃圾收集感兴趣的 Elasticsearch用户和发烧友。除此之外,想了解
如何改进查询相关性、如何使用 Elasticsearch Java API、如何编写自定义插件的读者,也会发现
本书的趣味性和实用性。
如果你是 Elasticsearch的初学者,连查询和索引这些基本概念都不熟悉,那么你会发现本
书的绝大多数章节难以理解,因为这些内容假定读者已经有相关背景知识。如果是这种情况,
建议参考 Packt出版社出版的另一本关于 Elasticsearch的图书—《 Elasticsearch Server, Second
Edition》。
读者反馈
欢迎读者的任何反馈。请让我们知道你对本书的看法——喜欢或者不喜欢哪些内容。读者
的反馈对我们开发一些大众能够受益的课题是非常重要的。
般性的反馈可直接发送emai至feedback@apacktpub.com,请在邮件标题中提及相关书名。
如果你觉得自己在某个话题上有专长,并有兴趣撰写一本书或做一些贡献,请浏览www
packtpub. com/ authors上的作者指南。
客户支持
现在,你已经成为 Packt图书尊贵的读者了。我们提供了各种服务来帮助你从本次购书行为
中获得最大价值。XII
范例代码下载
如果读者通过htt:packtpub.com账号购买了Packt图书,可直接在本网站下载范例
代码。如果读者在其他地方购买了 Packt图书,可登录htt:!/ ww.packtpub com/ support,并注
册账号,我们将通过e-mai发送代码给你
勘误
尽管我们已经尽了最大努力来保障图书内容的准确性,错误还是难以避免的。如果读者
发现了任何错误,不论是文字部分还是代码部分,请报告我们,我们将不胜感激。你的这种行
为能帮助其他读者免受误导,并能帮助我们提高图书后续版本的质量。发现任何错误,请登录
htp:/ vww.packtpub. com/submit-errata,选择相应的书名,单击 errata submissionform并在表单
中输入错误的详细信息。一旦所提交的错误被确认,它会被上传至我们的网站,或者被添加到
现有的勘误表里。可登录htt:/www.packtpub.com/support选择具体的书名,查看现有的勘误表。目录
译者序
21.3 Elasticsearch如何看评分
21
作者简介
214个例子
21
评审者简介
2.2查询改写
……………………24
前言
221前缀查询示例
24
222回到 Apache Lucene……
26
第1章 Elasticsearch简介
22.3查询改写的属性
28
1.1 Apache Lucene简介……12.3查询模板…
……30
1.1.1熟悉 Lucene……………………2
2.3.1引入查询模板
…31
1.1.2 Lucene的总体架构…
2.3.2 Mustache模板引擎…
33
1.13分析数据
2.3.3,把查询模板保存到文件………35
1.1.4 Lucene查询语言
5
24过滤器的使用及作用原理
……36
12何为 Elasticsearch…
24.1过滤及查询相关性……………36
1.2.1 Elasticsearch的基本概念
24.2过滤器的工作原理……………40
12.2 Elasticsearch架构背后的关键
24.3性能考量
概念……
10
2.4.4后置过滤和过滤查询·
42
1.2.3 Elasticsearch的工作流程…………10
24.5选择正确的过滤方式………44
13在线书店示例………142.5选择正确的查询方式…
………45
14小结
17
2.5.1查询方式分类
45
252使用示例…
……50
第2章查询DSL进阶…………18
26小结
……65
2.1 Apache Lucene默认评分公式解释……18
2.1何时文档被匹配上………19第3章不只是文本搜索
……66
2.1.2TFDF评分公式:…
19
3.1查询二次评分…
663.1.1什么是查询二次评分…67
4.1.3 suggester
…121
3.1.2一个查询例子……6742改善查询相关性……………142
3..3二次评分查询的结构
……67
4.2.1数据…………………………142
3.14二次评分参数
4.2.2改善相关性的探索之旅……………145
3.1.5总结……………70
43小结…
……………157
3.2多匹配控制…
159
33重要词项聚合
…78
第5章分布式索引架构
3.3.1一个例子
79
51选择合适的分片和副本数…
159
3.32选择重要词项…
81
5.1.1分片和过度分配…
…160
333多值分析
81
5.1.2一个过度分配的正面例子……16
334额外的配置
………84
51.3多分片与多索引…………161
3.3.5使用限制…………………89
5.1.4副本……………161
34文档分组…
…………89
52路由………………………………162
34.1 top hits聚合……………90
52.1分片和数据
162
34.2一个例子
…………………90
522测试路由功能
……162
3.5文档关系
……………05
523素引时使用路由
………166
3.5.1对象类型
95
524别名…
169
3.52嵌套文档
………98
52.5多个路由值
…169
3.53 parent-child关系…
5.3调整默认分片的分配行为……170
3.54其他解决方案
102
5.3.1部署意识………………171
3.6 Elasticsearch各版本中脚本的变化…102
5.3.2过滤…………
173
3.6.1脚本变迁……
02
5.3.3运行时更新分配策略………174
3.6,2 Groovy简单介绍
…103
5.34确定每个节点允许的总分片数…175
363全文检索中的脚本…………108
5.3.5确定每个物理机器允许的
3.6.4 Lucene表达式………………115
总分片数…
…175
3.7小结………………118
54查询执行偏好
…………179
小结
………………181
第4章改善用户搜索体验
…119
4.1改正用户拼写错误……………119
第6章底层索引控制…………182
4.1.1测试数据………12061改变 Apache Lucene的评分方式…182
4.1.2深入技术细节
…………121
6.1.1可用的相似度模型…………………183X
612为每字段配置相似度模型………183
7.2.2使用 Cat API……………231
6.1.3相似度模型配置…
184
7.23一些例子…………………232
6.1.4选择默认的相似度模型
185
7.3备份………
……232
62选择适当的目录实现—— store模块…188
7.4联盟搜索………236
63准实时、提交、更新及事务日志……191
7.4.1测试用的集群……………236
63.1索引更新及更新提交
192
7.4.2建立部落节点
………237
63.2事务日志……………………193
7.43通过部落节点读取数据………238
63.3准实时读取
……19
4
7.44通过部落节点写入数据………239
64控制索引合并
………………195
7.4.5处理索引冲突
240
6.4.1选择正确的合并策略……196
7.4.6屏蔽写操作
…241
6.4.2合并策略配置……………197
7.5小结
………242
64.3调度…
199
6.5关于IO调节
200
第8章提高性能
…243
6.5.1控制IO节流
200
8.1使用 doc values来优化查询…243
6.52配置·
…200
811字段缓存存在的问题………244
66理解 Elasticsearch缓存……
202
8.12使用 doc values的例子…245
6.6.1过滤器缓存
……………………203
8.2了解垃圾回收器…………247
66.2字段数据缓存
…204
8.2.1Java内存………………248
663查询分片缓存…………212
8.2.2解决垃圾回收问题……………249
6.6.4使用 circuit breaker…………213
823在类UNX系统上避免内存
6.6.5清除缓存…………………214
交换………………………254
67小结………………………215
8.3对查询做基准测试
255
8.3.1为基准测试配置集群………256
第7章管理 Elasticsearch…216
8.3.2进行基准测试
…256
7.1发现和恢复模块…
……216
8.3.3控制运行中的基准测试
…259
7.1.1发现模块的配置
217
84热点线程
……………261
7.1.2主节点……………………218
84.1热点线程的使用说明…261
7.1.3网关和恢复模块的配置
223
842热点线程API的响应……262
7.1.4索引恢复API…………
226
8.5扩展 Elasticsearch…263
7.2使用人类友好的 Cat API………229
8.5.1垂直扩展…………………263
7.2.1基础知识…
……230
8.5.2水平扩展
…………264XVI
8.5.3在高负载的场景下使用
923执行构建过程…………………286
Elasticsearch…………………271
924引入 Maven装配插件
287
86小结
283
93创建自定义REST行为……289
93.1设定………………289
第9章开发 Elasticsearch插件…284
93.2实现细节……
89
9.1创建 Maven项目
284
94创建自定义分析插件…………295
9,2了解基本知识
285
94.1实现细节
921 Maven java项目的结构…
…285
94.2测试自定义分析插件…
……302
9,22POM的理念
2859.5小结……
…………………304篇题嚣题题
题
第1章Cy
Elasticsearch简介
我们希望读者通过阅读本书来获取和拓展关于 Elasticsearch的基本知识。假设读者已
经知道如何使用 Elasticsearch进行单次或批量索引创建,如何发送请求检索感兴趣的文档,
如何使用过滤器缩减检索返回文档的数量,以及使用切面/聚合( faceting/ aggregation)机
制来计算数据的一些统计量。不过,在接触 Elasticsearch提供的各种令人激动的功能之前,
希望读者能对 Apache Lucene有一个快速的了解,因为 Elasticsearch使用开源全文检索库
Lucene进行索引和搜索。此外,我们还希望读者能了解 Elasticsearch的一些基础概念。为
了加速我们的学习,需要牢记这些基础知识,当然,这并不难掌握。同时,我们也需要确
保读者能按 Elasticsearch所需要的那样正确地理解 Lucene。到本章结束为止,将涵盖以下
内容:
口 Apache Lucene是什么
口 Lucene的整体架构
口文本分析过程是如何实现的
日 Apache Lucene的查询语言及其使用
口 Elasticsearch的基本概念
口 Elasticsearch内部是如何通信的
1.1 Apache Lucene简介
为了全面理解E! lasticsearch的工作原理,尤其是索引和查询处理环节,对 Apache2◆深入理解 Elasticsearch
Lucene的理解显得至关重要。揭开 Elasticsearch神秘的面纱,你会发现它在内部使用
Apache Lucene创建索引,同时也使用 Apache Lucene进行搜索。在接下来的几页里,将向
读者展示 Apache lucene的基木概念,特别是那些从来没有使用过 Lucene的读者们。
1.1.1熟悉 Lucene
读者也许会好奇,为什么 Elasticsearch的创始人决定使用 Apache Lucene而不是开发
一个自己的全文检索库。对于这个问题,笔者并不是很确定,毕竟我们不是这个项目的创
始人,我们猜想是因为 Lucene的以下特点而得到了创始人的青睐:成熟,高性能,可扩
展,轻量级以及强大的功能。 Lucene内核可以创建为单个Java库文件,并且不依赖第三方
代码,用户可以使用它提供的各种所见即所得的全文检索功能进行索引和搜索操作。当然,
Lucene还有很多扩展,它们提供了各种各样的功能,例如多语言处理、拼写检查、高亮显
示等。如果不需要这些额外的特性,可以下载单个的 Lucene core库文件,直接在应用程序
中使用它。
1.12 Lucene的总体架构
尽管我们可以直接探讨 Apache Lucene架构的细节,但是有些概念还是需要提前了解
的,以便于更好地理解 Lucene的架构,它们包括
口文档( document):索引与搜索的主要数据载体,它包含一个或多个字段,存放将要
写入索引的或将从索引搜索出来的数据。
口字段(ield):文档的一个片段,它包括字段的名称和字段的内容两个部分。
口词项(term):搜索时的一个单位,代表了文本中的一个词。
词条( token):词项在字段文本中的一次出现,包括词项的文本、开始和结束的偏移
以及词条类型。
Apache Lucene将写入索引的所有信息组织为倒排索引( inverted index)的结构形式
倒排索引是一种将词项映射到文档的数据结构,它与传统的关系数据库的工作方式不同。
你可以认为倒排索引是面向词项的而不是面向文档的。我们来看看简单的倒排索引是什么
样的。例如,假设我们有一些只包含tte字段的文档,如下所示:
口 Elasticsearch server(文档1)
口 Mastering Elasticsearch(文档2)
口 Apache Solr4 Cookbook(文档3)
这些文档索引好以后,可简略地显示如下图:第1章 Elasticsearch简介◆3
词项
数量
文档
Apache
Cooking
Elasticsearch
Mastering
Servel
3
正如你所见,每个词项指向该词项所出现过的文档数。这种索引组织方式允许快速有
效的搜索操作,例如基于词项的查询。除了词项本身以外,每个词项有一个与之关联的计
数(即文档频率),该计数可以告诉 Lucene这个词项在多少个文档中出现过。
每个索引由多个段( segment)组成,每个段写入一次但是查询多次。索引期间,一个
段创建以后不再修改。例如,文档被删除以后,删除信息单独保存在一个文件中,而段本
身并没有被修改。
多个段将会在段合并( segments merge)阶段被合并在一起。或者强制执行段合并,或
者由 Lucene的内在机制决定在某个时刻执行段合并,合并后段的数量更少,但是更大。段
合并非常耗费ⅠO,合并期间有些不再使用的信息将被清理掉,例如,被删除的文档。对于
容纳相同数据的索引,段的数量更少的时候搜索速度更快。尽管如此,还是需要强调一下:
因为段合并非常耗费IO,请不要强制进行段合并,你只需要仔细配置段合并策略,剩余的
事情 Lucene会自行完成。
洼如果你想知道段由哪些文件组成以及每个文件都存储了什么信息,请参考 Apache Lucene
的官方文档:ht/ lucene.apache. org/core/4103/ ore/org/apache/lucene/codecs/lucene10pa
ckage-summary. html
更深入地了解 Lucene索引
当然,实际的 Lucene索引比前面提到的更复杂、更高深,除了词项的文档频率和出现
该词项的文档列表外,还包含其他附加信息。在这里我们会介绍一些索引中的附加信息。
了解这些信息对我们很有帮助,尽管它们只在 Lucene内部使用。
(1)norm
norm是一种与每个被索引文档相关的因子,它存储文档的归一化结果,被用于计算查
询的相关得分。norm基于索引时的文档加权值( boost)计算得出,与文档一起被索引存储。
使用norm可以让 Lucene在建立索引时考虑不同文档的权重,不过需要一些额外的磁盘空
间和内存来索引和存储norm信息。4心深入理解 Elasticsearch
(2)词项向量
词项向量( term vector)是一种针对每个文档的微型倒排索引。词项向量的每个维由词
项和出现频率结对组成,还可以包括词项的位置信息、。 Lucene和 Elasticsearch默认都禁用
词项向量索引,不过要实现某些功能,如关键词高亮等需要启用这个选项
(3)倒排项格式
随着 Lucene4.0的发布, Lucene引人了解码器架构,允许开发者控制索引文件写入磁
盘的格式,倒排项就是索引中可定制的部分之一。倒排项中可以存储字段、词项、文档、
词项位置和偏移以及载荷( payload,一个在 Lucene索引中随意存放的字节数组,可以包含
任何我们需要的信息)。针对不同的使用目的, Lucene提供了不同的倒排项格式。比如,有
一种优化后的格式是专门为高散列范围字段如唯一标识提供的。
(4)doc values
我们前面提到过, Lucene索引是一种倒排索引。不过,针对某些功能,如切面( faceting)
或聚合( aggregation),这种倒排索引架构就不是最佳选择。这类功能通常需要操作文档而
不是词项, Lucene需要把索引翻转过来构成正排索引才能完成这些功能所需要的计算。基
于这些考虑, Lucene引入了 doc values和额外的数据结构来进行分组、排序和聚合。doc
values存储字段的正排索引。 Lucene和 Elasticsearch都允许我们通过配置来指定 doc values
的存储实现方式。可选的存储实现包括基于内存的、基于硬盘的,以及二者的混合。
1.1.3分析数据
读者也许会好奇,文档中的数据是如何转化为倒排索引的?查询串又是怎么转换为可
以用于搜索的词项的?这个转换过程被称为分析( analysis)。
文本分析由分析器来执行,它建立在分词器( tokenizer)、过滤器( filter)及字符映射器
( character mapper)之上。
Lucene的分词器用来将文本切割成词条,词条是携带各种额外信息的词项,这些信息
包括:词项在原始文本中的位置,词项的长度。分词器工作的结果被称为词条流,因为这
些词条被一个接一个地推送给过滤器处理。
除了分词器,过滤器也是 Lucene分析器的组成部分。过滤器数额可选,可以为零个
一个或多个,用于处理词条流中的词条。例如,它可以移除、修改词条流中的词条,甚至
可以创造新的词条。 Lucene中有很多现成的过滤器,你也可以根据需要实现新的过滤器。
以下是一些过滤器的例子。
口小写过滤器:将所有词条转化为小写。
口 ASCII 1过滤器:移除词条中所有非ASCI字符。
口同义词过滤器:根据同义词规则,将一个词条转化为另一个词条。第1章 Elasticsearch简介◆5
口多语言词干还原过滤器:将词条的文本部分归约到它们的词根形式,即词干还原。
当分析器中有多个过滤器时,会逐个处理,理论上可以有无限多个过滤器。
过滤器可以一个接一个地被调用,因此我们可以通过逐个添加多个过滤器的方式来获
得近乎无限的分析能力。
最后我们介绍字符映射器,它用于调用分词器之前的文本预处理操作。字符映射器的
一个例子就是HTML文本的去标签处理。
索引与查询
也许读者会好奇, Lucene以及所有基于 Lucene的软件是如何控制索引及查询操
作的?在索引期, Lucene会使用你选择的分析器来处理文档中的内容,可以对不同的
字段使用不同的分析器,例如,文档的ttle字段与 description字段就可以使用不同的
分析器。
在检索时,如果你使用了某个查询分析器( query parser),那么你的查询串将会被分析。
当然,你也可以选择不分析数据。有一点需要牢记, Elasticsearch中有些查询会被分析,而
有些则不会被分析。例如,前缀查询( prefix query)不会被分析,而匹配查询( match query
会被分析。
你还应该记住,索引期与检索期的文本分析要采用同样的分析器,只有査询( query)分
词出来的词项与索引中词项能匹配上,才会返回预期的文档集。例如,如果在索引期使用
了词干还原与小写转换,那么在査询期,也应该对查询串做相同的处理,否则,查询可能
不会返回任何结果。
1.1.4 Lucene查询语言
Elasticsearch提供的一些查询类型( query type)支持 Apache Lucene的查询解析语法,
因此,我们应该深入了解 Lucene的查询语言。
1.理解基本概念
在 Lucene中,一个查询( query)通常被分割为词项与操作符。 Lucene中的词项可以是
单个的词,也可以是一个短语(用双引号括起来的一组词)。如果査询被设置为要被分析,
那么预先选定的分析器将会对查询中的所有词项进行处理。
个查询也可以包含布尔操作符。布尔操作符连接多个词项,使之构成从句( clause)
有以下这些布尔操作符。
口AND:它的含义是,文档匹配当前从句当且仅当AND操作符左右两边的词项都在
文档中出现。例如,我们想执行“ apache AND lucene”这样的查询,只有同时包含
apache”和“ lucene”这两个词项的文档才会被返回给用户。6◆深入理解 Elasticsearch
口OR:它的含义是,包含当前从句中任意词项的文档都被视为与该从句匹配。例
如,我们执行“ apache OR lucene”这样的查询,任意包含词项“ apache”或词项
“ lucene”的文档都会返回给用户。
口NOT:它的含义是,与当前从句匹配的文档必须不包含NOT操作符后面的词项。例
如,我们执行“ lucene not elasticsearch”这样的查询,只有包含词项“ lucene”且
不包含词项“ elasticsearch”的文档才会被返回给用户。
除了前面介绍的那些操作符以外,我们还可以使用以下这些操作符。
口+:它的含义是,只有包含了“+”操作符后面词项的文档才会被认为与从句匹配。
例如,我们想查找那些必须包含“ lucene”但是“ apache”可出现可不出现的文档,
可执行如下查询:“+ lucene apache
口-:它的含义是,与从句匹配的文档,不能出现“-”操作符后的词项。例如,我们
想查找那些包含了“ lucene”但是不包含“ Elasticsearch”的文档,可以执行如下查
询:“+1 lucene- elasticsearch
如果查询中没有出现前面提到过的任意操作符,那么默认使用OR操作符
除了前面介绍的内容之外,有一件事情值得一提:可以使用圆括号对从句进行分组,
以构造更复杂的从句,例如:
Elasticsearch AND (mastering oR book)
2.在字段中查询
就像 Elasticsearch的处理方式那样, Lucene中所有数据都存储在字段( field)中,而字
段又是文档的组成单位。为了实现针对某个字段的查询,用户需要提供字段名称,再加上
冒号以及将要在该字段中执行查询的从句。如果你想查询所有在“ title”字段中包含词项
“ Elasticsearch”的文档,可执行以下查询:
title: Elasticsearch
也可以在一个字段中同时使用多个从句,例如,如果你想查找所有在“ title”字段中同
时包含词项“ Elasticsearch”和短语“ mastering book”的文档,可执行如下查询:
title: (+Elasticsearch +mastering book")
当然,上面的查询也可以写成下面这种形式:
+title: Elasticsearch +title: " mastering book
3.词项修饰符
除了使用简单词项和从何的常规字段查询以外, Lucene允许用户使用修饰符( modifier)
修改传入查询对象的词项。毫无疑问,最常见的修饰符就是通配符( wildcard)。 Lucene支
持两种通配符:?和*。前者匹配任意一个字符,而后者匹配多个字符。第1章 Elasticsearch简介心7
请记住,出于对性能的考虑,通配符不能作为词项的第一个字符出现。
除通配符之外, Lucene还支持模糊( fuzzy and proximity)查询,办法是使用“~”字
符以及一个紧随其后的整数值。当使用该修饰符修饰一个词项时,意味着我们想搜索那些
包含该词项近似词项的文档(所以这种査询称为模糊査询)。~字符后的整数值确定了近
似词项与原始词项的最大编辑距离。例如,当我们执行査询 writer~2,意味着包含词项
writer和 writers的文档都可以被视为与查询匹配。
当修饰符~用于短语时,其后的整数值用于告诉 Lucene词项之间多大距离是可以接受
的。例如,我们执行如下查询:
title: " mastering Elasticsearch"
在 title字段中包含 mastering Elasticsearch的文档被视为与查询匹配,而包含 mastering
book elasticsearch的文档则被认为不匹配。而如果我们执行下面这个查询:
title:"mastering Elasticsearch"-2
则这两个文档都被认为与查询匹配。
此外,还可以使用^字符并赋以一个浮点数对词项加权( boosting),从而提高该词项的
重要程度。如果都被加权,则权重值较大的词项更重要。默认情况下词项权重为1。可以参
考2.1节进一步了解什么是权重值( boost value),以及其在文档评分中的作用。
我们也可以使用方括号和花括号来构建范围查询。例如,我们想在一个数值类型的字
段上执行一个范围查询,执行如下查询即可:
prIce:[10.00To15.00
上面查询的返回文档的 price字段的值大于等于10.00并小于等于15.00。
当然,我们也可以在字符串类型的字段上执行范围查询( range query),例如:
name: [ Adam TO Adria]
上面查询的返回文档的name字段中,包含了按字典顺序介于Adam和 Adria之间(包
括Adam和 Adria)的词项。
如果想执行范围查询同时又想排除边界值,则可使用花括号作为修饰符。例如,我们
想查找pice字段值大于等于10.00但小于15.00的文档,可使用如下查询:
prIce:[10.00T015.00}
如果想执行一边受限而另一边不做限制的范围查询,例如,查找 price字段值大于等于
10.00的文档,可使用如下查询:
price: [10.00 TO*
4.特殊字符处理
很多应用场景中,也许你想搜索某个特殊字符(这些特殊字符包括+、-、&&、‖、!、(,)、8
深入理解 Elasticsearch
旮}、口、^、"、~、*、?、∷、、),需要先使用反斜杠对这些特殊字符进行转义。例如,你
可能想搜索abc"eg这个词项,需要按如下方式处理:abcw"eg
12何为 Elasticsearch
当读者手持本书阅读时,可能已经对 Elasticsearch有所了解了,至少已经了解了它的
一些核心概念和基本用法。不过,为了全面理解该搜索引擎是如何工作的,我们最好简略
地讨论一下它。
也许你已经了解到, Elasticsearch是一个可用于构建搜索应用的成品软件(译者注:区
别于 Lucene这种中间件)。它最早由 Shay banon创建,并于2010年2月发布。之后的几
年, Elasticsearch迅速流行开来,成为其他开源和商业解决方案之外的一个重要选择。它是
下载量最多的开源项目之
1.2.1 Elasticsearch的基本概念
现在,让我们浏览一下 Elasticsearch的基本概念以及它们的特征。
1.索引
Elasticsearch将它的数据存储在一个或者多个索引( (index)中。用SQL领域的术语来类
比,索引就像数据库,可以向索引写入文档或者从索引中读取文档。就像之前说过的那样,
Elasticsearch在内部使用 Lucene将数据写入索引或从索引中检索数据。读者需要注意的是
Elasticsearch中的索引可能由一个或多个 Lucene索引构成,细节由 Elasticsearch的索引分
片( shard)、复制( replica)机制及其配置决定。
2.文档
文档( document)是 Elasticsearch世界中的主要实体(对 Lucene来说也是如此)。对于所有
使用 Elasticsearch的案例来说,它们最终都会被归结到对文档的搜索之上。文档由字段构成,
每个字段包含字段名以及一个或多个字段值(在这种情况下,该字段被称为是多值的,即文
档中有多个同名字段)。文档之间可能有各自不同的字段集合,文档并没有固定的模式或强制
的结构。这种现象看起来很眼熟(这些规则也适用于 Lucene文档)。事实上, Elasticsearch的
文档最后都被存储为 Lucene文档了。从客户端的角度来看,文档是一个JSON对象(想了解
更多关于JSON格式的细节,请参考htp:/ en. wikipedia.org/wiki/JSON)
3.类型
Elasticsearch中每个文档都有与之对应的类型(type)定义。这允许用户在一个索第1章 Elasticsearch简介9
引中存储多种文档类型,并为不同文档类型提供不同的映射。如果同SQL领域类比
Elasticsearch的类型就像一个数据库表。
4.映射
正如你在1.1节所了解到的那样,所有文档在写入索引前都将被分析。用户可以设置一
些参数,决定如何将输入文本分割为词条,哪些词条应该被过滤掉,或哪些附加处理有必
要被调用(例如移除HTML标签)。这就是映射( mapping)扮演的角色:存储分析链所需
的所有信息。虽然 Elasticsearch能根据字段值自动检测字段的类型,有时候(事实上几乎是
所有时候)用户还是想自己来配置映射,以避免出现一些令人不愉快的意外。
5.节点
单个的 Elasticsearch的服务实例被称为节点(node)。很多时候部署一个 Elasticsearch
节点就足以应付大多数简单的应用,但是考虑到容错性或者数据膨胀到单机无法应付这些
状况,也许你会更倾向于使用多节点的 Elasticsearch集群。
Elasticsearch节点可以按用途分为3类。众所周知, Elasticsearch是用来索引和查询数
据的,因此第1类节点就是数据(data)节点,用来持有数据,提供对这些数据的搜索功能
第2类节点指主( master)节点,作为监督者负责控制其他节点的工作。一个集群中只有
个主节点。第3类节点是部落( tribe)节点。部落节点是 Elasticsearch1.0版新引入的节点
类型,它可以像桥梁一样连接起多个集群,并允许我们在多个集群上执行几乎所有可以在
单集群 Elasticsearch上执行的功能。
6.集群
多个协同工作的 Elasticsearch节点的集合被称为集群( cluster)。 Elasticsearch的分布
式属性使我们可以轻松处理超过单机负载能力的数据量。同时,集群也是无间断提供服
务的一种解决方案,即便当某些节点因为宕机或者执行管理任务(例如升级)不可用时,
Elasticsearch几乎是无缝集成了集群功能。在我们看来,这是它胜过竞争对手的最主要优点
之一。在 Elasticsearch中配置一个集群是再容易不过的事了。
7.分片
正如我们之前提到的那样,集群允许系统存储的数据总量超过单机容量。为了满足这
个需求, Elasticsearch将数据散布到多个物理的 Lucene索引上去。这些 Lucene索引被称为
分片( shard),而散布这些分片的过程叫做分片处理( sharding)。 Elasticsearch会自动完成
分片处理,并且让用户看来这些分片更像是一个大索引。请记住,除了 Elasticsearch本身
自动进行分片处理外,用户为具体的应用进行参数调优也是至关重要的,因为分片的数量
在索引创建时就被配置好了,之后无法改变,除非创建一个新索引并重新索引全部数据。10◆深入理解 Elasticsearch
8.副本
分片处理允许用户推送超过单机容量的数据至 Elasticsearch集群。副本( replica)则
解决了访问压力过大时单机无法处理所有请求的问题。思路是很简单的,为每个分片创
建冗余的副本,处理查询时可以把这些副本当作最初的主分片( primary shard)使用。值
得注意的是,副本给 Elasticsearch带来了更多的安全性。如果主分片所在的节点宕机了,
Elasticsearch会自动从该分片的副本中选出一个作为新的主分片,因此不会对索引和搜索服
务产生干扰。可以在任意时间点添加或移除副本,所以一旦你有需要,可随时调整副本的
数量。
1.22 Elasticsearch架构背后的关键概念
Elasticsearch的架构遵循了一些设计理念。开发团队希望这个搜索引擎产品易于使用和
扩展,这些特征在 Elasticsearch的每个角落里都可以被看到。从架构的视角来看,有下面
这些主要特征:
口合理的默认配置,使得用户在简单安装以后能直接使用 Elasticsearch而不需要任何
额外的调优,这其中包括内置的发现(例如,字段类型检测)和自动配置功能。
口默认的分布式工作模式。每个节点总是假定自己是某个集群的一部分或将是某个集
群的一部分。
口对等架构(P2P)可以避免单点故障。节点会自动连接到集群中的其他节点,进行相
互的数据交换和监控操作。这其中就包括了索引分片的自动复制。
口容易扩充新节点至集群,不论是从数据容量的角度还是数量的角度。
口 Elasticsearch没有对索引中的数据结构强加任何限制。这允许用户调整现有的数据模
型。正如之前我们所描述的那样, Elasticsearch支持在一个索引中存在多种数据类型
允许用户调整业务模型,包括处理文档之间的关联(尽管这种功能非常有限)。
口准实时( near real time searching)搜索和版本同步( versioning)。考虑到 Elasticsearch
的分布式特性,查询延迟和节点之间临时的数据不同步是难以避免的。 Elasticsearch
尝试减少这些问题,并且提供了额外的机制用于版本同步。
1.2.3 Elasticsearch的工作流程
本节我们将探索一些关键的 Elasticsearch特性,如启动、故障检测、数据索引和査询等
1.启动过程
当 Elasticsearch节点启动时,它使用发现( discovery)模块来发现同一个集群中的其他
节点(这里的关键是配置文件中的集群名称)并与它们连接。默认情况下, Elasticsearch节第1章 Elasticsearch简介11
点会向网络中发送广播请求,以找到拥有相同集群名称的其他节点。读者可以通过下图的
描述来了解相关的处理。
Elasticsearch
Elasticsearch
节点
节点
数据库
应用
4- Elasticsearch Cluster
多播请求
Elasticsearch
多播响应
新节点
集群中有一个节点被选为主( master)节点。该节点负责集群的状态管理以及在集群拓
扑变化时做出反应,分发索引分片至集群的相应节点上去。
洼请记住,从用户的角度来看, Elasticsearch中的管理节点并不比其他节点重要,这
与其他的某些分布式系统不同(例如数据库)。在实践中,你不需要知道哪个节点
是管理节点,所有操作可以发送至任意节点, Elasticsearch内部会自行处理这些不
可思议的事情。如果有需要,任意节点可以并行发送子查询给其他节点,并合并
搜索结果,然后返回给用户。所有这些操作并不需要经过管理节点处理(请记住,
Elasticsearch是基于对等架构的)。
管理节点读取集群的状态信息,如果有必要,它会进行恢复( recovery)处理。在该阶
段,管理节点会检查有哪些索引分片,并决定哪些分片将用作主分片。此后,整个集群进
入黄色状态。
这意味着集群可以执行查询,但是系统的吞吐量以及各种可能的状况是未知的(这种状
况可以简单理解为所有的主分片已经被分配了,但是副本没有被分配)。下面的事情就是寻
找到冗余的分片用作副本。如果某个主分片的副本数过少,管理节点将决定基于某个主分
片创建分片和副本。如果一切顺利,集群将进入绿色状态(这意味着所有主分片以及副本均
已分配好)。
2.故障检测
集群正常工作时,管理节点会监控所有可用节点,检查它们是否正在工作。如果任何
节点在预定义的超时时间内不响应,则认为该节点已经断开,然后错误处理过程开始启动。
这意味着可能要在集群一分片之间重新做平衡,选择新的主节点等。对每个丢失的主分片,12◆深入理解 Elasticsearch
一个新的主分片将会从原来的主分片的副本中选出来。新分片和副本的放置策略是可配置
的,用户可以根据具体需求进行配置。更多的信息可以在第7章了解到。
为了描述故障检测( failure detection)是如何工作的,我们用一个只有3个节点的集群
作为例子,将会有一个管理节点,两个数据节点。管理节点会发送ping请求至其他节点,
然后等待响应。如果没有响应(实际上多少次ping请求无响应可以确认节点失败取决于配
置),则该节点会被从集群中移除出去。相反地,所有节点也会向主节点发送ping请求来检
查主节点是否在正常工作。节点之间的相互探测如下图所示。
png响应
Elasticsearch
Elasticsearch
主节点
ping请求
节点1
Elasticsearch
节点2
Elasticsearch集群
3.与 Elasticsearch通信
前面已经讨论过 Elasticsearch是如何构建的了,然而,对普通用户来说,最重要的部
分是如何向 Elasticsearch推送数据以及构建查询。为了提供这些功能, Elasticsearch对外公
开了一个设计精巧的API。如果我们说,基本上每个 Elasticsearch功能模块都有一个API,
这将是令人鼓舞的。这个主AP是基于REST的(REST细节请参考htt:en. wikipedia. org/
wiki/ Representational state transfer),并且在实践中能轻松整合到任意支持HTP协议的系
统中去。
Elasticsearch假设数据由URL携带或者以JSON(JSON细节请参考(htt:/en. wikipedia.
org/wiki/json)文档的形式由HTTP消息体携带。使用Java或者基于JVM语言的用户,
应该了解一下 Java API,它除了 REST API提供的所有功能以外还有内置的集群发现功能。
值得一提的是, Elasticsearch在内部也使用 Java API进行节点间通信。因此, Java aPI
提供了所有可被 REST API调用的功能。
(1)索引数据
Elasticsearch提供了多种索引数据的方式。最简单的方式是使用索引API,它允许用户
发送一个文档至特定的索引。例如,使用cur工具(curl细节请参考http://curl.haxx.se/)第1章 Elasticsearch简介◆13
可以使用如下命令创建一个文档:
curl-xputhttp://localhost:9200/blog/article/1-dimtitle":"new
version of Elastic Search released!", "tags":["announce",
"Elasticsearch","release"]'
第2种方式允许用户通过 bulk api或 udP bulk ap一次发送多个文档至集群。两者的
区别在于网络连接方式,前者使用HTTP协议,后者使用UDP协议。后者速度快,但是不
可靠。还有一种方式使用被叫作河流( river)的插件来发送数据。不过在这里我们不需要了
解这种河流插件,因为它们将在 Elasticsearch未来版本中被移除。
有一件事情需要记住,建索引操作只会发生在主分片上,而不是副本上。当一个索引
请求被发送至一个节点上时,如果该节点没有对应的主分片或者只有副本,那么这个请求
会被转发到拥有正确的主分片的节点。然后,该节点将会把索引请求群发给所有副本,等
待它们的响应(这一点可以由用户控制),最后,当特定条件具备时(比如说达到规定数目
的副本都完成了更新时)结束索引过程。
下图展示了我们刚刚探讨的索引处理过程。
主分片1主分片2
Elasticsearch节点
应用
索引请求
副本1
副本2
分片
分片
Elasticsearch节点
Elasticsearch集群
(2)查询数据
查询API占据了 Elasticsearch API的大部分。使用查询DSL(基于JSON的可用于构建
复杂查询的语言),我们可以做下面这些事情:
口使用各种查询类型,包括,简单的词项查询,短语查询,范围查询,布尔查询,模
糊查询,区间查询,通配符查询,空间查询,以及具备人类可读的打分控制功能的14心深入理解 Elasticsearch
函数查询,等等。
口组合简单查询构建复杂查询。
口文档过滤,在不影响评分的前提下抛弃那些不满足特定查询条件的文档。这一点可
以提升性能。
口查找与特定文档相似的文档。
口査找特定短语的查询建议和拼写检查。
口使用切面构建动态导航和计算各种统计量。
口使用预搜索( prospective search)和查找与指定文档匹配的 query集合。
谈到查询操作,读者应该了解一个很重要的事实:查询并不是一个简单的、单步骤的操
作。一般来说,查询分为两个阶段:分散阶段( scatter phase)和合并阶段( gather phase)
在分散阶段将查询分发到包含相关文档的多个分片中去执行查询,而在合并阶段则从众多
分片中收集返回结果,然后对它们进行合并、排序,进行后续处理,然后返回给客户端。
该机制可以由下图描述。
分散阶段
分片1
合并阶段
玛 sticsearch节点
结果
应用
查询
分片2
asticsearch节点
Elasticsearch集群
注 Elasticsearch对外提供了6个系统参数,通过使用其中之一来定制分散/合并机制。
飞薏
在本书的姐妹版《 Elasticsearch Server, Second edition》( Packt出版社)中已经讨论
过这个问题了
13在线书店示例
本书可作为《 Elasticsearch server, Second edition》一书的延续。因此,我们在这里也第1章 Elasticsearch简介心15
沿用在那本书中的案例。总的来说,假设自己正在实现和运作一个在线书店。
首先需要一个 library索引,它的映射定义如下:
ibook
index:I
Enabled": true
id
"index":"not analyze
store :yes
properties
lt author n
ype:string
"characters ":
type
string
copies":
type
ong",
ignore malformed": false
title
type
string
i ta
type
' string
"index": " not analyzed"
titler
ype":
year
type
ong
'ignore malformed": false
l availablel
"type":"boolean"
ireview l
type :"nested",
properties":
nickname l
type
stri
text
type": "string"
n stars:
ntype integer16◆深入理解 Elasticsearch
这段映射代码位于随书提供的 library. json文件。
我们将要使用的数据也可以在随书提供的 books. json文件中找到。这个文件中的文档
示例如下:
"index":I" index":"library","type":"book","id":"1"1
["title":"All Quiet on the Western Front","title:"Im Westen
nichts
Neues","author":Erich Maria Remarque","year": 1929,"characters "
["Paul
Baumer","Albert Kropp","Haie Westhus","Fredrich Muller "
u Stanislaus
Katczinsky","Tjaden"],"tags":["nove1"],"copies":1,"available":
true
section
3
I index":I"index":"library","type":"book","id":2"31
[" title:"Catch-22","author":"Joseph Heller","year:
1961,characters":
["John Yossarian", "Captain Aardvark","Chaplain Tappman","Colonel
Cathcart","Doctor Daneeka"],"tags":["novel"],"copies":6,
availablel
false, "section": 1
"index":I" index": "library ", type":"book", id:3"11
title":"The Complete Sherlock Holmes","author "Arthur Conan
Doyle","year": 1936,"characters":["Sherlock Holmes","Dr. Watson",
G
Lestrade"],"tags": [],"copies": 0,"available": false, "section":
12}
I "index": I" index":"library"," type":"book","id":4"11
("title":"Crime and punishment","title":"npecTynneHwe n
HaKa3aHMe",author":"Fyodor Dostoevsky ,"year": 1886,"characters":
["Raskolnikov","Sofia Semyonovna Marmeladova","tags":[],"copies":
l available: true
法读者可以从自已在htp:/www.packtpub.com的个人账户中下载所有已购Packt书
籍的示例代码文件。如果您从其他地方购买本书,可以访间htp://ww, packtpub
com/support进行登记,随后 Packt出版社会把文件通过e-mai发送给您。
我们需要执行如下命令来创建带以上映射的索引,并索引数据
curl -xPOST localhost: 9200/library I
curl-XPUT localhost: 9200/library/book/ mapping'-d @library. json
curl -s -XPOST ' localhost: 9200/ bulk'--data-binary @books. json第1章 Elasticsearch简介◆17
14小结
在本章中,我们了解了 Apache Lucene的一般架构,例如它的工作原理,文本分析过程
是如何完成的,如何使用 Apache lucene查询语言。此外,我们还讨论了 Elasticsearch的
些基本概念,例如它的基本架构和内部通信机制。
下一章将学习 Apache lucene的默认评分公式,什么是查询重写过程( query rewrite
process以及它是如何工作的。除此之外,还将讨论 Elasticsearch的一些功能,例如查询
模板、过滤器,以及它们影响査询性能的机制。我们将学习如何使用过滤器,并选择合适
的查询方式来完成查询工作。香4
木4幸
留题圆器
器
题额
vhei第2章
查询DSL进阶
在上一章,我们了解了什么是 Apache Lucene,它的整体架构,以及文本分析过程
是如何完成的。之后,我们还介绍了 Lucene的查询语言及其用法。除此之外,我们也
讨论了 Elasticsearch,讨论了它的架构,以及一些核心概念。在本章,我们将深入研究
Elasticsearch的查询DsL( Domain Specific Language)。在了解那些高级查询之前,我们将
先了解 Lucene评分公式的工作原理。到本章结束,将涵盖以下内容:
口 Lucene默认评分公式是如何工作的
口什么是查询重写
口什么是査询模板以及如何使用査询模板
口如何优化复杂的 Boolean查询
口复杂 Boolean查询的性能奥秘
口如何为特定场景选择合适的查询类型
21 Apache lucene默认评分公式解释
评分是 Apache Lucene查询处理过程的一个重要环节。评分是指针对给定查询计算某个
文档的scre属性的过程。什么是文档得分?它是一个刻画文档与查询匹配程度的参数。在
本节,我们将了解 Apache lucene的默认评分机制:TFDF(词频/逆文档频率)算法以及
它是如何影响文档查询结果的。了解评分公式的工作原理对构造复杂査询以及分析査询中
因子的重要性都是很有价值的。同时,掌握 Lucene评分机制的基础知识有助于我们更好地第2章查询DSL进阶◆19
优化查询来获取符合我们使用场景的结果。
2.1.1何时文档被匹配上
个文档被 Lucene返回,意味着该文档与用户提交的查询是匹配的。在这种情况
下,每个被返回文档会有一个得分。在某些场景下,所有文档的得分都一样(比如使用
constant score查询),不过一般情况下,各个文档的得分是不一样的。得分越高,文档更相
关,至少从 Apache Lucene及其评分公式的角度来看是这样的。得分还取决于匹配的文档、
查询和索引内容,因此,很显然同一个文档对不同查询的得分是不同的。读者需要注意,
同一文档在不同查询中的得分不具备可比较性,不同查询返回文档中的最高得分也不具备
可比较性。这是因为文档得分依赖多个因子,除了权重和查询本身的结构,还依赖被匹配
的词项数目、词项所在字段,以及用于查询规范化的匹配类型,如此等等。在一些比较极
端的情况下,同一个文档在相似查询中的得分非常悬殊,仅仅是因为使用了自定义得分查
询或者命中词项数的急剧变化。
现在,让我们再回到评分过程。为了计算文档得分,我们需要考虑以下这些因子。
口文档权重( document boost):索引期赋予某个文档的权重值。
口字段权重( field boost):查询期赋予某个字段的权重值。
口协调因子( coord):基于文档中词项个数的协调因子,个文档命中了查询中的词项
越多,得分越高。
口逆文档频率( inverse document frequency):一个基于词项的因子,用来告诉评分公
式该词项有多么罕见。逆文档频率越高,词项就越罕见。评分公式利用该因子,为
包含罕见词项的文档加权。
口长度范数( Length norm):每字段的基于词项个数的归一化因子(在索引期被计算并
存储在索引中)。一个字段包含的词项数越多,该因子的权重越低,这意味着 Apache
Lucene评分公式更“喜欢”包含更少词项的字段。
口词频( Term frequency):一个基于词项的因子,用来表示一个词项在某个文档中出现
了多少次。词频越高,文档得分越高。
口查询范数( Query norr):一个基于查询的归一化因子,它等于查询中词项的权重平方
和。查询范数使不同查询的得分能互相比较,尽管这种比较通常是困难和不可行的。
2.1.2TFDF评分公式
从 Lucene4.0版本起, Lucene引入了多种不同的打分公式,这一点或许你已经有所了
解了。不过,我们还是希望在此探索一下默认的TF/DF打分公式的一些细节。请记住,为
了调节查询相关性,你并不需要深入理解这个公式的来龙去脉,但是了解它的工作原理却20心深入理解 Elasticsearch
非常重要,因为这有助于简化相关度调优过程。
1. Lucene的理论评分公式
TF/DF公式的理论形式如下
v()*v(d
score(a, d)= coord(q, d)*query Boost(q)
IV(qI
LengthNorm(d)*docBoost(d)
上面的公式融合了布尔检索模型和向量空间检索模型。我们不打算在此讨论理论评分公
式,而是直接跳到实践中使用的评分公式,看看 Lucene内部是如何实现和使用评分公式的。
法关于布尔检索模型和向量空间检索模型的知识远远超出了本书的讨论范围,想了
解更多相关知识,请参考htt:!en. wikipedia. org/wiki/Standard Boolean_ model和
http://en.wikipediaorg/wiki/vectorSpaceModel
2. Lucene的实际评分公式
现在让我们看看 Lucene实际使用的评分公式:
score(a, d)= coord(a, d)*query Norm(q)
∑
(tf(t in d)*idf(t)2* boost(t)* norm(t, d))
t in q
也许你已经看到了,评分公式是一个关于查询q和文档d的函数,正如我们之前提到
的一样。有两个因子并不直接依赖查询词项,它们是 coord和 queryNorm,这两个因子与查
询词项的一个求和公式相乘。
求和公式中每个加数由以下因子连乘所得:词频,逆文档频率,词项权重,范数。范
数就是之前我们提到过的长度范数。
这个公式听起来很复杂。请别担心,你并不用记住所有的细节,你只需要意识到哪些
因素是与评分有关的即可。从前面的公式我们可以导出一些基本的规则
口越罕见的词项被匹配上,文档得分越高。 Lucene认为包含独特单词的文档比包含常
见单词的文档更重要。
口文档字段越短(包含更少的词项),文档得分越高。通常, Lucene更加重视较短的文
档,因为这些短文档更有可能和我们查询的主题高度吻合。
口权重越高(不论是索引期或是査询期赋予的权重值),文档得分越高。因为更髙的杈
重意味着特定数据(文档、词项、短语等)具有更高的重要性。
正如你所见, Lucene将最高得分赋予同时满足以下条件的文档:包含多个罕见查询
词项,词项所在字段较短(该字段索引了较少的词项)。该公式更“喜欢”包含罕见词项
的文档。第2章查询DSL进阶
21
法如果你想了解更多关于 Apache Lucene TF/IDF评分公式的信息,请参考 Apache
lucene中 TFIDFSimilarity类的文档
:http://lucene.apacheorg/core/490/core/org/
apache/lucene/search/similarities/TFID Similarity. html
2.1.3 Elasticsearch如何看评分
总而言之, Elasticsearch使用了 Lucene的评分功能,幸运的是 Elasticsearch允许我们
挑选可用的 similarity类实现,或者自定义 similarity类,来替换默认的评分算法。不过请
记住, Elasticsearch不仅仅是 Lucene的简单封装,因为它虽然使用了 Lucene的评分功能,
但不仅限于 Lucene的评分功能。
用户可以使用各种不同的查询类型,以精确控制文档评分的计算。例如使用 function
score查询时,可以通过使用脚本( scripting)来改变文档得分,也可以使用 Elasticsearch0.90
中出现的二次评分功能,通过在返回文档集之上执行另外一个查询,重新计算top-N文档
的得分。
想了解更多 Apache Lucene查询类型,请参考htp:/ ucene.apache. org/core//490/
queries/org/apache/ lucene/queries/package- - summary. html上的相关文档。
2.14一个例子
现在,我们已经了解评分的工作原理。接下来我们看一个在现实生活中应用评分的简
单例子。首先我们需要创建一个名为 scoring的新索引。使用如下命令创建这个索引
curl -XPUT'localhost: 9200/scoring'-d'
settings":i
index":i
number of shards
number of replicas":0
简单起见,我们使用了只有一个物理分片和0个副本的索引(我们不需要在这个例子中
关心分布式文档频率)。我们需要索引一个简单的文档,代码如下:
curl-XPOST 'localhost: 9200/scoring/doc/1-d I"name":"first
document"]
接着我们执行一个简单的匹配( match)查询,查询的词项是“ document”。22◆深入理解 Elasticsearch
curl-XGET localhost: 9200/scoring/ search?pretty -d
query
"match":[ "name":"document"]
Elasticsearch返回的结果如下
n took l: 1
timed out: false,
ut shards
l totall
nI successful#: 1
u failed: 0
hits
l totall: 1
" max score":0.19178301,
Whits "
l index : "scoring",
type ":"doc "
id":"1"
score":0.19178301,
source:["name": "first document "y
显然,刚才索引的这个文档被匹配上了,并且被赋予了得分。我们可以通过下面这条
命令来查看得分的计算过程
curl-xGET localhost: 9200/scoring/doc/ 1/ explain?pretty
query
matcha
{
n name" document
Elasticsearch返回的结果如下
n index": "scoring",
n type ":"doc",
" matched ": true,
"explanation":I
va1ue":0.19178301,
description": "weight(name: document in 0)
[PerFieldsimilarity], result of: r
details":
"va1ue":0.19178301,第2章查询DSL进阶◆23
"description":"fielaweight in 0, product of: "
"details":[t
I value": 1.0
"description ":"tf(freq=1. 0), with fred of:
"details":[i
It value": 1.0
"description" :"termFreg=1. 0"
}
" value":0.30685282,
"description": "idf(docFreq=l, maxDocs=l)"
" value":0.625
description":"fieldNorm(doc=O)
可以看出, Elasticsearch给出了针对给定文档和查询的详细的得分计算过程。同时
可以看出,得分等于词项频率(本例中是1)和逆文档频率(0.30685282)以及字段范数
(0.625)的乘积。
现在,我们再把另一个文档加入索引。
curl-XPOST 'localhost: 9200/scoring/doc/2-d i"name":"second
example document"]
此时,如果执行最开始的查询,我们将看到如下响应:
I took":6
l timed out: false
I shards":(
u total"
lI successfull
1
l failed": 0
whits"
li totall: 2
" max score":0.37158427
"hits":[
n index":"scoring",
n type": "doc It
n11
score l
0.37158427
"source":["name "first document")
index":"scoring",
n type":doc
a":"2
score":0.2972674,
source":("name":"second example document t24◆深入理解 Elasticsearch
现在,可以对比一下TF/IDF评分公式在现实场景中的工作了。在把第2个文档索引到
相同分片后(请记住我们创建的索引只有一个分片且没有副本),得分发生了变化,尽管此
时的查询和刚才的一样。这是因为一些影响得分的因子已经改变了。比如,逆文档频率变
了,因此得分也会跟着改变。我们还需要注意对比一下两个文档的得分。我们查询了一个
单词“ document”,查询匹配上了两个文档的相同字段的相同词项。第2个文档的得分为什
么较低,是因为和第1个文档相比,它的name字段多了一个词项。根据先前的知识储备,
我们知道,文档越短, Lucene给出的得分越高。
希望这个简短的介绍会让你对评分工作机制认识得更清楚,在你需要优化查询时理解
目标查询的工作过程
22查询改写
之前我们探讨了评分机制,这些知识非常珍贵,特别是当你尝试改进查询相关性时。
我们还认为,在对查询进行调试时,也很有必要搞清楚查询是如何执行的。因此我们决定
在本节介绍一下查询改写是如何工作的,为什么需要查询改写,以及我们应该如何控制它。
如果你之前使用过诸如前缀查询或通配符查询之类的查询类型,那么你会了解这些都
是基于多词项的查询,它们都涉及查询改写。 Elasticsearch使用查询改写是出于对性能的
考虑。从 Lucene的角度来看,所谓的査询改写操作,就是把费时的原始査询类型实例改写
成一组性能更高的査询类型实例,从而加快查询执行速度。查询改写过程对客户端不可见,
不过最好能够知道我们可以修改查询改写过程。举个例子,让我们看看 Elasticsearch是如
何处理前缀查询的。
2.2.1前缀查询示例
演示查询改写过程的最好方式莫过于通过范例深入了解该过程的内部实现机制,尤其
是要去了解原始查询中的词项是如何被改写成目标査询中那些词项的。假设我们索引了下
面这些文档中的数据:
curl-XPUT 'localhost: 9200/ clients/client/1-d
n id": l,name":"Joe "
curl-XPUT localhost: 9200/clients/client/21-d t
l id: 2, "name":"Jane第2章查询DSL进阶
25
cur1-XPUT ' localhost: 9200/clients/client/3-d '
n id:3","name": "JackI
curl-XPUT 'localhost: 9200/clients/client/4-d I
name l: Rob
现在我们想找出索引中所有name字段以字母j开头的文档。简单起见,我们在 clients
索引中执行以下查询:
curl -XGET 'localhost: 9200/clients/ search?pretty! -d
"query ": I
prefix":I
"name ":[
"prefix":"3",
Rewrite": " constant score boolean m
这里使用了一个简单的前缀查询,想检索出所有name字段以字母j开头的文档。我们
同时也设置了查询改写属性以确定执行查询改写的具体方法,不过现在我们跳过该参数,
具体的参数值将在本章的后续部分讨论。
执行前面的查询以后,我们将得到下面的结果:
n took: 2
timed out l: false
shards
cotal: 5
successful": 5
n failed" 0
whits
ttotal 3
max score: 1.0
"hits":[[
it index": "clients",
I type :client
ia":"3"
score : 1.0
source
id":"3
name :"Jack
It index: "clients
type
lclient26◆深入理解 Elasticsearch
id
score: 1.0
nid": 2 ,"name ": "Jane "
n index":"clients",
type:client
score": 1. 0
source:
id":"1,"name": "Joe"
如你所见,返回结果中有3个文档,这些文档的name字段以字母j开头。我们并没有
显式设置待查询索引的映射,因此 Elasticsearch探测出了name字段的映射,并将其设置为
字符串类型并进行文本分析。可使用下面的命令进行检查:
curl -XGET 'localhost: 9200/clients/client/ mapping?pretty i
Elasticsearch将返回类似下面的结果:
lclient n
"properties":t
d
"type:string
"name":
" type
ustring
222回到 Apache Lucene
现在我们回到 Lucene。如果你还记得 Lucene倒排索引是如何构建的,你会指出倒排索
引中包含了词项、词频以及文档指针(如果忘了,请重新阅读1.1节)。现在我们看看之前
存储到 clients索引中的数据大概是如何组织的。
Term
Count
Docs
ck
Jane
<2>
<1>
rob
<4>第2章查询DSL进阶27
Term这一列非常重要。如果我们去探究 Elasticsearch和 Lucene的内部实现,将会发现
前缀查询被改写为下面这种查询:
ConstantScore(name: jack name: jane name: joe)
我们可以用 Elasticsearch api来检查重写片段。首先,使用 Explain API执行如下命令:
curl -XGET localhost: 9200/clients/client/1/ explain?pretty -d
query
refix
l name
{
refill
rewrite":" constant sc。xebo。1ean
执行结果如下:
index" "clients
type":"client",
id
matched": true,
explanation:
u value": 1.0
description":"ConstantScore(name: joe), product of: "
details
value":1.0,
Idescripti
boost
},{
wvalue": 1.0,
"description":"queryNorm"
可以看到, Elasticsearch对name字段使用了一个词项是joe的 constant score查询。当
然,这一步发生在 Lucene中, Elasticsearch实际上只是从缓存中获取这些词项。这一点可
以用 Validate查询API来验证。
curl -XGET ' localhost: 9200/clients/client/ validate/query? explain&pretty
query l
prefix
iname h
"prefix
j",
Rewrite": "constant score boolean"28深入理解 Elasticsearch
Elasticsearch返回的结果如下:
nvalid": true
shards":I
n total: 1
n successful": 1
n failed
"explanations":[
"index":"clients",
nvalid": true
explanation":"filtered(name: ]*)->cache( type: client)"
}]
2.2.3查询改写的属性
当然,多词项查询的 rewrite属性也可以支持除了“ constant score boolean”之外的其
他取值。我们可以通过这个属性来控制查询在 Lucene内部的改写方式。我们可以将 rewrite
参数存放在代表实际查询的JSON对象中,例如,像下面的代码这样
query
"prefix":
i name
Rewrite "constant score boolean"
现在让我们来看看 rewrite参数有哪些选项可以配置。
口 scoring boolean:该选项将每个生成的词项转化为布尔查询中的一个或从句( Boolean
should clause)。这种改写方法需要针对每个文档都计算得分。因此,这种方法比较
耗费CPU(因为要计算和保存每个词项的得分),而且有些查询生成了太多的词项,
以至于超出了布尔查询默认的1024个从句的限制。默认的布尔查询限制可以通过设
置 Elasticsearch.yml文件的 index. query bool. max clause count属性来修改。用户需
谨记,改写后的布尔查询的从句数越多,查询性能越低。
口 constant score boolean:该选项与前面提到过的 scoring boolean类似,但是CPU耗
费更少,这是因为并不计算每个从句的得分,而是每个从句得到一个与查询权重相第2章查询DSL进阶29
同的一个常数得分,默认情况下等于1,我们也可以通过设置查询权重来改变这个默
认值。与 scoring boolean类似,该选项也有布尔从句数的限制。
口 constant score filter:正如 Lucene的 Javadocs描述的那样,该选项按如下方式改写
原始查询—通过顺序遍历每个词项来创建一个私有的过滤器,标记所有包含这个
词项的文档。命中的文档被赋予一个与查询权重相同的常量得分。当命中词项数或
文档数较大时,该方法比 scoring boolean和 constant score boolean执行速度更快。
口 top terms N:该选项将每个生成的词项转化为布尔查询中的一个或从句,并保存计
算出来的查询得分。与 scoring boolean不同之处在于,该方法只保留最佳的N个词
项,以避免触及布尔从句数的限制,并提升查询整体性能。
口 top terms boost N:该选项与 top terms N类似,不同之处在于它的文档得分不是
通过计算得出的,而是被设置为跟查询权重(bost)一致,默认值为1
③漆当 rewrite.性设置为 constant score auto或者没有设置时, Elasticsearch会根据查询
现在,让我们再看一个例子。如果我们想在范例查询中使用 top terms N选项,并且N
的值设置为2,那么查询看起来与下面的代码类似:
"query": i
prefix":
INane it
"prefix":""
"rewrite":"top terms 2"
从 Elasticsearch返回的结果中可以看出,和我们之前使用的查询不同,这里的文档得
分都不等于1.0。
itook l
3
l timed out l: false
shards"
"tota1":5,
I successful":5
failed":0
whits
"tota1":3,
" max score":0.30685282,
hit30◆深入理解 Elasticsearch
wt index: "clients
" type
clien
score":0.30685282
source":
nid":"3","name":"JackI
index
client s
I type":"client
id
sCOre":0.30685282
source
id:"2,"name":I Jane
inde
clients
n type":"client",
id
score:0.30685282
source
l id": 1, lname l: Joe
这是因为 top terms N需要保留得分最高的N个词项。
结束本节之前,读者应该会产生一个疑问,我们如何决定何时采用何种查询改写方
法?该问题的答案更多地取决于您的应用场景。简单来说,如果您能接受较低的精度和相
关性(但是追求更高的性能),那么可以采用top-N查询改写方法。如果您需要更高的查询
精度和更好的相关性(同时可以接受较低的性能),那么应该采用布尔方法。
23查询模板
在应用程序迭代的同时,它的运行环境很可能会越来越复杂。在你所处的组织中,很
可能同一个应用程序的不同部分分别有专人负责,比如说,至少有一个前端工程师和一个
负责数据库层的后端工程师。将应用程序划分为几个模块分别开发的方式非常便捷高效,
它能够让开发人员针对程序的不同部分并行进行开发工作,而无需在开发者之间和开发小
组内部时刻同步代码。当然,你正在阅读的这本书不是关于项目管理的,而是聚焦于搜索
的,因此让我们回到正题上。有时候,我们可以整理出程序使用的所有查询语句交给搜索
引擎工程师,让他们协助从性能和相关性两个方面对査询语句进行优化。这种做法通常是
很有帮助的。在这种情况下,应用程序开发者只需要把查询传递给 Elasticsearch,而不需要第2章查询DSL进阶31
考虑查询语句的构造、查询DSL语法、查询结果过滤等细节知识。
2.3.1引入查询模板
自 Elasticsearch 1.1.0版本开始,我们可以自定义查询模板。让我们回到本书开头的在
线书店例子中。假定我们已经确定了需要传递给 Elasticsearch的查询语句的类型,不过查
询结构并未最终确定,我们还需要对它进行微调和优化。通过使用査询模板,我们可以快
速构建出查询的基础骨架,然后让应用程序来提供对应的参数,最终由 Elasticsearch完成
查询参数的替换。
假定我们有一个针对 library索引的查询语句,可以返回最相关的书籍记录。在这个查
询中,我们还允许用户选择是否对书籍的库存状态做筛选。在这个场景中,我们需要传入
两个参数—一个查询短语和一个代表书籍库存状态的布尔变量。最初的简化示例如下:
query":
"filtered":
query:
I matchi
n all: QUERY
n filter
n term
available": BOOLEAN
代码中的 QUERY和 BOOLEAN是占位符,代表应用程序传递给查询的变量。显然这
个査询语句对当前示例场景来说实在太简陋了,不过之前我们已经说过,这只是它的最初
版本,我们马上将对它进行改进。
既然已经有了最初版本的查询语句,我们可以基于它创建第一个查询模板。对该查询
语句做简单修改如下:
template:
"query "
l filtered
query n
tch":
all":"phrase32心深入理解 Elasticsearch
filter":
ii term
"available:"avail
3)
"params ":t
phrase":front "
mavail: true
可以看出,原来的占位符被替换成了{ phrase}和{ avail}两个变量,并且添加了
个新的 params片段。当 Elasticsearch在解析查询语句时,遇到一个{ phrase}变量,它将
尝试从 params片段中查找出名为 phrase的参数,并用参数值替换掉{{ phrase}变量。通
常,我们需要把参数值放到 params片段中,并在 query中使用形如{var}的标记来引用
params片段中参数名为var的参数。此外,查询本身被嵌套进一个 template元素中。通过
这种方式,我们实现了查询的参数化。
接下来让我们使用 Http Get请求把以下查询话句发送给地址为 library/ search/template
的REST端点(注意这里不是我们通常使用的 library/ search端点)。请求命令构造如下:
curl-xGET localhost: 9200/library/ search/template ?pretty! -d If
"template":I
nquery
filtered":I
query
Hmatch":
all":"phrase]]
￡i1term:{
"term":I
m available:"Ravail]]
params":I
phrase:"front"
m avail": true第2章查询DSL进阶心33
字符串形式的查询模板
查询模板也可以以字符串的形式提供。比如,刚才的查询模板可以变成这样:
template":"I\"query\":(\"filtered\":(V
n query
"match":{\"a11":\"{{phrase})"}},\"filter\":{
"term":{、"available\":\"{{avai1}"}}}}}"
params:
phrase":"front i
mavail": true
可见,这种形式不太适合阅读和书写,每个引号都需要被转义,换行符容易引发格式
问题,因此需要避免使用。尽管如此,如果你需要使用 Mustache(一个模板引擎,我们将
在下一小节探讨),则必须使用这种格式(至少在 Elasticsearch的1.1.0到1.4.0之间的所有
版本中必须这样做)
注本书写作时,笔者所使用的 Elasticsearch相关版本中有一个关于查询模板的小陷
阱。如果你提供的查询模板中有错误,被 Elasticsearch检测到后,会把错误写到服
务日志里,但是从API的视角来看,错误查询将被忽略,接口将返回所有文档,就
好像你刚刚发送了一个 match all查询一样。记得复查你的查询模板,直到这个缺
陷不再存在。
2.3.2 Mustache模板引擎
Elasticsearch使用Mustache模板引擎(参考http://mustache.github.io)来为查询模板
生成可用的查询语句。如你所见,每个变量被双大括号包裹,这一点是 Mustache规范要
求的,是该模板引擎间接引用变量的方式。 Mustache模板引擎的完整语法不在本书讨论
范围内,不过我们可以在这里简单介绍一下它最具魅力的部分,包括条件表达式、循环和
默认值。
Mustache语法的详细内容请参阅htp:/ mustache. github. io/mustache.hmn
1.条件表达式
val}表达式用来插入变量vl的值。{{#val}和{{/val}}则用来在变量val取值计
算为true时把位于它们之间的变量标记替换为变量值。
我们看一下下面这个示例:34◆深入理解 Elasticsearch
curl-XGET localhost: 9200/library/ search/template?pretty -d .i
template":" I #limit]\"size\":2 /limit]]
"params": I
m1im⊥t":fa1ge
这个命令将返回 library索引中的所有文档。不过,假如我们把 limit参数的取值改为
true,则再次查询后,我们将只能得到两个文档。这是因为判断条件满足了,模板内容因此
被激活。
注不幸的是,似乎直到本书写作时,笔者所使用的 Elasticsearch版本在处理条件表达
意
式时仍然有些问题。比如,其中一个相关问题可以在这里看到https://github.com
Elasticsearch/ Elasticsearch/issues/8308。我们决定保留条件表达式这一小节,以期
望相关问题都能在未来得到解决。使用条件表达式可以更方便地构造査询模板。
2.循环
循环结构定义和条件表达式一模一样,都位于{{#va}和{{val}}之间。如果表达式
中变量取值是数组,则可以使用{{}标记来指代当前变量值。
例如,假定我们需要模板引擎遍历一个词项数组来生成一个词项查询,可以执行如下
命令:
curl-xGET.localhost: 9200/library/ search/template?pretty' -d 'I
a template":
query
"terms":t
七主t1e":
"[[#tit1e}}",
"{.}}",
"{{/tit1e}}
parans:
title":["front""crime"]第2章查询DSL进阶35
3.默认值
默认值标记允许我们在参数未定义时给它设置默认取值。比如,给var变量设置默认值
语法的代码如下:
()]ivar))default value((/var)
举个例子,假定我们要给查询模板中的 phrase参数设置默认值“ crime”,可以使用如
下命令
curl-XGET 'localhost: 9200/library/ search/template?pretty
n template"
query:
term
title":"phrase]i[ phrase]]crime[[/phrase]]
params
phrase":"fr。ntn
这个命令将从 Elasticsearch查询出所有tte字段中包含 front的文档。而如果我们在
params片段中不指定 phrase参数的值,则使用 crime来代替。
23.3把查询模板保存到文件
抛开之前定义模板的方式不说,我们距离把查询跟应用程序解耦还有相当长的一段
路要走。我们能够做的仅仅是把查询语句参数化,而整个査询模板字符串仍然需要保
存在应用程序中。幸运的是,有一种简单的方法来改变目前这种查询定义方式,它允许
Elasticsearch从 config/ scripts目录中动态读取查询模板。
举例来说,让我们创建一个名为 book List. mustache的文件(在 config/ scripts目录中)。
使用如下命令
query:(
filtered"
query
"match":(
"_a11":"{{ phrase}}
filter: I
"term":I
"available":"avail)36◆深入理解 Elasticsearch
接下来我们就可以在査询中用模板名称来使用该文件的内容了(模板名称就是模板文件
名称去掉 mustache后缀)。例如,如果我们使用 book list模板,则可以使用如下命令
curl-xGET localhost:9200/library/ search/template?pretty -d
template":"bookList",
params":[
" phrase":"front",
nava⊥1:txue
洼 Elasticsearch有一个非常灰便的特性:它可以无需重启就检测到模板文件的变更
当然,我们还是需要在每个负责查询的 Elasticsearch节点上部署查询模板文件。从
Elasticsearch1.4.0版本开始,你可以把模板索引到一个名为, scripts的特殊索引中。
更多相关信息请参考Elasticsearch的官方文档http://www.Elasticsearch.org/guide
en/Elasticsearch/reference/current/search-template html
24过滤器的使用及作用原理
接下来,我们一起认识一下 Elasticsearch提供的过滤功能。初看起来,过滤好像一个
多余的功能,因为几乎每个过滤器在 Elasticsearch查询DSL中都以一个与查询代码极其相
似的方式呈现的。不过,这些过滤器一定有其独到之处,不然它们就不会在查询性能优化
时被广泛使用和推荐了。本节我们将着重探讨为什么过滤器如此重要,它们的工作原理
以及 Elasticsearch都提供了哪些过滤器给我们使用
24.1过滤及查询相关性
普通查询和过滤的第一个差异在于它们对文档打分的影响。让我们举例对比一下查询
和过滤的输出。首先执行如下查询
curl-xget"http://127.0.0.1:9200/library/search?pretty"-d'
nquery": I第2章查询DSL进阶◆37
n term
title"
value": # Front
这个查询的结果如下:
took:1
timed out": false,
shards
I totall
5
f successful: 5
l failed": 0
hits
totall
1
" max score":0.11506981
Shits": D
s index ":"library
typ
l book
id
1
score":0.11506981
source":"title":"All Quiet on the Western
Front", "title":"Im Westen nichts Neues","author "Erich
Maria Remarque","year": 1929,"characters":[Paul Baumer",
Albert Kropp","Haie Westhus", "Fredrich Mulleri
stanislaus Katczinsky ","Tjaden"], "tags"
["novel"],"copies": 1,
"available":true, " section":31
这个查询没有任何特异之处。 Elasticsearch将返回所有在ttl字段中包含“font”的
文档。需要指出的是,每个和查询匹配的文档都会被计算得分,其中得分最高的一组文档
被作为查询结果返回给用户。在本例中,该查询返回了一篇得分为0.11506981的文档。以
上这些就是查询的一般行为。
接着我们来对比一下查询和过滤。在一个同时包含查询和过滤的例子中,我们将加入
段代码片段,限制返回文档只能有一个副本( copies字段取值为1)。不使用过滤的查询
方式如下:
curl-xget"http://127.0.0.1:9200/library/search?pretty-d'
iquery38◆深入理解 Elasticsearch
bool m:
n must
nterm"
{
n七it1e
nvalue": front"
a term":I
c。pieB":{
nvalue: I
Elasticsearch返回的查询结果和上一个查询非常相似:
took: 1
Timed out ": false,
n shards
"tota1":5,
l successful: 5
l failed
"hits":i
totall: 1
" max score":0.98976034,
whits":
index":"library r
l type ":"book "
id
" score":0.98976034,
source""title":"All Quiet on the Western
Front title": "Im Westen nichts Neues","author: Erich
Maria Remarque","year": 1929,"characters":["Paul Baumer
"Albert Kropp", "Haie Westhus","Fredrich Muller",
"Stanislaus Katczinsky " "Tjaden"],"tags":
["novel"],"copies": 1,
"available": true,"section": 31第2章查询DL进阶☆39
上面这段査询代码中的bool査询由两个tem查询构成,每个结果文档都需要同时
匹配这两个term查询。这个查询返回了和上一查询相同的文档,不过文档得分变成了
0.98976034。这和我们读完2.1节后的期望一致:每个词项都会影响得分。
接下来我们来看看使用过滤的查询方式,在 titile字段匹配“ front”的查询,同时针对
copies字段进行过滤。
curl-xget"http://127.0.0.1:9200/library/search?pretty"-d'
query
term"
title"
nvalue": front"
post filter":
nterm":[
"c。pieg":{
lvalue": 1
现在,我们构造好了一个term查询,同时还添加了一个term过滤器。从下面的返回代
码中可以看出,输出的文档和不使用过滤时一样,不过文档得分发生了变化。
n took l: 1
n timed out: false
hards
"tota1":5,
I successfulll: 5
n failed: 0
whits i
"tota1":1,
max score":0.11506981,
"hits":[
index ":"library
type ":"book",
d
score":0.11506981,
l source":"title":"All Quiet on the Western
Front, title": Im Westen nichts Neues authorl: Erich深入理解 Elasticsearch
Maria Remarque"," year": 1929, "characters": ["Paul Baumer "
Albert Kropp","Haie Westhus","Fredrich Muller i
"Stanislaus Katczinsky "Tjaden"],"tags":
["novel"l,"copies": 1,
"available":true, "section":3 1
这个文档的得分为0.1506981,这和本节最开始的査询结果一模一样。通过得分对比
我们得出结论:过滤不影响文档得分。
注旧版 Elasticsearch使用“ filter”而不是上述代码中的“ post filter”来标识查询语
句中的过滤片段。在1x版本中,这两种标记方式都可以正常使用,不过请注意,
filter”方式可能将在之后的版本中停用。
般来说,查询和过滤在工作过程中存在一个主要的差异。过滤的唯一目的是用特定
筛选条件来缩小结果范围。而査询不仅缩小结果范围,还会影响文档的得分,这一点在强
调文档相关性时非常重要,不过需要付出一定的代价:需要额外的CPU消耗来计算文档得
分。当然,这不是查询和过滤的唯一区别。本节剩余部分将着重探讨过滤器的工作原理和
Elasticsearch提供的不同过滤方式之间的异同。
2.4.2过滤器的工作原理
前一小节我们已经提到,过滤不影响所匹配文档的得分。基于两个原因,这一点非
常重要。第1个原因是性能。针对索引中的一组文档进行过滤操作是非常简单高效的。
过滤器持有的关于文档的唯一重要信息是该文档是否匹配这个过滤器—仅仅一个标记
而已。
过滤器通过返回一个被称为 DocIdSet( org. apache. lucene search. DocIdSet)的数
据结构来提供这类匹配信息。这个数据结构的用途是为索引段提供经过滤器过滤后的
数据。它可以使用Bits接口( org. apache. lucene. util. Bits)的有关实现。Bits接口可以
随机访问过滤器中的文档信息(主要是检查索引段中的某个文档是否和该过滤器匹配)。
Bits的数据结构非常高效,因为CPU可以使用位运算来完成过滤(有一个精巧的CPU
部件用来处理这类运算,详情参考环形移位的维基百科htp:/en. wikipedia.org/wiki
Circular shift)。 DocIdSet还针对内部文档标识的有序集合提供了一个 DocIdSetiterator
迭代器给我们使用。
下表展示了这些类是如何使用Bits进行工作的。第2章查询DSL进阶心41
doc
bits get(doc)
Result
FALSE
2
FALSE
TRUE
TRUE
4
Lucene(以及 Elasticsearch)提供了 DocIdSet的多种实现来应对不同场景。不同实现的
性能各不相同。不过,选择合适的实现是 Lucene和 Elasticsearch的职责,我们一般不需要
关心这一点,除非我们要针对它们进行功能扩展
不是所有的过滤器都使用Bits结构,比如数值区间过滤器、脚本过滤器、以及基于
意她理位置的一组过滤器。这些特殊的过滤器选择把数据记录在字段缓存里,然后再
遍历所需处理的文档集合,逐个进行过滤操作。这意味着过滤器链条中的下一个过
滤器只能获取到匹配前一个过滤器的文档集合。因此,可以针对这些过滤器进行优
化,比如把最重的(译者注:匹配文档最多的,或者性能最差的)过滤器放到过滤
器链的最后去执行
布尔过滤器和与或非过滤器
我们在《 Elasticsearch server, Second edition》一书中探讨了过滤器的有关知识,在这
里只需要提醒读者注意一点:与或非过滤器不使用Bits,而布尔过滤器使用了Bits。因此,
请尽可能使用布尔过滤器。与或非过滤器一般在需要脚本过滤、地理位置过滤和数值区间
过滤时使用。还需要注意的是,如果把任何不使用Bts的过滤器嵌套在与或非过滤器中,
它们同样不会用到Bits
一般来讲,在组合使用多个处理器时,如果其中包含不使用Bits的处理器,则需要使
用与或非处理器来对它们进行组合。而如果要组合的所有处理器都使用Bits,则可以选择
使用布尔过滤器来组合它们。
2.4.3性能考量
通常,过滤器都是很快的。这一点有多种原因。首先,最重要的一点是,由过滤器所
处理的查询部分不需要计算文档得分。之前我们就提到过,打分过程与给定查询和索引中
的文档集合密切相关。42心深入理解 Elasticsearch
洼使用过滤器时需要注意一点:在 Elasticsearch1.4.0版本发布后,执行嵌套查询时
意所使用的 bitsets默认提前就加载好了。这样做的目的是使嵌套查询执行得更快,不
过可能伴随内存使用问题。可以通过设置 index. load fixed bitset filters eagerly配
置项为 false来禁用提前加载。如果需要查看固定大小 bitsets的内存占用情况可以
执行以下命令: curl -XGET‘ localhost:9200/ cluster/stats? human& pretty’,在响应
中寻找 fixed_ bit set memory in bytes属性即可。
在使用过滤器时,过滤结果不依赖于査询,因此过滤结果可以被轻易地缓存起来供后
续查询使用。值得一提的是,每个 Lucene索引段都有一个过滤结果缓存。这意味着无需在
每次 commit时重建缓存,重建操作只发生在段生成和合并时。
当然,有得必有失,过滤器也有一些不好的地方。不是所有的过滤器都可以被缓
存。考虑那些依赖于当前时间的过滤器,对它们做缓存不会有任何意义。在某些场
景下不值得做缓存,因为可能存在非常多的唯一值,缓存命中率极低,比如基于地
理位置过滤的场景。
2.44后置过滤和过滤查询
如果某人说过滤比实现相同功能的查询执行更快,这不一定是真的。的确,过滤器需要考
虑的东西更少,并且可以在后续查询中复用,不过 Lucene早就针对查询做了高度优化,以确保
査询能够高速执行,甚至在考虑文档评分的情境下。当然,如果匹配结果数量极多,过滤器
会执行得更快一些。不过,还有一些事我们没有告诉你。某些时候,在使用后置过滤(post
filter)时, Elasticsearch査询的执行速度没有我们期望的那么快。假如我们执行如下查询:
curl-xgethttp://127.0.0.1:9200/library/search?pretty!-d(
m query": I
"terms":I
title":["crime","punishment","complete","front"
post filter":[
n term"
nava⊥1abie
nvalue": true,
ache": true第2章查询DSL进阶◆43
下图展示了查询的执行过程:
Search
Terms
Term
Query
Filter
Result
Index
Collected
Filtered
Doc1
DocA
DocA
Doc
Doc2
Doc
Dock
Doc1
Doc1
Doc1
DoC
当然,针对大量数据的过滤是很有价值的。不过在本例中,我们使用现有的少量数据。
从上图可见,索引中包含4个文档。例子中的 terms查询匹配了3个文档:Doc1、Doc3和
Do4。每个匹配的文档都被计算得分并根据得分做了排序。之后, post filter开始工作。在
索引的所有文档中,它只通过了两个文档:Docl和Doc4。可以看到,一共传递给过滤器3
个文档,而只有其中的两个被作为结果输出。既然如此,还有必要对Doc3计算得分吗?本
例我们浪费了一部分CPU时间来计算一个最终不匹配的文档的得分。如果类似的文档数量
很多,这将是一个性能问题。
法本例中我们使用了term过滤器。该过滤器在 Elasticsearch1.5版本之前都是默认
缓存的。而从1.5版本开始,默认不再缓存(参考https://github.com/elasticsearch/
Elasticsearch/pull7583)。因此,我们在例子中使用term过滤器时特意使用了强制
缓存。
让我们修改一下这个查询,让文档过滤操作发生在 Scorer计算文档得分之前。修改后
的查询如下:
curl-xget'http://127.0.0.1:9200/library/search?pretty-d'i
query": I
"filtered":(
query n
n terms
title":["crime","punishment","complete","front"]44◆深入理解 Elasticsearch
n filter l
i term
m available"
wvalue": true,
cache": true
在这里我们使用了过滤査询( filtered query)。返回的查询结果和前一个查询一模一样,
不过执行过程稍微有一些变化,特别是在执行过滤操作时。下图揭示了这个查询在理论上
的执行过程:
Search
Term
Terms
Result
Filter
Query
Index
Filtered
Collected
Doc1
Doc1
Doc
DocA
Doc2
Doc
Doc
Doc
Doc1
Doc1
现在,最初的工作是由term过滤器完成的。如果这个过滤器在之前被使用过,它将从
缓存中加载,整个文档集合将被筛成只剩两个文档。最后,这两个文档仍然需要被计算得
分,不过评分模块需要做的工作少了一些。当然,本例中,查询和过滤后的文档相匹配,
不过这一点并非在所有查询场景下都满足。
从技巧上看,我们让过滤器被一个查询所包裹,让 Lucene库能够只收集被过滤通过的
结果。当然,过滤通过的结果还需要被传递给主查询做进一步处理。多亏了过滤器,打分
程序需要处理的文档数量减少了。
2.4.5选择正确的过滤方式
读了前述关于后置过滤和过滤查询的解释,你可能会在以后只考虑使用过滤查询并远第2章查询DSL进阶◆45
离后置过滤。这一规则在绝大多数情况下是正确的,不过在某些条件下,存在例外情况
经验法则告诉我们,开销最大的操作需要移动到查询处理链条的尾部。如果过滤器执行很
快,开销很小,并且易于缓存,很简单,直接选择过滤査询即可。相反,如果过滤器执行
很慢,CPU开销大,并且难于缓存(比如有大量唯一值的情况),请使用后置过滤,或者尝
试优化过滤器。优化途径包括简化过滤器和使得过滤器对缓存更友好,比如,可以降低时
间区间过滤器的时间粒度。
25选择正确的查询方式
在《 Elasticsearch server, Second edition》一书中,我们详细介绍了 Elasticsearch的查
询DSL,这一种使用JSON结构化的查询语言,可以构建极其复杂的查询语句。不过,在
那本书中我们没有探讨在不同的场合可以用到哪些查询方式,以及应该使用哪种查询方式。
对于一个在全文搜索引擎领域没有经验储备的人来说, Elasticsearch提供的查询方式显得太
多了,而且容易让人迷惑。因此我们将在本书中对这方面的知识做一些深入探讨,从而引
导读者如何选择合适的查询方式。
我们把本节内容划分为独立的两部分。第1部分试图对所有查询方式进行分类,并
告诉你在特定分类下的查询将会产生什么输出。第2部分将针对每种分类举例加以说明,
并探讨分类间的不同。请注意,本节接下来的内容不是对 Elasticsearch的查询DSL的完
整阐释,如果你需要了解查询DSL的基本知识,请参考《 Elasticsearch Server, Second
Edition》一书,或者查阅ElasticsearchI的官方文档:htp:/www.Elasticsearch.org/guide/en
Elasticsearch/reference/current/query-dsl html
251查询方式分类
当然,对查询方式进行分类是一件艰难的任务,我们也不敢打包票说在这里给出的分
类列表是唯一正确的。我们甚至可以说,如果你询问其他 Elasticsearch使用者,他们可能
会给出自己的分类方式,或者声称每个查询方式都可以被归入多个类别。有趣的是,他们
有可能是对的。我们也曾考虑过多种分类方式存在的情况,不过,最终我们认为,每个查
询方式都可以被归入以下列出的一个或多个类别中。
口基本查询:这类查询允许针对索引的一部分进行检索,其输入数据既可以分析也可
以不做分析。这类查询的一个关键特征是,不支持在其内部再嵌套其他查询。基本
查询的一个示例是term查询。
口组合查询:在这类查询中可以包含其他查询和过滤器,比如bool查询和 dismay查询。
口无分析查询:这类查询不分析输入内容,直接将它们原样传递给 Lucene term查询46◆深入理解 Elasticsearch
就是这类查询的一员
口全文检索查询:这类査询成员众多。许多査询都支持全文检索、输入内容分析、同
时很可能支持可被 Lucene识别的查询语法。比如 match查询。
口模式匹配查询:这类查询都在查询语句中支持各种通配符。比如,前缀查询可以归
入此类。
口支持相似度操作的查询:这类查询拥有一个共同的特性—支持近似词语的匹配。
这类查询的成员如 fuzzy like this、 more like this查询等。
口支持打分操作的查询:这类查询非常重要,尤其是在和全文搜索查询组合使用的场
景下。这个类别包括那些允许在查询时修改打分计算过程的查询方式。在第3章介
绍的 function score查询可以归入此类。
口位置敏感查询:这类查询允许我们使用索引中存储的词项位置信息。 span term查询
就是一个很好的例子。
口结构敏感査询:这类查询的工作基于结构数据,如父子文档结构。这个类别的一个
例子是 nested one查询
当然,我们在这里只讨论查询分类,不探讨过滤器的分类。不过,对过滤器来说,你
也可以使用相同的分类逻辑。让我们先把过滤器置之脑后。在距离阐释每种查询类别之前,
我们先简短描述一下每种查询类别的目的。
1.基本查询
在基本查询内部不可以包含其他查询,它们只有索引检索这一个用途。这类查询通常
作为其他复杂查询的一部分或者单独传递给 Elasticsearch。你可以把基本查询比作修筑大厦
的砖块,而大厦就是各种复杂查询。举个例子,如果你想匹配某个文档中的一个特定词项,
且没有其他要求,可以考虑使用基本查询。本例中, match查询就能很好地满足需求,无需
再跟其他查询组合使用。
归属于基本查询的一些查询方式举例如下:
口 match查询:一种(实际上指好几种)查询方式,适用于执行全文检索且需要对输入
进行分析的场景。一般来说,当需要分析输入内容却不需要完整 Lucene查询语法支
持时,可以使用这种査询方式。这种査询不需要进行查询语法解析,发生解析错误
的概率极低,因此特别适合接收用户输入文本的场景。
口 match all查询:这个查询匹配所有文档,常用于需要对所有索引内容进行归类处理
的场景。
口term查询:一种简单的、无需对输入进行分析的查询方式,可以查询单个词语。这
种查询方式的使用场景包括针对不分词字段进行检索,比如在我们的测试代码中检第2章查询DSL进阶心47
索tags字段。term査询还经常跟过滤器配合使用,比如在我们的测试代码中针对
category字段进行过滤操作。
简单查询分类可包括:mach, multi match, common, fuzzy like this, fuzzy like
this field, geoshape, ids, match all, query string, simple query string, range, prefix,
regexp, span term,term, terms, wildcard查询。
2.组合查询
组合查询的唯一用途是把其他查询组合在一起使用。如果说简单查询是建造高楼的砖
块,组合査询就是粘合这些砖块的水泥。我们可以把组合查询无穷嵌套,用来构建极其复
杂的查询,唯一能够阻止我们这样嵌套的障碍是性能。
组合查询的一些示例和用法如下。
口bool查询:最常用的组合查询方式之一。能够把多个查询用布尔逻辑组织在一起
可以控制查询的某个子查询部分是必须匹配、可以匹配还是不应该匹配。如果我
们要把匹配不同查询条件的查询组合在一起使用,bool查询就是一个很好的选择
Bool查询还可以用在这样的场景:我们希望结果文档的最终得分为所有子查询得分
的和。
口 dis max查询:一种非常有用的查询方式。这种查询的结果文档得分和最高权重的子
查询打分高度相关,而不是如bool查询那样对所有子查询得分进行求和。 Dis max
查询返回匹配所有子查询的文档,并通过一个简单公式计算最终得分:max(各子查
询的得分)+ tie breaker*(非最高得分子查询的得分之和)。如果你希望最高得分
子查询能够在打分过程中起决定作用, dis max查询是不二选择。
组合查询类别可包括这些查询方式:boo, boosting, constant score, dis max,
filtered, function score, has child, has parent, indices, nested, span_ first, span multi
span_first, span_multi, span_near, span_not, span or, span term, top children t ij
3.无分析查询
有一类查询不会被分析,而是直接传递给 Lucene索引。这意味着我们既不需要操心分
析过程是否如我们期望的方式执行并生成合适的词项,也不需要针对特定的不分词字段执
行查询。如果你把 Elasticsearch当作 NOSQL数据库使用,这种查询方式就比较适合你。这
类查询精确匹配传入的词语,不会使用语言分析器等工具对词语进行分词和其他处理
以下示例可帮你理解无分析查询的目的。
口term查询:即词项査询。当提及无分析查询时,最常用的无分析查询就是term查询
⊙ tie breaker参数是一个0到1之间的浮点数,取0时意为仅取最高得分子查询的得分,和不使用 dtie breaker
的 dis max查询效果相同,取1则意味着对所有匹配子查询一视同仁,等效于bool查询。——译者注48心深入理解 Elasticsearch
它可以匹配某个字段中的给定值。比如说,如果你希望匹配一个拥有特定标签(我
们示例文档中的tags字段)的文档,可以使用term查询。
口 prefix查询:即前缀查询。另一种无需分析的查询方式。前缀查询常用于自动完成功
能,用户输入一段文本,搜索系统返回所有以这个文本开头的文档。需要注意的是,
尽管前缀查询没有被分析, Elasticsearch还是对它进行了重写,以确保它能高速执行。
这类查询包括
common, ids, prefix, span term, term, terms, wildcard
查询
4.全文检索查询
当你需要构建类似 Google的查询界面时,可以使用这种查询类别。这类查询会根据索
引映射配置对输入进行分析,支持 Lucene语法和打分计算等功能。一般来说,如果查询的
部分文本来自于用户输入,则可以从全文检索查询类别中选择其一,比如 query string、
match或 simpe query string查询。
全文检索查询类别的示例和用法如下。
simle query string查询:该查询方式构建于 Lucene的 SimpleQuery Parser类(参考
http://lucene.apache.org/core/49__0/queryparser/org/apache/lucene/queryparser/simple/
SimpleQuery Parser. html,被设计为解析人类可读的查询串)之上。通常情况下,如
果你不希望在遭遇解析错误时直接失败,而是尝试给出用户期望的答案,那么这种
查询方式是不错的选择。
属于本类的查询方式包括: match, multi match, query string, simple query string查询。
5.模式匹配查询
Elasticsearch直接或间接提供了一些支持通配符的查询方式,比如通配符查询
( wildcard query)和前缀查询( prefix query)。除此之外,我们还可以使用正则表达式查询
( regexp query),这种查询能够找出内容中包含给定模式的文档
我们在之前已经展示过一个前缀查询的示例,因此在这里主要介绍一下正则表达式查
询。如果想找出其词项匹配某个固定模式的文档,正则表达式查询是唯一的选择。举个例
子,假定你的各种日志存储于 Elasticsearch中,可以使用正则表达式查询找出所有含有如
下词项的日志记录:词项以“er”前缀开头、以“ memory”结尾、中间可以有任意数量
的字符。最后,需要注意的是,所有模式匹配查询如果包含可匹配海量词项的表达式,性
能代价将十分高昂。
本类查询包括: prefix, regexp, wildcard查询。
6.支持相似度操作的查询
我们认为这类查询是一些可以根据给定词项查找近似词项或文档的查询方式的集合。第2章查询DSL进阶心49
举例来说,假定我们需要找出包含“ crimea”近似词项的文档,可以执行一个 fuzzy查询。
这类查询的另一个用途是提供类似“你是不是想找XXX”的功能。比如你希望找出文档标
题和输入文本相似的文档,可以使用 more like this查询。一般来说,你可以使用本类别下
的某个查询来查找包含和给定输入近似词项或字段的文档。
属于这个类别的查询有: fuzzy like this, fuzzy like this field,fuzy, more like
this, more like this field查询。
7.支持打分操作的查询
这是一组用于改善查询精度和相关度的查询方式。这类查询可以通过指定自定义权重
因子或提供额外处理逻辑的方式来改变文档得分。这类查询的一个很好的例子是 function
score查询。 function score查询可以让我们使用函数,从而通过数学计算的方式改变文档得
分。举个例子,如果你希望离给定地理定位点越近的文档得分越高,则 function score查询
可以帮助实现这个目的。
本类查询包括
: boosting, constant score, function score, indices查询。
8.位置敏感查询
这类查询不仅可以匹配特定词项,还能匹配词项的位置信息。 Elasticsearch提供的各
种范围查询就是这类查询的典型代表。我们还可以把 match phrase查询归入本类,因为至
少从某种程度上来说,它也需要考虑被索引词项的位置信息。如果需要找出一组和其他单
词保持一定距离的单词,比如“找出以下文档,同时包含 mastering和 Elasticsearch且这两
个单词相互临近,其后不超过距离3的位置包含 second和 edition单词”,可以使用各种范
围查询。不过,需要注意的是,这些范围査询将在未来版本的 Lucene库中将被移除,届时
Elasticsearch也不再提供支持。这是因为这些查询开销很大,需要消耗大量CPU资源才能
保证正确处理。
本类查询包括
match_phrase, span_first, span_multi, span_ near, span not, span
or, span term查询。
9.结构敏感查询
最后一类查询是结构敏感查询( structure aware query)。这类查询包括:
口 nested查询
口 has child查询
日 has parent查询
日 top children查询
一般来说,所有支持对文档结构进行检索并且不需要对文档数据进行扁平化处理的查50心深入理解 Elasticsearch
询方式都可以归入此类。如果你正在寻找一种查询方式,能够在子文档或嵌套文档中进
行查询,或查找属于给定父文档的子文档,则需要使用刚刚提及的查询方式之一。换句话
说,如果需要处理文档中的数据关系,请选择使用这类査询。不过需要注意的是,尽管
Elasticsearch可以支持一些数据关系,但它毕竞不是真正的关系数据库。
252使用示例
既然我们已经了解了各类査询方式的适用场合以及期望结果,现在可以趁热打铁,用
具体的使用示例来进一步加强对它们的认知。注意,这些例子并不能覆盖 Elasticsearch查
询的方方面面,而仅仅是对于我们通过查询获取所需信息的一些简单示例说明。
1.测试数据
为了达到本节的目的,我们给 library索引加入了两个新文档。
首先,我们需要微调一下索引映射以支持嵌套文档(本节某些例子中需要用到)。修改
映射的命令如下:
curl-xputhttp://localhost:9200/library/mapping/book'-d'
nbook h
properties:
review:
mtype":"nested",
properties":(
"nickname":i "type":"string"y
n text":["type":"string"),
nstars.
"type":"integer"y
然后,接着索引两个新文档。相关命令如下:
curl -XPOST localhost: 9200/library/book/5'-d '[
title":"The Sorrows of young Werther "
author :"Johann Wolfgang von Goethe",
ava⊥lab1e":txue
W characters": ["Werther l,
L。tte"," Albert
Fraulein von B"]
copies":第2章查询DSL进阶心51
motile: "Die Leiden des jungen Werthers",
section":4,
tags":["novel","classics"
year":1774,
review": [i"nickname":"Anna",textu : Could be good, but not
my style,"stars":3]
curl-XPOST 'localhost: 9200/library/book/6,-d '
title": "The Peasants
author :"Wladyslaw Reymont"
available":true,
Characters"
"Maciej Borna","Jankiel","Jagna Paczesiowna",
"Antek Borna
"c。piea":4
"otit1e":"ch±op主
" secti。n":4,
tags":["novel","polish","classics"]
yeax":1904,
review": [["nickname": "anonymous","textm awsome
book","stars":5),[
nickname":"Jane","text":"Great book, but
too long","stars": 4,"nickname":"Rick","text":"Why bother,
when you can find it on the internet","stars": 351
2.基本查询示例
让我们看一下使用基本查询类别的例子。
(1)查询给定范围的数据
匹配给定取值范围的文档的查询是最简单的查询方式之一。通常,这种查询作为一个
更复杂查询或过滤器的一部分而存在。举例来说,一个可以查出副本数在[1,3]区间的书籍
的查询如下所示:
curl -XGET ' localhost: 9200/library/ search?pretty
que
range" 3
copies:
gt
1te":352◆深入理解 Elasticsearch
(2)简化的多词项查询
想象一个场景,用户需要传人一组书籍标签,期望査询出匹配这些标签的书籍。还有
一个条件,如果用户给出的标签超过3个,则只要求至少75%的给定标签与索引中的书籍
匹配。通常我们可以通过bool查询去实现这个目的,不过 Elasticsearch提供了可以实现相
同目的的 terms查询。执行查询的命令如下
curl -xGET .localhost: 9200/library/ search?pretty' -d 'i
query
"terms": i
"tags": ["novel","polish","classics","criminal","newl,
minimum should match":3<75%
3.组合查询示例
现在我们看看如何使用组合查询来组合其他查询方式
(1)对匹配文档加权
最简单的示例是使用包含一个可选的加权片段的bool查询来实现对部分文档的权重提
升。举例来说,如果需要找出所有至少拥有一个副本的书籍,并对1950年后出版的书籍进
行加权,可以使用如下查询命令:
curl-XGET localhost: 9200/library/ search?pretty'-d't
"query": I
booln:
Must":
"range":t
c。pie8"
gte:
M should":
range:
year 8
"gt":1950第2章查询DSL进阶心53
(2)忽略查询的较低得分部分
我们之前提到的 dis max查询可以控制查询中较低得分部分的影响。举例来说,如果
我们期望找出所有 title字段匹配“ crime punishment”或 characters字段匹配“ raskolnikov
的文档,并在文档打分时仅考虑得分最高的查询片段,可以执行如下查询命令:
curl -XGET ' localhost: 9200/library/ search?pretty! -d
fields":[ id
score"],
quer
ndis maxI
tie breaker
0.0
queries":[
"match"
"title":"crime punishment
natch
" characters"
askolnikov
查询结果如下:
l took: 3
timed out": false
shards
total: 5
"successful: 5
failed"
hits54心深入理解 Elasticsearch
ltotal
max score":0.2169777,
"hits":[
w index": library
type":"book
a
4
sCore":0.2169777,
fields
id
我们来单独看一下查询各部分的打分。可以单独执行如下查询片段:
curl -XGET localhost: 9200/library/ search?pretty'-d't
fields": [" id","score"1
query
match"
title":"crime punishment
查询结果如下
took
lt timed out
false
u shards
ntotal: 5
l successful": 5,
n failed": 0
hits":
total
" max score":0.2169777
whits
u index": "library,
type
book
scoe":0.2169777
'fields":(
单独执行下一个查询片段的命令如下:第2章查询DSL进阶☆55
curl-xGET 'localhost: 9200/library/ search?pretty' -d i
"fields":["id"," score"]
"query":I
match"
Characters" "raskolnikov l
查询结果如下:
took
1
n timed out false
shards
l total: 5
I successful: 5
n failed": 0
shits
"tota1":1,
" max score":0.15342641
"hits":[
n index":"library ",
type":"b。ok",
4
SCOre":0.15342641
fields"
n id"
4
可以看出, dis max査询返回的文档得分等于打分最高的查询片段的得分(上面的第一
个查询片段)。这是因为我们设置 tie breaker属性为0.0。
4.无分析查询示例
让我们看看两个不使用任何分析器的查询示例。
(1)找出符合标签的结果
Elasticsearch提供的term查询是最简单的无分析查询之一。我们一般很少单独使用
term查询,而是常常将其使用在各种复合查询中。举个例子,假设我们想要查找出所有
tags字段包含“ novel”值的书籍。为了达到这个目的,需要执行如下查询命令:56
深入理解 Elasticsearch
curl -xGET localhost: 9200/library/ search?pretty -d
query
n term
"tags":"novel"
(2)在查询时高效处理停用词
Elasticsearch提供了普通的 terms查询,可以在查询时用一种高效的方式处理停用词。
它将查询词项分成两组——重要的词项和不重要词项。重要词项的出现频率较低,相反,
不重要词项的出现频率很高。 Elasticsearch首先用重要词项执行查询并计算文档得分,然后
再使用不重要词项执行查询,这时不再计算文档得分。因此查询可以变得更快。
举例来说,以下两个查询单就查询结果而言非常相似,而结果的打分却不一样。注意,
如果想清楚地看出两者打分的不同,我们需要准备大量的数据样本,并在索引时禁用停用词。
curl-XGET 'localhost: 9200/library/ search?pretty! -d t
lquery
Coon
title
query" : "the western front",
"cutoff frequency :0.1,
low freq operator:"and
第二个查询如下:
curl-xGET localhost: 9200/library/ search?pretty! -d i
query&
nmust":
term":["title":"western"]
terr
七主t1
￡ront"}
should
texm”:{"t土te":"the"}第2章查询DSL进阶心57
5.全文检索查询示例
全文检索是一个宽泛的主题,其使用场景也十分广泛。在这里我们选出两个简单场景
的查询示例加以展示。
(1)使用 Lucene查询语法
某些时候,使用 Lucene查询语法是不错的选择。我们曾在1.1.4节介绍过 Lucene查询
语法。举个例子,假如我们想找出 title字段包含“ sorrows”和“ young”词项、 author字
段包含“ von goethe”短语,并且副本数不超过5个的文档,可以执行如下查询:
curl-XGET 'localhost: 9200/library/ search?pretty'-d 'i
query":t
" query str⊥ng";{
query":"+title: sorrows +title: young +author: \"von goethe\"
cop⊥eB:{5T0*
在这个查询中,我们使用了 Lucene查询语法来传递所有匹配条件,让 Lucene通过查
询解析器来构造合适的查询。
(2)对用户查询串进行容错处理
在某些场景下,来自用户的查询可能包含错误。比如,下面这个查询:
curl-XGET 'localhost: 9200/library/ search?pretty!-d
uery string":[
"query :"+Borrows +young \"
n default field": "title
Elasticsearch将返回如下响应:
" error :"SearchPhaseExecutionException [Failed to execute phase
[query]
这意味着在构建査询时遇到了解析错误,查询无法被成功地构建出来。这也是
Elasticsearch引人 simple query string查询的原因。它使用一个可尝试处理用户输入错误的
查询解析器,并试图猜测用户的查询用意。如果用 simple query string查询来改写上面这
个例子,代码如下:58◆深入理解 Elasticsearch
curl-xGET 'localhost: 9200/library/ search?pretty -d 'I
"query": i
"simple query string":[
"query +sorrows +young \""r
fields": ["title"
如果执行这个查询,你将看到 Elasticsearch能够返回合适的文档结果,尽管查询并未
被恰当构造。
6.模式匹配查询示例
模式匹配查询的例子很多,不过在这里我们只打算展示其中两个。
(1)使用前缀查询实现自动完成功能
针对索引数据提供自动完成功能是一种常见的应用场景。如我们所知,前缀查询不会
被分析,直接工作于特定字段中被索引的词项上。因此,实际的功能依赖于索引时生成词
条的方式。举例来说,假定我们希望针对 title字段的所有词条提供自动完成功能。此时用
户输入的前缀是“wes”,符合条件的对应查询构造如下:
curl-XGET 'localhost: 9200/library/ search?pretty! -d 't
query
"pre￡ix":{
m七it1e": wes
(2)模式匹配
如果我们想匹配特定模式,而此时索引中的词条无法支持,可以尝试使用 regexp查询。
读者需要注意的是,这种查询非常昂贵,请尽量避免使用。当然,有时候我们不得不使用
它。还有一点需要注意的是, regexp查询的执行性能与所选正则表达式相关。如果你选择
了一个能够被改写成大量词项的正则表达式,执行性能将极其糟糕。
现在我们来看一下使用 regexp查询的例子。假定我们需要找出符合以下条件的文档
文档的 characters字段中包含以“wat”开头、以“n”结尾、中间有两个任意字符的词项。
为了实现这些条件,可以使用类似下面的 regexp查询命令:
curl-XGET 'localhost: 9200/library/ search?pretty! -d'i
nquery
regexp第2章查询DSL进阶◆59
n characters swat. n"
7.支持相似度操作的查询示例
让我们看两个关于如何查找近似文档和词项的简单示例。
(1)找出给定词项的近似词项
一个非常简单的例子是使用fuzy查询找出包含给定词项近似词项的文档。比如,如果
我们需要查找包含“ crimea”的近似词项的文档,可以执行如下查询命令
curl-xGET 'localhost: 9200/library/ search?pretty! -d'I
"query:
fuzzy:I
ti七1e
Wvalue": "crimea"
m fuzziness": 3,
"max expansions":50
(2)找出拥有近似字段值的文档
另一个相似度查询的案例是,根据我们在查询中提供的字段值,找出包含类似字段值的文
档。比如,我们想找出 title字段值类似“ western front battles”的书籍,可以构造如下査询
curl-XGET 'localhost: 9200/library/ search?pretty! -d 'i
query
fuzzy like this field":
titles:
like text":#western front battles"
" max query terms": 5
查询结果如下:
n took
n timed out: false60◆深入理解 Elasticsearch
nI shards"
totall :5
l successfuln: 5
n failed 0
hits":I
i total
l max score
1.0162667,
"hits":[
index
libran
type":"book
"ia":"1"
" score":1.0162667,
source":("title:"All Quiet on the Western
Front","otitle": "Im Westen nichts Neues","author: "Erich
Maria Remarque " ,"year":1929,"characters":["Paul B -umer",
"Albert Kropp","Haie Westhus","Fredrich Mller",
l Stanislaus Katczinsky","Tjaden"],"tags":
["novel"],"copies":1
"available": true, "section":3]
l index":"library,t
type":"b。。k
id
5
core":0.4375
I source":[title: " The Sorrows of Young Werther","author m
: "Johann Wolfgang von Goethe","available":
true,"characters": ["Werther","Lotte","Albert","fraulein
von B"],"copies":1,"title":"Die Leiden des jungen
Werthers","section":4,"tags":["novel",
"classics"],"year": 1774,"review: [["nickname
"Anna","text ":"Could be good, but not my style","stars":
3
从上面结果可见,有时候查询结果跟我们的期望有些出入(比如结果中第2本书的标
题)。这是因为 Elasticsearch认为它们之间有相似性。在前面这个查询中, Elasticsearch将
对所有词项执行一次模糊查询,然后为匹配的文档选择出一组最佳查分词项
8.支持打分操作的查询示例
涉及相关度, Elasticsearch提供了一些可以按需修改文档得分的查询。当然,大多数查
询方式都支持权重,可以让我们拥有更多的操作余地。接下来让我们看看两个支持打分操
作的查询示例。
(1)偏爱新书
假定我们更喜欢新出版的书籍,因此1986年出版的书籍要比1870年出版的书籍拥有
更高的得分。满足这个需求的查询命令如下:第2章查询DSL进阶心61
curl-XGET 'localhost: 9200/library/ search?pretty' -d . t
ue
n function score"
"query: i
imatch all":
"score mode":"multiply,
funct⊥ona":[
gauss":
year
"。 rigin":2014,
"sca1e":2014,
"。 REset":0,
ecay:
我们将在第3章介绍 function score查询。在这里,如果你仔细观察刚才这个查询的响
应结果,可以发现越新的书籍得分越高。
(2)对拥有某些值的书籍扣分
有时候,我们需要降低某些文档的重要性,却依然要在结果列表中输出它们。举个例
子,我们可能想要列出所有的书籍,不过要通过降低书籍得分的方式把那些当前无货的书
籍放到结果列表的末尾。我们不希望按标记是否有货的字段进行排序,因为用户有时候清
楚地知道他要找什么书,因此针对全文检索查询的结果得分是很重要的。不过,如果仅仅
想把当前无货的书籍排到结果尾部,可以执行如下查询命令:
curl -xGET .localhost: 9200/library/ search?pretty
query B
"boosting":I
positive":t
"match all":
"negative":
term:
"ava⊥ab1e:fa18e62◆◆深入理解 Elasticsearch
negative boost": 0.2
9.位置敏感查询示例
位置敏感查询允许我们匹配包含正确次序短语和词项的文档。这类查询因为资源占用
问题,不经常被使用。让我们看两个例子
(1)匹配短语
匹配短语的 match phrase查询是最简单的位置敏感查询,也是本类别中使用最多的
举例来说, title字段匹配短语“ leiden des jungen”的查询命令如下:
curl -XGET localhost: 9200/library/ search?pretty
query
"match phrase":I
wotitle":"leiden des jungen"
(2)处处可见范围查询
当然,短语查询在处理位置敏感需求时非常简便。不过,如果我们想执行一个查
询,找出符合以下条件的文档:在“de”词项后面不超过两个位置的地方包含一个“des
Jungen”短语,并且紧跟着短语后面是一个“ werthers”词项。这时候,该怎么办呢?我们
可以使用范围查询。符合这些条件的查询命令类似如下:
curl-XGET'localhost: 9200/library/ search?pretty! -d t
query n
"span near": I
"clauses":
span near
Clauses":[
"span term":I
wotitle": die"
"span near": I
clauses":[第2章查询DSL进阶☆63
"span term":t
title" des"
span term":
title": "jungen
"8。p":0,
min order" true
s⊥
n⊥ n order
.n: false
span term:
title": werthers w
"8。p":0
win order": true
注意,范围查询是不经过分析器处理的。我们可以通过查看 Explain API的响应来
确认这一点。为了看到 Explain API的响应,我们需要把刚才这个查询命令的请求体
(或者叫查询内容)发送到/ library/book/5/ explain这个REST端点。响应的有趣部分
如下
description":"weight (spanNear( [spanNear( lotitle: die,
spanNear( lotitle: des, title: jungen], 0, true)], 2, false)
otitle: werthers], 0, true) in 1) [PerFieldsimilarity], result
10.结构敏感查询示例
如果涉及嵌套文档或父子文档关系,迟早会用到结构敏感查询。让我们从下面两个例
子中看一下这类查询是如何使用的。64心深入理解 Elasticsearch
(1)返回包含某个嵌套子文档的父文档
第一个例子非常简单。假定我们要查找所有拥有4星及以上评论的书籍。相应的查询
命令如下:
curl -XGET 'localhost: 9200/library/ search?pretty! -d ' i
query
nested":I
"path":"rev⊥ew",
uery
了aee
Stars:
gte":4
33333
(2)嵌套子文档的得分影响父文档得分
假定我们要返回所有拥有评论的书籍,并且按照最高评论星级对这些书籍进行排序。
满足这些条件的查询命令如下:
curl-XGET ' localhost: 9200/library/ search?pretty' -d'i
query
nested
"path":"review",
sc。e
e mode":"max"
query B
function score": I
quer
nmatch all
sc。 re mode":"max,
"boost mode":"replace",
n field value factor m
"field":"stars",
n factor l: 1
"""none第2章查询DSL进阶◆65
26小结
在本章中,我们了解了 Apache Lucene默认的打分机制是如何运作的,探讨了查询改
写的处理过程—查询改写是如何实现的以及为什么需要查询改写。我们还认识了查询模
板的工作原理,以及它们是如何简化查询构建的。我们还一起探索了不同的查询过滤方式、
它们之间的差异,以及它们的使用时机。最后,我们把查询指派到不同的分组中,并学习
了不同分组的使用场景和具体示例。
下一章中,我们将告别全文检索,把目光投向其他查询功能上。首先我们将把知识面
拓展到二次评分功能,并具备对搜索结果前N个文档重新打分的能力。然后我们将学习如
何加载重要词项,并使用聚集功能实现文档分组。我们还将对比父子关系和嵌套文档之间
的差异,掌握方法查询的使用。最后,我们还将学习如何高效地对结果文档集进行分页。■」
题题圆题题m器
题
圈匿國
Chaire?3第3章
不只是文本搜索
在上一章中,我们着重讨论了 Elasticsearch的各种查询。本章将开始介绍默认 Apache
Lucene评分( scoring)、过滤( filtering)的工作原理,同时也将讨论在特定场合应选用何种
查询。在本章中,我们也会继续讨论 Elasticsearch的一些与查询和数据分析都相关的功能。
到本章结束时,将涵盖以下内容:
口什么是查询二次评分,如何利用它优化查询以及为某些文档重新打分
口控制 multimachine
口分析数据,从中获取有意义的词项(集)
口使用 Elasticsearch对文档分组
口使用对象、嵌套文档、 parent- child功能等处理关系类型数据时的差异
口 Elasticsearch脚本的使用,如 Groovy及 Lucene表达式等
31查询二次评分
Elasticsearch提供的关键特性中就包括了查询二次评分( query rescoring),它能改变某
个查询执行后返回文档的得分,自然而然地也能改变这些文档的排序。 Elasticsearch只使用
了一个简单的技巧,它只对返回文档中的topN进行二次评分,即只改变部分返回文档的排
序结果。这么做的理由有很多。其中一种就是基于性能方面的考虑,如评分时使用了脚本,
而脚本非常耗时,作为折中,可以仅对返回文档的一个子集进行重新打分。读者能想象得
到,二次评分使用户有很多机会定制业务逻辑。现在,让我们深入了解一下这项功能,并第3章不只是文本搜索心67
分析能从中获得什么便利。
31.1什么是查询二次评分
查询二次评分是 Elasticsearch中的一种机制,能对查询的返回文档的前若干个文档重
新打分。这意味着 Elasticsearch先取得某个查询(或 post filter短语)的命中文档的前N
个,然后执行某个公式为这些文档重新打分。以 Term Query为例,首先执行查询,得到该
查询的命中文档,然后对命中文档的前100个进行重新打分,而不是对所有的命中文档重
新打分。请记住,如果 search type为scan或 count,二次评分操作将不会被执行。这意味
着在类似案例中,二次评分功能不予考虑。
3.12一个查询例子
下面是一个简单的查询例子:
"fields": ["title","available"],
Iquery
match_all":
该査询执行后将命中所有文档。因为使用了 match all查询,所有命中文档的得分都等
于1.0。这个查询非常简单,但足以用来演示查询二次评分对检索结果的影响。
31.3二次评分查询的结构
现在,我们将使用査询二次评分的功能来改写前面的查询。改写逻辑很简单,就是将
文档得分改为文档的year字段的值。修改后的查询如下所示:
fields":["title","available"]
query":[
l match all
rescore n
"query ":
"rescore_ query":
"function score":I
query:
"match all":
"script_ score":I
"script":"doc[year'] value"68◆深入理解 Elasticsearch
③法读者请记住,如果使用Eaeh4或更老的版本,使用者带要将前面的查询
an
groo
Elastic
14.3版本之前都可以使用goy动态脚本,在版本1.2之前可使用MⅤEL脚本。
如果想通过 groovy使用动态脚本,可设置 Elasticsearch yml文件的 script. groovy
sandbox. enabled的属性为true。但是需要记住,开启该功能会有安全风险。
进一步考察前面的查询。首先要注意的是 rescore对象,该对象持有一个查询,它将对
特定査询的命中文档的得分产生影响。在我们的案例中,此影响方式非常简单,就是将文
档得分改写为文档的year字段的值。读者还要注意,如果使用curl客户端,需要对脚本值
进行转义,如 docl'year'] value应转义为doc"year"] value
法前面的例子中,在 rescore对象的内部,可以看到有一个 query对象。在本书撰写
时,只有查询对象可用。随着 Elasticsearch版本的演进,会有其他更多的选项可影
响文档得分的计算。
如果将上面的查询保存在 query]son文件中,可使用下面的命令来执行该查询:
curl localhost: 9200/library/book/ search? pretty -d @query ] son
返回结果与下面类似(请注意这里略去了响应消息的结构信息):
took
1
timed out false
n shards i
"tota1":5,
l successful": 5,
failed
"hits":
u total: 6
I' max score: 1962.0r
"hits":[
index":"library i
type ":book ",
id"
2
sCore":1962.0
fields"
title":[ "Catch-22"I
"available":[ false第3章不只是文本搜索心69
n index:"library",
"type":"b。ok",
score":1937.0,
n fields
"title":["The Complete Sherlock Holmes"],
"available":[ false I
n index":"library,
type": "book ",
id":1
score":1930.0
fields":(
"title:["All Quiet on the Western Front" 1
"available":[ true I
index":"library
type":"book
id":"6",
" score":1905.0,
u fields
"title":[ "The Peasants" 1
"available":[ true
n index": "library,
type ": "book
id":"4"
" score":1887.0,
fields
"title":[ "Crime and Punishment"]
"available":[ true
u index": "library,
n type
n book
ia":"5"
score":1775.0,
fields
title":[ The Sorrows of Young Werther"]
'available":[ true 1
如你所见, Elasticsearch执行了第一个查询,并召回了所有文档。进一步查看文档得分,
此时发现 Elasticsearch已使用第2个查询对第1个查询的前N个命中文档进行重新打分了。
最终,这些被重新打分的文档的得分为两个查询下的得分之和。
读者不难理解,如果性能需要重点注意,那么对脚本的使用需要谨慎。这就是为什么70◆◆深入理解 Elasticsearch
要在 rescore阶段使用脚本。如果第1个查询命中成千上万的文档,在此阶段对所有文档使
用脚本将会导致极其糟糕的性能。因为 rescore只对返回文档的top-N的文档进行打分,因
此极大地缓解了性能问题。
在我们的例子中,只有一个 rescore的定义,但是从 Elasticsearch 1.1)本开始,有
多个 rescore查询可用于修改返回结果的得分。因此可以构建多层次的查询来改变
返回结果的top-N文档的得分与排序,每个 rescore查询的处理结果可以作为下
个 rescore查询的输入。
现在再来看看如何对查询二次评分调优,以及有哪些可用的参数。
3.14二次评分参数
可对 rescore对象中的查询使用下面这些参数。
口 window size(默认为from、size参数之和):该参数指定了每个 shard中需要二次评
分的文档个数。
口 query weight(默认为1):第1个查询的得分将乘以该参数值,之后再与二次评分查
询得分相加
口 rescore query weight(默认为1):在与第1个查询得分相加之前,二次评分查询得
分将乘以该参数值。
换句话说,文档最终得分公式如下:
original query score query weight rescore query score
rescore query weight
选择评分模式
默认情况下,被改写的文档的得分为两个查询下的得分之和。可设置 score mode来修
改评分模式。该参数有下面这些选项。
口 total:文档得分为两个查询下的得分之和。
multiply:文档得分为两个查询下的得分之积
口avg:文档得分为两个查询下得分的平均值。
口max:文档得分为两个查询下得分之中的最大值
口min:文档得分为两个查询下得分之中的最小值。
3.1.5总结
有的时候,也许我们想干预返回结果中第1页文档的排序,使之按某种规则排序。不第3章不只是文本搜索◆71
幸的是,并不能通过二次评分功能来实现这个目的。读者可能第一时间想到了 window size
参数,而事实上该参数与返回结果的第1页并无关联,它用于指定每个 shard返回文档的个
数。此外 window_size不能小于 page size(如果 windows size的值小于 page size,则被设
置为 page size的值)。另外有件事情非常重要,二次评分并不能与排序( sorting)结合使用,
这是因为排序在重新打分之前就结束了,因此排序并不能预知文档得分的变化。
3.2多匹配控制
在 Elasticsearch1.1版本中,只能对 multi match查询做有限的控制。我们当然能设置
query要查询的字段,同样也能设置析取( disjunction)查询的最大数量(通过设置 use dis
max参数)。最后,可以通过设置权重告诉 Elasticsearch每个字段的重要程度。下面是一个
在多个字段上执行查询的范例
curl-XGET ' localhost: 9200/library/ search?pretty -d.
query:
I multi match"
" query "complete conan doyle,
"fields":["title20","author 10", "characters]
针对上面这个简单的查询,命中任意指定字段的任意文档都将被召回。除此之外,上
面查询中 title字段权重最高,其次是 author字段。
当然,我们也可以使用最大析取查询( disjunction max query
curl-XGET 'localhost: 9200/library/ search? pretty! -d'I
"query":I
I' multi match"
query:complete conan doyle",
"fields":["title20","author 10", "characters"
nuse dis max": true
最大析取査询除了对文档得分计算有影响外,其他方面作用不大。
多匹配类型
自 Elasticsearch1.1版本发布以后, use dis max属性被弃用,同时 Elasticsearch又提72◆深入理解 Elasticsearch
供了一种新属性:type。可使用该属性决定 multi match查询内部的执行方式。现在我们来
探究一下有哪些可能的方式来控制 Elasticsearch的多字段查询。
请记住, tie breaker并未被废弃,不用担心未来使用该属性时的兼容性问题。
1.best_ fields匹配
使用这种查询匹配类型( best field matching),需要将 multi match查询的type属性值
设置为 best fields查询。此时 multi match查询会为 fields字段中的每个字段生成一个查
询。这种查询匹配类型特别适合有多字段且 query文本相同的最佳匹配查询。可查看下面这
个查询范例:
curl -XGET ' localhost: 9200/library/search?pretty' - '(
g
I multi match"
query :" complete conan doyle "r
fields":["title", "author","characters"I
I type": "best fields "
ntie breaker:0.8
前面的查询有更规整的表述方式:
curl-XGET 'localhost: 9200/library/search?pretty' -d '
"query ":
"dis max":I
queries":[
"match":
title":"complete conan doyle
l match"
author:"complete conan doyle
"match":t
"characters":"complete conan doyle"第3章不只是文本搜索◆73
ntie breaker t: 0.8
观察这两个查询的返回结果,你可能会注意到下面的内容:
"took":1
timed out: false
shards":[
ttotal
5
success full: 5
failed
"hits":t
"tota1":1,
" max score":0.033352755
hits
index" libraryi
type":"book"
" score";0.033352755
source":i"title":"The Complete Sherlock
Holmes ","author":"Arthur Conan Doyle","yearim
1936,"characters": ["Sherlock Holmes ","Dr. watson","G
Lestrade " ],"tags":[],"copies":0,"available": false
n section: 12
读者不难发现,这两个查询的返回文档完全一样,文档得分也一样。读者需要注意的
是文档得分的计算方式。如果査询中 tie breaker属性被设置,则文档得分等于最佳匹配字
段得分与其他匹配字段的得分之和,只是其他被匹配上的字段得分需要乘以 tie breaker的
值。如果 tie breaker属性没有被设置,则文档得分等于最佳匹配字段的得分。
此外,值得一提的是最佳字段匹配的原理:当我们使用AND操作符或 minimum
should match属性时,会发生什么事情?答案很简单,最佳字段匹配被转换为多个 match
查询,并且 operator、 minimum should match的属性值被应用到这些被生成的 match查询
上。由于这个原因,下面的查询将不会返回任何命中文档:
curI-XGET 'localhost: 9200/library/_search? pretty! -d'
"query": i74◆深入理解 Elasticsearch
I multi match
"query "complete conan doyle
"fields":["title","author", "characters "J
"type ":"best fields".
"operator n: "and"
这是由于上面的查询被转换为下面这样了:
curl -XGET ' localhost: 9200/library/ search?pretty'-d
query:
"dis max"l:
"queries":[
l match
title i
query :"complete
conan doyle
operator:"and"
Il match"
author
query: "complete conan doyle ",
operator l and
Il match
" characters":I
query: "complete conan doyle",
operator "and"
33、3
而这个查询与 Lucence中的这个复合查询是等价的:第3章不只是文本搜索
75
(+title: complete +title: conan +title: doyle)(+author: complete
+author: conan +author: doyle)(+characters: complete
+characters: conan +characters: doyle)
事实上,索引中并没有任意文档在单个字段中包含了 complete、 conan、doye这3个
词项。还好天无绝人之路,我们可以使用 cross- fields(跨字段)匹配来实现在多个字段中命
中(不同的)词项。
2. cross fields匹配
如果期望查询中所有词项都在命中文档中出现,那么使用 cross fields匹配是非常合适
的。来回忆一下上一个查询范例,这里只是用 cross fields匹配类型替换其中了 best fields
匹配类型,如下所示
curl -XGET'localhost: 9200/library/ search?pretty ' -d 1
query
"multi match":I
query :complete conan doyle",
"fields":[ " title","author", "characters
type :"cross fields"
'operator: "and"
此时 Elasticsearch返回结果是这样的:
l took 1
timed out": false
shards
l tota
l successful: 5
n failed": 0
whits il
"tota1":1,
" max score":0.08154379
thit
index":"library
type "book"
id":"3",
score
0.08154379,
source": " title":"The Complete Sherlock
Holmes","author":"Arthur Conan Doyle", "yearn
1936,"characters": ["Sherlock Holmes","Dr. Watson",#
Lestrade"],"tags":[,copies":0,"available": false
'section": 12176心深入理解 Elasticsearch
这是因为查询被转化为如下等价的 Lucene查询:
+(title: complete author: complete characters: complete)
+(title: conan author: conan characters: conan) +(title: doyle
author: doyle characters: doyle)
此时只有命中所有词项(任意字段)的文档才被返回。当然,这是使用AND操作符时
的搜索结果,如果使用OR操作符,在任意字段中命中了至少一个词项的文档会被召回。
当使用 cross fields类型时,有件事情需要特别引起注意,就是不同字段的词项频率可
能会带来问题。 Elasticsearch对查询中涉及的多个字段中的词项频率做了平衡。简单来说
在查询涉及字段中,为每个命中词项赋予近似的权重。
3. most fields匹配
另一种可用的 multi field选项为 most fields类型。根据官方文档所述,该匹配类型用
于帮助检索那些多处包含相同文本,但是文本分析处理方式不同的文档。典型例子就是多
语言处理(多字段)。例如,我们想搜索tte或 original title字段中包含 die leiden的文档,
可执行下面这个查询:
curl -XGET .localhost: 9200/library/ search?pretty' -d'
" query
l multi match"
"query ":"Die Leiden",
fields" :["title","title"]
"type":"most fields
在 Elasticsearch内部,上面的查询被转换为如下查询:
curl-XGET localhost: 9200/library/ search?pretty! -d
"query":(
n should":[
It match
title
Idie leiden
"match":(
nottle die leiden"第3章不只是文本搜索77
4. phrase匹配
接下来要介绍的是 phrase匹配类型,它与前面提到的 best fields匹配类型非常类似。
区别在于,后者将原始查询转换为 match查询,而前者将原始查询转换为 match phrase查
询。可以查看下面的查询范例:
curl-XGET 'localhost: 9200/library/ search?pretty l-d
"query":I
l multi match"
query": "sherlock holmes",
"fields":["title","author
ntype
phrase
因为使用了 phrase匹配,上面的查询被转换为下面这种形式
curl-XGeT 'localhost: 9200/library/search?pretty -d
query i
"dis max":
"queries":[
"match phrase":
ititle":sherlock holmes i
"match phrase":
n author : "sherlock holmes i78◆深入理解 Elasticsearch
5. phrase with prefixes匹配
该类型与 phrase类型原理完全一致,只是原始查询被转换为 match phrase prefix查询
而不是 match phrase查询。读者可试运行下面这个查询:
curl-XGET localhost: 9200/library/ search?pretty! -d '(
query
l multi match"
"query :"sherlock hol",
"fields":[ title""author "]
"type":"phrase prefix"
在 Elasticsearch内部,原始查询被转换为类似下面这样的查询:
curl-XGET 'localhost: 9200/library/ search?pretty' -d'
"query : i
ldis max
queries:
"match phrase prefix":t
title": sherlock holi
match phrase prefix:
l authorl "sherlock holtt
截至现在,我们已经探讨了 multi match查询的type属性的各种可能的选项。使用者
无须构造复杂的查询,就能获取各种所需的结果。 Elasticsearch会自行搞定评分及相关问题。
33重要词项聚合
Elasticsearch1.0之后新增了多种聚合类型,其中之一就是 significant terms聚合,从
Elasticsearch1.1版本之后它就可以使用了。该聚合能帮助用户获取跟指定查询高度相关的第3章不只是文本搜索心79
词项(集)。这种聚合的意义在于不仅能从查询返回结果中提取与查询最相关的一组词项,
并且能找出最相关的那个词项。
这种聚合用途广泛,既可以帮助用户找到应用环境中最不堪重负的服务器,也可以帮
助用户从文本中提取人名绰号推荐项。更引人入胜的是, Elasticsearch可以监控词典中词项
重要度的变化,重要度提升比较明显的就被推荐为候选重要词项。
③ significant terms聚合被官方标记为实验性质的,可能在未来的版本中被修改或移除。
33.1一个例子
描述 significant terms聚合的最好方式当然是通过范例。现在,我们来索引12个简单
的文档,这些文档代表了对实习生的工作评价(索引命令保存在 significant.sh脚本中,便
于在 Linux平台上执行):
curl-XPOST 'localhost: 9200/interns/review/1-d ' ["intern"
Richard","grade":"bad", "type":"grade")
curl -XPOST 'localhost: 9200/interns/review/2-d 'i"intern":"Ralf",
grade
perfect","type":"grade")
curl-XPOST 'localhost: 9200/interns/review/3-d '["intern":
Richard" ,"grade :"bad","type":"grade").
curl -XPOST 'localhost: 9200/interns/review/4-d "intern"
"Richard","grade":"bad","type":"review"'
cur--XPOST 'localhost: 9200/interns/review/5-d " intern"
"Richard","grade": "good","type":"grade"'
curl-XPOST 'localhost: 9200/interns/review/6-d "intern":"Ralf",
grade":"good","type" :"grade")
curl-XPOST 'localhost: 9200/interns/review/7-d("intern": "Ralf n
"grade":"perfect","type :"review")
curl-XPOST 'localhost: 9200/interns/review/8-d"intern":
"Richard","grade ":"medium","type"
Review" t
curl -XPOST 'localhost: 9200/interns/review/91 -d "intern":
"Monica","grade":"medium","type":"grade")
curl -XPOST ' localhost: 9200/interns/review/10-d"intern":
Monica","grade":"medium","type":"grade)
curl-XPOST 'localhost: 9200/interns/review/111-d "intern":
Ralf","grade :"good","type":"grade"I'
curl-XPOST 'localhost: 9200/interns/review/12-d "intern":
Ralf","grade":"good",type":"grade"I'
当然,为了演示 significant terms聚合的实力,固然可以使用更大的数据集。不过本书
的目标是向读者传授 significant terms聚合的用法及原理。因此12个文档已经足够。
现在,让我们来查找针对 Richard的典型评价。为了实现该目的,可使用下面这个
查询:80◆深入理解 Elasticsearch
curl-XGET 'localhost: 9200/interns/ search?pretty! -d '
query
"match":t
wintern": "Richard"
"aggregations":I
Description
"significant terms": t
Field":"grade
查询结果如下
u took 2
timed out l: false
shards i
u total": 5
successfull: 5
n failed": 0
hit
"tota1":5,
" max score":1.4054651,
"hits":[
index": interns
i type :review",
id
4
" score":1.4054651
source":"intern":"Richard"
"grade":"bad"
index
interns"r
type:revie
id
score " 1.0,
source":["intern":"Richard","grade":"bad")
n index": interns "
type :review
"id":"8",
score": 1.0,
source":["intern":"Richard","grade":"medium")
n index: interns
type":review",
ut id第3章不只是文本搜索心81
score: 1.0
source:"intern ":"Richard", grade : "bad")
index interns
type:"review",
id
IE I
It score": 1.0,
source:"intern":"Richard","grade":"good")
"aggregations ":
Description"
n doc count": 5
n buckets n
ke
n bad
doc count":3,
score:0.84,
"bg count":3
如读者所见, Elasticsearch返回结果中,针对 Richard的主流评价是Bad。也许这个评
价对他来说是不客观的,但是谁又知道呢。
3.3.2选择重要词项
为了计算词项的重要度, Elasticsearch会从两个数据集中查询词项重要度变化的报告信
息。这两个数据集被称为前台数据集( foreground)和后台数据集( background)。前台数据
集指的是査询返回的文档集,后台数据集指的是索引中的数据集(索引可能有多个,这依赖
于我们查询数据源的设置)。假设某个词项仅在被索引的100万个文档中的10个文档中出
现,但是在被召回的10个文档中的5个中出现,那么这个词项应该被定义为重要词项,需
要重点对待。
现在我们再返回之前的范例,再深入分析一下。 Richard被打分者评价了5次,有3种得
分,bad三次, medium一次,god一次。这3种评分,bad在查询的5个召回文档中的3个
中出现了(参考 bg count属性),而索引中总共有12个文档(这里的索引为后台数据集)。因
此bad出现的比例占召回文档的60%。如读者所见,bad在前台数据集中重要度相对后台数
据集中重要度有大幅变化,因此 Elasticsearch在 significant terms聚合结果中返回它。
33.3多值分析
当然, significant terms聚合也可以嵌套使用,提供连接多个数据集的强大数据分析82◆深入理解 Elasticsearch
能力。例如,我们想找出每个实习生的典型评分,可以在查询的 terms聚合中嵌套使用
significant terms聚合。如下所示:
curl-XGET.localhost: 9200/interns/ search?size=0&pretty'-d
aggregations":(
"grades":
n terms
l field": intern"
"aggregations ":
"significantGrades":
"significant terms":
afield" grade"
Elasticsearch的返回结果类似下面这种:
"took":71,
timed out": false,
shards
n total": 5
"successful: 5,
ll failed: 0
Shits
"tota1":12,
Imax score:0.0,
Whits:[]
aggregations":
grades":
"doc count error upper bound":0,
l sum other doc count :0
" buckets":
"key " "ralf
ll doc count i
"significantGrades":I
n doc count 5
"buckets":[
"key :"good"
f doc count
3
" score":0.21000000000000002第3章不只是文本搜索83
g c
"key " "richard"
I' doc count
5
"'significantGrades"
"doc count :5.
"buckets":[
ikey: "bad"
ll doc count 3
i score:0.6
ibg count":3
nkey " "monica"
n doc count l: 2
"significantGrades":
Il doc count " 2
"buckets":
如读者所见,我们得到了实习生Ralf(key属性值为raf)和 Richard(key属性值为
richard)对应的结果,但没有 Monica的任何信息。这是因为与 intern字段中 monica值关联
的 grade字段中的词项重要度没有显著改变。
重要词项聚合及全文搜索字段
当然, significant terms聚合可用于全文搜索字段,尤其是在用于确定文本关键字时。
有件事情需要谨记,已分词字段的聚合非常耗费内存,因为需要把所有词项加载到内存中。
举个例子,我们在 library索引的tte字段中运行 significant terms聚合,如下所示
curl-XGET 'localhost: 9200/library/search?size=0&pretty!-d.
"query ":
n term
available": true
"aggregations ":I
description":(
"significant_terms":(
field" title84◆深入理解 Elasticsearch
然而,返回结果并没有给我们带来任何有用的信息:
I took #: 2
timed out n: false
shards":
n total: 5
I successful": 5,
u failed": 0
Hits l
totall: 4
Imax score":0.0,
hits
aggregations":
"description":
l doc count ll
4
"buckets":[
the
I doc count: 3,
l score
1.125
bg count:3
造成这种现象的原因是数据集不够大,造成返回结果效果不明显。仅从逻辑的角度来
看,词项the是 title字段中的重要词项。
3.34额外的配置
对于 significant terms聚合的介绍,似乎是足够了。然而我们并不会就此画上句号,还
会继续介绍该聚合类型的各种配置,使得用户能通过配置来控制内部计算方式,以满足应
用需求。
1.控制返回 bucket数量
Elasticsearch运行控制返回结果的最大 bucket数量,可通过设置size属性来配置它。
然而,最终返回的 bucket链表的长度会大于size的值。如果词项个数大于size的值,就会
出现这种情况。第3章不只是文本搜索心85
如果读者想控制更多,可考虑设置 shard size属性。该属性确定每个 shard返回多少个
候选的重要词项。值得注意的是,低频词项通常是非常有意义的,而 Elasticsearch在聚合
节点上合并返回结果时没有考虑这个因素。因此,将 shard size属性值设置为大于size属
性值是很有必要的
还有一点需要说明一下:如果 shard size属性值设置为小于size属性值,那么
Elasticsearch会将 shard size的值设置为size的值。
请记住,从 Elasticsearch1.20版本开始,如果将 shard siz或se属性设置为0,
系统会自动用 Integer. MAX VALUE替换。
2.后台数据集过滤
前面提到过, significant terms聚合中后台数据集指的是整个索引(可能有多个索引)。
当然可以通过设置过滤条件(设置 background filter属性)来缩小后台数据集的大小。如果
我们想在指定上下文中查找重要词项,这种过滤是非常有用的。
例如,也许我们想缩小第1个例子中后台数据集的范围到真实得分,而不是人为打分,
此时可对查询使用term过滤器
curl-XGET 'localhost: 9200/interns/ search?pretty&size=0-d t
query
"match":I
n intern: rIchard i
"aggregations":
"description":
"significant terms "
"field":"grade",
"background filter":
i term
ltype
grade'
进一步查看返回结果,读者可以发现 Elasticsearch为更小的文档集找出了相关的重要
词项:86
深入理解 Elasticsearch
took
timed out": false,
shards
total
5
lI successful: 5
t failed: 0
hit
l totall: 5
II max score
0.0
whits":[ J
aggregations:
n description"
n doc count: 5
"buckets":[
key
l bad
I doc count":3
" score":1.02,
"bg count ":2
请注意,这里 bg count的值由最初范例中的3变为了2。这是因为仅有两个文档的
grade字段中出现了bad,这与我们之前设置的 background filter的过滤效果吻合。
3.最小文档数量
对于 significant terms聚合,一个比较好的想法是能控制重要词项的最小命中文档数,
并且这些文档被组织为一个 bucket。可以通过设置 min doc count属性为任意预期数字来
实现该目的。
例如,我们想为计算实习生典型评分的查询添加这个参数。可以将 min doc count的默
认值降低至2。修改后的查询如下所示:
curl-XGET ' localhost: 9200/interns/ search?size=0&pretty'-d
"aggregations":i
"grades":t
terms
n field": wintern"
"aggregations":
significantGrades":
"significant terms":
"field":"grade "第3章不只是文本搜索87
min doc count
上面这个查询的返回结果如下所示
took
3
timed out l false
shards
total
successful": 5
failed
hits
total
I max score:0.0
hit
[]
aggregations
grades":
"doc count error upper bound": 0,
Isum other doc count": 0
buckets
[{
key
alfl
n doc count :5,
"significantGrades":(
I doc count ":5,
buckets":
Itk
erfect
ll doc count 2
" sCOre":0.3200000000000001
"bg count
good
"doc count":3,
" score":0.21000000000000002,
"bg count
key
richard
"doc count":5.
"significantGrades":I
5
buckets
ike
l bad n
l doc count " 388心深入理解 Elasticsearch
score:0.6
bg count
"key " :" monica"
ldoc count 2
"significantGrades":
n doc count 2
"buckets":[I
"key " "medium"
it doc count
score: 1.0
"bg count":3
读者可以看到,查询结果与最初的查询有差异,这是因为重要词项的约束条件变弱了
也可以这么理解,检索结果质量现在可能变得更差了。如果将该参数设置为1,结果可能会
很差,如拼写错误的词项,冷僻的词项都会涌现出来,因此不建议这么设置。
有件事情需要注意,当使用 min doc count属性时,在聚合计算的第1阶段,
Elasticsearch会收集每个 shard中得分最高的词项。然而,每个 shard并不知道全局的词频
信息,因此会基于 shard局部词频来推荐候选的重要词项。而 min doc count属性在聚合
计算的最后阶段才被使用到,此时已经对各 shard的返回结果进行完合并了。由于这个原
因,本应属于重要词项列表中的高频词项被高得分词项取代了。为了避免这种情况,可调
大 shard_size属性值,但是此时要承受更大的内存和网络开销。
4.执行模式
当计算 significant terms聚合时,可设置不同的执行模式。根据使用者需要,可以将
execution hint属性设置为map或 ordinal前者告诉 Elasticsearch对每个 bucket中的数据,根
据其值进行聚合,而后者则根据初始值进行聚合。在大多数情况下, execution hint被设置为
ordinal,这种模式执行速度稍快,但是计算被强制在初始值上。如果进行 significant terms聚
合的字段为高基字段(该字段有大量不同的词项),那么使用map模式会更合适一些。
③熹请记住,如果 execution hint属性不可用, Elasticsearch会自动忽略之。
5.更多选项
由于 Elasticsearch处于持续开发升级过程中,本书中不对可配置属性做一一列举。我第3章不只是文本搜索心89
们也忽略了那些很少被使用的属性,这样可以为更常用的选项或特性腾出篇幅。完整的选
项列表可参考:htp:/ww. Elasticsearch. org/guide/en/ Elasticsearch/reference/ current/search
aggregations-bucket-significantterms-aggregation. html
33.5使用限制
在本书撰写之时, significant terms聚合的使用还存在各种限制。当然,我们还是会使
用这种聚合类型,知道其局限之处非常重要。
1.内存消耗
由于 significant terms聚合计算针对的是索引字段,因此在计算时会加载所有相关词项
到内存中。因此在对大数据集的索引字段进行这种聚合计算时,需要特别小心。此外,也
不能通过使用 doc values字段来减少内存使用量,因为 significant terms聚合不支持。
2不应作为顶级聚合使用
当在 match_all询中使用 significant terms聚合时,不应将其作为顶级聚合来使用,
因为 match al的作用是返回所有文档。此时前台数据集和后台数据是完全一样的,因此系
统感知不到词项在两者中的频率差异,因此无法通过比较词频来发现重要词项。
3.计数是近似值
Elasticsearch在统计有多少个文档中包含了某词项时,是基于各 shard的返回信息来估
算的。读者需警惕,这种计数很多时候对用户存在误导(例如 shard返回文档中靠前部分文
档包含指定词项较少,会导致计数预估偏低)。官方文档曾经指出过,这么设计的动机是为
了提高计算性能,当然,随之而来的是计数结果存在一定的不确定性。
4.不能使用浮点数字段
最后需要注意的一点是, significant terms聚合计算的目标不能是基于浮点数的字段
可使用基于long或 Integer类型的字段。
34文档分组
Elasticsearch有很多令人着迷的功能,其中之一就是文档分组( document folding或
document grouping)。这也是 Elasticsearch开发者社区最热门的话题。这并不令人觉得奇
怪。因为用户经常需要根据某个值对文档进行分组,尤其是当返回结果数非常大时,有了
文档分组功能,实现该目标变得非常容易了。类似的案例中,并不需要向用户展示所有文
档,而是从每个分组中返回一个或一些文档。举个例子,也许我们想在图书馆中查询有关90◆深入理解 Elasticsearch
野生动植物的书,返回结果按日期排序,但是限制每年出版的书仅能返回两本。再举个例
子,计算某个字段中不同值的个数并显示它们,这种例子很常见,比如说某本书有多个版
本,然而我们只想返回其中的一本。
34.1 top_ hits聚合
自 Elasticsearch1.3版本开始,引人了 top hits聚合,这与脚本( scripting)的变化有关。
在本章后续小节将会介绍脚本。令人着迷的是,我们可以利用这种类型的聚合提供分组功
能。事实上,文档分组只是 top hits聚合的副产品,我们只能利用 top hits聚合来完成这件
事。在本节中,我们将只关注 top hits聚合,并且假定读者已经对 Elasticsearch的聚合机制
有基本的了解。
如果读者对聚合功能一无所知,可参考本社另外一本著作《 Elasticsearch Server,
SecondEditiony或参考官方文档http://www.Elasticsearch.org/guide/en/elasticsearch/
reference/current/searchaggregations html
这种聚合背后的原理非常简单。每个文档被指派给一个特定的 bucket,系统也能记住
这种指派关系。默认情况下,系统只记忆了每个 bucket中的3个文档。现在,继续使用
library索引来演示我们的案例。
342一个例子
为了演示如何使用 top hits聚合,我们决定采用下面这个查询:
curl-xgethttp://127.0.0.1:9200/library/search?pretty-d'
"aggs ": I
ll when
histogram
"field":year",
winterval: 100
l agas
book
"top hits":t
source:
include ":
七it1e
n available第3章不只是文本搜索
91
size: 1
在上面的例子中,对年份区间使用了 histogram聚合,为每100年的区间构造了一个
bucket。嵌套的 top hits聚合会记住每个 bucket中得分最高的那个文档(因为这里size属性
值被设置为1了)。我们在査询中添加了 include选项,主要是为了简化返回结果,这里我
们限制只返回被聚合文档的 title和 available字段。这意味着 Elasticsearch的返回结果会与
下面类似:
n took": 2
n timed out l: false
shards i
tota
1";5
n successful": 5
"failed": 0
"hits":I
"tota1":4,
Imax score 0
hits.
"aggregations":
t when
"buckets":[
"key as string":1800",
"key":1800,
I doc count ":1
mbook
whiten:
total: 1
max score": 1,
hits":
index": "library
"type":"b。。k"
id":"4
n score: 1
source":
title": "Crime and Punishment"
l available": true92◆◆深入理解 Elasticsearch
"key as string":19001
"key":1900,
I' doc count 3
nbook
whits": I
total": 3
"max score: 1
hits":
index":"library
type":"book",
id":"3"
score": 1
source:
title": "The Complete Sherlock
Holmes
M available": false
查询返回结果中我们感兴趣的部分已经用粗体标出。我们可以看到,由于使用了top
hits聚合,得分最高的那些文档(每个 bucket的)被返回了。在这个具体的例子中,查询类
型为 match all因此所有文档的得分都一样,因此为每个 bucket挑选出得分最高的文档变
成很随机的行为了。默认情况下,在 Elasticsearch中使用 match al询与不指定查询效果
是等价的。如果用户想采用自定义排序,也完全没有问题。例如,比如你想返回给定世纪
的第一本书,我们只需设置适当的排序选项,就像下面这个查询一样:
curl-xget'http://127.0.0.1:9200/library/search?pretty
s1ze":0,
aggs
l when"
"histogram":I
field":"year
winterval#: 100第3章不只是文本搜索◆93
aggs":
nt book i
"top hits"
sort
year:a8c
source
1nc⊥uae:
"title"
m available"
"s1ze";1
请注意上面这个查询中的粗体部分。我们为 top hits聚合添加了排序选项,因此返回结
果会基于year字段排序。这意味着每个 bucket里年份最小的那本书将会被返回。
额外参数
除了排序及指定排序字段以外, top hits聚合还有一些其他功能。 Elasticsearch支持其
他若干种文档检索功能。但是在这里不一一赘述,因为读者如果了解聚合功能,那么基本
上已经对这些功能非常熟悉了。然而,为了支持本章的主题,下面再补充一个例子:
curl-xget'http://127.0.0.1:9200/library/_search?pretty'-d'(
query:
n filtered
query:
"match ":
all":"quiet i
filter":
term
'copies":1
name":copies filter"94◆◆深入理解 Elasticsearch
size: o
aggs":
when
"histogram": I
"field":"year r
aggs":
"book":
top hits
Highlight
fields
title":
explain": true,
I version true,
It source
include":
ititle
ll available
"fielddata fields":["title"],
"script fields":
" century": I
script":"(doc[\"year\"]. value
100).intvalue(
ize: 1
读者可以发现,我们的查询包含了如下功能:
口指定过滤器和查询(例子中为 copies filter)
口获取文档版本信息第3章不只是文本搜索
95
口文档源过滤(选择返回哪些字段)
口使用feld-data字段及脚本字段
口获取文档被召回的解释性信息
口高亮显示
3.5文档关系
当 Elasticsearch受到越来越多的关注时,它慢慢演化,变得不仅仅是一个搜索引擎了。
它可以被视为一种数据分析解决方案,或者一种数据存储系统。既能存储数据又能快速检
索高效的全文检索,看起来是个好主意。 Elasticsearch不仅能存储文档,还能进行全文检索
对数据进行分析赋予其语义,这是传统SQL数据库所不能企及的。不过,如果您对传统
关系数据库非常了解,在使用 Elasticsearch时就会理解对文档关系建模之必要性。不幸的
是,在 Elasticsearch做到这点不太容易,关系数据库中的很多特性 Elasticsearch并不具备,
因为其底层使用的是倒排索引,与传统数据库实现机制不同。但是利用嵌套对象和 parent
child功能, Elasticsearch可以提供文档建模功能(可参考《 Elasticsearch Server, Second
Edition》。现在我们来看看文档建模功能及其陷阱。
3.5.1对象类型
Elasticsearch对数据建模和全文索引构建的限制少之又少。不像关系数据库,
Elasticsearch能很自如地索引结构化对象。这意味着即便是对JsON文档的索引,也完全不
在话下。请查看下面这个文档:
title":"Title
quantity: 100
editioni
isbn":"1234567890",
"circulation": 50000
读者可以看到,上面的文档只有两个简单的字段及一个嵌套对象( edition对象)及其属
性。范例中用到的 mapping也很简单(保存在 relations. json文件中),如下所示:
n book
"properties ": I
title"
ntype":"string
"quantity":["type": "integer")96◆◆深入理解 Elasticsearch
edition
"type ":"object i
properties":(
"isbn":("type":"string","index":"not_analyzed"),
"circulation":("type":integer"
不幸的是,如果想要一切工作正常,内部对象与其父对象必须是一对一关系。例如添
加第2个对象,如下所示:
title:Title"
quantity :100,
edition":
isbn":"1234567890"
circulation: 50000
isbn":"9876543210"
circulation: 2000
Elasticsearch会把内部对象打平( latten)。前面的那个文档会变得与下面这个文档类似
(当然, source字段会保持不变)
title":"Title",
quantity l
:100
edition
isbn":["1234567890","9876543210"],
CIrcu1 ation":[50000,2000]
这并不是我们所预期的,这种文档表示会导致问题,比如说当我们想查找包含指定
ISBN及发行量的图书,而此时 Elasticsearch会返回包含指定ISBN但是任意发行量的图书。
可使用下面的命令索引文档并测试查询效果,索引命令如下:
curl-XPOST 'localhost: 9200/object/doc/1-d
title": "Title"
quantity: 100,
Edition":第3章不只是文本搜索97
isbn":"1234567890",
circulation": 50000
"isbn":"9876543210
n circulation: 2000
现在可以来执行一个查询,如果搜索那些isbn字段值为1234567890且 circulation字段
值为2000的图书,将不会返回任何文档。然而,可执行下面这个查询:
curl-XGET 'localhost: 9200/object/ search?pretty'-dr
n fields
id","title"1
uery
"boo1":{
Imust :[
term
n isbn
1234567890
terms
circulation": 2000
下面是 Elasticsearch返回的结果
"took": 5,
timed out": false,
hard
l total":5
successful": 5
Failed: 0
hits l98◆深入理解 Elasticsearch
total
1
" max score":1.0122644
l hits
n index":"object
n type ": "doc "r
ia":1
" score":1.0122644
u fields
title":["Title"I
可以通过重新排列 mapping和文档来避免交叉查找,所以源文档看起来会像下面这样:
title: Title
"quantity:100
edition
isbn":["1234567890","9876543210"],
" circulation1234567e90":50000,
circulation 9876543210:2000
现在可以使用前面提到的那个查询了,此时能利用字段之间的关联关系,但是代价是
会构建出更复杂的查询。此时会引发更重要的问题, mapping中将会包含字段中所有数值的
信息,如果文档字段中包含超过两个值,结果可能不是我们想要的。换个角度来说,这里
并不允许我们构建某些复杂的查询,例如查找所有销量大于10000且ISBN以23开头的图
书。这种查询,嵌套对象是更好的解决方案。
总结一下, object类型只有在很简单的情景中好用,如不存在跨字段查找等麻烦时,即
你不需要在嵌套对象中搜索,或者仅需要在单个字段中搜索而不需要关联多个字段时。
3.52嵌套文档
从 mapping的角度来看,定义一个嵌套文档很简单,仅仅是把之前的 object替换为
nested类型( object是 Elasticsearch默认类型)。举个例子,我们将前面的范例修改一下
让它使用嵌套文档:
"properties":
"title":["type":"string"
"quantity":i"type":"integer")
edition
"type":"nested",第3章不只是文本搜索“99
"properties":
"isbn":I"type":"string","index":"not analyzed"
"circulation":I"type":"integer")
当使用嵌套文档时, Elasticsearch实际上是为主对象创建了一个文档(这里也可以称
之为父对象,但是考虑到避免与后面将要介绍的 parent- child功能混淆,所以把它叫作主
对象),并为内部对象创建额外的文档。普通查询中,这些额外文档被自动过滤掉,不会被
搜索到或展示出来。这在 Apache Lucene中被称为块连接( block join)(块连接详情可参
考Lucene委员会成员Mikemccandless的博客http://blog.mikemccandless.com/2012/01/
searching-relational- content- with html)。出于性能方面的考虑,额外的文档与主文档保存在
一个索引块( segment block)中。
这也是为什么嵌套文档必须要与主文档同时被索引。因为相互关联的两端文档的存储
与索引是同时进行的。因此有人也将嵌套文档称为索引期连接( index-time join)。当文档都
很小且主文档数据易于获取时,这种强关联关系并不会造成什么问题。如果这些文档很大,
关联双方之一变化较频繁,那么重建另外一部分文档变得不太现实了。另外就是如果一个
嵌套文档属于多个主文档时,问题会变得非常棘手。而这些问题在 parent-child功能面前会
迎刃而解。
回到前面的例子中,对我们的索引做些改变,转而使用嵌套对象( nested object),并将我
们的査询修改为嵌套查询( nested query)。此时查询不会返回任何文档,这是因为单个嵌套
文档并不与这样的查询匹配。
3.53 parent-child关系
谈及 parent-child功能,应从其最大优势谈起——关系两端的文档是相互独立的——每
端的文档都是独立索引的。这么做也是有代价的,会导致更复杂的查询及更慢的查询性能。
Elasticsearch中提供了特殊的查询和过滤器来处理这种关系。 parent- child关系又被称为查
询期连接( query- time join)。 parent- child关系的第二个优势是这种关系适用于大型应用及多
节点场景,这个优势看起来更有价值。现在让我们来看看如何在多节点分布式 Elasticsearch
集群中使用 parent- child关系。
注读者请记住这里与嵌套文档的不同之处,此时子文档检索并不强制在主文档上下文
意
中进行,而这是嵌套文档机制所不能做到的。100心深入理解 Elasticsearch
集群中的 parent-chd关系
为了更好地演示集群中 parent-child关系用法,让我们来创建两个索引: rel pch m索
引和 rel pch s索引,前者存储主文档,后者存储子文档。索引创建命令如下:
curl-XPUT localhost: 9200/rel pch m -d
" settings
number of replicas":0
curl-XPUT localhost: 9200/rel_ pch s -d "settings":(
"number of replicas":0
索引 rel pch m对应的 mapping很简单,可发送下面的命令至 Elasticsearch来设置它
curl -XPOST localhost: 9200/rel pch m/book/mapping? pretty -d'
n book t
"properties":
"title":"type":"string"]
"quantity: type":"integer 3
索引 rel pch s对应的 mapping同样也很简单,只是需要通知 Elasticsearch其父文档类
型。可使用下面的命令将第二个索引的 mapping发送给 Elasticsearch
curl -XPOST localhost: 9200/rel pch s/edition/ mapping?pretty -d 1
medition:
parent l
ntype ":"book
properties
"isbn":["type":"string","index":"not_analyzed"1
"circulation":I"type":"integer
最后一步是向索引中导入数据。不妨先索引10000个文档。下面是文档范例:
i"index":I"index": "rel pch m"," type":"book","id":"1"1
I"title":"Doc no l","quantity": 101
I"index":I"index":"rel pch s"," type":edition", w id":"1",
parent":"1"11
I"isbn":"nol",
/CIrculation n 501
注如果读者很好奇并想自已做实验,可以找到随书的bash脚本 create relation
意
indices.sh,通过运行它来生成范例数据。第3章不只是文本搜索
101
实验很简单,每个种类型(book和 edition类型)文档各10000个。关键是 parent字
段。在我们的范例中,该字段值总是被设置为1。于是索引数据中有10000本书,又有
10000个版本,每个版本属于特定的一本书。我们的范例比较极端,但是却揭示了一个重要
的事实。
洼如果想要儆些可视化展示,可使用 ElasticHQ插件,详情请登录htp:/ww
③
elastichq org
首先看看关系中的父文档部分,可参考下面这个截图:
18:52
rel_pch_m
Metrics Shards Aliases Administration
Shard
State
4 Docs
Size
Primary?
STARTED
00
1374
K
STARTED
1999
1373KB
ue
Samuel Silke
STARTED
1373KB
true
Cat-Man
STARTED
2,001
1375H
true
Stygian
STARTED
2,0
00
1373KB
Samuel Silke
如读者所见,索引的5个 shard分布在3个不同的节点上。每个 shard上的文档数类似。
这正是我们所期待的, Elasticsearch使用哈希算法来确定每个文档应放置在哪个 shard上
现在再来看看第二个索引,该索引中保存的是子文档,详情参考下面这个截图
10:1941
pch_ s
Metrics Shards Aliases Administration
Shard
睿Docs
Size
Node
STARTED
230B
Samuel Silke
STARTED
1230B
Cat-Man
STARTED
10,000
amuel Silke
123.0B
true
STARTED
0
1230B
Samuel Silke
两个索引的情况有所不同。此时仍然有5个 shard,但是其中4个为空索引,只有最后
个 shard中索引了10000个文档。因此肯定是哪里出问题了,所有的文档都被索引在一
个 shard上了,这不是我们所预期的。 Elasticsearch总是将父文档相同的文档放置在同一个
shard中(换句话说,子文档的 routing参数值总是与其 parent参数值相等)。在我们的范例
中,如果某些父文档有多个子文档,会导致文档在 shard之间的不均匀分布,这会引发性能
和存储问题。比如说某些 shard空闲,而某些 shard超负荷。102◆深入理解 Elasticsearch
3.54其他解决方案
读者已经了解到了,使用 Elasticsearch处理文档关系会有这样那样的问题。 Elasticsearch
的最大价值在于全文检索和数据分析,而不是文档关系建模。如果您的应用对文档关系建
模要求非常高,或者全文检索并不是应用的核心功能,那么可以考虑使用带全文检索扩展
的SQL数据库。如果这些全文检索扩展不如 Elasticsearch那么灵活或高性能,也不用诧
异,毕竟它们的主业不是全文检索,更重要的是我们得到了强大的关系数据处理支持。不
过,在大多数案例中,改变数据架构及通过反范式(de- normalization)设计等手段消除关系
就足以应付应用需求了。
36 Elasticsearch各版本中脚本的变化
脚本( scripting)是 Elasticsearch提供的最强悍的功能之一。可使用脚本进行计算分值、
文本相关性、数据过滤、数据分析。尽管脚本在很多情况中会导致较低的性能,如为每个
文档计算得分,但是我们认为 Elasticsearch提供的这种功能是非常重要的。本节中将会介
绍脚本功能在各版本中的变化,也是对《 Elasticsearch Server, Second edition》一书相关
章节的补充
3.6.1脚本变迁
Elasticsearch中的脚本功能自1.0版本以来重构过若干次。于是很多用户困惑不已,为
什么之前可用的脚本在升级到12版本以后变得不可用了,这是非常常见的情形。本节将会
介绍这些变化。
1.安全事项
在 Elasticsearch1.1版本的生命周期中,发现了一个重大安全隐患(参考htp:/ bouk co
blog/ Elasticsearch-rce): Elasticsearch默认配置并不安全。因此在 Elasticsearch1.2版本中,
动态脚本功能被默认禁用了。这使得使用 Elasticsearch更安全,但是脚本的使用却变得更
复杂了。
2. Groovy——新一代默认脚本语言
自 Elasticsearch1.3版本起,使用 Groovy作为默认的脚本语言( Groovy详情可参考
http://groovy.codehaus.org/)使用Groovy的理由很简单,因为它能被控制在自己的沙箱
( sandbox)中,能防止动态脚本做对集群或操作系统有害的事情。因为 Groovy能被沙箱
化,所以可以通过它来使用动态脚本。换句话来说,从 Elasticsearch1.3版本以后,如果
种脚本语言能被沙箱化,它就可以在动态脚本中被使用。然而需要注意的是, Groovy并不第3章不只是文本搜索◆103
能做好所有的事情:自 Elasticsearch1.3起,允许用户使用 Lucene表达式(本节中将会介
绍)。然而从1.3.8版本及1.4.3版本发布后,动态脚本即便是 Groovy也默认被禁用。因此,
如果想在 Groovy中使用动态脚本,需要在 Elasticsearch.yml中添加 script. groovy. sandbox
enabled属性,并将其值设置为true,或者设置 Elasticsearch预存储脚本代码实现有限度的
动态化。但是读者需谨记,开启动态脚本功能会对外暴露安全隐患,使用时需谨慎。
3.MVEL语言的移除
由于安全问题及 Groovy的引入,从 Elasticsearch1.4版本开始,MVEL默认不可用。
默认脚本语言为 Groovy,如果想使用MVEL,则需使用相应的插件。请记住,如果您想移
除MVEL而转用 Groovy,是很容易的,甚至可以安装MVEL插件,但是禁止动态执行
MVEL脚本。
362 Groovy简单介绍
Groovy是一种基于Java虚拟机的动态语言。它构建在Java之上,同时又具备 Python、
Ruby、 Smalltalk等语言的多种优点。 Groovy的话题远远超出了本书的范围,我们只是
简单介绍一下,因为从 Elasticsearch14起, Groovy成为默认的脚本语言。如果读者对
Elasticsearch中的 Groovy使用已经有所了解,可跳过本小节,阅读后续的3.6.3节。
读者需谨记, Groovy仅在1.3.8版本和1.4.3版本前可沙箱化。而此后 Groovy动态
脚本默认是禁用的,除非在 Elasticsearch中配置使用它。后面我们的范例查询涉及
动态脚本,需要在 Elasticsearch yml配置文件中设置 script. groovy sandbox enabled
属性值为true。
1.将 Groovy当成脚本语言来使用
在介绍 Groovy之前,先来了解如何在 Elasticsearch中使用脚本。在此之前,请检查您
使用的 Elasticsearch的版本。如果版本老于14,则需要在 query中添加lang属性,其值设
置为 groovy,如下所示:
curI-XGET 'localhost: 9200/library/ search?pretty'-d
"fields":[ "id"" score", "title
"query : i
"function score":
"match all ":
"script score":I
lan
It " groovy
"script " index[\"title\"]. doc Count()"104◆◆深入理解 Elasticsearch
如果使用的版本为1.4或者更新版本,则不需要设置。因为此时 Elasticsearch默认使用
Groovy作为脚本语言。
2.脚本中的变量定义
Elasticsearch允许 Groovy在脚本中定义变量。为了定义新变量,可使用def关键字,
后面紧随变量名及变量值。例如,我们想声明一个叫sum的变量,并将它初始化为0,可
使用下面这段代码:
def sum =0
当然,不限于上面这样的变量定义,也可用一列值来初始化变量,如用4个值:
def listofvalues =[0, 1, 2, 3]
还可用一个数值区间来定义变量,如下面这行代码,数值区间为0~9:
def rangeofvalues = 0..9
最后,也可以定义字典:
def map=[ count: 1, 'price: 10, quantity: 121
上面这行代码执行结果是定义了一个字典,里面有个3个keys( count, price, quantity),
其值分别为1、10、12。
3.条件语句
当然也可以在脚本中定义条件语句。例如定义标准的 if-else if-else结构:
if (count >1)
return count
3 else if (count ==1)
return 1
3 else i
return 0
也可使用经典的三元操作符:
def isHigherThanZero =(count >0)? true false
上面的代码中,根据 count的值是否大于0,将变量 isHigher Than Zero的值设置为true
或者 false
该语言当然也支持标准的 switch结构,运行用户以很原始的方式基于变量值检测来执
行具体的语句。范例如下所示:第3章不只是文本搜索°105
def isEqual ToTenorEleven false;
switch (count)(
case 10
isEqual ToTenorEleven = true
break
case 11:
isEqual ToTenorEleven = true
break
default
isEqualToTenorEleven
false
上面的代码会将变量 isEqualTo TenOrEleven的值设置为true,如果 count的值等于10
或11,否则将 is EqualTo Ten OrEleven的值设置为 false。
4.循环语句
在 Elasticsearch中的 Groovy脚本中当然也可以使用循环语句。下面我们以 while循环
为例,当括号中条件为true时,循环体中的代码将一直执行下去:
def i= 2
def sum 0
while (i>0)
sum sum 1
上面的循环被执行两次然后退出。第1趟循环中,变量i的值为2,此时条件讠>0为tue,
因此执行循环体中代码。第2趟循环中变量i的值为1,此时条件讠0依然为tue,因此也执
行循环体中代码。第3趟循环中,i的值为0,此时括号内ⅳ>0为fase,此时循环结束。
也可以使用for循环,如果读者之前有过编程经验,会很容易理解for循环。例如,使
用for循环执行10次。可参考下面的代码:
def sum 0
for(i=0;i<10;i++){
sum + 1
也可以使用for循环在一个数值区间上迭代:
def sum =0
for( i in 0..9)
sum +E
或者在一个数值列表上迭代:
def sum=0
for(iin[0,1,2,3,4,5,6,7,8,9]){
sum + 1106深入理解 Elasticsearch
如果我们有一个字典,也可以通过字典的enty来迭代:
def map=[ quantity: 2, Ivalue: 1, 'count:31
def sum =0
for entry in map )I
sum + entry value
5.一个例子
现在可以开始介绍 Groovy了,现在我们来执行一个脚本以修改文档的得分。将在脚本
中实现如下评分算法:
口如果year字段的值大于800,那么文档(book)得分为1.0。
口如果year字段的值为1800~1900,那么文档得分为2.0。
口其余文档得分为year字段值减1000。
下面的查询用来实现前面的评分算法:
curl-XGET 'localhost: 9200/library/ search?pretty'-d
fields":[
score", '"title ","year I
query
"function score":
"match allm:
'script score
lang":"groovy '
script":"def year doc[\"year\"]. value; if (year 1800)(
return 1.0) else if (year 1900)( return 2.0 else ( return
ear
1000}
凄读者可能注意到了,在语句 def year=doc" year\"] value后面,我们用分号分隔了
意
这是为了告诉 Groovy,只是一行代码,分号前是赋值语句,分号后是另一条语句。
上面的查询的返回结果如下所示:
l took:4
timed out false
shards
total: 5
lI successfull: 5
n failed": 0第3章不只是文本搜索◆107
thats l
u total": 6
n max score:961.0,
whits":
nl index": library
type":"book"
2
sCOrE":961.0,
u fields il
title":["Catch-22"]
"year":[1961],
Hid":"2"
n index: "library r
type":"book",
" score":936.0,
"fields ":
"title":[ "The Complete Sherlock Holmes"I
"year":[1936]
id
1 2 tt
index":"library ",
I type :" book",
d
1
score": 929.0
fields"
"title":["All Quiet on the Western Front"]t
"year":[19291
n id
n index":"library",
type": "book
6
score":904.0,
li fields
"title":[ "The Peasants"]
"year":[1904
ia":"6"
index": "library '
type ":"book",
id
4
score
2.0,
f fields
title":[ "Crime and Punishment"]108◆深入理解 Elasticsearch
year
1886]
nt index
library
type
book
idi
score: 1.0,
fields
"title":[ "The Sorrows of Young Werther" J
"year":[1774
5
如我们预期的那样,脚本完成了它的使命。
6.额外的说明
显然,前面介绍的 Groovy的知识并不是一份全面的指南,我们也无意做这方面的努
力。因为 Groovy的全面介绍远远超出了本书的话题,本书为领读者稍做介绍,了解我们能
通过( roomy获得什么。如果读者对 Groovy有强烈的兴趣,想进一步了解,建议登录其官
网阅读相关文档http://groovy.codehaus.org/
363全文检索中的脚本
前面介绍了利用文档中数据计算得分的例子,而在全文检索上下文中,可以在脚本中
使用全文检索统计量,如词频、文档频率等。下面可以看看有哪些可用的信息。
1.字段相关信息
首先能想到的脚本中可以使用的文本相关信息就是字段相关信息。 Elasticsearch中可使
用的字段相关信息包括以下这些。
口_ index['field name] doccounto:有多少文档包含该字段。该统计量不考虑被删除文档。
日_ index' field name']. sumit:所有文档给定字段中词项出现次数之和。
口_ index' field name勹] sumif:文档频率之和。指定字段中词项的文档频率之和。
注请记住,上面这些统计量是 shard内统计量,同一个统计量在不同 shard之间的值
可能不一样。
例如,也许你想将文档得分赋值为所在 shard内包含 title字段的文档的个数,可执行下
面这个查询:第3章不只是文本搜索“109
curl -XGET 'localhost: 9200/library/ search?pretty! -d '
fields":["id", score","title"]
e
ll function score l
"query":
ll match alli
"script score
ilang":groovy
"script n index[\"title\"]. doc Count()"
、3
如果查看返回结果,会类似于下面这样
n took: 3
timed out": false,
shards":I
"tota1":5,
l successful: 5
failed
0
"hits":
l total: 6
max score: 2.0,
hits
index":"library
type
book it
id
score":2.0,
u fields
"title":[All Quiet on the Western Front "J
1
"index":"library"
type":"book"
d":"6
score": 2.0
l fields
"title:[ The Peasants"
indexI
library
type "book",110◆深入理解 Elasticsearch
id
score ": 1.0,
fields
"title":[ "Crime and Punishment "I
id
14
index":"library
type
5
n score: 1. 0
l fields r
"title": ["The Sorrows of Young Werther"]
ut id"
u index":"library ",
type ":"book
"ia":"2"
score
1.0
"fields":
atitle":[ nCatch-22]
id
index": "library "
type ":"book ",
ia":"3"
score: l.0.
n fields
"title": [ "The Complete Sherlock Holmes "],
如读者所见,查询返回了6个文档。前两个文档得分为20,后4个文档得分为1.0
这意味着这两批文档分别位于不同的 shard中。
2. Shard级信息
也有很多可使用的 shard级信息。
口 index. numDocsO: shard中的文档数。
口 index. max DocO: shard内部最大文档ID。
口 index. numDeletedDocs(: shard内已删除文档数
洼请记住,上面这些统计量是 shard内统计量,同一个统计量在不同 shard之间的值
意可能不一样。第3章不只是文本搜索心111
举个例子,如果我们基于每个 shard的最大文档ID对文档进行排序,可使用下面这个
查询:
curl-XGET 'localhost: 9200/library/search?pretty! -d
"fields":[ id", score","title"I
query:
"function score":
query:
I match alll
Iscript score
"lang":"groovy "
" script":" index. maxDoc()
当然,像这样简单使用单个统计量并没有什么意义。如果结合其他的全文检索统计量
使用,它们的用途就大大增强了。
3.词项级信息
在脚本中还可以使用另外一种统计量,词项级统计量。 Elasticsearch中有如下词项级统
计量。
口_ index['field name!' term].dfO:指定字段中,有多少个文档中出现过某词项。
日_ index[" field name'l['term!].tt:指定词项在所有文档的指定字段中出现的次数。
口 index" field name! Iterm].ti):某词项在文档的指定字段中出现的次数
为了向读者演示如何使用这些统计量,可使用下面的命令索引两个文档:
curl-XPOST 'localhost: 9200/scripts/doc/1-d '["name":"This is a
document"I'
curl-XPOST ' localhost: 9200/scripts/doc/21-d '("name":"This is a
second document after the first document")
现在,基于某词项在name字段中出现的次数来过滤文档。例如,我们想找出在name
字段中 document词项至少出现过两次的文档。为实现该目的,可使用下面这个查询:
curl-XGET 'localhost: 9200/scripts/_search? pretty'-d'
query ":
filtered":i
query": I
"match_ _all":y112◆深入理解 Elasticsearch
lt filter l
l script
"lang":"groovy
"script ": index[\"name\"][\"document\"].tf()>1"
查询返回结果如下所示
took
timed out l: false
n shards it
ltotal": 5,
l successful: 5,
ll failed": 0
hits":I
ltotal: 1,
Imax score 1.0,
whits":[[
n index":"scripts
"type";"d。c",
a"
score: 1
n source":I "name":"This is a second document after the first
document "I
如读者所见, Elasticsearch返回了预期的结果。
4.更多的高阶词项信息
除了前面提及的那些统计量,还有更多的词项级信息可在脚本中使用,如词项位置
偏移量、负载( payload)。可使用 index! field name].get(term', OPTION)获取这些统计量,
这里的 OPTION是下面这些选项
口 OFFSETS:词项偏移量
口 PAYLOADS:词项负载
口 POSITION:词项位置
③漆如果想获取位置、偏移量等信息,需要在索引期设置索引字段的处理方式第3章不只是文本搜索心113
除此之外,还可以使用 CACHE选项,该选项允许我们多次迭代词项所有的位置信
息,选项可以用“”操作符组合使用。如果您既想获取name字段中 document词项的位置
信息,又想获取其偏移量信息,可在脚本中使用下面的表达式:
index['title'I get ('document, _OFFSETS POSITIONS)
有一点读者需记住,类似上面这样的组合选项的处理结果因采用的选项而异,通常会
包含下面这些信息。
口 startOffset:词项起始偏移量
口 endoffset:词项结束偏移量
口 payload:词项负载
口 payloadAsInt( value):将词项负载转化为整数值,如果负载缺失用整数vaue替代
口 pay loadAsFloat( value):将词项负载转化为浮点值,如果负载缺失用浮点值 value替代
口 payloadS String( value):将词项负载转化为字符串,如果负载缺失用字符串 value替代
position:词项位置
出于演示用途,我们使用下面的 mapping创建一个新索引:
curl-XPOST 'localhost: 9200/scripts21-d I
"mappings":t
n doc l
properties":
"name":("type :"string","index_options":"offsets")
之后,用下面的命令索引两个文档:
curl-XPOST 'localhost: 9200/scripts/doc/1-d I("name":"This is the
first document")
curl-XPOST 'localhost: 9200/scripts/doc/2,-d ("name":"This is a
second simple document"1
现在来设置文档的得分计算方法,将每个文档得分设置为name字段中 document词项
的 startOffset之和。可执行下面这个查询:
curl-XGET ' localhost: 9200/scripts/ search?pretty! -d
query":(
n function score
query:
match all114◆◆深入理解 Elasticsearch
"script
"lang":groovy r
"script":"def termInfo index[\"name\"]. get(\"document\",OFFSETS);
def sum=0: for (offset in termInfo)I sum + offset startoffset;)i
return sum:
Elasticsearch返回结果如下所示
took": 3
timed out": false,
shards
total: 5
n successful: 5
failed": 0
whits
totall: 2
Imax score": 24.0,
whits":[
n index":"scripts,
type
I doc
id"
2"1
score": 24.0,
n source":["name":"This is a second simple document")
l index":"scripts
l type
a
ia":"1",
score": 18.0,
source":"name":"This is the first document")
读者不难发现,脚本正常工作了。下面是前面脚本代码的更规整的写法:
def termInfo index['name'] get(' document, OFFSETS )i
def
0
for (offset in termInfo)(
sum + offset. startoffset i
return sum;
这段脚本代码其实并不复杂。首先,获取一个对象的偏移量信息;然后,创建一个变
量保存偏移量之和;之后,使用循环对偏移量进行累加(同一个词项在多个位置出现了)。第3章不只是文本搜索◆115
最后的总和作为文档得分返回。
除了前面各节介绍的内容之外,我们也可以使用词项向量信息( erm vector,,词项向
量的构建需要在索引期设置。可使用 index term Vectors表达式获取词项向量,使
用该表达式会返回一个 Lucene的 Fields对象实例。更多 Fields对象细节,可参考官
方文档:htps:/ ucene.apache. org/core/4_90/core/org/ apache/ Lucene/ index/ Fields. html。
364 Lucene表达式
尽管这项功能被官方标识为实验性的,笔者还是打算花费一定篇幅来介绍它。它一种
崭新的但是又非常有用的特性。 Lucene表达式吸引人的理由是它执行速度非常快,甚至与
原生脚本一样快,但是它也像动态脚本那样存在某些限制。本节内容将展示 Lucene表达式
的一些功能。
1.基础知识
Lucene支持将 JavaScript表达式编译成Java字节码。这也是 Lucene表达式的实际工
作原理。正因如此,它们和普通的 Elasticsearch脚本执行得一样快。 Lucene表达式可以在
Elasticsearch的下面这些功能中被使用:
口用于排序的脚本
口数值字段中的聚合
口 script score查询中的 function score中
口使用 script fields的查询中
除此之外,用户需记住:
口 Lucene表达式仅能在数值字段上使用
口 Lucene表达式不能访问存储字段
口字段缺失值用数值0替换
口可使用 score访问文档得分,可使用 doc['field name!]. value访问文档的单值数值字
段中的值
口 Lucene表达式中不允许使用循环,只能使用单条语句
2.一个例子
通过前面的介绍,读者已经可以利用 Lucene表达式来修改文档得分了。我们再回顾
下之前提到过的 library索引,我们将每个命中文档的得分赋值为其出版年份数的10%。为
实现该目的,可执行下面这个查询:116◆深入理解 Elasticsearch
curl-XGET localhost: 9200/library/ search?pretty -d .
Fields":[ w id",#score",title]]]]
query
l function score":
"query":
imatch all
"script score": I
u lang":"expression
uscript": score doc[\"year\". value percentage",
params":
percentage: 0.1
查询本身很简单,我们感兴趣的是查询的结构。首先,用 function score查询包装了
match all查询。这是因为我们希望所有文档命中,并且对文档得分进行定制。然后设置脚
本语言为表达式(将ang属性值设置为 expression),这么做的目的是通知 Elasticsearch脚
本类型为 Lucene表达式。当然,我们提供了脚本,也需要提供对应的参数,就像我们使用
其他脚本一样。前面的查询将会返回类似下面这样的结果:
took: 4
u timed out: false
uI shards
total
5
lI successful": 5.
l failed": 0
white
"tota1":6,
I max score: 197.1
hits":[i
index":"library r
type
book
id
" score":197.1,
u fields n
title":[ "Catch-22"]
id
2
i index": "library ",第3章不只是文本搜索117
type
book
id
12n
I score: 194.6
fields
title":[ "The Complete Sherlock Holmes "]
id"
3
nt index library l
typ
book
id
1
n score
193.9,
fields"
title":["All Quiet on the Western Front"]
id
I index":"library,
pe
ll book
id
6
score: 191. 4
fields
title
The Peasants"]
id
index
libra
type: " book
id
SCOrE":189.6,
n field
"title":[ "Crime and Punishment"],
index
libra
type":"book
5
" score":178.4
field
"title:["The Sorrows of Young Werther"I
id":"5
此时读者不难发现,查询结果与预期的完全一致。
额外说明
本节提供的范例比较简单,如果读者对 Lucene表达式很感兴趣,可参考以下官方文118◆深入理解 Elasticsearch
t:http://lucene.apacheorg/core/49o/expressions/index.html?org/apache/lucene/expressions/js/
package- summary. html。该文档向读者展示 Lucene的 expression模块所提供的功能。
37小结
在本章中,扩展了读者在查询处理与数据分析方面的知识。首先,介绍了查询二次评
分,即如何对査询返回文档计算二次得分。同时也讨论了如何控制多匹配查询。然后介绍
了两种重要的聚合类型:一种是提取返回结果中的重要词项(集),另一种是对文档进行分
组(这是一种用户参与度极高的特性)。我们也探究了 Elasticsearch中文档建模的不同方法。
最后讨论了 Elasticsearch中的脚本功能,以及自1.0版本以后的各种变化。
在下一章中,我们将探讨如何提升用户搜索体验。从拼写检査开始,介绍拼写检査的
基本功能,以及如何将错误的查询纠正为正确的查询。之后将讨论在各种拼写错误的场景
中使用合适的方法。最后,通过一个范例来介绍如何提升查询的相关性。我们将向读者展
示一个返回较差结果的查询,并不断对其调优。留鹦题酯:
圈膜
器翻题
第4章cyt
改善用户搜索体验
在上一章我们了解了查询处理及数据分析。首先,我们介绍了查询二次评分功能,它
能重新计算查询返回文档的top-N文档的得分。然后学习了如何在 Elasticsearch中控制多
匹配,同时介绍了两种非常具有吸引力的聚合类型: significant terms聚合及 top hits聚合。
还讨论了多种不同的文档关系建模技术。最后,我们了解了 Elasticsearch的脚本模块,及
1.0版本后脚本功能的变迁。本章,我们将聚焦在用户搜索体验上。到本章结束时,将涵盖
以下内容:
口如何使用 Elasticsearch Suggest API改正用户的拼写错误
口如何使用 term suggester给出单词建议
口如何使用 phrase suggester提示完整词组
口如何配置建议功能以匹配你的需求
口如何使用 complete suggester的自动补全功能
口如何使用 Elasticsearch的各种功能改进搜索相关性
41改正用户拼写错误
改善用户搜索体验最简单的方式之一是纠正他们的拼写错误。要么自动地,要么仅显
示正确的查询短语,并允许用户使用它。例如,当我们输入 elasticsaerch(正确拼写应是
Elasticsearch)时, Google会这样提示我们:120深入理解 Elasticsearch
Google「 elasticsaerch
Web Images Maps More Search tools
About 706,000 results(0. 15 seconds)
Showing results for elasticsearch
Search instead for elastics aerch
自0.90.0.Beta版本起, Elasticsearch允许我们使用 Suggest APl改正用户拼写错误。
不过,相关文档指出这个功能仍在开发中。在即将问世的 Elasticsearch新版本中,它可能
会发生巨大变化,引入很多新特性。在本小节中我们将对 Elasticsearch提供的 Suggest API
做完整的介绍,同时会提供一些范例,其中既有简单的案例,也有需要较多配置的案例。
4.1.1测试数据
为了阐述本节内容,我们需要多准备一些文档。为了获取需要的数据,我们决定使用
Wikipedia river插件来索引一些 Wikipedia上公开的文档。首先我们需要运行如下命令来安
装这个插件
bin/plugin -install elasticsearch/elasticsearch-river-wikipedia/2.4.1
接着执行如下命令:
curl-XPUT 'localhost: 9200/ river/wikipedia river/ meta! t
mtype":"wikipedia"
uindex
nindex":"wikipedia
在此之后, Elasticsearch开始从 Wikipedia上下载英文文档并索引它们。
如果读者查看系统日志,将会看到如下信息:
[2014-08-2822:35:01,5661[INFo][ river. wikipedia
J [Thing]
[wikipedia] [Wikipedia river] creating wikipedia stream river for
[http://download.wikimediaorg/enwiki/latest/enwiki-latest-pages
articles. xml. bz21
2014-08-2822:35:01,568][INFo】[ rIver, wikipedia
1 [Thing]
[wikipedia] [Wikipedia river] starting wikipedia stream
如读者所见,该插件已开始工作。经过一些时间,创建的 wikipedia索引中已经有数据
了。如果您想索引 Wikipedia上所有最近的英文文档,则需要点耐性,这个比较耗时。出于
演示的目的,我们仅索引了部分文档,当索引文档数到达7080049时,我们停止了索引操
作。此时索引大小为19GB(没有使用副本)。第4章改善用户搜索体验◆121
4.1.2深入技术细节
Suggest APl从版本0.90.3开始被引入,但是它并不是 Elasticsearch中最简单的AP。为了获得
期望的建议信息,我们可以在查询中增加一个 suggest节点,或者使用一个 Elasticsearch提供的特
殊的REST端点。此外,我们还拥有多个不同的 suggest实现,用来纠正用户的拼写错误及创建
自动补全等功能。以上功能给予我们一个强力且灵活的机制,用来使我们的搜索体验更佳。
当然,建议功能的效果跟我们的数据有关。如果索引中的文档数较少,可能就找不到
合适的建议结果。当数据量较小时, Elasticsearch索引中含有的词汇相对较少,因此能给出
的候选建议结果也偏少。相反,数据量越大,我们拥有错误数据的可能性就越大。尽管如
此, Elasticsearch都能很好地处理这些情况。
漆本章的布局结构与其他章节稍有不同。我们以一个简单例子作为本章开始。这个例
子着重于告诉我们如何获取建议结果,以及如何解释 Suggest API的响应,而不关
注完整的配置选项。这是因为我们不想让你沉入过多的技术细节,而是想告诉你能
从中得到什么。更多的配置参数稍后再谈。
4.1.3 suggester
在我们继续进行查询和分析响应结果之前,先简单交代一下可用的 suggester类型。
Elasticsearch目前允许我们使用3种 suggester:一种是 term suggester,一种是 phrase
suggester,还有一种是 complete(自动完成) suggested,前两种 suggester可以用来改正拼
写错误,而第3种 suggester能够用来开发出迅捷且自动化的补全功能。不过目前,我们暂
不聚焦于特定的 suggested我们先看看查询的可能性和 Elasticsearch的响应。我们将试着
展示普遍原则,然后再深入探讨各种 suggester的细节。
1.使用 suggest REST终端
为获取给定文本的提示结果,第一个可行办法是使用精心设计的 suggest REST端点。
我们需要提供分析的文本和 suggester类型(term或 phrase)。假如我们想得到关于 graphics
designer(我们故意使用错误的拼写)的提示建议,需要执行如下查询:
curl -XPOST localhost: 9200/wikipedia/ suggest?pretty -d'
"first suggestion":(
n text": wordl war iim
u term"
n field"
alln122◆深入理解 Elasticsearch
如你所见,每个 suggestion请求都以对象(JSON对象)的形式发送给 Elasticsearch
对象中包含我们指定的名字(在上面的例子中,名字是 first suggestion)。我们用text参数
指定想要查询的文本信息。最后,我们添加 suggester对象,可以为term或 phrase类型的
suggester.这些 suggester对象拥有自己的配置。例如在之前的例子中,我们使用了term
suggester类型,并通过 field属性来指定建议从哪个字段里产生。
我们可以在一次请求中包含多个 suggestion对象。每个对象拥有不同的名字。例如,如果
我们要在上面的请求中增加一个针对单词“ racing”的 suggestion对象,可以使用如下命令:
curl-XPOST 'localhost: 9200/wikipedia/ suggest?pretty! - 't
"first suggestion": I
七ext":" wordl war 1主
u term
fie1d”;"a11
n second suggestion":
l text ": "racing",
n term"
field": text
乙〔(
2.理解_ suggest REST端点的响应
首先我们看看_ suggest REST终端的响应示例。不同类型的 suggester响应格式有所差
异。仍然以之前使用的第一个命令为例,该命令中使用了词项类型 suggester,我们看看它
的响应:
shards i
"tota1":5,
n successful: 5
l failed: 0
first suggestion":[ I
n text w wordl
offset: 0
"length ":5,
"options":[
itext
orld
score:0.8.
"freg":130828
ntext": words "第4章改善用户搜索体验“123
score :0.8,
"freq":20854
text": " wordy "
score
0.8
u frea
210
ntext": woudl
score:0. 8
nfre
29
"text":"worde"
"score :0. 8,
fred": 20
text: war t
offset :6
"length":3
options
[]
text
11
ll offset 10
"length": 2,
options
在响应的“ first suggestion”对象中, term suggester为每个text字段中的词返回一个
建议列表。列表中包含可能的建议词以及一些附加信息。例如,从“ wordl”这个词的响
应数据中我们可以看到以下信息:请求原始词(text参数),原始词在请求text中的偏移量
( offset参数)及长度( length参数)。
options数组包含给定词的建议词。如果 Elasticsearch没有找到任何建议词,则 options
数组为空。该数组的每一项都包含一个建议词和以下可以用来表征该建议的信息:
口text: Elasticsearch给出的建议词。
口 score:建议词的得分,得分越高的建议词其质量越高。
口freq:建议词的文档频率。这里的频率指建议词在被查询索引的多少个文档中出现
过。文档频率越高,说明包含这个建议词的文档也越多,并且这个词符合我们查询
意图的可能性也越大。
淒 phrase suggester的响应结构和这里 term suggester的响应结构有所不同。我们将在
本节的后面探讨 phrase suggester的响应。124◆深入理解 Elasticsearch
3.在查询请求中包含建议请求
除了使用 suggest REST端点,我们也可以在普通的 Elasticsearch查询请求中包含建议
请求。例如,我们可以通过如下方式,在查询请求中融入我们之前例子中的建议请求:
curl-XGET 'localhost: 9200/wikipedia/ search?pretty! -d I
query":[
"match all":
suggest": I
"first suggestion":[
m text": "wordl war ii",
term:
n field# m alll
如读者所期望的那样,上面这个査询的响应既包括了查询结果,也包括了建议结果
如下所示:
took": 5
timed out: false
hards
ntotal": 5/
It successful: 5
l failed": 0
lt hits
"tota1":7080049
Imax score: 1.0,
Whits":
"suggest":i
first suggestion":[
Itext :"wordl"
offset": 0
"length":5
"options":[I
n":world
fscore:0.8,
"freq":130828
n text l: words
n score第4章改善用户搜索体验
125
freq":20854
ntext " wordy
score:0.8,
"freg":210
text i
score : 0.8
fre
:29
text
de
score:0.8,
freg'
text
war
offset 6
length
"options":[
text
offset
10,
length
2
"options":[ J
上面的查询响应中包含了查询结果及查询建议,查询建议的消息体结构之前已经讨论
过了
还有一种可能场景:我们可能希望一次性获得针对问一段文本的多种类型的查询建议
这时候我们可以用 suggest对象把建议请求封装起来,让text作为 suggest对象的一个选项。
例如:如果我们希望获取“ wordl war ii”文本在text字段和all字段中的建议,可以使用
如下命令
curl-XGET 'localhost: 9200/wikipedia/ search?pretty! -d Ii
atch all
urges
text":"w。 rdl war ii",
"first suggestion":
a term
fie1d”:ma11m
secondsuggestion":i
u term:126◆深入理解 Elasticsearch
n field: "text
现在我们学会了如何通过查询请求获取查询建议,以及如何使用 suggest REST端点。
下面我们深入了解一下各种 suggester的细节。
4. term suggester
事实上, term suggester基于编辑距离来运作。这意味着,建议词通过增删改某些字符
转化为原词所改动的字符数越少,它越有可能是最佳选择。拿worl和wok举例,为了把
worl转化为work,我们需要把字母1改为字母k,改动了一个字符,因此编辑距离为1。当
然, suggester的text文本需要先经过分词转化为词项,之后再针对各个词项给出查询建议。
接下来,我们介绍一下 Elasticsearch中 term suggester的各种配置选项。
(1)配置
在 Elasticsearch中, term suggester有多个配置属性,允许用户对其行为调优,以适应
各种不同的数据和需求。显然,到此为止读者已经知道 term suggester是如何工作及它能返
回什么样的结果。因此现在我们要聚焦于它的配置细节。
(2) term suggester的通用配置选项
term suggester的通用配置选项对所有基于 term suggester的 suggester实现都有效。目
前来说,这些 suggester包括 phrase suggester,以及最基础的 term suggester自身。可用配
置选项如下。
口text:这个选项代表我们希望从 Elasticsearch得到建议的文本内容。这个选项是必需
的,因为 suggester有了它才能工作。
口 field:这是另一个必备选项。这个选项允许我们指定产生建议的字段。例如,如果
我们仅希望从titl字段的词项中产生建议,我们给本选项赋值为tle
口 analyκer:这个选项指定分析器。分析器会把我们提供的text文本切分成词项。如果
不指定本选项的值, Elasticsearch会使用 field参数所对应字段的分析器。
口size:这个选项指定针对每个词项的最大建议词数量。默认值是5。
口sort:这个选项指定 Elasticsearch给出的建议词的排序方式。默认值为 score,表示
先按建议词得分排序,再按文档频率排序,最后按词项本身排序。另一个可选值是
frequency,表示先按文档频率排序,再按建议词得分排序,最后按词项本身排序。
口 suggest mode:这个选项可以用来控制什么样的建议词可以被返回。目前有3个可用
取值: mIssing、 popular和 always。默认值是 mIssing,要求 Elasticsearch对text参第4章改善用户搜索体验心127
数的词项做一个区分对待,如果该词项不存在于索引中的,则返回它的建议词,否
则不返回。如果本选项取值为 popular,则要求 Elasticsearch在生成建议词时做一个
判断,如果建议词比原词更受欢迎(在更多文档中出现),则返回,否则不返回。最
后一个可用取值是 always,意思是为每个text中的每个词生成建议词。
(3) term suggester的其他配置选项
除了刚刚提到的通用配置选项, Elasticsearch还提供一些仅适用于 term suggester的选
项。列举如下。
口 lowercase terms:如果本选项设置为true, Elasticsearch会把text文本分词得到的词
项都转为小写。
口 max edits:默认值是2,用来设定建议词与原始词的最大编辑距离。 Elasticsearch允
许我们设置为1或2。设置为1可能会得到较少的建议词,而对于有多个拼写错误的
原始词,则可能没有建议词。一般来说,如果看到很多建议词项,可能是由于某些
错误引起,此时可以将 max edits的值设置为1。
口 prefix len:一般来说拼写错误不会出现在单词开头。 Elasticsearch允许我们设置建
议词的开头几个字符必须和原始词开头字符匹配。这个选项的默认值为1。如果我们
正在与 suggester的性能作战,可以通过增加这个取值来得到更好的性能,因为这样
做会减少参与计算的建议词数量。
口 min word len:这个选项用于指定可供返回的建议词的最少字符数。默认值是4。
口 shard size:这个选项用于指定每个分片返回建议词的最大数量。默认等于size参数
的值。如果给这个参数设定更大(大于size参数值)的值,会得到更精确的文档频率
(因为词项分布在多个索引分片中,除非我们的索引只有一个分片),但是会导致拼写
检查器的性能下降。
口 max Inspections:这个选项用于控制 Elasticsearch在一个分片中检查多少个候选者
来产生可用的建议词,默认值是5。 Elasticsearch针对每个原始词总共最多需要扫描
shard size* max inspeciton个候选者。如果给这个选项设置更大(大于5)的值,
会提高精准度,但会降低性能。
口 min doc freq:这个选项的默认值是0,表示未启用。这个选项可以控制建议词的最
低文档频率,只有文档频率高于本选项值的建议词才可以被返回(这个值是针对每
个分片的,不是索引的全局取值)。例如,取值为2表示只有在给定分片中文档频率
大于等于2的建议词才能被返回。把取值设置为大于0的数,可以提高返回提示词
的质量,但是会让一些文档频率低于本值的建议词无法被输出。利用这个选项可以
帮助我们去掉那些文档频率低、可能不正确的建议词。这个选项的取值也以设置为
百分比,如果这样做,这个取值必须小于1。例如,0.01表示建议词的文档频率最低128◆深入理解 Elasticsearch
不能小于当前分片文档数的1%(当然,该数值也是针对每个 shard的)。
口 max term freq:这个选项用于设置text中词项的最大文档频率,文档频率高于设定
值的词项不会给出拼写纠错建议。默认值是0.01。和 min doc freq选项类似,本选
项的取值可以是精确数字(例如4或者100),也可以是小于1的小数,表示百分比
(例如,0.01表示1%)。请记住,这个值也是针对单个分片设定的。取值越高,拼写
检査器的性能越好。一般来说,如果我们想要在拼写检查时排除掉高频词,这个参
数非常有用,因为高频词往往不会存在拼写错误。
口 accuracy:这个选项取值范围是0~1,默认值是0.5。这个选项指定建议词和原词
的相似度。取值越高,相似度越高。这个值用于在计算编辑距离时与原始词做比较。
口 string distance:这个选项是个高级设置,用于指定计算词项相似度的算法。支持
以下算法: internal, damerau levenshtein, levenshtein, jarowinkler以及 ngram。
internal比较算法基于 Damerau levenshtein相似度算法的优化实现。 damerau
levenshtein是DamerauLevenshtein字符串距离算法(http://en.wikipediaorg/wiki/
Damerau-Levenshteindistance)的实现olevenshtein是Levenshtein距离算法(http:/∥
en.wikipedia. org/wiki/Levenshtein distance)的实现。 jarowinkler是Jaro- Winkler距
离算法(htt:/. wikipedia. org/wiki/Jaro- Winkler distance)的实现。 ngram是基于
n-gram距离的算法实现。
因为我们在之前已经用 term suggester做过示例,这里我们就不再演示如何使用
term suggester以及其响应信息的格式。你可以回到本节开头阅读这些信息。
5. phrase suggester
term suggester提供了一种基于单个词项的拼写纠错方法。然而,当我们想要得到短语
建议时,它就不能胜任了。所以我们引入了 phrase suggester.。 phrase suggester建立在term
suggester之上,并添加了额外的短语计算逻辑,因此可以返回完整的短语建议而不是单
个词项的建议。它基于n-gram语言模型计算建议项的质量,在短语纠错方面它是比term
suggester更好的选择。 n-gram方法将索引中的词项切分成gram。gram指由一个或多个字
母组成的单词片段。例如,我们将 mastering切分成 bi-grams(两个字母的 n-gram),切分结
果如下: ma as st te er ri in ng
③;你可以阅读后面这篇维基百科的文章来了解更多关于ngam模型的知识:htp
en.wikipedia. org/wiki/Language model#N-gram models第4章改善用户搜索体验129
(1)使用示例
在展示所有可能性之前,我们需要先配置一下 phrase suggester首先我们演示一下如
何使用它。我们可以执行如下命令,向 search端点发送一个仅含有 suggests片段的简单查
询请求:
curl -XGET 'localhost: 9200/wikipedia/ search?pretty
y!-d'{
"suggest": t
i text":"wordl war ii
"our- suggestion": t
"phrase":[
"fie1d”;"a11
333
这段代码几乎和使用 term suggester查询时的代码一模一样,只是用 phrase类型替代了
term类型。这段代码的响应信息如下:
"took":58,
I timed out false
shards
"tota1":5,
successful":5,
l failed": 0
shits
"tota1":7080049,
max score: 1.0,
Whits":[
"suggest": I
lour suggestion:
text:"wordl war ii
offset ":0
length":12
"options":[
ntext":world war iiI
" sCOre":7.055394E-5
ntext": " words war ii",
" score":2.3738032E-5
text:"wordy war iin
score":3.575829E-6130心深入理解 Elasticsearch
ntext: worde war ii
score":1.1586584E-6
text
oudl war i
score":1.0753317E-6
我们看到,响应信息也和 term suggester的响应信息非常相似。不过这里返回的是完整
的短语建议,而不是针对单个词项的建议。建议项列表默认按得分排序。我们同样可以在
phrase片段中配置附加参数。接下来我们就看看都有那些可用的配置选项
(2)配置
phrase suggester的配置项分为三组:基本参数,用来定义一般表现;平滑参数,用来
平衡 n-gram权重;候选者生成器参数,负责生成各个词项的建议列表,这些列表被用来生
成最终的短语建议。
法因为 phrase suggester是建立在 term suggester之上的,所以它可以使用term
suggester的一些配置选项,包括:text、size、 analyzer和 shard size。请参考本章
之前关于 term suggester的描述来了解这些参数的含义。
(3)基本配置
除了前面提到的这几个选项之外, phrase suggester对外提供如下基本配置项
口 highlight:该选项可设置建议项高亮处理。该选项需要结合 pre tag及 post tag属性
使用,这两个属性是可配置的,返回项将会被 pre tag和 post tag括起来。例如,这
两者可以被设置为<b>和</b>,返回项将会被显示为高亮。
口 gram size:这个选项指定与fld参数对应字段中存储的 n-gram的最大的n。如果
指定字段中没存储n-gram,这个值应该被设置为1,或者根本不用在请求中携带这
个参数。如果这个值没有设置, Elasticsearch会尝试自己去探测出正确的值。例如,
对于使用 shingle过滤器(htp:/ww. Elasticsearch. org/guide/ reference/index- modules
analysis/shingle- tokenfilter)的字段,这个值会被设置为 max shingle size属性的取
值(如果没有显式设置)。
口 confidence:使用这个选项可以基于得分来限制返回的建议项。选项值被作用到输入
短语的原始得分上(原始得分乘以这个值),得到新的得分。新的得分作为临界值用
于限制生成的建议项。如果建议项的得分髙于这个临界值,它可以被放入输出结果
列表,否则被丢弃。例如,取值1.0(本选项默认值)意味着只有得分高于输入短语第4章改善用户搜索体验心131
的建议项才会被输出。另一方面,设置为0.0表示输出所有建议项(个数受size参数
的限制),而不管它们的得分高低。
口 max errors:这个属性用于指定拼写错误词项的最大个数或百分比。取值可以是一个
整数,例如1、5,或者一个0~1的浮点数。浮点数会被解释成百分比,表示最多
可以有百分之多少的词项含有拼写错误。例如,0.5代表50%。而如果取值为整数,
比如1、5, Elasticsearch会把它当作拼写错误词项的最大个数。默认值是1,意思是
最多只能有一个词项含有拼写错误。
囗 separator:这个选项用于指定 bigram字段中词项间的分隔符。默认分隔符是空格。
口 force unigrams:这个选项用于指定拼写检査器是否强制使用一元语法模型
( unigram)。默认值为true。
token limit:这个选项用于指定建议列表最多可包含的词项数。默认值是10。设置
为更高的值能够提升建议精准度,不过需要付出性能下降的代价。
a collate:该选项允许用户检查特定查询(在 collat对象内部使用 query属性)或过滤
器(在 collate对象内部使用 filter属性)返回建议项的每一项。这里的查询或过滤实
际上是一个模板,对外暴露一个{ suggestion}变量,该变量代表当前正在处理的
建议。在 collate对象中添加 prune属性,将其值设置为tue, Elasticsearch将会将
建议项与查询或过滤器的匹配信息包含进来(这些信息被包含在返回结果的 collate
match属性中)。除此之外,如果使用了 preference属性,查询偏好信息也会被包含
进返回结果中(可使用普通查询中的同名参数的值)。
口 real word error likehood:这个选项用于设定词项有多大可能拼写错误,尽管它存在
于索引的词典中。选项取值是百分比,默认值为0.95,用于告知 Elasticsearch它的
词典中约有5%的词项拼写不正确。减小这个值意味着更多的词项会被认为含有拼
写错误,尽管它们可能是正确的。
现在,我们来查看一个范例,该范例中用到了上面所提及的这些参数。我们修改一下
之前的那个 phrase suggestion查询,添加粗体显示。命令如下:
curl -XGET 'localhost: 9200/wikipedia/ search?pretty! -d 1
"suggest":t
n text":wordl war ii
mour suggestion":t
"phrase":t
"f主e1d":ma11m
Highlight":
pre tag":"<b>",
"post tag": "</b>"132◆深入理解 Elasticsearch
collate
prune": true,
nquery
"match":t
title":"suggestion]
上面这个查询的返回结果如下所示
"took":3,
timed out": false,
shards
total: 5
l successfull: 5
failed":0
Whits":(
"tota1":7080049,
l max score": 1.0
wt ll
"suggest" :(
"our suggestion":[
ntext": wordl war ii"
offset
Ilength": 12
Options
ntext":"world war iit
highlighted":"<b>world</b> war ii"
" score":7.055394E-5,
l collate match" true
ntext: "words war ii
"highlighted":"<b>words</b> war ii,
" score":2.3738032E-5
l collate match": true
"text": "wordy war ii
highlighted": <b>wordy</b> war ii
" sCore":3.575829E-6,
collate match": t第4章改善用户搜索体验◆133
itext:worde war ii
"highlighted": "<b>worde</b> war iii
" score":1.1586584E-6,
l' collate match
true
text : "woudl war ii"
Highlighted":<b>woudl</b> war iin
" score":1.0753317E-6,
I collate match": true
(4)配置平滑模型
平滑模型( smoothing model)是 phrase suggester的一个功能。它的职责是平衡索引中
不存在的稀有 n-gram词元和索引中存在的高频n-gram词元之间的权重。这是个非常高级
的选项。如果你修改它,你应该检查一下查询建议的响应信息,看看它是不是满足你的需
求。平滑技术被用于语言模型中,用来避免某些词项的出现零概率的情况。 Elasticsearch的
phrase suggester支持多种平滑模型。
潜通过以下链接你可以了解更多语言模型的信息:htp:/ en. wikipedia. org/wiki
Language model
为了选择使用某个平滑模型,我们需要在请求中添加一个 smoothing对象,并让它包含
个我们要使用的平滑模型名称。当然我们也可以根据需要设置平滑模型的各种属性。例
如,我们可以执行如下命令:
curl-XGEr 'localhost: 9200/wikipedia/_search?pretty&size=0. '(
suggest":
text:wordl war ii
generators example suggestion":
"phrase
"analyzer ":"standard",
nfieldn: allm
"sm。 othing":
"linear": i
trigram lambda":0.1
bigram lambda": 0.6
unigram lambda": 0134◆深入理解 Elasticsearch
Elasticsearch共提供3种可用的平滑模型。让我们看看 Elasticsearch中可供 phrase
suggester使用的平滑模型。
Stupid backoff是 Elasticsearch的 phrase suggester默认的平滑模型。为了能够修改它
或强制使用它,我们需要在请求中使用它的名称 stupid backoff Stupid backoff平滑模型的
实现是这样的:如果高阶的 n-gram出现频率为0,它会转而使用低阶的 n-gram的频率(并
且给该频率打个折扣,折扣率由 discount参数指定)。举例来说,假定有一个 bigram ab和
一个 unigram C。ab和c普遍存在于我们的索引中,而索引中不存在 trigram abc。这种情况
下 Stupid backoff模型会直接使用ab二元分词模型,并且给它一个与 discount属性值相同
的折扣。
Stupid backoff模型只提供了一个 discount参数供我们调整。 discount参数的默认值是
04,被用来给低阶的 n-gram打折。
你可以访问以下网址来获取更多关于N元语法模型的信息:htp:/en. wikipedia.org/wiki
N-gram# Smoothing techniques以及htt: en. wikipedia. org/wiki/ Katz' s back- off model(该模
型和 stupid backoff模型类似)。
aplace平滑又称为加法平滑( additive smoothing)。当我们使用它时(为使用该模型
我们需要使用 laplace作为模型的名字),由 alpha参数指定的常量(默认值0.5)将被加到
词项的频率上,用来平衡频繁和不频繁的n-gram。之前提到过, Laplace平滑模型可通过
alpha参数进行配置。 Alpha参数默认值为0.5,取值通常等于或小于1.0
可以在http://en.wikipediaorg/wiki/Additivesmoothing这个网页中了解更多关于加法
平滑的信息。
线性插值是这里介绍的最后一种平滑模型。它使用配置中提供的 lambda值计算
trigram、 bigram及 unigram的权重。为了使用线性插值平滑模型,我们需要在查询对象中
指定 smoothing为 linear,并提供3个参数: trigram lambda、 bigram lambdaand unigram
lambda。以上3个参数之和必须为1。每个参数对应一种N元分词类型。比如, bigram
lambda将被用作 bigram的权重。
(5)配置候选生成器
为了给text参数文本中的每个term返回可能的建议项, Elasticsearch使用被称为候选
生成器的工具。你可以把候选生成器当作 term suggester来理解,不过实际上它们不是一回
事。它们很相似,因为它们都被用在每个单独term上。返回的候选term将和查询文本中其第4章改善用户搜索体验心135
他term的建议词的得分合并,通过这种方式最终生成短语建议。
直接生成器( direct generator)是目前 Elasticsearch中唯一可用的候选生成器,尽管在
未来可能会有更多其他的候选生成器加入进来。 Elasticsearch允许在一个短语建议请求中指
定多个直接生成器。我们可以通过设置名为 direct generators的列表来做到这一点。例如,
我们可以执行如下命令:
cur1-XGET 'localhost: 9200/wikipedia/search?pretty&size=0'-dI
"suggest":t
n text wordl war iin
"generators example suggestion": i
"phrase":I
"analyzer " "standard",
n field"
all l
direct generator " :
u field": m allm
"suggest mode":"always",
umin word len": 2
n field": all
"suggest mode":"always",
Imin word len": 3
响应信息和之前非常相似,我们在此不做展示。
(6)配置直接生成器
用于配置直接生成器行为的参数和 term suggester暴露的参数相似。它们共同参数有:
field(必选参数)、size、 suggest mode、 max edits、 prefix length、 min word len(这里默
认为4)、 max Inspections、 min doc freq、 max term freq。请查阅 term suggester相关内容
来了解这些参数的含义。
除了以上提及的配置属性,直接生成器还支持 pre filter和 post filter参数。这两个参
数可以用来向 Elasticsearch提供一个分析器的名称。 Pre filter参数指定的分析器用于处理
传人直接生成器的词项,而 post filter参数指定的分析器用于处理由直接生成器输出的词
项。处理操作在词项被传递给短语评分器( phrase scorer)之前进行。136心深入理解 Elasticsearch
我们可以使用直接生成器的过滤功能(通过设置 pre filter)来在建议项被传递给直接生
成器之前添加一些它们的同义词。例如,让我们更新一下 wikipedia索引的设置以支持简单
同义词,然后把这些同义词用在过滤功能中。使用下面这些命令:
curl -XPoST 'localhost: 9200/wikipedia/ close'
curl -XPUT 'localhost: 9200/wikipedia/ settings,-d ' i
"settings":
n⊥ndex";
" analysi日":
" analyzer":
sample synonyms analyzer: i
l tokenizer: " standard
filter #:
"sample synonyms"
"filter":I
"sample synonyms:i
type :synonym",
l synonyms":
war = conflicti
curl -xPoST 'localhost: 9200/wikipedia/ open'
我们需要先关闭索引,然后更新索引设置,再重新打开它,因为 Elasticsearch不允许
修改已打开索引的配置。现在可以测试直接生成器的同义词功能了。使用如下命令
curl -xGET 'localhost: 9200/wikipedia/ Bearch?pretty&size=0-d t
suggest":[
text": wordl war ii",
"generators with synonyms "
"phrase": I
analyzer:"standard",
"field":"all"
direct generator第4章改善用户搜索体验◆137
"fie1d":"a11",
"suggest mode":"always "
"post filter":"sample synonyms analyzer"
该命令响应结果如下:
took
47
timed out " false
hards
u total
5
l successful": 5.
failed: 0
hits
tota1":7080049
max score":0.0
"hits":[]
"suggest ":
"generators with synonyms ":[
ntext l l wordl war iil
offset: 0
"length": 12
"options ":[
ntext world war ii
" score":7.055394E-5
ntext words war iiI
score":2.4085322E-5
Itext:world conflicts ii",
score":1.4253577E-5
ntext: l words conflicts iil
score":4.8214292E-6
i text l
wordy war iin
sCOrE":4.1216194E-6
}]
可以看出,这里 phrase suggester返回的不是war词项,而是 conflict词项。这正是我138◆深入理解 Elasticsearch
们在本例中想要的效果。我们的同义词配置生效了。不过,请记住,同义词扩展发生在对
建议项打分之前,所以可能出现这种情况:同义词的建议项打分并不一定是最高的,你可
能无法在建议结果中看到它们。
6. completion suggester
Elasticsearch0.90.3版本的发布给予我们使用一个特殊 suggester的机会,该 suggester
基于前缀匹配。使用该 suggester我们可以很容易开发出自动完成功能,因为复杂的数据结
构都存储在索引中,不用在查询时实时计算。尽管这个高效的 suggester不是关于拼写纠错
的,我们还是认为,用一个简单示例来介绍一下它将会对你有所帮助。
(1) completion suggester背后的逻辑
基于前缀的 suggester构建在一种称为FST( Finite State Transducer)(htp:/en. wikipedia
org/ wiki/Finite state transducer)的数据结构之上。它十分高效,但是构建它的资源消耗却
非常显著,特别是在拥有大量数据的时候。如果我们在某些节点上构建这些数据结构,每
当节点重启或集群状态变更时,都会付出性能代价。鉴于这个问题, Elasticsearch的设计者
们决定在索引过程中创建类似FST的数据结构,并把它存储在索引中,在需要的时候可以
把它加载进内存。
(2)使用 completion suggester
为了使用基于前缀的 suggester,我们需要使用 completion类型的字段来索引数据。这种
类型的字段可以在索引中存储类似FST的数据结构。为了展示这个 suggester的使用,假设我
们要添加一个针对书籍作者的自动完成功能。除了作者名称外,我们还想返回该作者所写的
书的ID,我们通过一个额外查询来查找这些数据。首先使用如下命令建立 authors索引:
curl -XPOST 'localhost: 9200/authors'-d 't
"mappings": t
m author l
"properties":(
nname
i"type":"string"]
"ac":{
"type":"c。 plation
"index analyzer ":"simple",
"search analyzer":"simple",
"payloads":true第4章改善用户搜索体验139
该索引包括一个名为 author的类型。每个文档有两个字段:name和ac。name宇段存
储作者名字,ac字段是我们用来实现自动完成的字段。这里我们关心的是ac字段。我们定
义它为 complete类型,该类型表示在索引中存储类似FST的数据结构。我们在索引和查询
时都使用 simple分析器。最后需要提及的是 payload附加信息,它将伴随查询建议一起输
出。本例中 payload是书籍ID的数组。
淒将要使用自动完成功能的字段,其类型是强制提供的,必须是 completion。默认情况
下, search analyzer和 index analyzer设置为 simple,而 payload属性设置为 false
(3)索引数据
为了索引数据,我们需要提供一些额外信息。让我们看看下面这个命令,该命令将索
引两个描述作者信息的文档:
curl-xPOST localhost: 9200/authors/author/11-d
name":"Fyodor Dos toevsky r
ac
input":["fyodor","dostoevsky I
"output":"Fyodor Dostoevsky "
payload":{" books":["123456","123457"]}
curl -XPOST 'localhost: 9200/authors/author/2-di
" name":"Joseph Conrad",
"ac":{
input":[ "joseph","conrad"]
"output":"Joseph Conrad
" payload":{" books":["121211”]}
注意一下ac字段的数据结构。我们提供了 Input、 output和 payload属性。 payload属性
用于提供査询返回的额外信息。 Input属性提供的数据用于构建类FST数据结构,还用来匹
配用户输入,以决定当前文档是否需要被返回。 output属性用于告知 suggester返回文档中
应包含什么数据。
③请记住, payload必须是一个JsoN对象,以“{符号开头并以}”符号结尾。
如果你的 Input和 output属性取值相同,且不需要存储 payload,那么你可以如平常一
样索引数据。例如:可使用如下命令索引前面例子中的第一个文档:140◆深入理解 Elasticsearch
curl -XPOST 'localhost: 9200/authors/author/3-d i
name":"stan⊥ aw Lem
ac
stanislaw Lem"]
(4)查询数据
最后我们看看如何查询刚刚索引的数据。假如我们想要找到作者名以fyo开头的文档
可以使用如下命令:
curl -xGET 'localhost: 9200/authors/suggest?pretty -d .t
mauthorsAutocomplete":
text": Eyo
completion":(
field": "acl
在查看结果之前,我们先探讨一下查询本身。可以看出,我们发送请求的目标是
suggest端点,因为我们在这里不想发送一个标准查询,而仅仅对自动完成结果感兴趣。查
询的其他部分和标准的建议查询如出一辙。查询类别需要设置为 completion
之前命令的执行结果如下:
ul shards ir
n total": 5
"successful":5.
u failed": 0
"authorsAutocomplete ":[
n text
offset":0,
"length":3,
"options ":[
u text
l Fyodor Dostoevsky
score 10r
"pay1oad":{" books":["123456”,"123457"]}
}]
可以看出,我们从响应中获得了想要的文档。文档中包括 payload信息, payload包含
了某作者的图书的ID(列表)。
5)自定义权重
默认情况下,词项频率( term frequency)将被基于前缀的 suggester作为文档权重。然第4章改善用户搜索体验心141
而,当你拥有多个索引分片或者你的索引由多个索引段组成时,这可能不是最好的方案。
在这些情况下,自定义权重是有价值的。一般通过给 completion类型的字段指定 weight属
性来实现。 weight属性取值应该设置为整数,而不是浮点数,与査询 boost、文档 boost的
情况类似。 weight取值越大,建议项的重要性越大。这项功能绐予我们很多调整建议项排
序的机会。
例如,假定我们想要给前面例子中的第一个文档指定权重。使用如下命令
curl-XPOST 'localhost: 9200/authors/author/1-d t
" name":"Fyodor Dos toevsky
ac":{
input":[ "fyodor", "dostoevsky 1,
output" :"Fyodor Dos toevsky
" payload":{" books":["123456","123457"]},
eight
80
然后,如果执行刚才的查询,结果将是
shard
total
5
l successful: 5
failed
authorsAutocomplete:[
n text: "Eyo r
offset": 0
" length":3,
"options":[I
"text" :"Fyodor Dostoevsky ',
" score":80.0,
→)1y1oad":{" books":"123456”,123457"]
查看一下返回结果得分的变化。在最初的例子中,得分是1.0,而现在得分是80.0。因
为我们在索引时设定 weight参数为80
(6)额外参数
基于前缀的 suggester还有3个额外参数我们尚未提及: max input length、 preserve
separators和 preserve position Increments。后两个属性都可以设置为true或 false。如果把
preserve separators设置为 false, suggester将忽略如空格之类的分隔符(当然,需要合适
的分析器)。而如果建议项的第一个单词是停用词并且我们使用了过滤停用词的分析器,则142深入理解 Elasticsearch
需要把 preserve position increments设置为 false。例如,文档内容为“ The clue”,这时
The”将被分析器丢弃。通过设置 preserve position Increments为flse, suggester将可以
通过查询“c”来返回这个文档。
而 max input length参数默认设置为50,该属性确定了能输入的最大的UTF-16字符
串长度。该属性用于索引期限制内部结构能存储的最大字符数。
4.2改善查询相关性
事实上,包括 Elasticsearch在内的搜索引擎通常都是用来提供搜索服务的。某些特定
情况下,只需要查看索引的一部分数据,更一般的情况下我们需要使用查询相关的所有数
据,因而引入了评分机制。我们在2.1节中也提到过这一点。 Elasticsearch利用了 Apache
Lucene本身的评分功能,并允许我们使用多种查询类型来控制查询结果的得分。我们甚至
可以修改底层评分算法,这一点我们将在第6章中提到。
有了这些功能之后,在设计查询时,我们通常可以找到最简单的查询来满足查询需求。
尽管我们可以在 Elasticsearch中做很多事,但一旦涉及评分控制,这些查询的结果可能就
不是最有利于提升用户搜索体验了。这是因为 Elasticsearch猜不出我们的业务逻辑是什么,
也不知道从我们使用者的角度看,哪些文档是最好的。本节我们将追踪一个实际的查询相
关性调优的例子。我们想让本章内容稍微有些与众不同,不是简单地把知识点告诉你,而
是提供一个关于查询调优过程运作的完整示例。尽管本节某些例子是通用的,在你把它们
移植到自己的应用中时,请确保它们有实际意义。
这里给一点小小的剧透,我们首先将执行一个简单的查询并返回我们想要的结果,然
后修改这个查询,引入不同的 Elasticsearch查询来使结果更好,我们会使用过滤器,还会
降低垃圾文档的得分,之后我们将引入切面计算,用来提供下拉菜单让用户缩小查询结果
范围。
4.2.1数据
当然,为了展示查询修改后的返回结果,我们需要数据。我们乐于分享现实工作中的
真实数据,不过我们不能这么做,原因可想而知。不过还有另一个解决办法:为了本节的
演示目的,我们决定索引 Wikipedia的数据。为了做到这一点,我们需要重复使用与41节
中相同的那个 Wikipedia rivero
如果不存在名为 wikipedia的索引, Wikipedia river将为我们创建。不过,该索引已经
存在了,我们需要删掉它。尽管使用了相同的索引,但是索引字段需要做一些调整,因为
我们需要添加一些额外的分析逻辑,另外为了重新索引数据,需要先创建索引。第4章改善用户搜索体验143
洼添加新 river前需要移除旧 river。为了移除旧iver,需要执行下面这个命令:curl
XDELETE 'localhost: 9200/ river/wikipedia river
为了重新导入文档,需执行下面这个命令:
curl-XDELETE ' localhost: 9200/wikipedia
curl -XPOST 'localhost: 9200/wikipedia'-d't
"settings":[
"index":[
m analysis"
analyzer
keyword ngram":i
Filter":
L。 encase
tokenizer": ngram"
"mappings":I
page:
"properties":
category
type": string
n fields:
untouched
type":"string"
mindex":"not analyzed"
"disambiguation":
type":"bo。1ean
"link":i
type":"string
windex": "not analyzed"
redirect n
type": "boolean"144◆深入理解 Elasticsearch
redirect page":
ype":"string
"special":I
n type":"boolean"
"stub":t
type":"boolean"
tex七
ype":"string
title":i
type":string
f⊥e]dg":{
"ngram": t
type
tring
"analyzer": "keyword ngram"
"simple: I
type":"string
analyzer": "simple"
现在我们在索引中创建了一个page类型的映射,用它来表示一个 Wikipedia的页面。
我们将在两个字段中执行查询:text和 title text字段存储页面内容,而titl字段存储页面
标题
接下来我们需要启动 Wikipedia river。我们想要获得最新的数据。使用如下命令来实例
化 river并索引数据:
curl-XPUT ' localhost: 9200/river/wikipedia/ meta'-d ' I
n type":#wikipedi
以上就是我们要做的全部操作。 Elasticsearch将自动把最新的 Wikipedia数据索引到名
为 wikipedia的索引中。我们只须耐心等待即可。不过,我们显然不够耐心:我们决定仅索第4章改善用户搜索体验心145
引前1000万文档。当 river索引的页面数量达到这个值时,我们就停止 river。通过执行如
下命令检查最终的文档数:
curl -xGET 'localhost: 9200/wikipedia/ search?q=*&size=0&pretty
响应结果如下:
I took": 5,
t timed out false
i shards":i
total
5
I successfull: 5
n failed 0
whits
"tota1":10425136,
I max score
:0.0
whits
可以看出,一共索引了10425136个文档
注在运行本章中的示例代码时,请注意,我们用来建立索引的数据是随着时间不断变
意化的。因此本章这些示例的结果可能和书中描述的不一样。
4.2.2改善相关性的探索之旅
准备好索引数据后,我们就可以搜索了。我们从头开始,先使用一个简单查询来获取
感兴趣的结果,然后再尝试逐渐改善查询相关性。我们还将关注查询性能的改变,这些改
变在我们优化相关性过程中很可能发生。
1.标准查询
如你所知, Elasticsearch默认把文档内容存入_all字段中。既然这样,我们为什么还要
为如何同时查询多个字段伤脑筋呢?仅仅使用一个all字段就可以了,对吗?按照这个思
路,假定我们构建了如下査询,并使用它来获取感兴趣的数据:
curl-XGET localhost: 9200/wikipedia/ search?fields=titlespretty'-d'
n query
natch"
"a11":{
query :"australian system"
operator "OR"146心深入理解 Elasticsearch
因为我们只想获取it字段的内容(因为tte字段设置为不存储, Elasticsearch将使
用 source字段来返回ttle字段的内容),我们在命令中添加了 fields=ile请求参数。当然,
我们还希望结果是方便人类阅读的,因此还添加了pret参数。
然而,结果并不是如我们期望的那样完美。返回结果第一页中的文档如下:
Australian Honours System
List of Australian Awards
Australian soccer league
Australian football league system
AANBUS
Australia Day Honours
Australian rating system
TAAATS
Australian Arbitration system
Western Australian Land Information System (WALIS)
来看一下文档标题。发现某些同时包含两个词项的文档被排在了后面。这个搜索结果
多少有些差强人意。让我们来尝试改善一下。
2.多匹配查询
首先我们要做的是,不再使用_al字段,因为我们想让 Elasticsearch明白各字段的权
重。例如,在这里ttle字段比存储页面内容的text字段更重要。为了让 Elasticsearch明白
这一点,我们需要使用 multi match查询。发送如下命令给 Elasticsearch:
curl-xGET localhost: 9200/wikipedia/ search? fields=title&pretty'-d'
query
"multi match":
"query ":"australian system
H￡ie1ds":[
mtitle100",
n text 10,
allm
返回结果第一页中的文档如下(完整的响应内容保存在随本书一起提供的 response第4章改善用户搜索体验心147
query_multi match.json文件中):
Australian Antarctic Building System
Australian rating system
Australian Series System
Australian Arbitration system
Australian university system
Australian Integrated Forecast System
Australian Education System
The Australian electoral system
Australian preferential voting system
Australian Honours System
在这里我们舍弃了针对单个all字段的查询,转而选择同时查询 title、text和all字段。
我们还做了加权处理: boost值越大,则该字段越重要(字段 boost的默认值为1.0)。我们
在此声明tl字段比text字段重要,text字段比al字段重要。
再回头看查询结果,它们看起来比之前的结果更相关了,不过还是没有我们期望的那
样好。例如,比较一下前两个文档,第1个文档的标题是“ Australian Antarctic Building
System”,而第2个文档的标题是“ Australian rating system”。我希望第2个文档的得分更高。
3.引入短语查询
接下来我们应该想到的是引入短语查询。短语查询可以搞定刚才描述的问题。不过,
我们还是希望能够在与短语匹配的查询结果后面列出那些没有包含完整短语的结果。为此,
我们需要修改查询,在最顶部加上一个布尔查询( bool query)。当前的查询将放入must区
域,短语查询将放在 should区域。修改后的查询示例如下:
curl-XGET 'localhost: 9200/wikipedia/ search?fields=title&pretty -d.
query
Mbool"
must": D
mu1t主 match"
query":"australian system",
fields":[
ntitle100"
text 10
a11
should":[148
深入理解 Elasticsearch
"match phrase":t
title":"australian system"
"match phrase":i
text": "australian system"
查询结果的前几条如下:
Australian honours system
Australian Antarctic Building System
Australian rating system
Australian Series System
Australian Arbitration system
Australian university system
Australian Integrated Forecast System
Australian Education System
The Australian electoral system
Australian preferential voting system
尽管结果比之前的要好一点,不过与我们的期望还是有点距离。因为没有找到和所有
短语匹配的记录。我们可以考虑引入slop参数。slop参数用来设置单词间的最大间隔,在
最大间隔之内的单词可以被认为与查询中的短语匹配。例如,我们这里使用的“ australian
system”短语查询,如果设置slop为大于等于1的数,可以和标题为“ australian education
system”的文档匹配上。让我们执行一条带slop参数的查询命令:
curl-xGET localhost: 9200/wikipedia/ search?fields=title&pretty'-d'
"query":(
"bool":t
nmust#:
"multi match": I
query":"australian system",
fields":
t⊥t1e^100
n text 10第4章改善用户搜索体验心149
a11
n should"
"match phrase":I
t主t]e":{
"query": "australian system",
"s。p":1
"match phrase":
text日
query":"australian system"
"81op":1
现在再看看结果(完整响应内容保存在随本书一起提供的 response query phrase slop
json文件中)
Australian Honours System
Australian honours system
Wikipedia: Articles for deletion/Australian university system
Australian rating system
Australian Series System
Australian Arbitration system
Australian university system
Australian Education System
The Australian electoral system
Australian Legal System
看起来结果变得更好了。不过,我们还可以通过更多调整来查验结果是否能够变得更好。
4.扔掉垃圾信息
现在我们可以做的是设法移除查询结果中的垃圾信息。我们需要移除重定向页面和特150◆深入理解 Elasticsearch
殊文档(例如,那些被标记为已删除的文档)。我们在这里引入一个过滤器。过滤器的引入
不会干扰其他文档的排序(因为过滤器不具备评分功能),反而可以缓存被过滤的结果(这
点由 Elasticsearch自动完成),并使这些结果能够被之后的查询再次使用。带过滤器的查
询命令如下:
curl -XGET ' localhost: 9200/wikipedia/ search?fields=title&pretty'-d'
query
￡i1 tered";{
querys
Mbool
nmust h
u multi match"
query": "australian system",
fields":
七主t1e^100"
n text10
all
should":[
match phrase":
title#:
"query": "australian system",
1°p
Imatch phrase:
n text
query":"australian system",
Blo
1第4章改善用户搜索体验◆151
n filter l
bool"
nmust not
term":
redirect": true
n term
n special":" true"
命令的响应结果如下:
Australian honours system
Australian Series System
Australian soccer league system
Australian Antarctic Building System
Australian Integrated Forecast System
Australian Defence Air Traffic System
Western Australian Land Information System
The Australian Advanced Air Traffic System
Australian archaeology
Australian Democrats
结果变得更好了,不是吗?事实上还可以继续提高査询相关性。
5.现在引入 boost
如果需要调整短语查询的权重,可以用 function score查询把短语查询包装一下。例
如,假如我们想将一个针对 title字段的短语査询的权重设置为1000,可以调整之前查询的
下面这个部分
n match phrase "
"title":I
"query ":"australian system",
slop152◆◆深入理解 Elasticsearch
它将被调整为以下内容:
I function score"
nl boost factorl: 1000
query:
match phrase":(
title
query :australian system"
"s1op":1
在经过调整后,带有短语的文档的得分将高于之前的得分,但这留给读者去测试。
6.创建一个可纠正拼写错误的查询系统
回头看一下索引的映射配置,你将发现有一个tite字段被定义为 multi field类型,
而其中的一个字段需要被 ngram分析器做分词处理。默认情况下, ngram分析器会产生
bigram,例如,对于单词 system,将生成 sy ys st te em等几个 bigram。想象一下,我们可
以在查询时忽略其中的一些分词结果,从而使我们的查询系统具备自动纠正拼写错误的能
力。我们用一个简单的查询来演示具体该怎么做:
curl-XGET localhost: 9200/wikipedia/ search?fields=title&pretty'-d'
n query
"query string": I
" query": "australia
default field: titlem
"minimum should match":#100%
返回的查询结果如下:
"took":10,
timed out": false,
shards":[第4章改善用户搜索体验◆153
"tota1":5,
l successfull: 5
n failed": 0
shits
"tota1":0,
" max score": null,
Whits":[]
在这里我们针对 title字段发送了一个带有错误拼写的查询命令。因为索引中没有和拼写
错误词项完全匹配的文档,我们什么也没得到。然后我们转而使用 title. ngram字段,并忽略
一些 bigram,这样 Elasticsearch就可以找到一些匹配的文档了。修改后的查询命令如下:
curl-XGET ' localhost: 9200/wikipedia/ search?fields=title&prettyl-d'
query
"query string": I
query":" austre1主an
"default field":"title. ngram
"minimum should match":85%
在这里我们把 default field属性由 title改为 title. ngram,从而让 Elasticsearch使用会生
成 bigram的字段。另外,我们还引入了 minimum should match,把它设置为85%。这个
设置的意思是让 Elasticsearch知道,我们并不想要所有的 bigram分词结果都匹配上,而是
匹配它们中的一部分,我们也不关心具体哪些词项会被匹配。
凄调小 minimum should match的取值,我们将得到更多的文档,不过会降低精度。
相反,调大它的取值,我们将得到较少的文档,不过返回的文档中会包含更多匹配
到的 bigram分词结果,因此相关性更高
查询结果的前几条如下:
Aurelia (Australia
Australian Kestrel
Austrlia
Australian-Austrian relations
Australia-Austria relations
Australia-Austria relations
Australian religion
CARE Australia154◆深入理解 Elasticsearch
Care Australia
Felix Austria
如果你想要了解使用 Elasticsearch的 suggester来做拼写检查的相关知识,请查阅4.1节。
7.继续探讨切面计算
最后我们想要讨论的话题是切面计算( faceting)。你可用切面计算同时做好几件事,比
如计算直方图、字段统计、地理距离范围等。不过,只有词项切面计算( terms faceting)能
够切实帮助用户获取想要的结果。例如,在amazon.com的搜索框中输入“kidsshoes”,你
将看到类似下面的截图:
amazon Your Amazon. com Today's Deals I Gin Cards sell Help
Try Prime
shop by
Departments
Departments
"kids shoes
Shoes
Related Searches: boys shoes, giris shoes, toddler shoes
Boys' Sneakers
is’ Sneakers
Showing 1-16 of 70, 717 Results
Boys' Running Shoes
Girs’ Running shoes
Top Results for " kids shoes
Girls'Sport Sandals
See more
See All 31 Departments
Shipping Option what's this?)
Free Super Saver shipping
Brand
U New Balance
L Puma
Boys' Sneakers Boys' Running Shoes Girls' Sneakers Girls Running shoe
D DC
O Keen
Puma Voltaic 3 V Kids Running Shoe (Toddler/!
D Timberland
$2500-$6991·h
☆☆☆☆☆回
U Reebok
Eligible for FREE
Saucony
Some sizes/cold
O Skechers
Shoes, See al 2
D Tsukihoshi
See visually sim
b TOMS
O Stride Rite
你可以通过选择页面左侧的品牌来缩小结果范围。品牌列表不是静态的,而是基于搜
索结果动态生成的。我们也可以通过 Elasticsearch的词项切面计算达到同样的效果。
②溘请记住,我们同时使用切面计算及合计算术滴示查询:初面计算以楼度,
lasticsearch
算,我们还是使用同一个查询的不同变体来演示范例。
让我们回到之前的 wikipedia数据。假定用户可以在初次查询后通过选择文档分类来缩
小结果范围。为了达到这一目的,我们需要在查询中加入 facets设置(为了简化示例,我们
使用 match all e询替换之前的复杂查询),新的查询命令如下:第4章改善用户搜索体验“155
curl - 'localhost: 9200/wikipedia/ search?fields=title& -d 't
query:
match all#
n facets":
"category facet":(
"terms":I
field":"category. untouched",
B⊥ze":10
在这里,词项切面计算基于已经索引的数据。我们选择在 category. untouched字段上
执行切面计算。如果选择在 category字段上执行切面计算,则结果中只有一个单独的词项,
而我们想要完整的分类。查询结果的切面计算结果部分如下(完整内容保存在随本书一起提
供的 response query facets. json文件中)
i facets
"category_ facet "
type: terms
missing": 6175806
i tota1":16732022,
" other":16091291,
terms h
term":"Living people
nt":483501
nterm": " Year of birth missing (living people)",
" count":39413
term":"English-language films"
" count":22917
nterm": "American films l
n count I
16139
wterm": Year of birth unknown",
" count":15561
n term"
n The Football League players
" count":14020
term": "Main Belt asteroids"
" count":13968
'term":"Black-and-white films ll156
深入理解 Elasticsearch
" count":12945
nterm":"Year of birth missing",
I count 12442
wterm":"English footballers
l count: 9825
}
默认情况下,切面计算结果按 count属性降序排列。 count属性代表特定类别的结果数
量。当然,我们也可以使用如下基于聚合的查询:
curl-xGET localhost: 9200/wikipedia/ search?fields=title&pretty! -d ' t
"query": I
"match all
}
maggs":I
m category agg": I
n terms
field":"category. untouched",
日⊥ze":10
现在,如果我们的用户想将返回结果缩窄至 English- -language电影类别,可使用下面这
个查询:
curl -xGET .localhost: 9200/wikipedia/ search?fields=title&pretty'-d't
"query":[
mf⊥1 tered:
" query": I
"match all":
Hf⊥1tex":
u term"
category. untouched":"English-language films"
u facets"第4章改善用户搜索体验157
"category facet": I
"terms":I
field":"category. untouched",
n size: 10
我们修改了查询,使之包含了一个过滤器,过滤器过滤的文档将会做切面计算处理。
当然,也可通过下面这个聚合查询来实现同样的目的:
curl-XGET 'localhost: 9200/wikipedia/Bearch?fields=title&pretty'-di
w query:
n filtered
query":I
Mmatch all"
"filter: I
u term
category. untouched":"English-language films"
"aggs":t
m category agg
terms":I
field":"category. untouched",
⊥ze":10
43小结
本章我们学习了如何通过 term suggester和 phrase suggester来纠正用户的拼写错误。因
此,我们已经掌握了避免因拼写错误产生空白页的技巧。另外,我们通过改进查询相关度
来改善了用户搜索体验。我们从一个简单查询开始,然后逐步添加了多匹配查询、短语查
询、査询权重( boost)、查询间距( query slop)等功能。我们还展示了如何过滤掉垃圾结果,158◆深入理解 Elasticsearch
以及如何优化短语匹配的权重设置。我们使用n- grams分词代替 Elasticsearch的 suggester
来避免拼写错误。我们还探讨了使用切面计算来缩小搜索结果范围,从而简化用户找到想
要文档或产品的途径。
下一章我们将探讨与性能相关的话题。最开始,我们会讨论 Elasticsearch中的可扩展
性。之后将了解如何为集群部署选择合适的分片数及副本数,以及剖析路由( routing)是
如何帮助系统部署的。紧接着将研究如何更改默认的分片分配逻辑以满足应用需求。最后,
将了解 Elasticsearch提供了哪些查询执行逻辑,以及如何控制它来完美地适应我们的部署
目标及索引架构。国D器翻
器篱腰题
额
第5章Cy5
分布式索引架构
在上一章,我们聚焦于改善用户搜索体验。我们首先使用了词项和短语建议器来改正
用户査询中的拼写错误,然后使用自动完成建议器实现了高效的、基于索引的自动完成
功能。最后,我们还了解了 Elasticsearch调优的一些知识。我们以一个简单查询开始,逐
渐添加多匹配査询、短语查询、调整权重以及査询间隔等功能。我们学习了如何过滤掉垃
圾结果,以及如何改善短语查询的效果。我们使用n- grams来避免拼写错误,并把它作为
Elasticsearch查询建议器的一种替代方法。我们还探讨了如何使用分组查询来筛选查询结
果,从而简化用户找出期望文档或产品的途径。到本章结束时,将涵盖以下内容:
口选择合适的分片数和副本数
口路由
口分片分配行为的微调
口利用查询执行偏好
51选择合适的分片和副本数
当你开始使用 Elasticsearch时,大概会先创建索引,往索引中导入数据,然后开始执
行查询。我们很确定开始的时候一切都很顺利,至少在数据量不大和查询压力不是很高的
时候。在后台, Elasticsearch会创建一些分片和适当数量的副本(如果使用默认配置的话),
般情况下你也不会在部署时过多关注这部分的配置。
随着应用程序的成长,你不得不索引越来越多的数据,每秒钟处理越来越多的请求。160◆◆深入理解 Elasticsearch
这个时候一切都变了,问题开始出现了(可阅读第8章的内容来了解如何应对应用程序的扩
张)。现在应该考虑如何规划你的索引及其配置,使它们适应应用的变化。在本章里,我们
将给出如何处理这个问题的一些指导方针。不幸的是没有确切的秘诀,每个应用程序都有
各自的特性和需求,不仅索引结构依赖于此,配置也依赖于此。例如,文档或者索引的大
查询类型以及期望的吞吐量都是其影响因素
51.1分片和过度分配
读者已经在1.2节中了解了索引分片的相关概念,不过在这里我们还是来回忆一下。
分片是将一个 Elasticsearch索引分割成一些更小的索引的过程,我们能够在同一集群的
不同节点上散布它们。在查询的时候,结果汇总了索引中每个分片的返回结果(有时可能
不是真的汇总,因为可能某个分片上就包含了所有感兴趣的数据)。 Elasticsearch默认为
每个索引创建5个分片,即使在单节点环境下也是如此。这种冗余被称作过度分配(over
allocation)。目前看起来这么做是完全没有必要的,反而在索引文档(散布文档到各个分
片)和处理査询(査询多个分片并合并结果)时增加了复杂性。幸运的是,这种复杂性被
Elasticsearch自动处理了。既然如此, Elasticsearch为什么还要这么做呢?
例如说我们有一个且仅有一个分片的索引。这意味着当应用程序的增长超过了单一服
务器的容量时,我们会遇到问题。当前的 Elasticsearch版本还无法将索引分割成多份,我
们必须在创建索引时就指定好需要的分片数量。我们所能做的只有创建一个拥有更多分片
的新索引,并重新索引数据。然而,这样的操作需要额外的时间和服务器资源,例如CPU
内存和大量的存储。我们可能根本就没有前面提到的时间和资源。另一方面,当使用过
度分配时,我们可以仅仅增加一台安装了 Elasticsearch的服务器, Elasticsearch会重新平
衡( rebalance)集群,将部分索引迁移到新的机器上,不需要额外的重新索引数据的开销。
Elasticsearch设计者选择的默认配置(5个分片和1个副本)在数据量增长和多分片搜索结
果合并之间做了平衡。
默认的5个分片是标准用法。那么问题就来了:什么时候我们需要用更多的分片,或
者与之相反,使用尽可能少的分片数量?
第一个答案很明显。如果你有一个有限的和明确的数据集,你可以只使用一个分片。
如果没有,那么依照经验,最理想的分片数量应该依赖于节点的数量。因此,如果你计划
将来使用10个节点,你需要给索引配置10个分片。需要记住的一点是:为了保证高可用
和查询的吞吐量,我们同样需要配置副本数,而且它跟普通的分片一样需要占用节点上的
空间。如果每个分片有一份额外的拷贝( number of replicas等于1),你最终会有20个分
片。10个包含主数据,10个是其副本。
总的来说,节点数和分片数、副本数的简单计算公式如下:第5章分布式索引架构心161
所需最大节点数=分片数*(副本数+1)
换句话说,如果你计划使用10个分片和2个副本,那么所需的最大的节点数是30。
512一个过度分配的正面例子
如果你仔细阅读了本章前面的部分,你就会有一个强烈的信念:我们应该使用最少数
量的分片。但是有时拥有更多的分片有其便利之处,因为一个分片事实上是一个 Lucene索
引。更多的分片意味着每个在较小的Lucn索引上执行的操作会更快(尤其是索引过程)。
有时这是一个使用更多分片的很好的理由。当然,将查询分散成对每个分片的请求,然后
合并结果,这也是有代价的。这个对于使用固定的参数来过滤查询的应用程序是可以避免
的。有这种现实的案例,例如那种每个查询都在指定用户的上下文中执行的多租户系统。
原理很简单,我们可以将每个用户的数据都索引到一个独立的分片中,在查询时就只查询
那个用户的分片。这时需要使用路由(我们将在52节中详细讨论它)。
51.3多分片与多索引
你可能会奇怪,如果一个分片事实上是一个小的 Lucene索引,那么什么才是真正的
Elasticsearch索引?拥有多个分片和拥有多个索引有什么不同?从技术上讲,它们的区别不
大,而且对于某些应用场景来说,使用多个索引是更好的选择(例如,将基于时间的数据如
日志等索引到以时间段切分的不同索引中)。如果使用拥有多个分片的单个索引,某些时候
可以通过路由把查询定位到一个分片上。而如果使用多个索引,你可以有机会选择只在那
些感兴趣的索引上执行查询,比如,通过名称为logs2014-10-10、logs_2014-10-11…
这
样的方式来选择基于时间区间构建的索引。更多的不同可以在分片和索引的平衡逻辑上看
出来,尽管可以人为配置两者的平衡逻辑。
5.1.4副本
分片处理使我们能存储超过单节点容量的数据,而使用副本则解决了日渐增长的吞吐
量和数据安全方面的问题。当一个存放主分片的节点失效后, Elasticsearch能够升级一个可
用的副本为新的主分片。默认情况下, Elasticsearch只为每个索引分片创建一个副本。然而,
不同于分片处理,副本的数量可以通过使用相关API随时更改。该功能让构建应用程序变
得非常方便,因为我们的查询吞吐量随着用户的增长而增长,而使用副本则可以应对增长
的并发查询。增加副本数目可以让查询负载分散到更多机器上,理论上可以让支持处理更
多的并发请求。
使用过多副本的缺点也很明显:额外副本占用了额外的存储空间,构建索引副本的开
销。当然,主分片及其副本之间的数据拷贝也存在开销。在选择分片数量的时候你应当同162◆深入理解 Elasticsearch
时考虑所需要的副本数量。如果选择了太多的副本,可能会耗光磁盘空间和 Elasticsearch
的资源,而事实上这些副本很多时候根本不会用到。另一方面,如果不创建副本,当主分
片发生问题时,可能会造成数据的丢失。
52路由
在5.1节中,我们提到过路由是限定查询在单个分片上执行的一个解决方案。现在是时
候进一步介绍该功能了。
521分片和数据
通常情况下, Elasticsearch将数据分发到哪个分片,以及哪个分片上存放特定的文档
是不重要的。査询时,请求会被发送至所有的分片,所以最关键的事情就是使用一个能均
匀分发数据的算法,使得每个分片都包含差不多数量的文档。我们并不希望某个分片持有
99%的数据,而另一个分片持有剩下的1%,这样做极其低效。
而当我们想删除文档或者增加一个文档的新版本时,情况就有些复杂了。 Elasticsearch
必须确定哪个分片需要更新。尽管看起来挺麻烦,实际上,这并不是一个大问题。只要分
片算法能对同一个文档标识符永远生成相同的值就足够了。如果我们有了这样一个算法,
Elasticsearch在处理一个文档时就知道该去找哪个分片了。
另外,某些时候我们希望把数据的一部分索引到相同的分片上。举例来说,我们希
望将特定类别的书籍都存在一个特定的分片上,在查询这类书时我们可以避免查询多
个分片及合并搜索结果。这时候,因为我们确切地知道路由时使用的取值,就可以把
Elasticsearch引导到与索引时相同的分片上。这就是路由要做的事情。它允许我们提供信息
给 Elasticsearch,然后 Elasticsearch用这个信息来决定哪个分片用来存储文档和执行查询。
相同的路由值总是指向同一个分片。换个说法就是:“之前你使用某个路由值将文档存放在
特定的分片上,那么搜索时,也去相应的分片查找该文档。”
522测试路由功能
现在向读者展示一个例子,用来演示 lasticsearch是如何分配分片,以及如何将文档
存放到特定的分片上。在这里,我们将使用一个额外的插件,名为 paramedic,它能帮助我
们查看 Elasticsearch到底对数据做了什么。可使用下面的命令来安装 paramedic插件:
bin/plugin -install karmi/elasticsearch-paramedic
重启 Elasticsearch后,可以通过浏览器访问htp:/ localhost:9200/ plugin/ paramedic
index hmtI,然后会看到一个页面,上面有索引相关的各种统计量和其他信息。对于我们的第5章分布式索引架构◆163
例子来说,最令人感兴趣的信息是象征集群状态的集群颜色和每个索引的分片和副本列表。
现在启动两个 Elasticsearch节点,然后用下面的命令创建一个索引:
curl -XPUT ' localhost: 9200/documents.-d
"settings":t
"number of replicas":0
nnumber of shards#: 2
我们创建了一个只有两个分片但是没有副本的索引。这意味着集群最多可以有两个节
点,接下来的节点将不能填充数据,除非我们提高副本的数量(可参考5.1节)。下一步操
作是索引文档,我们使用下面一系列命令:
curl -XPUT localhost: 9200/documents/doc/1-d"title":"Document
No.1"}
curl-xPUT localhost: 9200/documents/doc/2-d"title":"Document
No,2"}
curl-XPUT localhost: 9200/documents/doc/3-d "title:"Document
No.3"}
curl -XPUT localhost: 9200/documents/doc/4 -d "title":"Document
No.4"}
之后 Paramedic向我们展示了两个主分片,见下面的截图:
Kymaera
★ Blade
ID: SrurCLWpSAeWbltuvr2gg D: 3LHAgBI6TzqRJFrtv7IG-A
iP:ie10.o2159201
P;ine10.0215:3200
HOST.
LoAD:1.010
LoAD:1.010
SE
DOCS: 2
DOCS: 2
HEAP.
HEAP/
INDICES
1. documents
shards /replicas/4 docs / indexing query ing /open
Kymaera
Blade
在上面给出的节点相关的信息中,我们也找到了目前感兴趣的内容。集群中的每个节
点都精确地容纳了两个文档,由此我们可以得出以下结论:分片算法完美地完成了它的工
作,我们得到了一个含有多个分片的索引,文档在分片之间均匀分布。
现在让我们人为制造一些灾难:关闭第2个节点。现在使用 Paramedic我们将看到类似
下面的截图:164◆深入理解 Elasticsearch
CLUSTER NAME
SHARDS
elasticsearch
PRIMARY 1
INITIALIZING O
RELOCATING O
UNASSIGNED 1
STATUS RED NODES 1 DOCS 2
htp:/localhost=s200
STATS
01:51
015201530154015501:56015701:5801:5902PM020102020203
0204
0205
0206
os cpu user Blade
process cpu percent(Blade
m. mem. heap_used_In_ bytes Bladel
htp. curmentopen (Blade
indices. Indexing index_ current [Bladel
indices. search query_curent (Blade
★ Blade
D: 3LH4gBI6TzqRJFrtv7IG-A
Pine10.02153200
LoAD:0.610
DOCS: 2
HEAP./
INDICES
1. documents
shards / replicas /2 docs // Indexing / querying / open
我们看到的第一个信息是集群的状态是红色的了。这意味着至少一个主分片丢失了,
因此一些数据不再可用,索引的某些部分不再可用。尽管如此, Elasticsearch还是允许我们
执行査询。至于是通知用户査询结果可能不完整还是拒绝查询请求,则由应用构建者来决
定。现在我们执行如下简单查询:
curl-XGET 'localhost: 9200/documents/ search?pretty
Elasticsearch给出的响应如下
l took 26
timed out": false,
shards"
"tota1":2,
n success ful": 1
n failed": 0
w hits
w total
2
"max score": 1.0,
"hits" :[I
nt index": " documents
type :"doc",
id":"2"
score: 1.0
source":"title":"Document No. 2"1
n index": "documents",第5章分布式索引架构◆165
type
u doc
ia":"4
score: 1
source":"title":"Document No. 4"
正如你所看到的, Elasticsearch返回了关于故障的信息。我们看到有一个分片是不可用
的。在返回的结果集中,我们只能看到标识符为2和4的文档。而其他文档丢失了,至少
在主分片恢复正常之前是这样的。如果你启动第2个节点,经过一段时间(取决于网络和网
关模块的设置)后,集群会恢复到绿色状态,此时所有的文档都可用。现在我们使用路由重
复前面的范例,同时观察 Elasticsearch的行为与上次有何不同。
在索引过程中使用路由
我们可以通过路由控制 Elasticsearch选择将文档发送到哪个分片。此时需要指定路由
参数“ routing”。路由参数值无关紧要,你可以选择任何值。重要的是在将不同文档放到同
个分片上时,需要使用相同的值。简单地说,给不同的文档使用相同路由参数值将确保
这些文档被索引到相同分片中。
向 Elasticsearch提供路由信息有多种途径。最简单的办法是在索引文档时加一个URI
参数 routing。例如下面的例子
cur1-xPUT localhost: 9200/bookS/doc/1?routing=A -d "title":
l Document
当然,我们也可以在批量索引时使用这个参数。在批量索引时,路由参数由每个文档
的元数据中的“ routing”属性指定。例如
curl -XPUT localhost: 9200/ bulk --data-binary
"index":i m index":"books","type":"doc",
routing:"A
{
title": "Document"
另一个选择是在文档里放一个“ routing”字段。不过,这种方式要想生效,需要确保
先在索引映射中定义了“ routing”字段。例如,使用如下命令创建一个命名为“boks
routing”的索引:
curl-XPUT 'localhost: 9200/books_ routing'-d
mappings":
n doc
routing":I
"required": true,
"path": routing"166◆深入理解 Elasticsearch
"pr。 perties":{
title":I"type":"string"1
现在,可以在文档中使用“ routing”字段了。例如:
curl-xPUT localhost: 9200/books routing/doc/1 -d'i"title":
"Document", m routing":"A"I
在这个例子里我们使用了 routing字段。值得一提的是path参数可以指向文档中任意
未分词字段。这是一个十分强大的功能,也是路由特性最主要的优势之一。举例来说,如
果我们用代表图书所在图书馆的 library id字段扩展我们的文档,那么当基于 library id来
设置路由时,有理由认为所有基于图书馆的查询更有效率。不过,需要注意,从文档字段
中解析出“ routing”值需要额外的一些解析工作。
523索引时使用路由
现在重复前面的例子,只是这次会使用路由。首先要删除旧文档。如果不这么做,那
么使用相同的标识符添加文档时,路由会造成相同的文档被存放到另一个分片上去。因此,
我们执行下面的命令从索引中删除所有的文档:
curl-XDELETE localhost: 9200/documents/ query?q=*:*
然后重新索引数据,但是这次添加路由信息进去。索引文档的命令如下:
curl-XPUT localhost: 9200/documents/doc/1?routing=A -d i"title":
dOcument No. 1"]
curl -XPUT localhost: 9200/documents/doc/2?routing=B -d title
dOcument No. 2"3
curl-xPUT localhost: 9200/documents/doc/routing=A -d i"title:
"Document No. 3"1
curl-xPUT localhost: 9200/documents/doc/4?routing=A -d i"title":
"Document No. 4"1
路由参数指示 Elasticsearch应该将文档放到哪个分片上。当然,同一个分片常常会
存放多个文档。这是因为分片数往往少于路由参数值的个数。现在我们停掉一个节点,
Paramedic会再次显示红色的集群状态。执行匹配所有文档的查询, Elasticsearch将返回相
应的结果(当然,返回结果取决于我们停掉了哪个节点):
curl-xGET . localhost: 9200/documents/ search?q=*&pretty
Elasticsearch的响应结果如下:第5章分布式索引架构心167
took
24,
u timed out: false
u shards": i
total": 2
"successful": 1,
u failed: 0
whits"
l totall: 3
l max score: 1.0
whits":[
index": "documents",
type": "doc",
id":"1"
score: 1.0,
source":I "title":"Document No. 1"1
index: " documents
type":"doc",
id":"3
score
n source:I"title":"Document. No. 3"1
index": "documents
type ": "doc",
"id":"4",
scoe":1.0,
2, source":title:"Document No 4
在这个例子里,标识符为2的文档不见了。我们失去了拥有路由值B的文档所在的节
点。如果更倒霉一点,将会丢失3个文档!
查询
路由允许用户指定 Elasticsearch应该在哪个分片上执行查询。既然我们只需要从索引
的一个特定子集中获取数据,还有什么必要把查询发送到所有的节点呢?举例来说,假如
我们想要从由路由值A确定的分片上查询数据,可以执行如下查询命令:
curl-XGET ' localhost: 9200/documents/ search?pretty&q=*&routing=A'
我们仅仅在路由参数里加入了一个感兴趣的值。 Elasticsearch给出了下面的响应:
ul took I: 0
n timed out false
ut shards
totall: 1
l successful": 1168心深入理解 Elasticsearch
m failed": 0
hits
u totall: 3
max score:1.0,
"hits":[
ni index
n documents",
type " "doc",
score
0 source it
title: Document No, lI
n index": documents"
type
l doc
ll id
3"
"score": 1.0,"source:i"title":"Document No. 3"1
index": documents
id":"4"
score":1.0,"_source":i"title":"Document No. 4")
}
切都工作的似乎很好,但是仔细看看!我们忘记启动一个节点,这个节点上的分片
包含着索引时使用了路由值B的文档。尽管我们没有一个完整的索引视图, Elasticsearch的
响应中并未包含分片失败的信息。这证明了使用路由的查询只命中选定的分片,忽略其他
分片。如果我们使用路由值B再执行一次查询,我们会得到类似下面的异常:
"error: "SearchPhaseExecutionException [Failed to execute phase
[query fetch], all shards failed]
status: 503
我们可以通过 Search Shard API来验证刚才的行为。例如,执行如下命令:
curl -XGET 'localhost: 9200/documents/ search shards ?pretty&routing=A'
d["query":"match all":03
Elasticsearch的响应如下:
nodes r
l QK5r a5CsfaVIWx78k633w"
l name": "Western Kid"
transport address":"inet[/10.0.2.15: 9301]
shards":[[ I
State":"STARTED
primary: true第5章分布式索引架构◆169
"node":"QK5r d5csfav1Wx78k633w",
"relocating node ": null,
shard
0
index documents
}]
从响应中可以看出,只有一个节点被查询了。
有件重要的事情需要再强调一下。路由确保在索引时拥有相同路由值的文档被索引到
相同的分片上。但是,你需要记住一个给定的分片上可以有很多拥有不同路由值的文档。
路由可以限制查询时使用的节点数,但是不能替代过滤功能。这意味着无论一个查询有没
有使用路由都应该使用相同的过滤器。举个例子,如果我们拿用户标识来作为路由值,在
搜索该用户的数据时,还应当在查询中包含一个按用户标识进行过滤的过滤器。
524别名
如果你是一个搜索引擎专家,你大概会希望对程序员隐藏一些配置信息,好让程序员
们可以快速地工作且不必关心搜索细节。在理想的世界里,他们不需要担心路由、分片
副本。别名让我们像使用普通索引那样来使用路由。例如,让我们用下面的命令来创建
个别名:
curl-xpost'http://localhOst:9200/aliases-d't
Actions":
n addm
主ndex":" documents",
alias":"documenta",
"r。 uting":"A"
在前面的例子里我们创建了一个叫 doucments的虚拟索引(一个别名),用来代表来自
doucments索引的信息。同时,查询被限定在路由值A相关的分片上。多亏这个功能,你
可以将别名 documents的信息提供给开发者,他们可以直接用它进行查询和索引,就像其
他索引一样。
5.25多个路由值
Elasticsearch允许我们在一次查询中使用多个路由值。文档被放置在哪个分片上依赖于170心深入理解 Elasticsearch
文档的路由值,多路由值查询意味着在一个或多个分片上查询。我们看看下面的查询:
curl-XGET 'localhost: 9200/documents/ search?routing=A,B.
查询执行后, Elasticsearch会将查询请求发送到两个分片上(在我们使用的示例中,刚
好是索引的所有分片),这是因为路由值A涵盖了索引两个分片中的一个,而路由值B涵盖
了另一个。
当然,多路由值也支持别名。下面的例子展示了如何使用这些特性:
curl-xpost'http://localhost:9200/aliases'-d'[
n actions:
m add"
n⊥ndex":" documents"
alias":"documents"
lsearch routing":"A, B
mindex routing":"A"
上面的例子里有两个额外的配置参数是我们之前没有提到过的,我们可以为查询和
索引配置不同的路由。在前面的例子里,我们定义在查询时( search routing参数)使
用2个路由值(A和B)。而索引时( index routing参数)仅有一个路由值(A)被使用。
记住,索引时不支持多个路由值,同时你也应记住要做适当的过滤(你也可以把它加到
别名中)。
53调整默认分片的分配行为
在 Packt出版社出版的《 Elasticsearch server, Second edition》一书中我们介绍了许多
有关 Elasticsearch分片分配功能的知识。我们探讨了 Cluster Reroute api,分片再平衡,以
及分片部署意识。尽管这些知识不常用,但是如果你想完全掌控你的 Elasticsearch集群,
这些内容将非常重要。有鉴于此,我们决定扩展《 Elasticsearch Server, Second edition》
一书中的相关示例,展示给读者关于以下主题的指导方针:如何使用 Elasticsearch的分片
部署意识功能,以及如何调整默认分片分配机制。
让我们从一个简单示例开始展开。假如我们有一个4个节点的集群,看上去像下面
这样:第5章分布式索引架构171
工 P address:192.168,21
P address:192.168,2,2
node. tag: nodel
ie group: gm
node group: g2
Node: 8GVd-ktes2umduM4AAJQhQ
l 7BZ TaTfGRmbtCCPHF0Q
TP addres:192,168,3,1
2 addres:192,168,32
node, tag: node3
node tag: node4
group: groupB
grouP: 93
de: wJqOkPSHTHCovJUCBVK0-A
xKq1F-JJHD
Elasticsearch cluster
如你所见,我们的集群由4个节点构成。每个节点都绑定了一个指定的IP地址,每个
节点都被赋予了一个tag属性和一个 group属性(在 Elasticsearch.yml文件里对应的是node
tag和node. group属性)。这个集群用来展示分片分配的过滤处理是如何工作的。你可以给tag
和 group属性任意名字,你只需要给你期望的属性名前面加上node前缀。例如,如果你想将
party作为属性名,你只需要把node, party: partyI加入你的 Elasticsearch ym文件里即可。
5.31部署意识
部署意识允许我们使用通用参数来配置分片和它们的副本的部署。为何证明部署意
识是如何工作的,我们将使用我们的示例集群。为了让例子能够说明问题,我们需要在
Elasticsearch yml文件里加入下面的属性:
cluster routing allocation awareness. attributes: group
这会告诉 Elasticsearch使用node. group属性作为意识参数。
漆你可以指定多个值给 cluster routing allocation awareness. attributes展性,例如
lust
ares
ute
group r
node
然后,我们先启动前两个节点,node. group属性值是 groupA的那两个。接下来用下面
的命令创建一个索引:
curl-XPOST localhost: 9200/mastering'-d'i
settings": I
nindex172◆深入理解 Elasticsearch
nnumber of shards": 2
"number of replicas":1
执行了前面的命令后,我们拥有两个节点的集群看起来或多或少很像下面的截图
IP address: 192.168.2.1
Ip address: 192. 168.2.2
node. tag: nodel
tag:
I node group: groupA
node, group: groupA
Masterin
Mastering
Mastering
Mastering
Primary shard O
Replica shard 1
Replica shard o
Primary shard 1
ode: 6GVd-kteS2um4uMAAAJOha
Node: iw 76Z TaTIGRmbtCcPHFoQ
Elasticsearch cluster
如你所见,索引被平均部署到了两个节点上。现在让我们看看当我们加入其余两个节
点时会发生什么(node. group设置成 groupB的那两个)
2 address:92.168,2,1
2dde::192.168.2,2
node. tag: node2
node grouP: groupA
node grouP: groupA
Mastering
Mastering
Primary shard O
Primary shard 1
Nodo: 6GVd-ktcS2um4uMAAJQha
Node: iw76Z TaTfGRmbtccPHFoQ
工 P address;1921683
IP address: 192.168.3.2
node.tag: node3
tag: node4
Eoup: gRoupE
a, group: groupB
Mastering
Ma
astering
Replica shard O
Replica shard 1
WqokPSHTHCovjucsVK0-A
Node: xKq1f-JJHD_ vOXussBB-xo
Elasticsearch cluster
注意以下区别:主分片没有从原来部署的节点上移动,但是副本分片移动到了有不同
node group值的节点上。这恰恰是对的。当使用分片部署意识的时候, Elasticsearch不会将
主分片和副本放到拥有相同属性值(用来决定部署意识,在我们的例子里是node. gorup)的第5章分布式索引架构◆173
节点上。使用这个功能的一个例子是从虚拟机或则物理位置的角度分割集群的拓扑结构,
以确保你不会有单点故障。
请记得,在使用部署意识的时候,分片不会被部署到没有设定指定属性的节点上。所
以对我们的例子来说,一个没有设置 node group属性的节点是不会被部署机制考虑的。
强制部署意识
在我们预先知道我们的意识参数需要接受几个值,且我们不希望超过我们需要的副本
被部署到我们的集群里时(例如不想因过多的副本而使集群过载),有了强制部署意识就
很方便了。为了实现这个,我们可以强制部署意识由特定属性激活。我们可以通过使用
cluster routing allocation. awareness. force, zone. values属性,并给它提供一个用逗号分隔的列
表值来指定这些属性值。例如,如果我们希望对于部署意识来说只使用node. gorup属性的
groupA和 group B两个值,我们应该把下面的代码加到 Elasticsearch yml文件中:
cluster routing allocation awareness. attributes: group
cluster routing allocation, awareness. force zone. values groupA,
groupB
532过滤
Elasticsearch允许我们在整个集群或是索引的级别来配置分片的分配。在集群的级别上
我们可以使用带下面前缀的属性:
cluster, routing allocation include
cluster routing allocation. reugire
cluster routing allocation exclude
而处理索引级的分配时,使用带下面前缀的属性:
index. routing allocation. include
index routing allocation require
index routing allocation exclude
前面提到的前缀可以与我们在 elasticsearch.yml文件里定义的属性一起使用(tag属性
和 group属性)。通过使用一个名为_ip的特殊属性,我们就可以使用ip地址来进行包含或
者排除特定的节点。例如:
cluster routing allocation. include. ip: 192.168.2.1
如果我们希望包含一组 group属性是 groupA的节点,我们应该设置下面的属性:
cluster routing allocation. include group: groupA174
深入理解 Elasticsearch
请注意,我们已经使用了 cluster routing allocation include前缀,把它和属性名
group
连接在一起。
这些参数意味着什么
如果你仔细观察一下前面提到的参数,就会注意到它们有3种类型。
口 include:这种类型包含所有定义了这个参数的节点。如果定义了多个 include条
件,那么至少匹配一个条件的节点都会在分配分片时被考虑进去。举例来说,如
果我们增加2个 cluster; routing. allocaiton. include.tag参数到我们的配置中,一个赋
值 node l,另一个赋值node2,结果就是索引(确切地说是它们的分片)被分配到
了第1个和第2个节点上(从左向右)。总结一下,拥有 include参数类型的节点,
Elasticsearch在选择放置分片的节点时会加以考虑,但是这并不意味着 Elasticsearch
一定会把分片放到这些节点上。
口 equire:这种类型是在 Elasticsearch0.90版本的分配过滤器中被引入的。它要求所有
的节点都必须拥有和这个属性值相匹配的值。例如,如果我们向配置中添加 cluster
routing allocation. require tag参数并赋值 node 1,添加 cluster routing allocaiton. require
group参数并赋值 groupA。结果就是所有的分片都分配在第一个节点上(IP地址为
1921682.1的节点)。
口 exclude:这个属性允许我们在分片分配过程中排除具有特定属性的节点。例如,我
们给 cluster routing allocation include tag赋值 groupA,最终,索引只被分配在了IP
地址是192168.2.1和192.168.2.2的节点上(例子中第3和第4个节点)。
淒属性值可以使用简单的通配符。例如,如果我们希望包含所有 group属性值以
group开头的节点,我们应当设置 cluster routingallocation include. group属性的值为
group*。就样例集群来说,这会导致匹配 group参数值是 groupA和 groupB的节点。
533运行时更新分配策略
除了在 Elasticsearch yml文件里设置我们讨论过的那些属性外,在集群已经启动运行
后,我们也可以通过更新API来实时更新这些设置。
1.索引级更新
为了更新一个给定索引(例如 mastering索引)的设置,我们执行下面的命令:
curl -XPUT 'localhost: 9200/mastering/ settings.-d t
Windex routing allocation. require group":"groupA"第5章分布式索引架构心175
如你所见,命令发送给指定索引的 settings端点。你可以在一次调用中包含多个属性。
2.集群级更新
为了更新整个集群的设置,我们执行下面的命令:
curl -XPUT localhost: 9200/ cluster/settings'-d
n transient:
ncluster routing allocation require group":"groupA
如你所见,命令被发送至 cluster/settings端点。你可以在一次调用中包含多个属性。
注意前面命令中的 transient,它意味着在集群重启后属性将失效。如果想避免这样,想让属
性持久化,可以用 persistent属性替换 transient属性。一个在重启后保留设置的例子如下
curl-XPUT ' localhost: 9200/ cluster/settings'-d f
persistent":t
"cluster routing allocation. require group":"groupA"
③依赖于命令的内容和索引的分配情况,执行前面的命令可能造成分片在节点间的移动。
534确定每个节点允许的总分片数
除了我们前面提到的属性,还能够定义每个节点上可以分配给一个索引的分片总数(主
分片和副本)。为了实现该目的,我们需要给 index. routing. allocation. total shards per node
属性设置一个期望值。例如在 Elasticsearch.yml文件里我们设置
index routing allocation. total shards per node: 4
这会造成单个节点上最多为同一个索引分配4个分片。
这个属性同样可以在一个运行中的集群上使用 Update API来改变,例如:
curl-XPUT'localhost: 9200/mastering/ settings.-d'i
"index. routing allocation. total shards per node":"4"
现在,我们来看一些例子,在 elasticsearch.yml文件中使用分片分配属性后,创建单
索引时集群是什么样子的。
5.3.5确定每个物理机器允许的总分片数
当我们在单个物理机器上运行多个 Elasticsearch节点时,有一个属性值得我们注意:176心深入理解 Elasticsearch
cluster routing allocation. same shard. host。把这个属性设置为tue将阻止 Elasticsearch将主
分片和它的副本部署在同一台物理主机上。如果你拥有性能强大的服务器,并且打算在
个物理主机上运行多个节点,我们强烈建议你设置这个属性的值为true
1.包含
我们现在使用示例集群看看包含( include)方式是如何工作的。首先,用下面的命令删
除并重新创建 mastering索引:
curl-XDELETE 'localhost: 9200/mastering
curl-xPosT 'localhost: 9200/mastering'
"settings": I
"index":
number of shards": 2
"number of replicas":0
然后我们执行下面的命令:
curl-XPUT 'localhost: 9200/mastering/ settings'-d
mindex routing allocation include tag":"nodel",
"index. routing allocation include group":"groupA",
"index. routing allocation. total shards per node":1
如果我们把索引状态命令的响应可视化,就会看到集群看起来与下面的图片很相似:
Pad:192.16.21
工 p address192.168
node. tag: nodel
node.tag: node2
node group groupA
ode group: groupR
Mastering
Mastering
Shard 1
Shard o
Node: 6GVd-ktes2um4uMAAAJQho
Nodo: l76Z TaTIGRimbtCcPHF0O
P address:192.168,3
P addr客:192:160.3,2
node. tag: node3
tag
nodegroup: groupB
nodagroup: groupB
SHTHGovjuC sVKO-A
Node: xKq1N-JHD voxussB8-x0
Elasticsearch cluster第5章分布式索引架构心177
就像你看到的那样, Mastering索引的分片被部署到了tag属性为 node l或者 group属
性为 groupA的节点上了。
2.必须
现在我们还是使用前面的示例集群(假定集群里没有任何索引)来观察必须( require)
方式是如何工作的。执行下面的命令
curl-xPUT 'localhost: 9200/mastering/ settings,-d
index routing allocation require tag":"nodel"
nindex routing allocation require group":"groupA"
如果我们把索引状态命令的响应可视化,就会看到集群看起来像下面的样子:
IP address: 192. 168.2,1
r2 address192,168.2.2
node.tag
node. tag: node2
He group: groupA
node, group: groupA
Mastering
Masterin
Shard 1
Shard 0
Noda: 6GVd-ldtcS2um4uM4AAJQhQ
Node: iw76Z TaTfGRmbtCcPHFoQ
IP address: 192. 168 3.1
IP address:192. 168, 3.2
node. tag: node3
node. tag: node4
nodegroup: groupB
node, group: groupB
Node: wJqokPSHTHCovjucsVKO-A
Node: xKqlf-JJHD VOxUssBB-xo
Elasticsearch cluster
就像你看到的那样,这个视图跟前面我们使用 include选项的那个不一样了。这是由于
我们告诉 Elasticsearch,将 Mastering索引的分片仅分配到与两个 require参数都匹配的节点
上,我们的例子里两个都匹配的只有第一个节点。
3.排除
接着我们再看看排除( exclude)方式。执行下面的命令:
curl -XPUT localhost: 9200/mastering/ settings'-d
index routing allocation exclude tag":"nodel m,
nindex routing allocation require group":"groupA"178◆深入理解 Elasticsearch
再看看我们的集群:
IP address
2.168.21
IP address: 192.168 2,2
node. tag: nodel
node. tag: node2
I node group: groupA
node group: groupA
Mastering
Mastering
Shard 1
Shard o
Node: 6GVd-kteS2um4uM4AAJOho
lode: iw76Z TaTfGRmbtCcPHFoQ
IP address:192 1683:1
IP address: 192.168 3.2
ag: node3
node. tag: node4
node,group: groupB
node group: groupB
Node: wJgOkPSHTHCovjucsVKO
Node; xKa1f-JJHD VoxussBB-X0
Elasticsearch cluster
就像你看到的那样,我们要求 group属性必须等于 groupA,同时希望排除tag等于
node1的节点。这导致了一个 Mastering索引的分片被分配到了IP地址是192168,22的节
点上,这正是我们所期望的。
4.基于磁盘的分配
当然,除了刚刚提到的这些属性,我们还可以使用其他一些属性。从 Elasticsearch
1.3.0版开始,我们可以基于磁盘使用情况来配置分配意识。基于磁盘的分配属性默认是开
启的。如果我们想要关闭它,可以设置 cluster routing allocation disk threshold enabled属性
值为 false
还有另外几个属性可以辅助我们配置基于磁盘的分片分配行为。第一个属性是 cluster.
routing allocation disk watermark. low,可以让 Elasticsearch在触发条件时不再在节点上分
配新的分片。该属性的默认值是85,意味着当磁盘使用率达到85%后,节点上将不再分
配新的分片。另一个属性是 cluster routing allocation disk watermark. high,这个属性可以让
Elasticsearch在触发条件时尝试将分片从本节点上迁移出去。这个属性的默认值是90,意
味着当磁盘使用率达到90%后, Elasticsearch将尝试将部分分片从本节点上迁出。
low和high属性都可以设置为绝对值,比如,1024MB。第5章分布式索引架构◆179
54查询执行偏好
让我们忘记分片部署及其配置,至少就现在而言。除了 Elasticsearch允许我们设置分片
和副本的那些技巧以外,我们还能够指定查询(以及其他操作,例如实时获取)在哪里执行。
在了解细节之前,先查看一下我们的示例集群:
Mastering
Mastering
Primary Shard 0
Primary Shard 1
Node name: node, id: 6GVd-kteszumduiM4AAJOhQ
Node name: node2, Id: iw7szZ TaTfGRmbtCoPHFoQ
Mastering
Mastering
Replica Shard 0
Replica Shard 1
Nodo name: node3, Id: w.qOkPSHTHCovjuCsVKO-A
Elasticsearch cluster
如你所见,集群中有3个节点和一个叫作 Mastering的索引。索引被分割为两个主分
片,每个主分片有一个副本。
介绍 preference参数
为了控制我们发送的查询(和其他操作)执行的地点,可以使用 preference参数,它可
以被赋予下面这些值中的一个。
日 primary:使用这个属性,我们发送的操作仅在主分片上执行。所以如果我们向
mastering索引发送一个查询请求,并将 preference参数设置为 primary。那么这个
请求会在 node l和node2上执行。例如,如果你知道你的主分片在某个机柜,副本
在其他机柜,你可能希望通过在主分片上执行操作来避免网络开销。
口 primary first:这个属性的行为很像 primarly,但它有一个自动故障恢复机制。如
果我们向 mastering索引发送了一个查询请求,并设置 preference参数为 primary
fist,那么查询会在 nodel和node2上执行。而一旦一个(或多个)主分片失败了
查询会在另一个分片上执行,在我们的例子里这个分片位于node3上。就像我们说
的,该选项非常像 primary,只是当主分片由于某些原因不可用时转而使用其副本180心深入理解 Elasticsearch
口 local: Elasticsearch在可能的情况下会优先在本地节点上执行操作。例如,如果我
们发送一个查询请求给node3同时将 preference参数设为 local,那么查询就会在该
节点上执行。然而,如果我们将查询发送给node2,那么就会有一个查询在主分片1
上执行(部署在节点node2上),另一部分查询会在包含分片0的 node l或node3上
执行。这在我们想最小化网络延时时尤其有用,当使用 local时,确保只要有可能
(例如从本地节点发起的客户端连接或向一个节点发送查询)查询就在本地执行。
口_ only node: wJqOkPSHTHCovjuCsvK0-A:这个操作将仅在拥有指定标识符的节点
上执行(例子里用了 wJqokPShTHCovjuCs VK0-A)。因此在我们的例子里,查询会
在部署在node3上的两个副本上执行。请注意,如果没有足够的分片来覆盖所有的
索引数据,查询将仅在指定节点的可用分片上执行。例如,如果我们设置 preference
参数为_ only node:6Gvd-ktcS2um4uM4 AAJQhQ,结果是查询仅在一个分片上执行。
该设置在某些情况下非常有用,例如当我们知道某个节点比其他节点性能好,且我
们希望某些查询只在那个节点上执行的时候。
口 prefer_ node: wJqokPSHTHCovjuCs VK0-A:这个选项设置 preference参数
为 prefer node,后面跟着一个节点的标识符(例字里用了 wJqOkPSHTH
CovjucsvK0-A)。这会使 Elasticsearch优先在指定的节点上执行查询,但是如果该
指定节点上一些分片不可用时, Elasticsearch会发送恰当的查询部分给包含可用分片
的节点。同_ only node选项类似, prefer node可以用来选择一个特定的节点,只
是当特定节点不可用时转而使用其他节点。
口 shards:0,1:这个 preference参数值让我们指定操作在哪个分片上执行(在我们的例
子里,是指所有分片,因为在 mastering索引里我们只有分片0和1)。这是唯一可
以和其他选项值组合的 preference参数值。例如,为了在本地的0和1分片上执行
查询,我们用分号连接0,1和 local,最终 preference参数看起来是就像这样:0,1;
local。允许我们在一个分片上执行查询对于调试非常有用。
口自定义字符串:把 preference参数值设置为一个自定义字符串,可以确保使用相同
参数值的查询在相同的分片上执行。例如,如果我们发送一个 preference参数值为
mastering Elasticsearch的查询,假定查询会在位于node和node2节点的主分片上
执行。之后如果我们发送另一个有同样 preference参数值的査询,那么第2个查询
将在同样的分片上执行。这个功能在我们有不同的刷新频率,并且不希望用户在重
复查询时看到不同结果的时候可以帮助到我们。
还遗漏了一件事,就是 Elasticsearch的默认行为。 Elasticsearch默认会在分片和副本之
间随机执行操作。如果我们发送大量的请求,那么最终每个分片和副本上将会执行相同(或
者几乎相同)数量的查询。第5章分布式索引架构心181
55小结
在本章中,我们学习了如何为 Elasticsearch的部署选择正确的副本分片数,我们也了
解了在查询和索引时路由和别名是如何起作用的。同时学习了分片分配机制是如何工作的,
以及我们怎样配置它来满足我们的需求。最后,我们还了解了查询执行偏好能够带给我们
的各种特性。
在下一章中,我们将通过提供不同的 similarity模型来深入探讨如何调整 Apache
Lucene的打分机制。我们将使用解码器( codecs)来修改倒排索引的格式,还将探讨准实时
索引和查询,强制写入(fush)和刷新( refresh)操作,以及如何配置事务日志。我们还将
讨论IO节流和索引段合并的相关知识。最后,还将介绍 Elasticsearch的各种缓存,包括字
段数据缓存、过滤器缓存和查询分片缓存。鼴藏罐
腰
CTtee第6章
底层索引控制
在上一章中,我们介绍了一般的分配策略及索引本身的架构。最开始,读者了解了如
何选择正确的分片数和副本数,如何在索引期及查询期结合别名使用路由功能。同时也讨
论了如何调整索引分片的分配行为。最后,我们讨论了什么是查询偏好,以及它能为用户
带来什么。
在本章中,将会深入探讨 Elasticsearch如何在底层处理索引分片的。到本章结束,将
涵盖以下内容:
口使用多种相似度模型来改变 Apache Lucene评分
口使用编解码器改变索引写入方式
口准实时索引及搜索
口数据提交,索引更新及事务日志处理
口IO节流
口段合并控制及可视化
口 Elasticsearch缓存
61改变 Apache lucene的评分方式
自2012年 Apache lucene40发布以后,用户有机会改变默认的基于 TF/IDF的评分算
法。 Lucene的API做了一些改变,使得用户能轻松地修改和扩展该评分公式。不过,这并
不是 Lucene在改变文档评分计算方面仅有的改进。 Lucene4.0提供了更多的相似度模型,第6章底层索引控制“183
这允许我们采用不同的评分公式。本节中,我们将深入了解 Lucene40带来了哪些变化,
以及如何整合这些特性至 Elasticsearch中。
6.1.1可用的相似度模型
前面已经提到过了, Apache Lucene4.0之前,除了最原始和默认的相似度模型以外,
TF/IDF模型也是可用的。我们已经在21节中详细讨论过了。
而现在,有以下5种新的相似度模型可用。
口 Okapi BM25模型:它是一种基于概率模型的相似度模型,可以用来估算文档与
给定查询匹配的概率。为了在 Elasticsearch中使用它,你需要使用该模型的名字,
BM25。一般来说 Okapi BM25模型在短文本文档上的效果最好,这种场景中重复词
项对文档的总体得分损害较大。
口随机偏离( divergence from randomness)模型:这是一种基于同名概率模型的相似度
模型。为了在 Elasticsearch中使用它,你需要使用该模型的名字DFR。一般来说,
随机偏离模型在类似自然语言的文本上使用效果较好。
口基于信息的( information based)模型:该模型与随机偏离模型类似。为了在
Elasticsearch中使用它,你需要使用该模型的名字,B。与DFR模型类似,IB模型
在类似自然语言的文本上使用也有较好的效果。
口 LM Dirichlet模型:该相似度模型结合了狄利克雷先验与贝叶斯平滑。为了在
Elasticsearch中使用它,你需要使用该模型的名字, LMDirichlet。更多细节请参
:https://lucene.apacheorg/core/490/core/org/apache/lucene/search/similarities/
LMDirichletSimilarity. html
口 LM Jelinek mercer模型:该相似度模型使用了 Jelinek mercer平滑方法。为了在
Elasticsearch中使用它,你需要使用该模型的名字, LMJelinek mercer。更多细节请
e:https://lucene.apacheorg/core/490/core/org/apache/lucene/search/similarities/
LMJelinekMercerSimilarity. html
前面提到的相似度模型所涉及的数学知识已经远超过本书的讨论范围。如果您想
深入了解这些模型以及拓展相关知识,请参考htt:!ln. wikipedia. org/wiki/ Okapi
BM25( okapi bm25模型),及htt: terrier. org/ docs/v3.5/dfr- description. html(随机
偏离模型)。
6.1.2为每字段配置相似度模型
自 Elasticsearch090以后,允许用户在映射中为每字段设置不同的相似度模型。例如,假184◆深入理解 Elasticsearch
设我们有下面这个映射,用于索引博客的回帖(该映射存储在 posts no similarity json文件中)
"mappings":
"post:
"properties":
"id":"type": "long","store":"yes"
"name":i"type":"string","store :yes","index":
"analyzed"1,
"contents":type": "string","store":"no", "index"
analyzed"
我们希望的是,在name字段和 contents字段中使用BM25相似度模型。为了实现这个
目的,我们需要扩展我们的字段定义,添加 similarity字段,并将该字段的值设置为相应的
相似度模型的名字。修改后的映射(该映射存储在 posts similarity json文件中)如下所示:
mappings":
"post " :i
"properties: i
"id":I"type":"long","store":"yes"3,
"name":I"type":"string","store":"yes","index'
"analyzed","similarity":"BM25"3
"contents":[type":"string","store":"no,"index":
"analyzed","similarity" :"BM25"
以上更改就足够了,并不需要额外的信息。经过前面的处理, Apache lucene将在搜索
期在name字段和 contents字段上使用BM25相似度模型计算文档得分。
淒对于随机偏离模型及基于信息的模型,我们需要配置一些额外的属性,用于控制这
些相似度模型的行为。后续小节将会覆盖相关知识。
6.1.3相似度模型配置
我们已经知道如何为索引中每个字段配置相似度模型了,现在让我们来了解如何按需
求配置它们。事实上,这是相当容易的。我们所要做的就是,在索引配置相关部分提供
相应的相似度模型配置信息,例如,就像下面的代码这样(本范例存储在 posts custom
similarity json文件中)第6章底层索引控制◆185
settings":
l index I
"similarity":
"mastering similarity
ntype :"default "
Discount overlaps#: false
"mappings":I
"post "
properties
" d": "type":"long","store":"yes")
"name ": "type":"string","store":"yes","index"
"analyzed","similarity":"mastering similarity",
contents":"type":"string", "store":"no", index"
analyzed")
尽管用户可以配置多个相似度模型,但此时我们还是把目光投向前面的范例。我们定
义了一个名叫 mastering similarity的新的相似度模型,它基于默认的TF/IDF相似度模型。
并且将它的 discount overlaps属性值设置为 false,指定该相似度模型用于name字段。后
面我们将讨论不同相似度模型都有哪些属性,现在,让我们关注一下如何改变 Elasticsearch
的默认相似度模型。
δ.1.4选择默认的相似度模型
为了设置默认的相似度模型,我们需要提供一个名为 default的相似度模型的配置信息。
例如,如果我们想使用 mastering similarity模型作为默认的相似度模型,我们需要将前面
的配置文件修改为如下形式(该范例被存储在 posts_ default similarity json文件中)
settings "
nindex"
Similarity:
"default": i
'type":default"
"discount overlaps": false186心深入理解 Elasticsearch
由于所有的相似度模型都全局使用了 query norr和 coord这两个评分因子(详情见2.1
节),但是它们在 default相似度模型的配置中被移除了。 Elasticsearch允许用户根据需要改
变这种状况。为了实现该目的,用户需要定义个另外一个名为base的相似度模型。它的定
义方式与前面的范例如出一辙,将相似度模型的名字由 default改为base即可。可参考下面
的代码(该范例代码被保存在 posts base similarity json文件中):
"settings ":
u indext
"similarity: i
ubase ll
ntype":"default",
discount overlaps": false
如果base相似度模型出现在索引配置中,当 Elasticsearch使用其他相似度模型计算文
档得分时,则使用base相似度模型来计算 query norm和 coord评分因子。
配置被选用的相似度模型
每个新增的相似度模型都可以根据用户需求进行配置。 Elasticsearch允许用户不加配置而
直接使用 default和BM25相似度模型。这是因为它们是预先配置好的。而DFR和IB模型则
需要进一步配置才能被使用。现在,让我们看看每个相似度模型都提供了哪些可配置的属性。
(1)配置 TF/IDF相似度模型
在 TF/IDF相似度模型案例中,我们可以只设置一个参数: discount overlaps属性,其
默认值为true。默认情况下,位置增量( position increment)为0(即该词条的 position计数
与前一个词条相同)的词条在计算评分时并不会被考虑进去。如果在计算文档时需要考虑这
类词条,则需要将相似度模型的 discount overlaps属性值设置为 false。
(2)配置 Okapi Bm25相似度模型
在 Okapi Bm25相似度模型案例中,有如下参数可以配置。
口k1:该参数为浮点数,控制饱和度( saturation),即词频归一化中的非线性项。
口b:该参数为浮点数,用于控制文档长度对词频的影响。
口 discount overlaps:与TF/DF相似度模型中的 discount overlaps参数作用相同。
(3)配置DFR相似度模型
在DFR相似度模型案例中,有如下参数可以配置。第6章底层索引控制◆187
口 basic model:该参数值可设置为be、d、g、if、in,以及ine
口 after effect:该参数值可设置为no、b,以及1。
口 normalization:该参数值可设置为no、h1、h2、h3以及z。
如果 normalization
参数值不是no,则需要设置归一化因子。归一化因子的设置依赖于
我们选择的 normalization参数值。参数值为hl时,使用 normalization. hI.c属性;参数值
为M2时,使用 normalization.h2c属性;参数值为h3时,使用 normalization.h3c属性;参
数值为z时,使用 normalization,z.z属性。这些属性值的类型均为浮点数。下面的代码片段
展示了如何配置相似度模型:
"similarity
"esserverbook dfr similarity ":
type
U DERI
"basic model :"g",
n after effect: l
normalization":"h2",
normalization h2.c:# 2.0"
(4)配置IB相似度模型
在IB相似度模型案例中,有如下参数可以配置。
口 distribution:该参数值可设置为ll或spl
口 lambda:该参数值可设置为df或tf
此外,IB模型也需要配置归一化因子,它的配置方式与DFR模型相同,故不赘述。下
面的代码片段展示了如何配置IB相似度模型:
similarity": I
"esserverbook ib similarity": I
type:IB",
"distribution":"11",
ulambda": " df I
normalization
normalization. zz:0.25
(5)配置 LM Dirichlet相似度模型
在 LM Dirichlet相似度模型案例中,有如下参数可以配置。
口mu:该参数可配置,默认值为2000
下面是该模型参数配置的例子:
similarity":
"esserverbook Im dirichlet similarity: I188◆深入理解 Elasticsearch
"type:"LMDirichlet",
mu":"1000
(6)配置 LM Jelinek mercer相似度模型
在 LM Jelinek mercer相似度模型案例中,有如下参数可以配置。
口 lambda:该参数可配置,默认值为0.1。
下面是该模型参数配置的例子:
u similarity
esserverbook_lm jelinek mercer similarity": I
ntype ": "MJelinekMercer i
"1 ambda":"0.7"
来说,较短字段(例如文档的tt字段), lambda的值可设置在01左右,而
较长字段, lambda值应该设置为07
62选择适当的目录实现— store模块
当配置 Elasticsearch集群时,有些模块往往容易被用户所忽略, store模块正是其中之
。然而该模块非常重要,它是 Apache Lucene与其Io子系统之间的一个抽象。 Lucene
所有在磁盘上的操作都通过它的 store模块来处理。而 Elasticsearch中绝大多数 store类
型都是与 Lucene的 Directory类是一一对应的(参考:htt: lucene.apache. org/core490
core/org/ apache/ scene/ store/ Directory. htm)。目录( Directory)用来读写所有 Lucene索引相
关的文件,因此它的配置的非常重要。
store类型
Elasticsearch提供了5种可用的 store类型。现在我们来看看都有哪些 store类型,以及
如何利用它们的特性。
1.简单文件系统 store类型
Directory类的最简单实现就是使用一个随机存取文件(Java中的 RandomAccess file-
http://docs.oraclecom/javase/7/docs/api/java/io/randomaccessFile.html)对应的Apache
Lucene中的子类为 SimpleFSDirectory(htt:/ scene. apache.org/core/490/core/org/ apache第6章底层索引控制◆189
lucene/ store/SimpleFSDirectory html)。对于简单的应用,该 store类型足够了。其瓶颈在于
多线程读写,会导致很糟糕的性能。在 Elasticsearch中,通常使用基于NIO的 store类型
来替换简单文件系统 store类型。尽管如此,我们还是要介绍一下该 store类型的配置实用,
如果想使用简单文件系统 store类型,设置 index. store type属性值为 simples
2.NO文件系统 store类型
该 store类型使用了 Directory类基于 Java. n1o包中 File channel类的实现(可参考
htt:/docs.oracle.com/Javase/7/docs/api/java/nio/channels/Filechannel.html),该类型对应的
是 Apache Lucene中的 NIOFSDirectory类。该类型允许多线程操作同一个文件,同时不用
担心性能急剧下降。为了使用该 store类型,需要将 index. store.type属性值设置为 nios。
注读者请注意,由于针对 Windows平台的JVM存在一些bug,在 Windows上使用
意
nios很可能存在性能问题。想了解更多此类bug的信息,可参考:htt:/bugs.sun
com/bugdatabase/view bug. do?bug id=6265734
3MMap文件系统 store类型
该store类型使用了ApacheLucene中的MMapDirectory类(详情可参考httplucene
apache. org/core/4_9_0 core/org/ apache/ ucene/store/MMap Directory. html))。它使用了mmap
系统调用(详情可参考:htp:/en. wikipedia. org/wiki/Mmap)处理读操作,使用随机读写文
件处理写操作。读文件时,会将文件映射到同样的大小的虚拟地址空间中去(如果有足够
的空间的话)。因为mmap没有加锁操作,因此在多线程读写的时候是可扩展的。当使用
mmap读取索引文件时,感觉像是事前缓存了该文件一样(因为它被映射到虚拟地址空间中
去了)。由于这个原因,此时读取 Apache Lucene的索引文件,并不需要加载文件到操作系
统缓存中去,因此访问会更快。该 store类型等价于允许 Lucene或 Elasticsearch直接访问I
O缓存,因此读写索引文件速度更快。
在64位操作系统中使用MMap文件系统 store类型毫无意义,应仅在32位操作系统中
使用它,并确保索引足够小并且有足够的虚拟地址空间。如果想使用MMap文件系统sore
类型,应将 index store type属性值设置为mmap
4.混合文件系统 store类型
该 store类型出现在 Elasticsearch1.3.0中,它根据具体的文件类型,混合使用NIO
及MMap。在本书撰写之时,只针对词典文件及 doc values文件使用MMap,而其他索引
文件读写使用NO。如果想使用混合文件系统 store类型,应将 index store type值设置为
default190◆深入理解 Elasticsearch
5.内存 store类型
这是第2种不基于 Apache Lucene Directory的 store类型(第1种是混合文件系统sore类型)。
该类型允许直接将索引文件存储在内存中,而不是磁盘中。这个事实很重要,因为文件是存储在
内存中的,因此不可持久化。如果碰上集群重启这样的事情,内存中的索引文件将会丢失。但
是,如果用户想构建小容量、高性能,同时又有多个分片或副本以及能快速重建的索引,该 store
类型就非常值得期待了。如果想使用内存 store类型,应将 index. store.type值设置为 memory。
③内存soe类型与其他sore类型类似,其存储的数据能在多个节点之间被复制
额外的属性
当使用内存 store类型,用户可以进行某种程度的控制。允许控制内存 store特性,这
很重要。下面是可配置的内存 store参数(节点级控制)。
口 cache memory: direct:默认值为true,该参数用于确定是否在JVM堆内存之外分配内存
一般来说该参书保持为默认值是非常合适的,因为这样会避免JVM内存过度使用。
口 cache. memory. small buffer size:默认值为1kB,该参数指定了小块缓冲区的大小,
这里的缓冲区指的是一个内部内存结构,用来保存段信息及被删除文档的信息。
口 cache memory. large buffer-size:默认值为IMB,该参数指定了大块缓冲区的大小
这里的缓冲区指的是一个内部内存结构,用来保存除段信息及被删除文档信息之外
的索引文件。
口 cache memory. small cache size:数据对象的小块缓存的大小,这是一个内部的内存
结构,用来缓存段信息及被删除文件信息。默认值为10MB。
口 cache memory. large cache size:数据对象的大块缓存的大小,这是一个内部的内存
结构,用来缓存段信息及被删除文件信息以外的索引信息。默认值为500MB
6.默认 store类型
Elasticsearch1.3.0与之前及之后的版本中,默认 store类型有所不同。
7. Elasticsearch1.3.0及以后版本默认 store类型
从 Elasticsearch1.3.0开始,默认的 store类型为混合文件系统类型,可以通过设置
index store type值为 default来实现。
8. Elasticsearch1.3.0之前版本默认 store类型
从 Elasticsearch1.3.0往前,默认 store类型是基于文件系统的,但是具体选项会因操作
系统而异。例如,32位的 Windows操作系统中,默认使用 simples,而在 Solaris或64位
Windows操作系统中则使用mmap,其余的操作系统默认使用 nios类型。第6章底层索引控制191
如果想深入了解 Directory E的底层实现,可参考 Uwe Schindler的博客:hp:/blog
thetaphi de/2012/07/ use-lucenes-mmapdirectoryon-64 bit. html,及J6 org prate的博客:
http://jprante.github.io/lessons/2012/07/26/mmap-withlucene.html
通常来说,默认 store类型就是您想要的。有时候也会有所不同,例如也许内存量足够
大,索引也非常大,此时使用mmap类型会更合适。当使用mmap读取索引文件时,会
次性缓存索引数据,然后 Apache Lucene及操作系统能重复使用这些数据。
63准实时、提交、更新及事务日志
个理想的搜索解决方案中,新索引的数据应该能立即被搜索到。 Elasticsearch给人的
第一印象仿佛就是如此工作的,即使是在多服务器环境下,而事实上并不如此(至少不是每
种场景都能保证新索引的数据能被实时检索到),后面我们将讲解原因。
接下来的案例中,我们将使用下面的命令,将一篇文档索引到新创建的索引中
curl-XPOST localhost: 9200/test/test/1-d'i"title":"test"3.
现在,我们将更新该文档,并尝试立即搜索它。为实现该目的,我们将串行执行下面
的两个命令:
curl-XPOST localhost: 9200/test/test/1-d '"title":"test2"3.;
curl-xGET 'localhost: 9200/test/test/ search?pretty
前面的命令将返回类似下面的结果:
I index":"test", "type":"test", id":"l," version": 2,"created":f
alse
took: 1
timed out " false,
shards
"tota1":5,
I successful: 5
failed
whitsun
l totall: 1
I max score: 1.0
hits
Index
nt. wtest
type :test",
score": 1.0,
source":"title: "test192◆深入理解 Elasticsearch
我们把两个结果放在一起来考察。第1个返回结果对应索引命令的操作。正如你所见,
切正常(成功更新了文档,可查看返回结果的 version字段)。第2个返回结果是查询对
应的结果,它的 title字段的值应该是test2,然而返回的是修改前的那个文档,这是怎么回
事?关于上面这个问题,在给出答案之前,不妨去回顾一下 Lucene的内部机制,探究一下
Lucene是如何让新索引的文档在搜索时可用。
63.1索引更新及更新提交
在阅读1.1节时我们已经知道,索引期新文档被写入索引段。索引段是独立的 Lucene
索引,这意味着查询是可以与索引并行进行的,只是不时有新增的索引段被添加至可
被搜索的索引段集合之中。 Apache Lucene通过创建后续的(基于索引只写一次的特性)
segments N文件来实现此功能,该文件列举了索引中的索引段。这个过程被称为提交
( committing), Lucene以一种安全的方式来执行该操作,能确保索引更改以原子操作方式写
入索引。即便有错误发生,也能保证索引数据的一致性。
让我们回到之前的例子,尽管第一个操作添加了文档至索引中,但是它并没有执行提
交操作。这就是返回结果令人惊讶的原因。然而,一次提交并不足以保证新索引的数据能
被搜索到。这是因为 Lucene使用一个叫作 Searcher的抽象类来执行索引的读取。该类需要
被刷新。
如果索引更新提交了,但是 Searcher实例并没有重新打开,那么它觉察不到新索引
段的加人。 Searcher重新打开的过程叫作刷新( refresh)。出于性能考虑, Lucene推迟了
耗时的刷新,因此它不会在每次新增一个文档(或每次批量增加文档)的时候刷新,但是
Searcher会每秒钟刷新一次。这种刷新已经非常频繁了,然而有很多应用需要更快的刷新频
率。如果碰到这种状况,要么使用其他技术,要么审视需求是否合理。 Elasticsearch提供了
强制刷新的API。例如,在我们的例子中,可以使用下面的命令:
curl -XGET localhost: 9200/test/refresh
如果我们在搜索之前执行了该命令,那么将会得到我们预期的结果。
更改默认的刷新时间
Searcher自动刷新的时间间隔可以通过以下手段改变:通过更改 Elasticsearch配置文件
中的 index, refresh interval参数值或者使用配置更新相关的API。例如:
curl-XPUT localhost: 9200/test/ settings -d ' i
nindex
Refresh interval": 5m"第6章底层索引控制◆193
上面的命令将 Searcher的自动刷新时间间隔更改为5分钟。请注意,上次刷新之后新
增的数据并不会被搜索到。
逹刷新操作是很耗资源的,因此刷新间膈时间越长,索引速度越快。如果您需要长
时间高速建索引,并且在建索引结束之前并不执行查询。那么可以考虑将 index.
refresh interval参数设置为-1,然后在建索引结束以后将该参数恢复为初始值。
632事务日志
Apache Lucene能保证索引的一致性,这非常棒。但是这并不能保证当我们往索引中
写数据失败时不损失数据(例如,磁盘空间不足、设备损坏,或没有足够的文件句柄供索
引文件使用)。另外一个问题是频繁提交会导致严重的性能问题(因为每次提交会触发
个索引段的创建操作,同时也可能触发索引段的合并)。 Elasticsearch通过使用事务日志
( transaction log)来解决这些问题。事务日志用来保存所有的未提交的事务, Elasticsearch
会不时创建一个新的日志文件用于记录每个事务的后续操作。当有错误发生时,事务日志
将会被检査,必要时会再次执行某些操作,以确保没有丢失任何更改。事务日志的相关操
作都是自动完成的,用户并不会意识到某个特定时刻触发的更新提交。事务日志中的信息
与存储介质之间的同步(同时清空事务日志)被称为事务日志刷新( flushing)。
洼请注意事务日志刷新与 Searcher刷新的的区别。大多数情况下, Searcher刷新是你
回意所期望的,即搜索到最新的文档。而事务日志刷新用来保障数据正确写入了索引并
清空事务日志。
除了自动的事务日志刷新以外,也可以使用对应的AP例如,我们可以使用下面的命
令,强制将事务日志中涉及的所有的数据更改操作同步到索引中,并清空事务日志文件:
curl-XGET localhost: 9200/ flush
我们也可以使用fush命令对特定的索引进行事务日志刷新(比如说我们的索引名为 library
curl -XGET localhost: 9200/library/ flush
ur1-XGET localhost: 9200/library/ refresh
上面第2行命令中,我们紧接着在事务日志刷新之后,调用了 Searcher刷新操作,打
开了一个新的 Searcher实例。
事务日志相关配置
如果事务日志的默认配置不能满足用户需要, Elasticsearch允许用户修改默认配置以满194◆深入理解 Elasticsearch
足特定需求。以下参数可以通过修改 Elasticsearch yml文件来配置,也可以通过索引配置更
新API更改配置。
口 index. translog. flush threshold period:该参数默认值为30分钟,它控制了强制自动
事务日志刷新的时间间隔,即便是没有新数据写人。强制进行事务日志刷新通常会
导致大量的IO操作,因此有时当事务日志涉及少量数据时,更适合进行频繁的事
务日志刷新操作。
口 index translog flush threshold ops:该参数确定了一个最大的操作数,在上次事务日
志刷新以后,当索引更改操作次数超过该数,则强制进行事务日志刷新操作,默认
情况下不限制操作次数。
口 index. translog flush threshold size:该参数确定了事务日志最大容量,当容量超过该
参数值,就强制进行事务日志刷新操作,默认值为200MB
口 index translog interval:该参数默认值为5s,它描述了连续两次事务日志刷新检查之
间的周期。 Elasticsearch会将该值随机赋值为预设值及其预设值x2之间的一个数。
index. gateway. local sync:该参数定义了通过 fsync系统调用同步事务日志数据的频
度,默认情况是5s一次
口 index translog disable flush:禁用事务日志刷新。尽管默认情况下事务日志刷新是可
用的,但是有时候临时性禁用它能带来其他方面的便利。例如,向索引中导入大量
文档的时候。
洼尽管前面提及的所有参数都被指定用于用户选定的某个索引,但它们同时也定义了
意该索引的每个分片的事务日志处理方式。
当然,除了通过修改 Elasticsearch yml文件来配置上述参数,我们也可以使用API更
改相关配置。例如
curl -xPUT localhost: 9200/test/ settings -d t
nindex":i
translog disable flush":true
如果在向索引导入大量文档之前执行上述操作,则会大幅度提高索引的速度。但是请
记住,当导入数据完毕之后,要重新设置事务日志刷新相关参数。
6.3.3准实时读取
事务日志给我们带来一个免费的特性:实时读取(real- time get),该功能提供了返回第6章底层索引控制◆195
文档各种版本(包括未提交版本)的可能性。实时读取操作从索引中读取数据时,它会先检
查事务日志中是否有可用的新版本。如果近期索引没有与事务日志同步,那么索引中数据
将会被忽略,事务日志中的最新版本的文档将会被返回。
为了演示实时读取的工作原理,我们用下面的命令替换范例中的搜索操作:
cur1-XGET localhost: 9200/test/test/1?pretty
Elasticsearch将会返回类似下面的结果:
n index: l test
type:test
nt id
version
exists: true
source
":I "title":"test2"1
如果你查看了该结果,你将会看到,这正是我们想要的结果,这里我们并没有使用刷
新技巧就得到了最新版本的文档。
64控制索引合并
读者已经知道(我们已经在第1章中讨论过),在 Elasticsearch中每个索引都会创建
到多个分片以及0到多个副本。您当然也知道这些分片或副本本质上都是 Lucene索引,而
Lucene索引又基于多个索引段构建(至少一个索引段)。索引文件中绝大部分数据只写一
次,读多次。索引中只有用于保存文档删除信息的文件会被多次更改。在某些时刻,当某
种条件满足时,多个索引段会被拷贝合并到一个更大的索引段,而那些旧的索引段会被抛
弃并从磁盘删除。这个操作被称为段合并( segment merging)。
也许你会有疑问,为什么非要进行段合并?有以下这些理由:首先,索引段的个数越
多,搜索性能越低并且要耗费更多的内存。另外,索引段是不可变的,你并不能物理上从
中删除信息。也许你碰巧从索引中删除了大量文档,这些文档只是做了删除标记,物理上
并没有被删除。当段合并发生时,这些被标记为删除的文档并没有被拷贝至新的索引段中。
这样的话,减少了最终索引段中的文档数。
③
频繁的文档更改会导致大量的小索引段。这会导致文件句柄打开过多的问题。我们
必须要对这种情况有所准备,比如说,修改系统配置,设置合适的最大文件打开数。
从用户角度来看,可快速地在两个方面对段合并做如下概括:
口当一些索引段合并为一个索引段的时候,会减少索引段的数量并提高搜索速度。196◆深入理解 Elasticsearch
口同时也会减少索引的容量(文档数),因为在段合并时会移除被标记为已删除的那些
文档。
尽管段合并有这些好处,但是用户也应该了解到段合并也有它的代价。主要是IO操作
的代价。在速度较慢的系统,段合并会显著影响性能。基于这个原因, Elasticsearch允许用
户选择段合并策略( merge policy)及存储级节流( store level throttling)
6.4.1选择正确的合并策略
尽管段合并是 Lucene的责任, Elasticsearch也允许用户配置想用的段合并策略。到目
前为止,有3种可用的合并策略:
口 tiered(默认选项)
日 log byte size
日1 og doc
前面提到的每一种段合并策略都有它们自己的参数,这些参数定义了各自的行为特点,
并且这些参数的默认值都是可以被改写的(请阅读后续章节来了解这些参数)
为了告诉 Elasticsearch我们想使用哪个段合并策略,可以将配置文件的 index merge
policy.type字段配置成我们期望的段合并策略类型。例如像下面这样:
index. merge policy. type: tiered
洼一旦使用特定的段合并策略创建了索引,它将不能被改变。但是,可以使用相关
API改变该段合并策略的参数值。
接下来我们可以了解这些不同的段合并策略,以及它们提供的功能。此后我们将讨论
这些段合并策略的具体配置。
1. tiered合并策略
这是 Elasticsearch的默认选项。它合并大小相似的索引段,并考虑了每层允许的索
引段的最大个数。读者需要区分单次可合并的索引段的个数与每层允许的索引段数的区
别。在索引期间,该合并策略将会计算索引中允许出现多少个索引段,该数值被称为阈值
( budget)。如果正在构建的索引中的段数超过了阈值,该策略将先对索引段按容量降序排序
(这里考虑了被标记为已删除的文档),然后选择一个成本最低的合并。合并成本的计算方法
倾向于回收更多删除文档及产生更小的索引段。
如果某次合并产生的索引段的大小大于 indexmerge policy. max merged segment参数
值,则该合并策略将会选择更少的索引段参与合并,使得生成的索引段的大小小于阈值。
这意味着,对于有多个分片的索引,默认的 index merge policy. max merged_segment则显第6章底层索引控制◆197
得过小,会导致产生大量的索引段的创建,从而降低了查询速度。用户应该根据自己具体
的数据量,观察索引段的状况,不断调整合并策略以满足应用需求。
2. log byte size合并策略
该合并策略将会不断地以字节数的对数为计算单位,选择多个索引合并创建新索引
合并过程中,某个时刻会有一些较大的索引段,然后又会产生少于合并因子( merge factor
的一些索引段,如此循环往复。你可以想象,时而有一些相同数量级的索引段,然后索引
段的个数变得比合并因子还少。当碰到一个特别大的索引段时,所有小于该级别的索引段
将被合并。索引中的索引段个数与下次用于计算的字节数的对数成正比。该合并策略能够
保持较少的索引段数量并且极小化段索引合并的代价。
3. log doc合并策略
该策略与 log byte size合并策略类似,不同的是前者基于索引的字节数计算,而后者
基于索引段的文档数计算。以下两种情况中该合并策略表现良好:文档集中文档大小类似,
或者你期望参与合并的索引段在文档数方面相似。
6.42合并策略配置
我们现在已经知道索引的段合并策略的工作原理了,但是还缺乏配置方面的相关知识。
所以现在可以讨论一下每种合并策略及其提供的配置选项。请记住,大多数情况下默认选
项是够用的,除非有特殊的需求才需要修改。
1.配置 tiered合并策略
当使用 tiered合并策略时,以下这些选项可配置。
口 index. merge policy. expunge deletes allowed:默认值为10,该值用于确定被删除文
档的百分比,当执行 expungeDeletes时,该参数值用于确定索引段是否被合并。
a index merge policy. floor segment:该参数用于阻止频繁刷新微小索引段。小于该参
数值的索引段由索引合并机制处理,此时视这些索引段的大小为该参数值。默认值
为2MB
a index merge policy. max merge at once:该参数确定了索引期单次合并涉及的索引段
数量的上限。默认值为10。该参数值较大时,允许更多的索引段参与单次合并,但
是会消耗更多的IO资源。
口 index. merge policy. max_merge at once explicit:该参数确定了索引优化( optimize)
操作及 expungeDeletes操作能参与的索引段数量的上限。默认值为30。该值对索引
期参与合并的索引段数量的上限没有影响。198◆深入理解 Elasticsearch
口 index. merge policy. max_ merged segment:该参数默认值为5GB,它确定了索引期段
合并中产生的单个索引段大小的上限。这是一个近似值,只是因为合并后产生的索
引段的大小是通过累加参与合并的索引段的大小再减去被删除文档的大小而来的。
口 index. merge policy. segments per tier:该参数确定了每层允许出现的索引段数量的上
限。该参数值越小,则导致更少的索引段数量,这也意味着更多的合并操作以及更
低的索引性能。默认值为10,可以设置为大于等于 index. merge. policy. max merge
at once,否则你将遇到很多与索引合并以及性能相关的问题。
口 index reclaim deletes weight:该参数值默认为2.0,它确定了索引合并操作中清除
被删除文档这个因素的权重。如果该参数设置为0,则清除被删除文档对索引合并没
有影响。该值越高,则清除更多被删除文档的合并更受合并策略青睐。
口 index. compund format:该参数值类型为布尔值,它确定了索引是否存储为复合文件
格式( compound format)。默认值为 false。如果设置为tue,则 Lucene将所有文件
存储在一个文件中。有时候这样设置能解决操作系统打开文件句柄过多的问题,但
是也会降低索引和搜索的性能。
2.配置 log byte size合并策略
当采用 log byte size合并策略时,以下选项可配置。
口 merge factor:该参数确定了索引期间索引段以多快的频率进行合并。该值越小,搜
索的速度越快,消耗的内存越少,而其代价则是更慢的索引速度。如果该值设大,
情形则正好相反,更快的索引速度(因为索引合并更少,搜索速度更慢,消耗的内
存更多。该参数默认值为10.0,对于批量索引构建,可以设置较大的值,对于日常
索引维护则可采用较小的值。
口 min merge size:该参数定义了索引段可能的最小容量(段中所有文件的字节数)。
如果索引段大小小于该参数值,并且 merge factor参数值允许,则进行索引段合并。
默认值为1.6MB,该参数对于避免产生大量小索引段是非常有用的。然而,用户应
该记住,该参数值设置为较大值时,将会导致较高的合并成本。
口 max merge size:该参数定义了允许参与合并的索引段的最大容量(以字节为
单位),默认情况下不设置。因此默认情况下,在索引合并时对索引段大小没有
限制。
口 maxMergeDocs:该参数定义了参与合并的索引段的最大文档数。默认情况下不设置,
因此默认情况下索引合并时,对索引段没有最大文档数的限制。
口 calibrate size by deletes:该参数为布尔值,如果设置为true,则段中被删除文档的
数量用于索引段大小的计算。第6章底层索引控制“◆199
3.配置 log doc合并策略
当使用 log doc(文档数对数)合并策略时,可配置以下这些选项。
口 merge factor:与 log byte size合并策略中该参数的作用相同,请参考前面的解释。
口 min merge docs:该参数定义了最小索引段允许的最小文档数。如果某个索引段中
文档数低于该参数值,并且 merge factor参数也允许合并,则将会执行索引合并。
该参数默认值为1000,该参数对于避免产生大量小索引段是非常有用的。但是用户
需要记住,将该参数值设置过大将会增大索引合并的代价
口 max merge docs:该参数定义了可以参与索引合并的索引段的最大文档数。默认情
况下不设置,因此默认情况下,对参与索引合并的索引段的最大文档数没有限制。
口 calibrate size by deletes:该参数为布尔值,如果设置为true,则段中被删除文档的
数量用于索引段大小的计算。
与前面介绍的合并策略类似,上面提及的属性需要以 index merge- policy为前缀。例
如,如果我们想设置 min merge docs属性,则应该设置 index. merge: policy. min merge
docs属性。
6.4.3调度
除了可以影响索引合并策略的行为之外, Elasticsearch还允许我们定制合并策略的
执行方式。有两种索引合并调度器( scheduler),默认的是并发合并调度器 Concurrent
MergeScheduler
1.并发合并调度器
该调度器使用多线程执行索引合并操作。每次开启一个新线程直到线程数达到上限。
如果达到线程数上限,而又必须开启新线程(因为需要进行新的索引合并),那么所有的索
引操作将被挂起,直到至少一个索引合并操作完成。
为了控制最大线程数,可以通过修改 index merge. scheduler, max thread count属性来达
到目的。一般来说,可以按如下公式来计算允许的最大线程数
maximum_value(1, minimum value(3, available processors / 2)
如果我们的系统是8核的,那么调度器允许的最大线程数可以设置为4。
读者请记住,当您使用机械硬盘时,该合并调度策略不是很合适。您很快产生这种念
头:并发合并与磁盘的吞吐能力是否协调。一旦用户观察到很慢的合并,则应调小线程数
量。一般来说,如果用户使用的是机械硬盘,多发合并调度器的线程数应设置为1。
2.顺序合并调度器
该调度器非常简单,使用同一个线程执行所有的索引合并操作。它在执行合并时将会200◆深入理解 Elasticsearch
导致该线程的其他文档处理都被挂起,这意味着索引操作会被推迟。该合并调度器的存在
只是出于兼容性的考虑,事实上并发合并调度器将线程数设置为1时跟它是等价的。
3.设置合并调度
为了设置想要的索引合并调度器,用户可设置 index merge. scheduler type属性值设置为
oncurrent或 serial o。例如,为了使用并发合并调度器,用户应该如此设置:
index merge scheduler. type: concurrent
如果想使用顺序合并调度器,用户则应该像下面这样设置:
index merge scheduler. type: serial
注当谈论到索引合并策略和调度器,可视化演示它是最好不过了。如果您想了解在
Lucene之中索引合并是如何执行的,不妨参阅 Mike mccandless的博客:htp:/blog
mikemccandless. com201102/ visualizing- lucene- segment-merges. html。除此之外,也
可以使用一个叫作 SegmentSpy的插件。可参考下面这个URL中内容:htt: github
com/polyfractal/ Elasticsearch-segmentspyo
65关于IO调节
在本章前面的62节中,讨论了 store类型,并有能力配置适合需求的 store模块。不过
我们并没有深入讨论 store模块的方方面面,甚至没有提及IO调节( 1/0 throttling)。
651控制MO节流
在64节中我们了解到, Apache Lucene把索引数据保存在允许一次写入多次读取的不
可变索引段中。索引合并的过程是异步的,从 Lucene的角度看是不会干扰索引和查询过程
的。然而,很可能会出现问题,因为合并操作非常消耗IO,需要读取旧索引段然后合并写
入新索引段中。如果在此同时进行查询和索引,IO子系统的负荷会非常大,这个问题对于
那些IO速度较慢的系统尤其突出。这就是IO节流的切入点。我们可以控制 Elasticsearch
使用的IO量。
6.52配置
在节点级和索引级都可以配置IO节流。这意味着你可以分别配置节点的资源使用量和
索引的资源使用量。第6章底层索引控制心201
1.节流类型
在节点级配置节流,可以使用 indices. store: throttle type属性。它支持none、 merge、all
这3个属性值。none为默认值,表示不做任何限制。 merge表示在节点上进行索引合并时
限制IO使用量。AⅡl表示对所有基于 store模块的操作都做I/O限制。
在索引级配置节流,可以使用 index. store. throttle type属性。它除了支持 indices. store.
throttle type的所有属性值以外,还支持一个node属性值。node表示使用节点级配置取代
索引级配置。node是默认值。
2.每秒最大吞吐量
在上面两种配置中,无论使用索引级还是节点级的节流配置,我们都可以设置IO可使
用的每秒最大字节数。取值可以设置为10MB、500MB或任意我们需要的值。如果是索引
级的配置,可以使用 index. store. throttle. max bytes per sec属性;而如果是节点级的配置
可以使用 indices. store throttle. max bytes per sec属性。
以上配置都可以通过 Elasticsearch, yml文件配置,也可以动态更新:使用集群更新
设置接口来更新节点级配置,使用索引更新设置接口来更新索引级配置。
3.节点的默认节流配置
在节点级,IO节流从 Elasticsearch0.90.1版本起就默认开启。 indice. store throttle type
属性设置为 merge, indices, store. throttle. max_ bytes per sec属性设置为20MB。而0.90.1版
之前的 Elasticsearch没有默认开启IO节流。
4.性能考虑
如果您使用的是SSD(固态硬盘)或者查询对系统运行速度影响不大(例如索引期间不
执行查询),可以考虑将节流功能彻底关闭。通过将 indices. store throttle type属性值设置为
none来实现该目的。该操作会导致 Elasticsearch不使用任何存储级节流,转而对所有存储
操作使用磁盘。
5.配置示例
现在假定我们有一个4个节点的集群,我们需要给整个集群配置IO节流。我们希望单
节点的索引合并操作每秒最多处理50MB的数据。因为我们知道在这个限制下不会影响查
询性能,而这正是我们的目的。为此,我们需要执行如下命令:
curl-XPUT 'localhost: 9200/cluster/settings, '[
" persistent
indices. store throttle type":"merge",202◆深入理解 Elasticsearch
indices. store throttle. max bytes per sec":"50mb
此外,我们还有一个叫 payments的索引。这个索引极少使用,而我们把它放在整个集
群中最小的那台机器上。该索引是单分片的且没有副本。我们期望限制它的索引合并操作,
只允许它每秒最多处理10MB的数据。因此在上一个命令的基础上,我们还需要执行如下
命令:
curl-XPUT 'localhost: 9200/payments/ settings.-d 'f
index store throttle type":"merge"
windex store throttle. max bytes per sec":"10mb"
在执行完以上命令后,我们可以通过执行如下命令来检查索引设置:
curl-XGET 'localhost: 9200/payments/ settings?pretty
我们将得到如下JSON响应:
"payments":
"settings":[
n index
l creation date: #1414072648520
astore:
l throttle
ntype:merge "
"max bytes per sec":10mb"
"number of shards":5",
"number of replicas":"1
"version": I
n created :1040001
"uuid":"M31ePTOvSN2 jnDz1Jot4Uw
如你所见,通过更新索引设置、关闭再重新打开索引,我们最终让配置变更生效了。
6.6理解 Elasticsearch缓存
缓存在 Elasticsearch里扮演着重要角色,尽管很多用户意识不到它的存在。它允许我们第6章底层索引控制◆203
在内存中存储之前使用过的数据并根据需要适时重用它们。当然,我们不可能缓存所有的
数据,因为数据容量总是大于内存容量,另外内存的构建代价也非常高昂。在本节里,我
们将了解 Elasticsearch提供的各种缓存功能,以及如何控制使用这些功能。了解缓存是如
何工作的对于理解 Elasticsearch内部工作机制是非常有帮助的。
6.6.1过滤器缓存
过滤器缓存是 Elasticsearch中最简单的缓存。过滤器缓存是负责缓存查询中使用的过
滤器的执行结果的。在第2章中,已经介绍过过滤器的原理及使用方法了。为举例说明,
我们看看下面的这个查询:
I query
"filtered ":
"query ":
I' match alln
n filter
i term
category :"romance
它会返回所有在 category字段中包含 romance词项的文档。可以看到,我们使用了
match all查询连同一个过滤器。现在,在这个查询第一次执行以后,每个有与该查询相同
过滤器的查询都会重用其结果,这样节省了宝贵的IO和CPU资源。
1.过滤器缓存的种类
在 Elasticsearch中有两种类型的过滤器缓存:索引级的和节点级的。因此我们可以选择
配置索引级或节点级(默认选项)的过滤器缓存。因为我们不能总是预知给定索引会分配到
哪里(实际上是指索引的分片和副本),于是无法预测内存的使用,所以不建议使用索引级
的过滤器缓存。
2.节点级的过滤器缓存配置
节点级过滤器缓存是默认的缓存类型,它应用于分配到给定节点上的所有分片(设
置 index. cache filter type属性为node,或者不设置这个属性)。 Elasticsearch允许我们使用
indices. cache filter size属性来配置这个缓存的大小。既可以使用百分数,例如10%(默认
值),也可以使用确定的数值,例如1024MB。如果我们使用百分数, Elasticsearch会按当204◆◆深入理解 Elasticsearch
前节点的最大堆内存的百分比来计算内存使用量。
节点级过滤器缓存是LRU类型(最近最少使用)缓存,这意味着为了给新记录腾出空
间,在删除缓存记录时,使用次数最少的那些会被删除
3.索引级过滤器缓存的配置
第2种过滤器缓存类型为索引级过滤器缓存。 Elasticsearch允许我们使用下面的属性来
配置索引级过滤器缓存的行为。
口 index cache. filter type:这个属性设置缓存的类型,我们可以使用 resident、soft、
weak或node(默认值)。在 resident缓存中的记录不能被JVM移除,除非我们想移
除它们(通过使用API,设置最大缓存大小,或者设置过期时间),并且也是因为这
个原因而推荐使用它(填充过滤器缓存代价很高)。内存吃紧时,JVM可以清除soft
和weak类型的缓存,区别是在清理内存时,JM会先选择清除weak引用对象,然
后才是soft引用对象。最后的node属性代表缓存将在节点级控制。
口 index. cache. filter. max size:这个属性指定能够被存储到缓存中的最大记录数(默认
是-1,代表无限制)。需要注意这个设置不是应用在整个索引上的,而是应用于指定
索引的某个分片的某个索引段上的,所以内存的使用量会因索引的分片数和副本数
以及索引中段数的不同而不同。通常来说,结合soft类型,使用默认的无限制的过
滤器缓存就足够了。谨记,慎用某些查询以保证缓存的可重用性。
口 index cache. filter: expire:这个属性指定过滤器缓存中记录的过期时间,默认是-1
代表永不过期。如果我们希望对过滤器缓存设置超时时长,我们可以设置最大空闲
时间。例如,如果希望缓存在最后一次访问后再过60分钟过期,我们应当设置该属
性值为60m。
法如果你想阅读更多关于 Java soft引用和weak引用的信息,请参考Java文档,尤其是关
于这两个类型的说明:htp:/docs. oracle. com/javase/8/ docs/api/java/lang/ref/SoftReference
htmlfahttp://docs.oracle.com/javase/8/docs/api/java/lang/ref/weakreference.html
6.6.2字段数据缓存
字段数据缓存使用时机是当我们的查询涉及非倒排( uninverted)数据操作时。
Elasticsearch所做的是加载相关字段的全部数据到内存中,这样 Elasticsearch就能够快速地
基于文档访问这些值。这种缓存可以被 Elasticsearch用于切面计算、聚合、脚本计算、基
于字段值的排序等地方。当第一次执行非倒排数据相关操作时, Elasticsearch会把所有相关
字段数据加载入内存,默认情况下这些给定字段的数据不会被移除。因此,可以快速访问第6章底层索引控制心205
索引文档中给定字段的值。需要注意的是,从硬件资源的角度来看,构建字段数据缓存代
价通常很高,因为字段的所有数据都需要加载到内存中,这需要消耗IO操作和CPU资源。
法对于每个我们用来排序或做切面计算的字段,其数据都需要被加载到内存中,所有的
词项。这样做的代价非常高昂,尤其是应用于那些高基数的字段(拥有大量不同词项
的字段)时。
1.字段数据与文档值
Lucene的 devalues及其在 Elasticsearch中的实现,随着版本的演进变得越来越优异
从 Elasticsearch1.40开始, doc values几乎与字段数据缓存一样快。因为 doc values在索
引期计算并与索引文件一起存储,所以它并不耗费很多内存。事实上,它只需要少量堆内
存,而速度跟字段数据缓存非常接近。如果您在某些应用场景需要大量使用字段数据缓存,
不妨考虑对此字段使用 doc values。仅需要添加 doc values属性,将其设置为tue,剩下的
Elasticsearch会自行完成。
法在本书撰写之时, Elasticsearch尚不支持在已分词的文本字段上使用 doc values
但是可以在其他类型的字段上使用。
例如,如果您想设置year字段使用 doc values,可按如下方式修改配置信息:
l year
"type":"long"
ignore malformed": false,
nindex":"analyzed "
ll doc values" true
如果您已经重建了索引,当执行那些需要year字段中非倒排数据的操作时,那么此时将
会使用 doc values而不是字段数据缓存。
2.节点级字段数据缓存配置
,在 Elasticsearch0.90.0里,如果我们没有修改配置的话,节点级字段数据缓存是默认的
段数据缓存类型,我们可以通过使用下面的属性来进行配置。
口 index. fielddata. cache.size:这个属性指定了字段数据缓存的最大容量,既可以是一个
百分比的值,例如20%,也可以是一个绝对的内存大小,例如10GB。如果我们使用
百分数, Elasticsearch会按当前节点的最大堆内存的百分比来计算内存使用量。字段
数据缓存的大小默认没有限制,内存消耗应该被监控,因为缓存会消耗分配给JVM206
深入理解 Elasticsearch
的大量内存。
口 index fileddata. cache. expire:这个属性指定字段数据缓存中记录的过期时间,默认被
设为-1,表示缓存中的记录永不过期。如果我们希望设置字段数据缓存过期时长,
可以设置最大空闲时间。例如,如果希望缓存在最后一次访问后再过60分钟过期,
我们应当设置属性值为60m。请记住,字段数据缓存构建代价非常高昂,设置该参
数时需要慎重考虑。
⌒法如果想确保 Elasticsearch使用节点级的字段数据缓存,应当设置 index. fielddata
cache type属性为node,或者不设置这个属性。
3.索引级字段数据缓存配置
与索引级过滤器缓存类似,我们也可以使用索引级别的字段数据缓存,但是因为同样
的原因我们并不建议使用它。原因就是很难预测哪个分片或索引会分配到哪个节点上,因
此我们没法预估缓存每个索引的字段数据缓存需要的内存量,而这会带来内存使用方面的
问题(如当 Elasticsearch进行 rebalancing操作时)。
不过,如果你清楚你在做什么,并且清楚你想使用什么,那么你可以使用 resident或者
soft类型的字段数据缓存。这可以通过设置 index fielddata cache type属性为 resident或soft
来实现。跟我们在描述过滤器缓存时讨论过的情形类似,除非我们自己想删除, resident类
型的缓存是不能被JVM删除的,推荐在使用索引级字段数据缓存时使用 resident类型的缓
存。重建字段数据缓存代价很高,并且会影响 Elasticsearch的查询性能。soft类型的字段数
据缓存在缺少内存时会被JVM清除掉。
4.过滤
除了前面提到的配置选项外, Elasticsearch还允许我们选择将哪些字段值加载到字段数
据缓存中。这在某些情况下非常有用,尤其是在做基于字段数据排序或切面计算或聚合计
算时。 Elasticsearch支持3种类型的字段数据过滤:基于词频,基于正则表达式,或基于两
者的组合。
某些场景中,字段数据过滤非常有用,例如,你想从切面计算的结果中排除那些低频
词项。有时候可能需要这样做:例如,我们知道索引中有些词项存在拼写错误,而这些词
项一定是低基数词项。我们不想基于它们做切面计算,因此可以从数据里删除它们,在数
据源里修正它们,或者使用过滤器从字段数据缓存中删除它们。这不仅在 Elasticsearch的
返回结果里排除了它们,同时因为更少的数据存储在内存中,还降低了字段数据缓存的总
量。现在我们来了解一下可能的过滤选项。第6章底层索引控制心207
(1)添加字段数据过滤信息
为了引入字段数据缓存过滤信息,需要在映射文件的字段定义部分添加一个额外的对
象: fielddata对象及其子对象 filter。于是,扩展后的字段定义,以某个抽象的tag字段为
例,看起来与下面的配置类似:
"tag":
type :"string",
"index":not analyzed",
l fieldata
li filter l
我们会在下一节里介绍 filter对象里应该放些什么。
(2)基于词频过滤
基于词频过滤允许我们只加载那些频率高于指定的最小值且低于指定的最大值的词项。
词频最小值和和最大值由min和max参数指定。词项的频率范围不是针对整个索引的,而
是针对索引段的。同一个词项在段级和索引级的频率分布往往是不一样的,这个差别非常
重要。参数min和max可以赋一个百分比值,例如1%是0.01,50%是0.5,也可以赋一个
绝对词频数。
除此之外,我们可以包含 min segment size属性。这个属性指定了在构建字段数据缓
存时,索引段应满足的最小文档数,小于该文档数的索引段不会被考虑。
例如,如果我们希望只保存来自容量不小于100的索引段,且词频在段中介于1%和
20%之间的词项到字段数据缓存中,那么字段映射看起来会像是下面这样:
li book n
" properties
ntag
"type:string",
index":"not analyzed",
n fielddata
filter:
"frequency":
1
0.01,
:0.2
Imin segment size 100208心深入理解 Elasticsearch
(3)基于正则表达式过滤
除了可以基于词频过滤,也可以基于正则表达式过滤。这时只有匹配特定正则表达式
的词项会被加载到字段数据缓存中。例如,如果我们希望只缓存来自tag字段的数据,也许
是 Twitter标签(以字符#开头),应这样配置映射:
ibook
"properties ":
七
type :string
nindex ": "not analyzed"
"fielddata":
filter
regex:"#
(4)基于正则表达式和词频过滤
可以组合前面讨论过的过滤方法。因此,如果我们想把tag字段的数据保存到字段数据
缓存中,但是只缓存那些以字符#开头,且所在索引段至少有100个文档,并且词项在段
中介于%1和20%之间的词项。那么我们可以做如下映射:
n book i
properties":[
i tas
type
string
"index" :"not analyzed
nfielddatal
filter
frequency
min":0.1
"max":0.2,
min segment size": 100
egex":""井第6章底层索引控制◆209
请注意,字段数据缓存不是在索引期间构建的,但却可以在查询期间重建,于是我
们可以在运行时改变过滤行为,这可以通过使用映射API更新 fielddata配置节来
实现。然而,需谨记在改变字段数据缓存过滤设置后,应清空缓存。这可以通过使
用清理缓存APⅠ来实现,可参考后面的6.6.5节。
(5)一个过滤的例子
现在回到本小节刚开始的那个例子中。我们想排除切面计算结果中的低频词项。在我
们的例子中,低频词项指的是词频最低的那50%的词项。当然,这个频率非常高,例子里
只索引了4个文档,在生产环境中应该指定更低的值。为了验证过滤的效果,我们用下面
的命令创建一个 books索引:
curl-XPOST 'localhost: 9200/books,-d '
u settings":
Inumber of shards": 1
"number of replicas":0
mappings":I
n book t
"properties":i
tag
type" :"string",
lindex":"not analyzed"
Wfielddatal
"filter":i
frequency": I
nin":0.5
max":0.99
然后我们使用 bulk apl索引一些文档(代码存储在随书的 regex. son文件中)
curl -s -XPOST localhost: 9200/ bulk --data-binary
t "index":I"index":"books"," type":"book
idi
"tag":【"one"]}
i "index":[" index":"books m
type:"book","id:2"1
itag": ["one]1
mindex":["index":"books"," type":"book", id:3 31
["tag":["one"]1
t"index":["index":"books"," type ": "book", m idm: "4210◆深入理解 Elasticsearch
["tag":["four"]]
现在,运行下面的查询来验证一个简单的词项切面计算(前面已经讨论过了,切面计算
及聚合计算使用到了字段数据缓存)
curl-xGET localhost: 9200/books/ search?pretty'-d't
query
Mmatch alln
"aggregations":I
mtag":I
n terms
e⊥
ag
查询响应如下:
n took":1
timed out false
n shards
l total": 1
l successful: 1
n failed": 0
"aggregations":
ltag
"doc count error upper bound :0,
l sum other doc count:0,,,
a buckets
l ke
one
It doc count: 3
就像你看到的那样,切面计算只涉及了词项“one",其他4个被忽略了。如果我们假
定词项four存在拼写错误,那么就已经达到目了。
5.字段数据格式
字段数据缓存并不是一个简单的功能,因此它的实现需要尽可能地节省内存空间。由
于这个原因, Elasticsearch为字段数据缓存提供了多种数据格式,分别针对不同的数据类型。第6章底层索引控制◆211
用户可以通过设置 format属性来设置存储在字段数据缓存中数据的格式。可参考下面这个
例子:
itag
"type" :" string",
"fielddata":(
I format: paged bytes
现在,让我们来看看有哪些可用的数据格式。
(1)基于字符串的字段
针对基于字符串的字段, Elasticsearch为字段数据缓存提供了3种数据格式。它们分别
是: paged bytes、fst、 doc values。默认格式是 paged bytes,此时顺序存储词项所出现的位
置,将文档映射到词项,此时数据存储在内存中。第2种格式是fst,此时字段数据缓存中
的数据存储在一种叫作 Finite State Transducer(FST细节可参考htp:/en. wikipedia.org/wiki
Finite state transducer)的数据结构中。这种数据格式比默认的 paged bytes更节省内存
但是性能更慢。第3种数据格式为 doc values,使用该格式时会在索引期计算字段数据缓
存,数据存放在索引文件中。这种数据格式内存使用少,速度与默认格式相近。但是缺点
是不能存储分词字段的数据,另外也不支持字段数据过滤。
(2)数值类型字段
针对数值类型的字段,为字段数据缓存提供了两种格式。默认格式为aray,此时数据
在内存中以数组形式存储。第2种格式为 doc values,此时使用 doc values存储字段数据。
这意味着,使用该格式时会在索引期计算字段数据缓存,数据存放在索引文件中,同时也
不支持字段数据过滤。
(3)基于地理位置信息的字段
基于geo坐标的字段,与数值类型字段类似,默认格式为aray,坐标的经纬度都存储
为数组类型。该字段也支持 doc values格式,使用 doc values存储字段数据。当然,使用
doc values格式时,不支持字段数据过滤。
6.字段数据加载
除了前面介绍的, Elasticsearch还允许用户配置字段数据缓存的加载方式。前面提到过,
默认情况下,字段数据缓存会在第一次使用数据时加载数据,即査询第一次使用到非倒排
数据的时候。可以改变这种行为,方法是在查询中包含 loading属性,将其值设置为eaer
这样设置会驱使 Elasticsearch更主动地加载数据,一旦有数据更新,就会自动加载到缓存
中。例如,如果您想为字段数据缓存配置主动加载tag字段数据,可按如下方式配置:212◆深入理解 Elasticsearch
"tag":
type
istring
u fielddata
"loading": "eager i
将 format属性值设置为 disable,可禁用字段数据缓存的数据加载。例如,想禁止字段
数据缓存加载tag字段数据,可按下面方式修改配置:
tag
"type" :"string".
"fielddata":i
n format: disabled"
请记住,这样定义的字段,对于那些需要非倒排数据的功能是无效的。
6.6.3查询分片缓存
Elasticsearch1.4.0中引入了一种新的缓存(查询分片缓存),可以帮助提高查询性能。
其原理是为每个分片缓存本地查询结果。如果读者还记得的话,当 Elasticsearch执行一个
查询,查询会被发送给所有相关的分片,然后在每个分片上执行查询。然后查询结果会被
发送至接收查询的节点进行合并。而分片缓存的是分片级的局部查询结果。
法在本书撰写的时候,仅缓存 search type指定的那些查询的相关计数。因此,查
询返回的文档并不会被缓存,而每个分片返回的查询命中文档的个数、聚合、查
询建议将会被缓存,这样也能在一定程度上帮助提升查询速度。这种状况将在
Elasticsearch的未来版本中改变。
读者需注意,查询分片缓存默认是被禁用的。不过有两个方法开启它。第1种方法是
通过在索引设置中添加 index cache query enable属性,并将其值设置为true。或者用下面的
实时命令更新索引设置
curl-XPUT localhost: 9200/mastering/ settings'-d
"index. cache query enable":true
第2种方法是每个请求中开启查询分片缓存。可通过在每个查询中设置名为 query
cache的URI参数来实现。读者需注意,此时传递进来的参数将会覆盖索引级的同名设置。
下面是一个查询请求的范例:第6章底层索引控制心213
curl -XGET
localhost: 9200/books/ search? search type=count&query cache=true'-d
n query
"match all":
"aggregations":I
tags": I
i terms i
"field":"tag"
值得一提的是,查询分片缓存有一大优点,它会自动失效及更新。当分片内容变更时,
Elasticsearch会自动更新缓存内容,因此缓存或未缓存查询的结果都是一样的。
设置查询分片缓存
默认情况下, Elasticsearch集群中每个节点最多将1%堆内存用于查询分片缓存。这意
味着一个节点上的所有索引的查询分片缓存最多能使用该节点的1%的堆内存。可通过设置
配置文件 Elasticsearch.yml中的 indices. cache. query.size属性来调整这个百分比
除此之外,也可以设置缓存的超时时间,这个可以通过设置 indices cache query expire属
性来实现,例如,也许您想将超时时长设置为60分钟,那么将该属性值设置为60m即可。
6.64使用 circuit breaker
因为查询会给 Elasticsearch资源带来很大的压力,因此提供了一个叫作 circuit breaker
的功能用于限制某些特定功能使用过多的内存。 Elasticsearch会估算内存使用量,必要的
时候(内存使用量到达某个阈值)会拒绝执行查询。现在我们来看看有哪些可用的 circuit
breaker
1.字段数据 circuit breaker
如果某个査询的内存使用估算值髙于预定值,字段数据 circuit breaker将拒绝该查询执
行。默认情况下, Elasticsearch将 indices. reaker fielddata limit属国性值设置为60%,这意味
着最多JVM堆内存的60%能用于字段数据缓存。
可以设置一个倍增系数, Elasticsearch可以结合 indices. breaker fielddata. overhead属性
来估算内存使用量(内存估计量将会乘以该系数作为阈值)。默认情况下,该系数为1.03。214心深入理解 Elasticsearch
洼请记住,在 Elasticsearch140版本之前, indices. breaker fielddata limit,被称为 indices.
fielddata breaker limit
而 indices. breaker fielddata. overhead属性被称为 indices.
fielddatabreaker overhead
2. request circuit breaker
Elasticsearch1.4.0中引人了 request circuit breaker,允许用户配置当总体内存使用的估
计量高于 indices. breaker request limit属性值时拒绝执行查询(阈值设置为JM默认配置的
堆内存的40%)。
与字段数据 circuit breaker类似,可设置 indices. breaker; request overhead属性值,默认
为1
3. total circuit breaker
除了前面提到的这些 circuit breaker, ElasticsearchI4.0中还引入了 total circuit breaker,
该概念指的是所有 circuit breaker可用内存之和。可以通过设置 indices. breaker. total
overhead属性值来设置它,默认为JVM堆内存值的70%。
凄请注意,对于一个正常工作的集群,所有的 circuit breaker可以通过集群配置更新
API动态修改。
6.6.5清除缓存
我们在前面提到过,有时候清除缓存很关键。 Elasticsearch允许我们使用 cache rest
端点来清除缓存,我们现在就来讨论它的用法。
1.单一索引缓存、多索引缓存和全部缓存的清除
清空全部缓存的最简单的做法是执行下面的命令:
curl -xPoST localhost: 9200/ cache/clear i
当然,就像我们已经习惯了的那样,我们可以选择清空一个或多个索引的缓存。例如,
如果我们想清除 matering索引的缓存,可以执行下面的命令
curl -xPOST ' localhost: 9200/mastering/ cache/clear
如果我们想同时清除 mastering和 books索引的缓存,应该执行下面的命令:
curl -xPOST localhost: 9200/mastering, books/ cache/clear
2.清除特定缓存
默认情况下,当有缓存清除请求到达, Elasticsearch会清除所有的缓存。除了前面提到第6章底层索引控制
215
的清除缓存的方法,我们也可以只清除一种指定类型的缓存。下面列出的是可以被单独清
除的缓存类型。
口 filter:这类缓存可以通过设置 filter参数为true来清除。为了避免这种缓存被清除,
我们需要设置 filter参数为 false。请记住,此类缓存清理并不会立即生效,它会被
Elasticsearch调度到下一个60秒内执行。
口 field data:这类缓存可以通过设置 field data参数为true来清除。为了避免这种缓存
被清除,我们需要设置 field data参数为 false
口 parent- child关系:为了清除缓存中代表 parent-child关系的ID,可设置 id cache参
数值为true。设置该参数值为 false将会防止缓存被清除。
口 shard query:为了清除 shard query缓存,可设置 query cache参数值为tue。设置该
参数值为 false将会防止缓存被清除。
例如,如果我们希望清除 mastering索引的字段数据缓存,但是留下 filter缓存和 shard
query缓存,则可以执行下面的命令:
curl -XPOST
localhost: 9200/mastering/ cache/clear?field data=true&filter=false&g
uery cache=false'
67小结
在本章,我们学习了如何使用不同的相似度方法来改变 Lucene的评分方式。同时也
了解了通过 codec改写倒排索引的写入格式。除此之外,还介绍了准实时搜索和实时读取
及刷新对 Elasticsearch的意义。另外,还讨论了如何按需配置事务日志及O子系统节流。
最后介绍了索引的段合并、合并策略及调度,以及合并过程的可视化。最后,我们探讨了
Elasticsearch的缓存功能。
在下一章,我们将近距离观察 Elasticsearch的系统管理功能,也将了解节点发现与集
群恢复功能,此外还会介绍用户友好的 Cat API。另外,还将介绍如何备份我们的索引,什
么是联合搜索,以及如何在多个集群中索引和搜索数据。源圆题
lic?第7章
管理 Elasticsearch
在上一章中,我们讨论了如何通过使用不同的相关性方法来调整 Lucene的打分。我们
以近乎准实时的方式索引和搜索数据,学习了如何{fush}和{ refresh}数据。我们配置了
事务日志和节流IO子系统,谈到了分段合并以及如何将它可视化。
这一章会讲到 Elasticserarch配置和ES1.0版及后续版本引人的新功能。到本章结束
时,将涵盖以下内容:
口配置发现和恢复模块
口使用 Cat API以人类可读的方式洞察集群状态
口备份/还原功能
口联盟搜索
7.1发现和恢复模块
当你启动ES节点时,ES最先做的事情之一就是查找一个拥有相同集群名称且在网络
上可见的主节点。如果找到了,这个新启动的节点就加入那个已经存在的集群。如果没找
到,这个新节点就选自己成为主节点(当然了,如果你的配置允许它这么做的话)。发现节
点和组成集群的过程叫作发现( discovery)。负责发现的模块有两个作用:选主节点和发现
集群的新节点。
集群建立后,一个称为恢复( recovery)的过程就开始了。在恢复过程中,ES从网关读
取元数据和索引,并且准备好保存在那里的需要使用的分片。主分片恢复完成之后,ES就第7章管理 Elasticsearch◆217
应该可以响应外部请求了。同时,如果存在副本的话,ES将继续恢复其他的副本。
在这一节里,我们会深入了解这两个模块,并讨论ES提供了哪些配置以及修改这些配
置后会有哪些影响
Q法在已经发布的《 Elasticsearch Server, Second edition)中我们也提到了发现和恢复
模块,本节内容是对其的扩展。
7.1.1发现模块的配置
就如我们多次提到的,ES被设计成在分布式的环境中工作。这是ES与其他开源搜索
和分析解决方案相比最主要的区别。基于这个设定,非常容易在分布式环境中组建ES集
群,并不需要强制安裝额外的软件。默认情况下,ES假定集群由声明了相同集群名称且可
以使用组播来相互通信的节点自动组建。这允许我们在同一个网络中组建多个相互独立的
集群。
发现模块有多个实现,下面我们来看看具体是哪些。
zen发现
zen发现是ES里承担发现职责的默认实现,默认有效。Zen发现的默认配置使用组播
来发现其他节点。这是一个很方便的解决方案,只要启动一个ES节点就可以了(新节点会
自动加入拥有相同集群名称的集群,并对集群中其他节点可见)。这一模式非常适合开发阶
段,因为你无需关心如何配置。不过,我们不建议在生产环境中使用它。依赖于集群名称
是很方便的,但也会导致潜在的问题和错误,例如节点的意外加入。有时组播会由于各种
原因不可用,或者你由于这些提及的原因而不想使用组播。对于一个大规模的集群,组播
可能会产生大量不必要的通信,这是另一个我们不应该在生产环境下使用Zen发现的理由。
在这些情形下,Zen发现允许我们使用单播模式。当使用单播Zen发现时,集群外的
节点会发送一个Ping请求到所有配置中指定的地址。通过这种方式,它通知所有指定节点
其已准备好成为集群中的一员,要么加入一个现有集群,要么组建一个新的集群。当然了,
节点加入集群后会获得集群的拓扑信息,但是初始的请求仅发送给了指定的主机。有一点
需要注意一下,即使在使用单播Zen发现时,节点也需要有与其他节点相同的集群名。
包如果你想了解关于ping方法的单播和组播的更多不同之处,可以查看这些地址:
http://en.wikipedia.org/wiki/multicastfuhttp://en.wikipedia.org/wiki/unicast
如果你想了解组播Zen发现的更多配置,我们就来看看它们。218◆深入理解 Elasticsearch
(1)组播Zen发现配置
Zen发现模块的组播部分对外提供如下配置。
口 discovery.zen. ping. multicast. address:用来通信的网络接口,可以是地址或者用接口
名称来指定。默认是所有可用的网络接口。
口 discovery.zen, ping. multicast.port:用来通信的端口号,默认值是54328。
口 discovery. zen. ping. multicast group:组播消息需要发送到的地址,默认是224.2.2.4。
口 discovery.zen, ping multicast buffer size:组播消息使用的缓冲区大小,默认是2028。
口 discovery.zen. ping. multicast.t:组播消息的生存时间默认值是3。消息包每次通过
个路由器,TTS就减一。这可以限制消息能传输到的区域。路由器有可以配置的阈
值来对比TTL,这使得TTL的值可能不等于消息包可以通过的路由器的个数。
口 discovery.zen; ping multicast. enabled:是否开启组播,默认值是true。设置为 false时
会关闭组播。如果你想使用单播Zen发现的话,你应该关闭组播。
(2)单播Zen发现配置
Zen发现模块的单播部对外提供如下配置。
口 discovery.zen.ping. unicast hosts:集群初始节点列表。可以是一个节点列表或者数组。
每个节点可以配置一个名称或者IP地址,还可以加上一个端口号或者端口范围。例
如:[" master"," master2:8181"," master3[8000081000y。通常节点列表不必包含集
群中全部的节点,因为一旦节点连接上了列表中的任意节点,就会被告知集群中所
有节点的信息。
口 discovery;zen.ping, unicast; concurrent connects:单播发现使用的最大并发链接数,默
认10个。如果初始连接阶段有大量的节点需要连接,你应该调高这个默认值。
7.1.2主节点
主节点会监控和管理集群中的其他节点,除了连接其他节点外,选择主节点是也是发
现模块的主要用途之一。选择的过程被称为主节点选举( master election)。无论存在多少
主节点,每个集群在给定的时间内都只会有一个活动的主节点。如果集群中有多个主节点
那么当原来的活动主节点宕机并从集群中删除时,可以从中选举新的活动主节点。
1.配置主节点和数据节点
ES默认允许所有节点成为主节点和数据节点。然而,在特定的情况下,你可能会想
要只承载数据或者处理查询的工作节点,以及仅作为集群管理者的主节点。其中的一种
情况是处理大量的数据,这时数据节点需要尽可能高的性能,不应该被主节点的职能所
延误。第7章管理 Elasticsearch◆219
(1)配置只持有数据的节点
为了设置节点只持有数据,我们需要告诉ES我们不希望这个节点成为主节点。为了达
到这个目的,我们需要在 Elasticsearch yml文件中添加以下的属性:
node. master: false
node data: true
(2)配置只作为主节点的节点
为了设置节点不持有数据并且仅作为主节点,我们需要告诉ES我们不想这个节点持有
数据。为了达到这个目的,我们需要在 Elasticsearch yml文件中添加以下的属性:
node, master: true
node data: false
(3)配置只处理查询请求的节点
对于一个足够大的集群,配置一些仅聚合其他节点查询结果的节点是明智的。这些节点
应该配置为非数据节点、非主节点。于是它们的 Elasticsearch yml文件中应该有以下的属性:
node. master: false
node data: false
洼 node. master和node.data属性默认值是true,但为了使配置清晰,我们倾向于显式
地设置它们。
2.主节点选举的相关配置
我们已经在《 Elasticsearch server, Second edition》中写过关于主节点选举的配置,但
是这个主题非常重要,所以我们决定再刷新一下其相关的知识。
假设你拥有一个由10个节点组成的集群。它一直工作得很好,直到有一天,网络出现
故障,有3个节点从集群中断开连接了,但这3个节点仍然可以相互访问。由于Zen发现
和主节点选举进程的存在,这些脱离集群的节点会选举出一个新的主节点,于是就产生了
两个同名的集群和两个主节点。这种情形被称为脑分裂( split- brain,你必须尽可能地避免
出现这种情形。当发生脑分裂时,将会存在两个或者更多的集群,直至网络或者其他问题
被修复。如果你在这个期间索引数据,那么,当集群从脑分裂中恢复时,会出现数据丢失
和不可恢复的情况。
为了避免脑分裂的出现,或者至少降低其出现的概率, Elasticsearch提供了 discovery
zen minium master nodes属性。这个属性定义了为组建集群至少需要的相互连接的候选主
节点数量。现在回到我们前面讨论的集群,当我们设置 discovery, zen minium master nodes
属性的值为集群中一半的节点数加1时,对于我们的集群来说就是6,那么我们就只会有1
个集群。为什么会这样呢?因为在网络出现故障前,我们有10个节点,多于6个,这些节220今深入理解 Elasticsearch
点会组建一个集群。当有3个节点断开时,这个集群还会正常运行。然而,由于有3个节
点断开,而且3小于6,这3个节点不被允许选举一个新的主节点,它们会等待重新连接上
初始的那个集群。
Zen发现故障检测和配置
Elasticsearch在工作时会运行两个检测进程。第1个进程是由主节点发送ping请求到
集群中的其他全部节点,检测它们是否可用。第2个进程是相反的过程,每个节点都发送
ping请求到主节点,检测主节点是否在运行并履行其职责。然而,如果我们有一个缓慢的
网络或者我们的节点处在不同的地点,默认的配置就可能不够充分了。于是 Elasticsearch
的发现模块提供了3个我们可以修改的属性。
口 discovery.zen, fd ping interval:定义节点多久向目标节点发送一次ping请求,默认1秒。
口 discovery.zen.fd- ping timeout:定义节点在接到ping响应前会等待多久,默认30秒。
如果你的节点被100%的使用或者网络较慢,你可以考虑增加等待时间。
口 discovery.zen.fid; ping retires:定义在目标节点被认为不可用前最大的ping请求重试
次数,默认3次。如果你的网络丢包严重,你可以调高重试次数,或者你可以修复
你的网络。
还有一点我们想说一下。主节点是唯一可以改变集群状态的节点。为了实现一个恰当
的集群状态更新序列, Elasticsearch的主节点每次处理一个集群状态更新请求,在本地更
新,然后发送请求给其他节点,以使这些节点能够同步状态。主节点会在指定的时间内等
待其他节点的响应,如果超时或者全部的节点都返回了当前的确认信息,它会继续执行下
个更新集群状态的请求。为了修改主节点等待回应的时间,你可以修改 discovery.zen
publish timeout属性,默认是30秒。在一个繁忙的网络中工作的大型集群可能会需要调
高这个属性。
3.亚马逊EC2发现
亚马逊除了销售商品之外,还销售一些流行的服务,例如按使用量付费的存储空间和
计算能力。被称为亚马逊弹性计算云(EC2)的服务提供服务器实例,当然它们可以被用来
安装和运行 Elasticsearch集群(也能用来做其他事情,因为它们就是普通的 Linux服务器)。
为了应对流量的变化或者提高计算能力而按照你需要的实例数量来付费是很便利的,当流
量小的时候你可以关闭不必要的实例。 Elasticsearch可以很好地运行在EC2上,但由于环
境的特性,一些功能的工作方式会有所不同。其中一个功能就是发现,因为亚马逊EC2不
支持组播发现。当然我们可以切换到单播发现,但有时我们想要自动发现节点,而使用单
播我们至少需要配置初始主机列表。然而,我们有一个替代,我们可以使用亚马逊EC2插
件,它使用EC2的APⅠ来实现单播和组播发现。第7章管理 Elasticsearch221
洼确保在配置EC2实例期间,实例间是可以通信的(默认通过9200和9300端口),这对
Elasticsearch节点可以相互通信是重要的,组建集群需要它们能够相互通信。当然这个
通信依赖于 network bind host和 network publish host(或者 network host)的配置。
(1)EC2插件的安装
安装EC2插件同安装大多数插件一样的简单,为了安装这个插件,我们需要执行以下
的命令:
bin/plugin install elasticsearch/elasticsearch-cloud-aws/2.4.0
(2)EC2插件的通用配置
为了让EC2发现能够工作,EC2插件提供了一些需要我们配置的属性。
cluster. aws access key:亚马逊 access key,身份凭据之一,你可以在亚马逊配置面
板中找到它们。
u cluster. aws. secrete key:亚马逊 secrete key,同前面提到的 access key类似,你可
在EC2的配置面板中找到它。
最后要做的就是通知 Elasticsearch我们想要使用一个新的发现类型,并且关闭组播。
可以通过设置属性 discovery. type属性为ec2来通知 Elasticsearch
(3)EC2插件的可选配置
前面提到的配置已经足够运行EC2发现了,但是为了控制EC2发现的行为,
Elasticsearch提供了附加的配置。
口 cloud. aws region:地区在连接亚马逊Web服务时用到。你可以选择你的实例所驻留
的地区作为这项的值,例如eu-west-1代表冰岛。在本书写作时可选的值是eu-west、
sa-east、 us-east、us-west-1、 us-west--2、ap- southeast-1和ap- southeast-1。
cloud. aws. ec2 endpoint:如果你使用EC2的API服务,除了定义地区,你还可以提
供一个AwS端点的地址,例如,ec2eu-west-1.amazonas.com。
口 cloud. aws protocol:这是插件用来连接亚马逊web服务的协议。 Elasticsearch默认使
用Https协议(这意味着配置属性值为https我们也可以通过设置属性值为http
来改变这个行为,这样插件就会使用不加密的HTTP协议了。我们也可以通过配
置 cloud. aws.ec2. protocol和 cloud.aws.s3 protocol属性来覆盖每个服务的 cloud.aws
protocol配置,可选的值也是htps和htp
日 cloud. awsproxy host: Elasticsearch允许我们使用一个代理来连接Aws端点。
cloud. aws proxy host属性应当被设置为使用的代理的地址。
日 cloud. aws proxy port:AWS端点代理监听的端口号。
O cloud.aws ec2 ping timeout:等待发送到其他节点的ping请求的被响应的时间,默222◆深入理解 Elasticsearch
认3s。超过这个时间,没有响应的节点会被认为已经宕机并从集群中移除。在遇到
网络问题或者我们有大量EC2节点时,调高这项配置是有意义的。
(4)EC2节点扫描配置
我们想要提及的最后一组配置在组建工作在EC2环境下的集群时非常重要。它们能够
过滤运行在亚马逊云计算网络上的可用 Elasticsearch节点。EC2插件提供以下属性来帮助
我们控制它的行为。
口 discovery.ec2. host type:这个配置允许我们选择用来与集群中其他节点通信时使
用的主机类型。我们可以使用的值是 private ip(默认值,使用私有IP进行通信)
public ip(使用公开I进行通信)、 private dns(使用私有主机名进行通信)和
public dns(使用公开的主机名进行通信)。
口 discovery.ec2. groups:这项是一个用逗号分隔的安全组列表。只有组内的节点才能够
被发现并包含进集群中。
口 discovery.ec2 availability zones:数组或者逗号分隔的可用地区列表。只有指定地区
的节点才能够被发现并包含进集群中。
口 discovery.ec2. any group:默认是true,设置为 false时,会强制EC2插件仅发现那
些匹配全部安全组的节点。默认值仅要求匹配一个安全组。
discovery.ec2.tag:这是一组EC2相关配置的前缀。当你启动亚马逊EC2实例时,你
可以定义标签来描述实例的用途,例如自定义的名称或者环境类型。然后,你用这
些定义的标签来限制节点发现。假设你定义了一个名称为 evironment,值是qa的标
签。在配置文件中你可以做以下的配置
discovery.ec2. tag environment:qa(和只有定义了这个标签的实例在做节点发现时才
会被考虑进去)。
cloud node auto arrtibutes:当设置为true时,( Elasticsearch会添加EC2相关的节点属
性到节点属性中,例如地区和组。并允许我们在 Elasticsearch的分片部署和分片替
换时使用。你可以在第5章的分布式索引架构中找到更多的关于分片替换的信息
4.其他节点发现方式
Zen发现和EC2发现并不是仅有的发现类型。还有两种发现类型被 Elasticsearch团队
所开发并维护,它们如下所示。
OazUreXfe:https://github.com/elasticseaRch/elasticsearchcloud-azure
aGoogleComputeEnginediscoveryhttps:/github.com/elasticseaRch/elasticsearch
cloud-gce
除了这些,还有一些社区提供的发现实现,例如支持早期 Elasticsearch版本的第7章管理 Elasticsearch◆223
Zookeeper发现(htts:/github.com/sonian/Elasticsearch-zookeeper)。
7.1.3网关和恢复模块的配置
网关模块允许我们存储 Elasticsearch正常运行所需的全部数据。这意味着不仅存储
Apache lucene的索引数据,还存储所有的元数据(例如关于索引分配的相关配置),以及每
个索引的映射信息、。每当集群的状态改变时,例如,当分配属性被修改了,集群的状态都
会通过网关模块持久化。当集群启动时,集群的状态会从网关模块加载并应用在集群上。
当为不同的节点配置了不同的网关类型时,索引会使用其所在节点上的网关配置。如
果索引的状态不应该通过网关模块来保存,你需要显式地设置索引网关类型为none。
1.通过网关来恢复的过程
让我们说得更清楚些,恢复过程加载通过网关模块存储的数据以使 Elasticsearch正常
工作。每当集群整体重启发生时,恢复过程就会启动,加载所有我们提到的相关信息:元
数据、映射和索引。当恢复过程启动时,主分片( primary shard)会首先初始化,然后根据
副本( replica)的状态,副本会使用网关数据,或者当它们同主分片不同步时使用拷贝自主
分片的数据。
Elasticsearch允许我们配置何时需要使用网关模块恢复集群数据。我们可以告诉
Elasticsearch在开始恢复过程前等待一定数量的候选主节点或者数据节点加入集群。然而,
需要注意的是,在集群完成恢复前,其上的所有操作都是不被允许的。这样做的目的是防
止修改冲突。
2.相关配置属性
在开始讨论配置之前,还想说一件事情。你知道 Elasticsearch可以有不同的角色,它
们可以是数据节点(只持有数据),可以是主节点,或者仅作为请求处理节点(既不持有数
据,也不是主节点)。记住这些之后我们来看看可以修改的网关配置。
口 gateway. recovery after nodes:集群中存在多少个节点后才启动恢复过程。例如,设为
5,那么至少需要5个节点加入才会开始恢复过程,无论它们是数据节点还是主节点。
口 gateway. recovery after data_ nodes:集群中存在多少个数据节点后才启动恢复过程。
口 gateway. recovery after master nodes:集群中存在多少个主节点后才启动恢复过程。
日 gateway. recovery after time:当前面的条件满足后,等待多少时间才开始恢复过
程。例如设置为5m,当定义好的条件满足后,再过5分钟才会开始恢复过程。从
Elasticsearch1.3.0开始,默认是5分钟。
假设我们的集群有6个节点,其中4个是数据节点。我们还有一个由3个分片构成的
索引分布在集群中。最后两个节点是主节点,不持有数据。我们希望配置恢复过程在4个224◆深入理解 Elasticsearch
数据节点加入后延迟3分钟开始。那么我们的配置就会是下面的样子:
gateway recover after data nodes: 4
gateway recover after time: 3m
3.对于节点的期望
除了我们已经提到的属性外,还有一些属性可以强制开始 Elasticsearch的恢复过程。
它们如下所示:
口 gateway. expected nodes:立即开始恢复过程前集群中必须存在的节点数。如果你不
希望恢复过程延启动,建议设置这个属性为足够组成集群的节点数(或者至少是大
多数),因为这样能够确保集群恢复到最近的状态。
口 gataway. expected data_ nodes:立即开始恢复过程前集群中必须存在的数据节点数。
口 gateway. expected master nodes:立即开始恢复过程前集群中必须存在的主节点数。
现在回到前面的例子。我们希望在全部的6个节点在线时启动恢复过程。所以,除了
前面的配置外,我们可以加上以下的配置:
gateway expected nodes: 6
完整的配置如下:
gateway recover after data nodes: 4
gateway recover after time: 3m
gateway expected nodes: 6
上面的配置意味着,一旦有4个数据节点在线,恢复过程会延迟3分钟后启动;而当6
个节点在线时会立刻启动,不论它们是数据节点还是主节点。
4.本地网关
随着0.20版本 Elasticsearch的发布(以及一些0.19版之后的版本),除了本地网关外的
其他类型的网关都被弃用了。建议你不要再使用它们了,因为它们会在 Elasticsearch将来
的版本中被移除。现在它们还在,但是如果你想避免重新索引全部的数据,你应该只使用
本地网关。这也是为什么我们不讨论其他类型的网关。
本地网关使用节点上可用的本地存储来保存元数据、映射和索引。为了使用本地网关
和节点上可用的本地存储,需要有足够的磁盘空间来容纳数据。
本地网关持久化数据的方式不同于其他的类型的网关(已经弃用)。本地网关在写人数
据时是以同步的方式进行的,这样是为了确保在写入过程中不会丢失数据。
③漆想要设置使用的网关类型,可以设置 gateway type属性,默认是 local
关于 Elasticsearch的本地网关还有一点我们没有谈到,就是悬空索引( dangling
indices)。当一个节点加入集群,节点上存在的但不在当前集群中的分片和索引也会被包含第7章管理 Elasticsearch◆225
进集群中。这类索引就被叫作悬空索引。我们可以选择 Elasticsearch对待它们的方式。
Elasticsearch提供了 gateway. local auto_import dangling属性,可以接受的值有yes(默
认值,表示导人所有的悬空索引到集群中)、 close(导入悬空索引到集群中,但是置为关
闭状态)、no(删除悬空索引)。当配置为no时,我们还可以配置 gateway. local dangling
timeout属性(默认2小时)来指定在删除悬空索引时 Elasticsearch会等待多久。悬空索引
功能在我们重启 Elasticsearch旧节点,且不希望老索引被包含进集群中时能有所帮助。
5恢复过程的底层配置
我们讨论过可以通过网关来控制 Elasticsearch恢复过程的行为,但是,除此之外,
Elasticsearch也允许我们直接配置恢复过程如何工作。在谈到分片分配(5.3节)时,我们
已经提到过一些恢复配置选项,但是,我们认为在专注网关和恢复的章节里讨论一下这些
配置是有必要的。
(1)集群级别的恢复配置
恢复过程的配置多数都在集群级别给定,允许我们设置恢复模块工作时遵守的通用规
则。这些配置如下。
a indices, recovery. concurrent streams:在从数据源恢复一个分片时可以同时打开的流
的数量,默认为3个。这个值越髙,带给网络层的压力就越大,不过,依赖于网络
使用和吞吐量,恢复过程可能更快些。
a indices. recovery. max types per sec:在恢复分片时每秒可以传输的最大数据量,默
认为20MB。如果要需要传输限制,可以设置为0。同并发流的数量类似,这个属性
可以用来控制恢复过程对于网络的使用。设置为更高的值可带来更高的网络使用和
更短的恢复时间。
indices. recovery compress:恢复过程在传输数据时是否压缩数据,默认为true。设为
false可以降低CPU的压力,但是会造成网络传输数据量的加大。
d indices. recovery file chunk size:从源分片拷贝数据时数据块的大小,默认是
512KB,当开启了压缩选项时数据块会被压缩。
a indices. recovery. translog_ops:恢复过程的一次请求里在分片间传输的事务日志的行
数,默认为1000。
J indices. recovery. translog size:从源分片拷贝事务日志时使用的数据块的大小,默认
为512KB,当开启了压缩选项时数据块会被压缩。
在0.90.0版之前的 Elasticsearch版本中,有一个 indices. recovery. max Size per sec
属性,现在已经弃用了,并建议使用 indices. recovery. max types per sec属性来替
代。然而,如果你使用的是090.0之前的版本,可能需要用到这个。226
深入理解 Elasticsearch
前面提到的全部配置都能使用更新集群的API来设置,或者使用 Elasticsearch yml文
件来配置。
(2)索引级的恢复配置
除了前面提到的那些配置项,还有一个索引级的配置项。这个配置可以通过
Elasticsearch yml文件和更新索引的API来设置。这个配置项是 index. recovery. initial shards
通常,只有在有特定数量的分片存在,并且可以被部署时, Elasticsearch才会恢复一个分片。
这个特定数量是指定索引的分片数量的一半加上1。通过使用 index. recovery. initial shards配
置,可以改变 Elasticsearch将什么当作这个特定数量。可选的配置值如下
口 quorum:50%加1的分片存在且可部署。这项是默认值。
口 quorum-1:50%的分片存在且可部署。
口ful:给定索引的全部分片存在且可部署。
口full1:给定索引的全部分片数减1个分片存在且可部署。
口整数值:任意整数,例如1、2和5。指定需要存在的可部署分片数。例如,设置为
2意味着至少需要存在2个可部署的分片, Elasticsearch才会恢复这个索引的分片。
了解这个配置项是有意义的,但是在大多数情况下,默认值对于 Elasticsearch的部署
已经足够了。
7.14索引恢复AP
介绍了索引恢复API后,我们将不再受限于仅仅观察集群的状态,类似以下的内容:
curl 'localhost: 9200/ cluster/health?pretty'
cluster name": "mastering elasticsearch"
status":"red",
timed out false
Inumber of nodes": 10
iNumber of data nodes: 10
"active primary shards " :9,
n active shards: 9
"relocating shards":0,
initializing shards":0,
Unassigned shards":1
通过向 recovery端点发送GET请求(查询全部索引或者指定索引),我们可以得到索
引恢复的状态。例如,我们看以下的请求:
curl-xGET localhost: 9200/ recovery?pretty
前面的请求会返回关于集群中所有分片的恢复相关的信息,包括正在进行和已经完成
的。在我们的例子里如下:第7章管理 Elasticsearch◆227
ltest index
l shards
id":3
type : GATEWAY I
"stage
ISTART",
primary: true,
Start time in millis": 1414362635212
"stop time in millis":0,
ntotal time in millis": 175,
l source
wid":"3M ErmCNTR-huTgoTv5 smw,
"host":"192.168.1,10",
"transport address":"inet [/192.168.1.10: 9300]"
"ip":"192.168.10"
Iname: nodell
ntarget:
id":"3M ErmCNTR-huTgoTv5smw",
"host":"192.168.1.10"
transport address":"inet[/192.168.1.10: 9300]
"ip":"192.168.1,10
Iname t "nodel
n index"
l files
"tota1":400,
I reused: 400
Recovered":400
percent":"100.0号"
"bytes":
"tota1":2455604486,
" reused":2455604486,
" recovered":2455604486,
" percent":"100.0詈"
ltotal time in millis": 28
"translog": i
i recovered
n total time in millis": 0
"start "
l check index time in millis":0,
n total time in millis": 0
id":9
type:"GATEWAY
"stage":"DONE",
primary " true,
start time in millis": 1414085189696228◆深入理解 Elasticsearch
"stop time in millis":1414085189729,
ltotal time in millis": 33
nid": "nNw k7 XSOivvPCULHVE5A
"host":"192.168.1.11",
"transport address":"inet [/192.168.1. 11: 9300]"
"ip":"192.168,1.11",
lI name": "node 3
target":
id": nNw k7 XSOiVvPCULHVE5A'
lt host
192,168.1.11
u transport address "inet [/192 168.1. 11: 9300]
"192.168.1.11
name": "node 3 "
wt index"
u files"
u total": 0
Reused:0,
recovered"
percent":"o.0旨"
mbytes"
w total": o
Reused":0,
recovered":0,
" percent":"0.0号"
l total time in millis": 0
trans log
l recovered :0
n total time in millis": 0
start
l check index time in millis":0
n total time in millis: 33
前面的响应中包含了 test index索引的两个分片的信息(为了方便观察,其他的分片信
息被删除了)。我们可以看到一个分片正在恢复中(" state":" started"),另一个分片已经完成
恢复了(" state":"DONE")。我们可以看到大量的有关恢复过程的信息,这些信息是索引级
别的信息,通过这些信息我们可以清楚地看到 Elasticsearch处在怎样的状态。我们也可以第7章管理 Elasticsearch心229
通过在请求中加上 active only=true参数来限制只返回处在恢复中的分片。例如
curl-xGeT 'localhost: 9200/ recovery?active only=true&pretty
如果我们想获得更详细的信息,可以在请求中加上 detailed=true参数,就像下面这样:
curl-XGET localhost: 9200/ recovery ?detailed=true&pretty i
72使用人类友好的 Cat API
Elasticsearch管理API非常广泛,涵盖了 Elasticsearch架构的几乎每个部分,从有关
Lucene的低层信息,到关于集群节点和其健康状态的高层信息。所有的这些信息都能通过
Elasticsearch提供的 Java API或者 REST API来得到。然而,这些信息是JSON格式的,并
且,返回的数据有时不进行进一步的解析是难以分析的。例如,试着在你的 Elasticsearch
集群上执行以下请求:
curl -XGET 'localhost: 9200/ stats?pretty
对于本地只有一个节点的集群, Elasticsearch返回了如下的信息(做了大量的删减,完
整的响应可以在随书提供的 stats. ]son文件中找到)
It shards
n total: 60
"successful":30,
Failed": 0
a11
"primaries ":
"total:
lr indices
如果你查看 stats. ]son文件,你会看到响应有大约1350行。对于人类来说,不进行进
步的解析这是很难分析的。由于这个原因, Elasticsearch给我们提供了更加人性化友好的230◆深入理解 Elasticsearch
Cat API。 Cat API以简单的文本、表格的形式来返回数据,并且还提供常用的聚合信息,避
免了对数据的进一步处理。
法记得曾告诉过你, Elasticsearch允许你获取的信息并不限于JsON格式吗?如果你
意忘记了,请试着在请求中加上 format==yaml参数。
7.2.1基础知识
Cat ApI的基础端点非常明显,就是/cat,没有任何参数,它会显示所有可用的端点。
我们可以通过运行以下的命令来测试一下:
curl -xGET localhost: 9200/ cat'
Elasticsearch的响应应该跟下面的类似或者相同(依赖于你的 Elasticsearch的版本):
cat/allocation
cat/shards
cat/shards/index
cat/master
cat/nodes
cat/indices
cat/indices/index)
cat/segments
cat/segments/index]
cat/count
cat/count/index)
cat/recovery
cat/recovery/(index)
cat/health
cat/pending tasks
cat/aliases
cat/aliases/alias)
cat/thread pool
cat/plugins
cat/fielddata
cat/fielddata/(fields)
看一下 Elasticsearch允许我们使用 Cat API来获取哪些信息
口分片部署相关的信息
口所有分片相关的信息(限定为特定的索引)
口节点的信息,包括选出的主节点的信息
口索引统计信息(限定为特定的索引)
口段的统计信息(限定为特定的索引)
口文档计数(限定为特定的索引)第7章管理 Elasticsearch
231
口恢复信息(限定为特定的索引)
口集群健康情况
口待执行任务
口索引别名和指定别名所对应的索引
口线程池配置
口每个节点上安装的插件
口字段数据缓存的大小和每个字段数据缓存的大小
722使用 Cat Ap
让我们通过一个例子来开始使用 Cat API。我们以查看集群健康状态来开始。我们只需
执行以下的命令:
curl -xGET ' localhost: 9200/ cat/health'
Elasticsearch对于上面命令的响应应该类似于以下的内容:
41434709019:11:30e1 asticsearch ye11ow1147470047
这非常清晰易读。因为它是以表格的形式,非常容易把这个响应用于grep、awk或者
sed工具中。一旦你了解了响应内容的含义,可读性会更强。为了给每一列加上一个描述其
意义的标题,我们只需要增加一个v参数,就像下面这样:
curl -xGET localhost: 9200/ cat/health?v
这次的响应跟我们前面看到的很像,但是现在有一个表头来描述每一列
epoch
timestamp cluster
status node. total node data shards
pri relo init unassign
1414347107 19: 11: 47 elasticsearch yellow
47
47
47
通用参数
每个 Cat API都有自己的参数,但是有一些选项是它们共同拥有的。
口v:给响应添加一个表头,标明每列数据的名称。
口h:限制只显示选定的列(参见下节的内容)。
口help:显示这个特定端点可以显示的所有可能的列。显示这个特定端点的参数名、参
数缩写和其描述信息。
口 bytes:这是呈现字节量信息的格式。我们说过, Cat API被设计为给人类使用,由此
这些值默认以人类可读的方式呈现,例如:3.5kB,或者40GB。 bytes选项允许我们
给所有的数字设置基数,因此排序或者对比数值就相对容易了。例如 bytes=b表示所
有的值是以byte为单位的, bytes=k表示以kB为单位,以此类推。232◆深入理解 Elasticsearch
漆想查看每个 Cat API端点的完整参数列表,可以参考 Elasticsearch E官方文档,地
HiEXehttp://www.Elasticsearch.org/guide/en/elasticsearch/reference/current/cat.html
723一些例子
当我们撰写本书时, Cat APi有21个端点。我们不想全部都介绍一下,那样只是对官
方文档信息的重复,或者是对管理API章节的重复。但是在没有给出任何关于使用 Cat API
的例子前,我们还不想结束这个小节。因此,我们决定向你展示一下,与对比 Elasticsearch
标准的 JSON API相比,使用 Cat api获取信息有多么的容易。
1.获取关于主节点的信息
第1个例子向你展示获得集群中哪个节点是主节点的信息有多么容易。通过调用/cat
master端点,我们能够得到节点中哪个被选为了主节点。例如,我们执行以下的命令:
curl-XGET 'localhost: 9200/ cat/master?vI
对于本地的2节点集群, Elasticsearch的响应看起来是下面的样子
id
host
Ip
node
8gfdQIV-SxKBOuUxkjbxSg Bansheelocal 10.0.1.3 Siege
从响应中你可以看到,我们得到了哪个节点被选为主节点,我们能看到它的ID、IP地
址和名称。
2.获得关于节点的信息
/ cat/nodes端点提供了集群中全部节点的信息。让我们看看在执行以下的命令后
Elasticsearch会返回什么:
curl -XGET 'localhost: 9200/ cat/nodes ?v&h=name, node. role, load, uptime
在上面的例子里,我们使用了从这个端点的大约70个选项中定制我们想要返回的信息的
能力。我们现在只获得节点名称、角色(节点是数据节点还是客户端节点)、负载和运行时间。
Elasticsearch的响应如下
name
node role load uptime
Alicia Masters d
6.096.7m
Siege
a
6.09
lh
如你所见,/ cat/nodes端点提供了请求的关于集群中节点的全部信息。
73备份
对于管理员来说,其最重要的任务之一就是确保在系统出故障时没有数据会丢失。在第7章管理 Elasticsearch心233
Elasticsearch的设定中,它是一个健壮的、易于配置的由节点组成的集群,甚至能够在一些
并发的故障中幸免。然而,即使是完美配置的集群在面对网络分割和网络分区时也是脆弱
的,在一些罕见的情况下会造成数据损坏或者丢失。在这些情况下,能够从重建索引中拯
救我们的,就只有从备份中恢复数据这唯一的办法了。
你可能已经知道我们要说什么了: Elasticsearch提供的快照/还原功能。不过,就像
我们之前说的,我们不想重复我们自己,本书是面向 Elasticsearch的高级用户的。基础
的快照/还原AP我们已经在《 Elasticsearch server, Second edition》中描述过了,在
Elasticsearch官方文档中也有提及。现在,我们想聚焦在 Elasticsearch1.0版发布之后加入
的且在前一本书中被忽略了的功能让我们来讨论 Elasticsearch的云备份能力。
在云中保存备份
快照/还原功能的核心概念是一个仓库。它是一个我们的数据(索引和相关源数据信息)
可以安全存储(假设这个仓库是可靠的、高可用的)的地点。假设集群中的每个节点都能够
访问仓库,能够读取和写入。由于高可用性和可靠性的需要, Elasticsearch在附加插件的帮
助下,允许我们将数据推送到集群外部,例如云端。通过官方支持的插件,至少有3种可
以部署的仓库。
口S3仓库:亚马逊Web服务
口HDFS仓库: Hadoop集群
口 Azure仓库:微软云平台
因为我们没讨论过任何有关快照/还原功能的插件,让我们了解一下它们,看看我们能
将要备份的数据推送到哪里。
1.S3仓库
S3仓库是 Elasticsearch的AW插件的一部分,所以为了使用S3作为保存快照的仓
库,我们需要首先安装这个插件:
bin/plugin -install elasticsearch/elasticsearch-cloud-awB/2.4.0
在集群中的每个节点上都安装了插件后,我们需要修改它们的配置( Elasticsearch yml
文件)来提供AWS的访问信息。作为例子的配置如下:
cloud
aws
access key: YOUR ACCESS KEY
secret key: YOUT SECRET KEY
为了创建 Elasticsearch用来保存快照的S3仓库,我们需要执行一个类似下面代码的234◆深入理解 Elasticsearch
curl-xput'http://localhost:9200/Bnapshot/s3repository
type ":"83",
settings
{
bucket": "bucket name
在定义基于S3的仓库时支持以下的配置。
口 bucket:指定 Elasticsearch读写数据时使用亚马逊S3的哪个桶( bucket),这项是必
填项。
口 region:指定前面使用的桶所在的AWS区域,默认是“ US Standard”。
口 base path: Elasticsearch默认将数据写到根目录。这个参数允许你指定想要写入的
目录。
口 server side encryption:是否开启加密,默认关闭。如果想使用AES256算法来加密
数据,可以设置为true
口 chunk size:指定数据块的大小,默认为100MB。如果快照的大小大于 chunk size,
Elasticsearch会切分数据为不大于 chunk size的多个小数据块。
口 buffer-size:缓冲区的大小,默认5MB,也是最小有效值。如果数据块的大小大于
buffer size, Elasticsearch会把数据块切分为 buffer size大小的多个段,然后使用
AWS的 multipart接口来发送。
口 max retries:指定 Elasticsearch在放弃读取或者保存快照前最多重试的次数。默认为
3次。
除了以上的属性,我们还可以设置两个属性,它们可以覆盖保存在 Elasticsearch yml文
件中用来连接S3的身份信息。这在你想使用多个S3仓库时非常便利,每个仓库都有自己
的安全配置。
J access key:这项覆盖 elaticsearch.yml文件里的 cloud. aws access key
secret key:这项覆盖 elaticsearch yml文件里的 cloud. aws. secret key
2HDFS仓库
如果你使用 Hadoop和HDFS(htp:/ wiki. apache. org,/ hadoop/HDFS)系统,备份
Elasticsearch数据的一个不错的替代就是保存到 Hadoop集群中。如同S3的例子,有一个
专门的插件来实现这个功能。我们使用以下的命令来安装这个插件:
bin/plugin -i elasticsearch/elasticsearch-repository-hdfs/2.0.2
注意,有一个专门支持2.0版 Hadoop的插件。这种情况下,我们应该在插件名后加上
hadoop2来进行安装。于是对于 Hadoop2,我们安装插件的命令看起是下面的样子:第7章管理 Elasticsearch◆235
bin/plugin -i elasticsearchyelasticsearch-repository-hdfs/2.0.2-hadoop2
在 Hadoop已经安装 Elasticsearch所在的服务器上时,还有一个轻量级的版本。这个版
本不包含 Hadoop类库。要安装这个轻量级的版本,需要使用以下的命令:
bin/plugin -i elasticsearch/elasticsearch-repository-hdfs/2.0.2-light
当每个 Elasticsearch节点上都安装了插件(使用的是哪个版本的插件无所谓)且重新启
动了集群后,我们可以使用以下的命令在 Hadoop集群中建立一个仓库:
curl-xput'http://localHost:9200/snapshot/hdfsrepository'-d't
"type":"hdfs
settings:
{
path": "snapshots"
我们能够使用的配置如下。
口uri:指定HDFS的地址,可选参数,需要满足hdfs:/HOST:PORT这样的格式。
口path:关于快照需要被存储的路径的信息,这是必填参数。
口 load default:指定是否读取 Hadoop配置的默认参数,如果需要禁止读取这些参数,
可以设置为 false
口 conf location: Hadoop配置文件的名称,默认是 extra-cg.xml
口 chunk size:指定 Elasticsearch切分快照数据时使用的数据块的大小。默认是10MB。
如果你想加快保存快照的速度,可以设置一个更小的块大小和更多的流来向HDFS
推送数据。
口conf.<key>:key可以是任意的 Hadoop参数。通过这个属性配置的值会合并到
Hadoop配置里。
口 concurrent streams:指定一个单一节点使用多少个并发流来向HDFS读写数据,默
认为5个。
3. Azure仓库
我们想提及的最后一个仓库是微软的 Azure云。同亚马逊S3类似,我们可以使用一个专
门的插件来推送索引和元数据到微软的云服务。我们可以通过以下的命令来安装这个插件:
bin/plugin -install elasticsearchyelasticsearch-cloud-azure/2.4.0
插件的配置也类似亚马逊S3的配置。我们的 Elasticsearch yml文件需要包含以下的段落:
cloud
azure.
storage account: YOUR ACCOUNT
storage key: YOUT SECRET KEY236心深入理解 Elasticsearch
配置好 Elasticsearch后,我们需要创建具体的仓库,可以通过以下的命令来创建:
curl-xput'http://localhost:9200/_anapshot/azurerepository'-d'(
type":"azure
Elasticsearch的 Azure插件支持以下的配置。
口 container:跟使用亚马逊S3类似,所有的信息都保存在容器中。这项配置指定微软
Azure空间的容器名称。
口 base path:这项配置允许我们改变 Elasticsearch存放数据的路径。 Elasticsearch默认
把数据保存在根目录。
口 chunk size: Elasticsearch使用的数据块的最大值(默认64m,也是允许的最大值)。
在数据需要被切分成更小的数据块时,你可以改变这个值。
74联盟搜索
有时把数据保存在一个集群中是不够的。想象以下情况,你有多个地点需要索引和搜
索数据,例如:本地公司部门用他们自己的集群来保存数据。公司的数据中心可能也想搜
索这些数据,不是一个地点一个地点地搜索,而是一次搜索全部。当然,在你的搜索应用
中,你可以连接全部的这些集群,然后合并这些结果,但是从 Elasticsearch的1.0版开始,
还可以使用部落节点( tribe node)来实现。部落节点作为联合客户端可以提供访问多个
Elasticsearch集群的能力。部落节点的功能是从连接的集群中获取所有的集群状态,并合并
这些状态为一个全局的状态。在本小节中,我们会讨论一下部落节点,以及怎么配置和使
用它们。
法请记住我们讨论的功能是在 Elasticsearch的1.0版之后引入的,并且仍然被标记为
实验性的。在将来的版本中它可能被修改甚至被移除。
7.4.1测试用的集群
为了想你展示部落集群是如何工作的,我们会创建两个保存数据的集群。第1个集群
叫作 mastering_one(想必你还记得怎么设置集群名称,你需要在 Elasticsearch.yml文件
中设置 cluster name属性),第2个集群叫作 matering two。为了尽可能地简单,每个集
群都只包含一个节点。集群 mastering one的唯一节点的IP地址是192.168.56.10,集群
mastering two的唯一节点的IP地址是1921685640。第7章管理 Elasticsearch◆237
集群1中索引了以下的文档:
curl -XPOST 192.168.56.10: 9200/index one/doc/1-d I "name":"Test
document 1 cluster 1"1
curl -XPOST 192.168. 56.10: 9200/index one/doc/2'-d'Iname":"Test
document 2 cluster 1"]
集群2中索引了以下的文档:
curl-XPOST.168.56.40: 9200/index two/doc/1-d I"name":"Test
document 1 cluster 2"1
curl-XPOST 192.168 56.40: 9200/index two/doc/21-d 't"name":"Test
document 2 cluster 2"'
7.42建立部落节点
现在,让我们试着创建一个简单的部落节点,默认使用多播发现。为此,我们需要
个新的 Elasticsearch节点。我们同样需要为这个节点提供一个配置来指定部落节点需要连
接的集群,在我们的例子里,就是之前创建的两个集群。为了配置我们的部落节点,我们
需要 Elasticsearch yml文件中存在以下的内容:
tribe. mastering one cluster name: mastering_one
tribe. mastering two cluster name: mastering_ two
部落节点的配置项都以tibe为前缀。在上面的配置中,我们告诉 Elasticsearch我们有
两个部落,一个叫作 mastering one,一个叫作 masting two。部落名可以是任意的名称
只是用来区别不同的集群。
我们可以启动部落节点了,我们将在IP地址是1921565650的服务器上启动它。启动
后,我们将尝试使用默认的多播发现来找到 mastering one和 mastering two集群,并连接
它们。你会在部落节点的log中看到下面的内容:
[2014-10-3017:28:04,377][INFo][ cluster. service
[Feron] added i [mastering one node 1] [mGF6HHOORQGYkVTzuPd4JwJ
[ragnar] [inet [/192. 168.56.10: 930011(tribe name=mastering_one),
reason: cluster event from mastering one, zen-disco-receive(from
master [[mastering one node 1] [mGF6HHOORQGYkVTzuPd4Jw] [ragnar]
[inet[/192.168.56,10:930011])
[2014-10-3017:28:08,288][INFo][c1 uster. servlce
[Feron] added [mastering two node 1][ZqvDAsYIRmylH46hqCTEnw
ragnar] [inet [/192.168.56.40: 93001][tribe name=mastering_two),
reason: cluster event from mastering two, zen-disco-receive(from
master
Mastering two node 1] [ZqvDAsY1RmylH4 6hgCTEnw] [ragnar]
[inet[/192.168.56,40:9300]]])
可以看到,部落节点将两个集群联合到了一起。
使用单播发现来组成部落
当然了,使用多播发现来组建部落不是唯一的办法,如果需要,我们也可以使用单播238
深入理解 Elasticsearch
发现。例如,想让部落节点使用单播模式,我们可以把 Elasticsearch.yml文件修改为以下的
样子:
tribe. mastering one cluster name mastering one
tribe. mastering one discovery. zen, ping multicast enabled: false
tribe. mastering one discovery. zen. ping unicast hosts
["192.168.56.10:9300"]
tribe. mastering two cluster name: mastering two
tribe. mastering_two discovery. zen. ping multicast enabled: false
tribe. mastering two discovery. zen. ping unicast hosts:
["192.168.56.40:9300"]
正如你所看到的,对于每一个部落集群,我们禁止了多播,并指定了单播的主机地址。
再提一下我们已经写过的,部落节点的每个属性都是以 tribe为前缀的。
7.4.3通过部落节点读取数据
我们前面讲过,部落节点从所有连接的集群中获取集群状态,并合并为一个集群状态。
这样做是为了在使用部落节点进行读写操作时,让这些操作在所有的集群上执行。由于集群
状态合并过了,几乎所有的操作的工作原理都跟它们在单一集群中执行时一样,例如搜索。
让我们试着在部落节点上运行一个单一的查询,看看我们能得到什么。为此,我们使
用如下的命令:
cur1-XGET 192.168.56.50: 9200/ search?pretty
以上查询的结果如下:
took":9,
I timed out l: false
shards
"tota1":10,
lI successful": 10
l failed: 0
wt hits
"tota1":4,
'max score ": 1.0,
"hits":[
n index": "index two "
type :"doc
score: 1.0,
source":"name":"Test document 1 cluster 2"
It index": "index one
type :"doc
2
score: 1.0第7章管理 Elasticsearch239
source": "name":"Test document 2 cluster 1")
n index": " index two",
n type": "doc I
id":"2"
score: 1.0
source": "name ":"Test document 2 cluster 2
index: "index one",
typ
d
score": 1.0
source":I"name": "Test document 1 cluster 1")
正如你所看到的,我们得到了来自两个集群的文档。我们的部落节点从所有连接的部
落中得到数据,然后返回相关的结果。当然了,我们可以执行更加复杂的查询,我们可以
使用过滤( percolation)、联想( suggests)等。
主节点级别的读操作
需要主节点存在的读操作会在部落集群中执行,例如读取集群状态或者集群健康情况。
例如,我们看下部落节点返回的集群健康数据是怎样的。我们可以用如下的命令来查看:
curl -XGET 192.168.56.50: 9200/ cluster/health?pretty
以上命令的结果与如下的内容类似:
ncluster name":"elasticsearch"
status":"yellow",
timed out": false,
"number of nodes": 5,
"number of data nodes": 2,
"active primary shards ":10,
"active shards":10,
"relocating shards ":0,
initializing shards":0,
"unassigned shards": 10
正如你所看到的,部落节点报告存在5个节点。每个集群有1个节点,一个部落节点
和部落节点内的两个用来连接集群的内部节点。这是为什么有5个节点而不是3个的原因。
7.44通过部落节点写入数据
我们讨论过了查询和主节点级别的读操作,现在是时候使用部落节点向 Elasticsearch240◆深入理解 Elasticsearch
写入一些数据了。我们不会过多讨论索引过程,而是仅仅尝试向一个我们已经连接的集群
中索引一些额外的文档。我们可以执行如下的命令来完成这项工作:
cur1-XPOST 192.168.56.50: 9200/index one/doc/3-d["name":"Test
document 3 cluster 1"]
执行上面的命令会得到如下的响应:
I"index":"index one", type":"doc"," id:"3",
version":1,"created":true)
正如你所看到的,文档被创建了,并且被索引在了正确的集群上。部落节点只是将请
求在内部转发给正确的集群。所有不要求改变集群状态的写操作,例如索引,都能通过部
落节点正确地执行。
主节点级别的写操作
主节点级别的写操作不能在部落节点上执行。例如,我们不能通过部落节点创建索引。
创建索引这类操作在部落节点上执行时会失败,因为没有一个全局的主节点存在。通过运
行如下的命令我们可以很容易地验证这个结论:
curl -XPOST 192. 168.56.50: 9200/index three
以上的命令会在等待大约30秒后返回如下的错误信息
["error":"MasterNotDiscoveredException [waited for
[30s]]"," tatus":503}
正如你所看到的,索引没有创建。我们应当在组成部落的集群上来运行主节点级别的
写操作。
7.4.5处理索引冲突
部落节点不能正确处理的事情之一就是在其连接的多个集群中有同名的索引。
Elasticsearch的部落节点的默认行为是从中只选择一个。所以,如果你的多个集群中有相同
的索引,只有一个会被选择。
为了验证这个特性,我们在 mastering one集群和 mastering two集群上创建名为test
conflicts索引。我们可以使用如下的命令来创建:
curl -XPOST 192.168.56.10: 9200/test conflicts
curl -XPOST 192.. 40: 9200/test conflicts
除此之外,我们再索引两个文档,每个集群一个。我们使用了如下的命令:
curI-XPOST 192.168.56.10: 9200/test_ conflicts/doc/111-d ' f"name":
"Test conflict cluster 1"3
curl-XPOST 192.168.56.40: 9201/test_ conflicts/doc/21-d["name":
"Test conflict cluster 2"1第7章管理 Elasticsearch◆241
现在我们在部落节点上执行一个简单的查询命令:
curl-XGET 192.168.56.50: 9202/test conflicts/ search?pretty
命令的输出如下:
l took l: 1
l timed out: false
hards":i
total: 5
"successful": 5,
n failed
0
hits
"tota1":1,
imax score": 1. 0
"hits":[
index: test conflicts"
ype":"doc
11
score: 1.0
"_source":"name":"Test conflict cluster 1"]
如你所见,我们的结果中只包含一个文档。这是由于 Elasticsearch部落节点不能处理
来自不同集群的同名索引,只会选择一个。这非常危险,因为我们不知道能期望得到什么。
个好的事情是我们能通过在 Elasticsearch yml中指定 tribe. on conflict(在
Elasticsearch12.0时引入)属性来控制这个行为。我们可以配置为以下值之
口any:这项是 Elasticsearch的默认值。 Elasticsearch会从连接的部落集群中选择一个
索引
口drop: Elasticsearch会忽略同名索引,并排除在全局集群状态之外。这意味着在使用部
落节点时这些索引对读写都是不可见的,但仍然会存在于连接到部落节点的集群上。
prefer_ TRIBE NAME: Elasticsearch允许我们选择哪个集群的索引。例如,如果
我们设置为 prefer mastering one,这意味着 Elasticsearch会从冲突的索引中选择
mastering one集群上的那个索引
7.4.6屏蔽写操作
部落节点也可以配置为屏蔽所有的写操作和所有的修改元数据的请求。为屏蔽所有的
写请求,我们需要设置 tribe. blocks. write属性为true。为禁止元数据修改请求,我们需要设
置tibe. blocks. metadata属性为true。这两个属性默认为 false,这意味着允许写操作和更改242深入理解 Elasticsearch
元数据请求。当部落节点应该仅被用来执行搜索时就可以禁用这些操作了
另外, Elasticsearch 1.2.0引入了在指定索引上屏蔽写操作的能力。我们通过设置 tribe
blocks. indices. write属性为需要屏蔽的索引名来实现这个功能。例如,如果我们希望部落节
点屏蔽所有以test和 production开头的索引上的写操作,可在 elasticsearch yml文件中做如
下的配置:
tribe.blocks. indices. write: test*, production*
75小结
在本章中,我们更多地关注于 Elasticsearch的配置和其在1.0版之后引入的新特性。我们
配置了发现和恢复模块,使用了人类友好的 Cat API。另外我们使用了备份和还原功能,这个
功能可以方便地备份和还原索引。最后,我们着眼于联盟搜索,以及如何在多个集群上搜索
和索引数据。还是使用 Elasticsearch提供的功能,且只需要连接到一个节点就能实现。
在下一章中,我们会关注于 Elasticsearch的性能方面。我们会从使用过滤器( Filter)
优化查询开始。我们会讨论垃圾回收器的工作,我们会使用 Elasticsearch新的基准测试
( benchmark)功能来对我们的查询进行基准测试。我们会使用预热查询来减少查询的执
行时间,会使用热点线程AP来查看 Elasticsearch里正在发生什么。最后,我们会讨论
Elasticsearch调优和在高索引和查询压力场景下如何调整 Elasticsearch4,争
题
属颶
器器
源疆
第8章Cy5
宝也中面水公专为小画面长如的
提高性能
在上一章中,我们探讨了发现和恢复模块的配置。我们配置了这些模块,知道了它们
为什么是重要的。我们还关注了一些通过插件实现的可用发现模块,使用了对人类友好的
Cat APi,以人类可读的格式来获取集群信息,备份数据到外部的云存储,还一起探索了部
落节点(一个联盟搜索功能,它允许我们把一些 Elasticsearch集群连接到一起)。到本章的
结束时,将涵盖以下内容:
口在使用基于字段缓存的查询时, doc values能给我们什么帮助
口垃圾回收器是如何工作的
口在上线前如何对查询做基准测试并修复性能问题
口什么是热点线程API以及它怎样帮你调试问题
口如何优化 Elasticsearch以及在优化时要观察什么
口在高查询吞吐量场景下优化 Elasticsearch
口在高索引吞吐量场景下优化 Elasticsearch
81使用 doc values来优化查询
在66节中,我们描述了缓存:用来提高 Elasticsearch的杰出性能的方法之一。不幸的
是,缓存不是万能的,有时不使用缓存会更好。如果你的数据频繁更新,并且查询具有唯
一性且不可重复,那么缓存不会真的帮到你什么,甚至有时会让性能变得更加糟糕。244深入理解 Elasticsearch
8.1.1字段缓存存在的问题
每个缓存都基于几个简单的原理。主要的设想是:为了提高性能,避免从较慢的类似机
械硬盘的数据源获取数据,或者减少系统重新计算数据的需求,保存一部分数据到内存中
是值得的。然而,缓存不是免费的,有着它的代价。对于 Elasticsearch来说,缓存的代价主
要是内存。根据缓存类型的不同,你可能只需要保存最近使用的数据,但是同样,这并不
总是能够实现的。有时,容纳全部的信息是必须的,因为不然的话,缓存就毫无意义。例
如,用来在排序和聚合时使用的字段缓存,为了让缓存有作用,指定字段的所有值都必须被
Elasticsearch实例 uninverted,并保存在缓存里。如果我们有大量的文档,并且分片也非常大
那么可能会遇到麻烦。这类麻烦的征兆有时会使 Elasticsearch对于查询返回如下响应:
error: "Reduce SearchPhaseException [Failed to execute phase
[fetch], [reduce] i shardFailures [vWD3 FNVoTy-
64r2vf6NwAw] [dvt1][1]: ElasticsearchException [Java heap spaceli
nested:OutofMemoryError [Java heap spacel;([vWD3FNVoTy
64r2vf6NwAw] [dvt1] [2]: ElasticsearchException [Java heap space]i
nested:OutOfMemoryError [Java heap space]; ] nested
OutofMemoryError [Java heap spaceli
status": 500
另一个跟内存有关的问题的标志可能存在于 Elasticsearch日志中,看起来是下面的样子
[2014-11-29 23: 21: 32,991] [DEBUG] [action. search type
[Abigail Brand] [dvt1] [2], node [vWD3 FNVoTy-64r2vE6NWAw], [PI
s [STARTED]: Failed to execute
[org. elasticsearch, action. search SearchRequest@49d609d31
last Shard [true]
org. elasticsearch ElasticsearchException: Java heap space
at org. elasticsearch. ExceptionsHelper convertToRuntime
(ExceptionsHelper java: 46)
at org. elasticsearch. search. Searchservice executeQueryPhase
(Searchservice java: 304)
at org. elasticsearch search action
SearchserviceTransportActions5, call
(SearchserviceTransportAction java: 231)
at org. elasticsearch search action
SearchserviceTransportActions5. call
(SearchserviceTransportAction java: 228)
at org. elasticsearch search action
SearchServiceTransportAction$23.run
(SearchServiceTransportAction java: 559)
at java util. concurrent ThreadPool Executor. runworker
(ThreadPoolExecutor java: 1145)
at java util. concurrent. ThreadPoolExecutorsworkerrun
(ThreadPoolExecutor java: 615
at java. lang Thread. run(Thread. java: 744)
Caused by: java. lang. OutofMemoryError: Java heap space
这就是 doc values可以帮助我们的情形。 doc values是 Lucene中基于列的数据结构第8章提高性能心245
这意味着它们不将数据保存在倒排索引中,而是保存在一个基于文档的数据结构里,并存
储在磁盘上,在索引文档时就计算好。于是, doc values使得我们避免在字段缓存中保存
uninverted的数据,代替的是 doc values从索引中获取数据。从 Elasticsearch1.4.0开始,
doc values的访问与使用字段缓存一样快。
8.1.2使用 doc values的例子
为了向你展示基于 doc values和基于字段数据缓存在内存消耗上的不同,我们索引一些
简单的文档到 Elasticsearch中。我们索引相同的数据到两个索引中:dvtl和dvt2。它们的
结构相同,唯一的不同是下面代码中的粗体部分:
t
"properties":I
u token:
type " :"string",
index":"not analyzed"
m doc values" true
索引dv2使用 doc values,而dvtl不使用,因此dvtl上查询(如果使用了排序和聚合)
会使用字段数据缓存。
为了便于测试,我们设置JVM堆的大小低于 Elasticsearch的默认值。 Elasticsearch
实例化启动时使用:
bin/elasticsearch -xmx16m-xms 16m
这起初看起来有些荒谬,但是谁说我们不能在嵌入式设备上使用 Elasticsearch呢?
当然了,另一个模拟这个问题的办法是索引更多的数据。然而,只是为了测试的话,
保持小内存完全足够了。
现在来看看当命中我们的示例索引时 Elasticsearch的行为是怎样的。查询看起来并不
复杂,但能够很好地展现问题。我们尝试基于文档的一个字段来排序数据: token。我们知
道,排序需要 uninverted的数据,所以它要么使用字段数据缓存,要么在 Doc Values存在时
使用 doc values。查询本身看起来是这样的
"sort":
n token i246心深入理解 Elasticsearch
Forder: desc n
这是一个简单的排序,但是在我们尝试搜索dvt索引时已经足够让我们的服务器宕机
了。同时,在dvt2索引上执行的查询返回了期望的结果,没有任何出问题的迹象。
内存使用上的差别非常明显。在启动参数中删除内存限制,并重新启动 Elasticsearch
后,我们可以对比两个索引的内存使用情况。在dvt1和dvt两个索引上都执行了查询后,
可使用如下的命令来查看内存使用情况
curl-XGET localhost: 9200/dvtl, dvt2/ stats/fielddata?pretty
在我们的例子中, Elasticsearch的响应如下:
u shards":I
"tota1":20,
successful":10,
n failed": 0
a11
"primaries":
n fielddata
"memory size in bytes":17321304,
evictions": 0
itotal
l fielddata
"memory size in bytes": 17321304,
evictions": 0
indices
dvt":
"primaries":
"fielddata":
"memory size in bytes": 0
Evictions 0
total
l fielddata
" memory size in bytes :0,
Evictions: 0第8章提高性能心247
l dvt 1
"primaries": i
n fielddata ll
"memory size in bytes": 17321304
evictions
"total": I
n fieldata
"memory size in bytes": 17321304
evictions t
最有趣的部分已经被加粗显示了。你能看到,没有使用 doc values的索引使用了
17321304个字节(16MB)的内存来保存字段数据缓存。与此同时,第2个索引完全没有使
用任何RAM内存来保存 uninverted数据。
当然,同大多数优化类似,对于资源来说使用 doc values并不是免费的。使用doc
values的缺点之一是速度, doc values要比字段数据缓存慢。另一个缺点是需要额外的空
间来保存 doc values。例如,在我们简单的测试例子里,使用了 Doc Values的索引大小是
4MB,而没有使用 doc values的是34MB。这给索引大小带来了大约20%以上的增长,但
是这个通常取决于索引中的数据。然而,记得当遇到与查询和字段数据缓存有关的内存问
题时,你可能会想要开启 doc values,重新索引你的数据,然后就再也不用担心与字段数据
缓存相关的内存出现溢出异常了。
82了解垃圾回收器
Elasticsearch是一个Java应用,因此,它在Java虚拟机中运行。每个Java应用都会被
编译为叫作字节码的东西,它可以被JVM执行。用最一般的思考方式,你可以想象JVM
只是执行其他程序并控制它们的行为。然而,除非你为 Elasticsearch开发了插件(会在第9
章中讨论插件),否则,你并不需要考虑这个。你需要关心的垃圾回收器,它是JVM中负责
内存管理的部分。当对象不再被引用时,它们可以被垃圾回收器从内存中移除。当内存运
行时,低优先级的垃圾回收器开始工作,尝试回收那些不再被引用的对象。在本节中,我
们会看到如何配置垃圾回收器,如何避免内存交换,如何记录垃圾回收器的行为,怎样调
试异常,怎样使用Java工具查看垃圾回收器是如何工作的。248◆深入理解 Elasticsearch
③你可以从互联网上学习更多关于VM架构的信息,例如,维基百科:htp/∥
en. wikipedia. org/wiki/Java virtual machine
821Java内存
当我们使用Xms和Xmx参数(或者 ES MIN MEM和 ES MAX MEM属性)来指定
内存时,我们指定了最小和最大的JVM堆。它基本上是可以被Java程序(对于我们来说就
是 Elasticsearch)使用的物理内存上的保留区。一个Java进程从不会使用比我们通过xmx
参数(或者 ES MAX MEM属性)指定的多的堆内存。当一个对象在一个Java应用中被创
建,它就被放置在堆内存上。当它不再被使用后,垃圾回收器会尝试从堆上回收它来释放
内存空间,以使JVM能够在将来重用这个空间。可以想象如果没有足够的堆内存来供你的
应用在堆上创建新对象,那么不好的事情就会发生了。JM会抛出一个 OutOfMemory异
常,这是一个内存出了问题的迹象,要么是没有足够的内存给它,要么是有内存泄漏,导
致没有释放不再使用的对象
淒当在性能足够强悍且有大量剩余内存的机器上运行 Elasticsearch时,可能会问自
已,是运行一个分配了大量内存给JVM的 Elasticsearch大型实例好,还是运行
些堆内存小些的实例好。在回答这个问题之前,我们需要记得分配的JM的堆内
存越多,垃圾回收器的工作就越困难。并且,当设置堆的大小超过32GB时,我们
不能从指针压缩中获得好处,JVM将为数据使用64位的指针,这意味着我们将使
用更多的内存来保存相同数量数据的地址。基于这些因素,通常使用多个小些的
Elasticsearch实例比一个大实例更好些。
在Java7中JVM内存被分成如下的区域。
口 eden space:这是堆内存中JVM最初分配大多数类型的对象的部分。
口 survIvor space:这是保存从eden空间的垃圾回收中幸存下来的对象的部分。 survivor
空间被分成 survivor0和 survivor。
口 tenured generation:这里是容纳在 survivor空间里生存了一段时间的对象的部分。
日 permanent generation:这里是非堆内存,存储虚拟机自身数据的地方,例如类和对
象的方法都保存在这里。
口 code cache:这里是非堆内存,它存于 HostSpot JVM中,用来编译和存储 native
代码。
前面的分类可以简化。eden空间和 survivor空间被叫作年轻代堆空间, tenured
generation通常被称为老年代。第8章提高性能☆249
Java对象的生命周期和垃圾回收
为了明白垃圾回收器是如何工作的,让我们详细了解一下Java对象的生命周期。
当一个对象在Java应用中被创建后,它被放置在年轻代的eden空间中。然后,当下
次年轻代垃圾回收运行,且这个对象从中幸存下来(基本上,如果它不是一个一次性使用的
对象,应用仍然在使用它)时,它会被移动到年轻代的 survivor空间中(开始是 survivor0,
然后经过下一次年轻代垃圾回收,移动到 survivor)。
在 survivor1空间中存活了一段时间后,对象被移动到 tenured generation空间,于是它
现在是老年代的一部分了。从现在开始,年轻代垃圾回收器不能够在堆空间中移动这个对
象了。现在,这个对象会存活在老年代中直到我们的应用决定不再需要它了。在这种情形
下,当下一次 full gc到来时,它会从堆空间中移除,为新的对象留出空间。
通常你需要努力实现的是小而多次的垃圾回收,而不是一次长时间的回收。这是因
注
为你希望你的应用以稳定的性能水平运行,且垃圾回收器的工作对 Elasticsearch是
透明的。当一个大型的垃圾回收发生时,它可能会是一个 stop the world类型的垃
圾回收事件,这时巸 lasticsearch会冻结一小段时间,这会让查询变得缓慢,且索引
过程会停止一段时间
基于前面的信息,我们可以说(也确实如此)至少到目前为止,Java使用分代垃圾回收:
对象从垃圾回收中幸存下来的次数越多,就有越大的机会晋升。于是,可以说有两种类型
的垃圾回收器同时存在:年轻代垃圾回收器(也被称为 minor)和老年代垃圾回收器(也被
称为 major)。
③漆随着Java7 update9的释出, Oracle引入了一个新的垃投回收器,叫做G1。它
承诺完全不受st
to
op the world事件的影响
,并且应该比
其他垃圾回收器更
快。想
阅读更多关于G1的信息,请查看htt:/w. oracle. com/technetwork/tutorials
tutorials-1876574html。尽管 Elasticsearch创立者们不建议使用G1,但众多的公司
成功地使用了它,并使得他们在大数据量和重度查询的环境中使用 Elasticsearch时
克服了 stop the world事件带来的问题。
8.22解决垃圾回收问题
在解决垃圾回收问题时,你需要识别的第一件事是问题的源头。这不是一件简单的工
作,通常需要系统管理员或者负责管理集群的人员付出一些努力。在本节中,我们会向你
展示两种方法来观察和识别垃圾回收器的问题。第1个是打开 Elasticsearch的垃圾回收日250深入理解 Elasticsearch
志,第2个是使用 stat命令,它在大多数的Java分发包中存在。
除了以上的方法,请记住还有其他工具能帮助你调试与内存和垃圾回收器相关的问题
这些工具通常以软件监控解决方案的形式提供,例如 Sematext'? Group?SPM(htp:/ sematext
com/spm/index.html)或者Newrelic(http://newrelic.com/)这些解决方案提供了详细的信
息,不仅是关于垃圾回收的,还有整体内存使用的。
一个来自前面提到的SPM应用的样例面板展示了垃圾回收器的工作情况:
Garbage Collect
y-201411091245to2014.11.0914
Cluster Hea胜t
v'collechion time EI'colledion count
index Stats
Shand Stats
Search
s
C
Connections
CPU& Memory
collecton tme clacton count
JVM Memory
arbage Collectors Fime-201411.0912:45t。201411091445
os Actions·
JVM Threads
w ava collection time+
JVM Open File
125m8
Custom Metrics
50ms
s favg colection time
打开垃圾回收器的工作日志
Elasticsearch允许我们观察垃圾回收器超长时工作的周期。在默认的 Elasticsearch yml
文件中,你能看到如下的项,其默认被注释了:
monitorjvm. gc. young warn: 1000ms
monitorjvm. gc. young. info: 700ms
monitor jvm. gc. young debug: 400ms
monitor jvm. gc. old warn: 10s
monitor jvm. gc. old. info: 5s
monitorjvm. gc. old debug: 2s
如同你看到的那样,配置指定了3个log等级和每个的阈值。例如,对于info日志等
级,如果年轻代回收花费了700毫秒或者更多, Elasticsearch会把信息写人日志。对于老年
代,如果花费超过5s则会被计入日志。第8章提高性能心251
在老版本的 Elasticsearch中(10之前),记录年轻代垃圾回收信息的前级是
monitor ]vm. gc. ParNew.*,而记录老年代垃圾回收信息的前缀是 monitor.vm
gc. ConcurrentMarkS weep
你在日志中看到的内容会是下面这样:
[2014-11-0915:22:52,355][wARN][ moni tor.jvm
[Lizard] [gc] [old] [964][1] duration [148s], collections
[1]/[15.8s],tota1[14.8s]/[14.8s], memory[8.6gb]-
>[3.4gb]/[11.9gb], all pools [Code Cache] [8.3mbl
>[8.3mb]/[48mb]}{ young][13.3mb]->[3.2mb]/[266.2mb]}{ surve vor]
29.5mb]->[0b]/[33.2mb]}{[old][8.5gb]->[3.4gb]/[11.69b1}
如同你看到的,log文件的首行告诉我们这是关于老年代垃圾回收器的工作。我们能够
看到总的回收时间是148秒。在进行垃圾回收之前,使用了8.6GB的堆内存(总的堆内存
是119GB)。垃圾回收后,堆内存的使用量被缩减到3.4GB。这之后,你能看到关于堆的哪
个部分被垃圾回收器所涵盖的详细信息:代码缓存、年轻代空间、 survivor空间和老年代堆
空间。
当以特定的阈值来开启垃圾回收器的工作日志时,通过查看日志能够发现事情在何时
不再以所希望的方式运行。然而,如果想看到更多,Java提供了一个工具: stat
1.使用 STat
运行 stat命令来査看垃圾回收器如何工作的操作非常简单,执行如下的命令即可:
dstat- cuti112345620001000
开关- gcutil表示监控垃圾回收器的工作,123456是运行着 Elasticsearch的虚拟机的标
识符,2000是以毫秒表示的采样周期,1000是采样的数量。所以,对于我们的例子,前面
的命令会在33分钟(2000*1000/1000/60)多一点的时间后返回。
在大多数的情况下,虚拟机标识符同进程⑩类似,甚至相同,但并不总是这样。为了
查看哪个Java进程在运行和它们的虚拟机标识符是什么,可以执行jps命令,绝大多数的
Java分发包都提供。一个执行它的例子如下:
Gps
结果如下:
16232Jp8
11684 Elasticsearch
在js命令的结果中,我们看到每一行都包含了JVM的标识符,后面跟着的是进程的
名称。如果想学习更多关于jsp命令的信息,请查看Java文档,地址是:htt:docs. oracle
com/javase/7/docs/technotes/tools/share/jps. html252心深入理解 Elasticsearch
痔请记得使用与运行 Elasticsearch相同的账号来运行jsat命令,如果不能的话,使用
管理员权限来运行(例如在 Linux系统上使用sudo命令)。拥有访问 Elasticsearch所
在进程的权限是至关重要的,否则 stat命令就不能够连接到那个进程。
现在,我们来看一个 Stat命令输出的例子
So
S1
YGC YGCT
FGC
FGCT
GCT
12.440.0027.209.4996.7078
0.176
0.495
0.672
12.440.0062.169.4996.7078
0.176
0.495
0.672
12.440.0083.979.4996.7078
0.176
0.007.740.009.5196.7079
0.177
55555
0.495
0.672
0.495
0.673
0.007.7423.379.5196.70790.177
0.495
0.673
0.007.7443.829.5196.7079
0.177
0.495
0.673
0.007.7458.119.5196.7179
0.177
0.495
0.673
上面的例子来自Java文档,我们决定采用它是由于它很好地向我们呈现了 stat是关于
什么的。现从说明每列的含义开始。
口S0: survivor0空间的使用情况,以空间容量的百分比表示。
口Sl: survivor空间的使用情况,以空间容量的百分比表示。
口E:eden空间的使用情况,以空间容量的百分比表示。
口O:老年代空间的使用情况,以空间容量的百分比表示。
口YGC:年轻代垃圾回收的次数。
口YGCT:年轻代垃圾回收消耗的时间。
口FGC: full gc的次数。
口FGCT: full gc消耗的时间。
口GCT:gc的总用时。
现在,回到例子中。你可以看到,在第3个样本后和第4个样本前有一次年轻代垃圾
回收事件。我们能看出这次回收耗时0.001s(第4个样本的YGCT值0.117减去第三个样本
的YGCT值0.116)。我们也知道这次回收从eden空间(第4个样本中的使用百分比是0,
而第3个样本中的使用百分比是83.97)晋升对象到老年代堆空间(从第3个样本的9.49%
增长到了第4个样本的951%)。这个例子向你展示了如何分析 stat的输出。当然,这会
耗用一定的时间,并且需要一些关于垃圾回收器如何工作的知识,以及堆上都保存了什么。
然而,有时,这是分析为什么 Elasticsearch在特定时刻卡住的唯一方式。
记住,如果你见到 Elasticsearch没有正常工作,S0、S1或者E列显示100%,并且垃
圾回收器不能回收这些堆空间,那么,要么是年轻代太小了需要增加(当然,如果有充足的
剩余物理内存),要么是内存问题。这些问题可能与内存泄漏有关,即一些资源没有释放不第8章提高性能
253
再使用的内存。另一方面,当你的老年代空间达到100%时,垃圾回收器努力回收它(频繁
的垃圾回收),但却不能回收,那么这大概意味着没有足够的堆空间来让 Elasticsearch节点
正常工作。这时,在不改变索引结构的前提下,你能做的是增加运行 Elasticsearch的JVM
的可用堆空间(关于JM参数的更多信息,参见htt:/ww. oracle. com/technetwork/java
javase/tech/vmoptions-jsp-140102. html)
2.创建内存dump
我们到目前为止都还没讨论的一件事是dump堆内存到一个文件的能力。Java允许我
们获得一个给定时点的内存快照,我们可以使用这个快照来分析内存中存储了什么以及发
现问题。为了dump出Java进程内存,可以使用jmap(htt: locs, oracle. com/ Javase/7docs
technotes/tools/share/jmap.html)命令,例如,像这样:
jmap -dump: file=heap. dump 123456
在我们的例子里,“123456”是想要获得内存dump的Java进程的标识符,
-dump:fle-heap.dump”指定我们想要保存dump到一个名称为heap.dump的文件里。通
过使用特殊软件,这个dump可以被进一步分析,例如使用jhat(htt:docs. oracle. com
Javase7/docs/ technotes/tools/share/ hat. html),但是如何使用这些工具超出了本书的讨论范围
3.关于垃圾回收器工作的更多信息
优化垃圾回收不是一个简单的过程。使用 Elasticsearch为我们设置的默认选项进行部
署,这在绝大多数情况下通常是足够的,你需要做的唯一一件事是调整节点的内存数量。
调优垃圾回收器工作的主题超出了本书的范畴,它的范围广阔,被一些开发者称为“黑魔
法”。然而,如果想阅读更多关于垃圾回收器的问题,如它们有哪些选项,它们如何影响
你的应用,这里推荐一篇极好的文章,你可在:ht:/w. oracle. com/technetwork/java
Javase/gc- tuning-6-140523html上找到。尽管这篇文章是关于Java6的,但是绝大多数的选
项都能使用在Java7的部署上。
4.调整 Elasticsearch的垃圾回收器的工作
现在我们知道了垃圾回收器是如何工作的,以及怎样调试它的问题,所以知道如何
调整 Elasticsearch启动参数来改变垃圾回收器的工作是很有益的。这取决于是如何运行
Elasticsearch的。我们会着眼于两个最常用的方式: Elasticsearch的分发包提供的标准的启
动脚本和使用服务包装器( service wrapper)。
5.使用标准启动脚本
当使用标准启动脚本来增加额外的JM参数时,我们应该把它们包含进 JAVA OPTS
环境变量中。例如,对于类似 Linux的系统,如果我们想包含XX:+ Use ParNewGC254◆深入理解 Elasticsearch
XX:+ Use ConcMarkSweepGC到 Elasticsearch的启动参数中,我们会做如下的事情:
export JAVA OPTS="-XX: +UBeParNewGC -XX: +UseConcMarkSweepGC"
为了查看属性是否配置成功了,我们只需执行另一个命令:
echo SJAVA OPTS
前面的命令对于我们的例子应该返回以下的输出:
XX: +UseParNewGC -XX: +UseConcMarkSweepGC
6.服务包装器
Elasticsearch允许我们使用服务包装器来把它安装为一个服务(htts:/github.com
Elasticsearch/ Elasticsearch- service wrapper)。如果你正在使用服务包装器,设置JVM参数的
方法就与前面展示的方法不同了。我们需要做的是修改 Elasticsearch conf文件,它大概会
被放在/ opt/Elasticsearch/bin,/ service/(如果你的 Elasticsearch安装在/ opt/Elasticsearch)。在
Elasticsearch conf文件中,你会看到一些属性,例如:
set default ES HEAP SIZE=1024
你也会看到如下的属性:
wrapper. java. additional l=-Delasticsearch-service
wrapper.java. additional2=-Des path home=%ES HOME%
wrapper. java. additional 3=-Xss256k
wrapper.java. additional 4=-XX: +UseParNewGC
wrapper. java. additional 5=-XX: +Use ConcMarkSweepGC
wrapper, java. additional.6=-XX: CMSInitiatingoccupancy Fraction=75
wrapper. java. additional 7=-XX: +UseCMSInitiatingoccupancyonly
wrapper.java. additional8=-XX: +HeapDumpOnoutofMemoryError
wrapper.java. additional 9=-Djava awt headless=true
第1个属性负责设置 Elasticsearch的堆内存的大小,其余的是JVM的附加参数。如果
想添加另一个参数,则只需增加一个 wrapper. java. additional属性,其后跟着一个点和下
个可用的数字,例如:
wrapper.java. additional10=-server
注有一件事必须牢记,垃圾回收器调优不是一件一次性的工作。它需要不断试验,同
章
时它也非常依赖于你的数据、查询和它们的组合。出了问题时不要害怕调整,只要
观察它们,看看调整后 Elasticsearch工作得怎样。
823在类UNⅨX系统上避免内存交换
尽管这个不是与垃圾回收和堆内存使用严格相关,但我们认为,了解如何禁止内存交
换是重要的。内存交换是把内存页写入磁盘的过程(对于基于UNIX的系统指的是交换分第8章提高性能◆255
区)。当物理内存的数量不够了或者操作系统由于某些原因认为把一部分RAM内存写入磁
盘更好些时,就会发生内存交换。如果交换了的内存页再次被需要,操作系统会从交换分
区中加载它们,并允许进程使用它们。正如你所想象的那样,这个过程会消耗时间和资源。
当使用 Elasticsearch时,我们希望避免它的进程内存被交换。你可以想象,如果有部
分 Elasticsearch使用的内存被写到磁盘然后再从磁盘上读取,这会影响搜索和索引的性能。
鉴于此, Elasticsearch允许我们关闭它的内存交换。为了做到这个,你需要在 Elasticsearch
yml文件中设置 bootstrap. mlockall属性为true
然而,上述设置仅仅是个开始。你还需要通过设置Xnx和Xms属性为相同的值来确保
JVM不会改变堆的大小。可以通过指定 Elasticsearch的环境变量 ES MIN MEN和 ES MAX
MEN为相同的值来做到这点。还要记得,你需要有足够的物理内存来与你的设置匹配。
现在,如果我们启动 Elasticsearch,我们能够在日志中看到如下的信息:
[2013-06-1119:19:00,858][WARN][ common.jna
Unknown mlockall error o
这意味着我们的内存锁定没有生效。那么现在让我们来修改两个 Linux操作系统的文
件(这需要管理员权限)。假设运行 Elasticsearch的用户是 elasticsearch
首先,修改/etc/ security/ limits.conf,添加如下内容:
elasticsearch nofile 64000
elasticsearch memlock unlimited
其次,修改etc/pam.d/ common- session文件,添加如下内容:
session required pam limits. so
重新使用 Elasticsearch账户登录后,再次启动 Elasticsearch,你就应该不会看到
mlockall错误了。
83对查询做基准测试
在处理搜索或者数据分析时有一些事情很重要。我们需要结果是精确的,且需要它们
是相关的,同时还需要它们尽量快地返回。如果你负责设计在 Elasticsearch上执行的查
询,迟早会发现你处在一个需要优化查询性能的境地。原因有很多,从基于硬件的问题
到不良的数据结构,再到糟糕的查询设计。在写作本书时,基准测试 APIHIA只存在于
Elasticsearch的分支上,这说明它不是官方 Elasticsearch分发包中的一部分。目前来说我们
要么使用类似 jMeter或者ab( Apache基准测试工具,参见htt:;htd. apache. org/docs/2.2
programs/ ab. html),要么使用 Elasticsearch分支的版本。还要记得现在讨论的功能在最终
版本发布时可能会有所改动,所以如果想要使用基准测试功能的话,留意网页htt:/ww
Elasticsearch org/ quide/en/ Elasticsearch/reference/ master/search- benchmark html是个好主意256心深入理解 Elasticsearch
83.1为基准测试配置集群
基准测试功能默认是关闭的。任何在正确配置的 Elasticsearch节点上使用基准测试的
尝试都会导致一个类似下面的错误:
error n:"BenchmarkNodeMissingException [No available nodes for
executing benchmark [benchmark name]]
status
503
这是正常的,没人希望冒险在生产环境的集群上执行有潜在危险的功能。在进行性
能测试和基准测试期间,你会执行许多复杂的和重度的查询,因此在真实用户使用的
Elasticsearch集群上执行这类的基准测试似乎不是一个好主意。它会导致集群响应缓慢,可
以造成系统崩溃和不好的用户体验。为了使用基准测试,你必须告诉 Elasticsearch哪个节
点能够运行需要测试的查询。每个你希望使用基准测试的实例都应该在启动时设置-node.
bench选项为true。例如,可以这样来启动一个 Elasticsearch实例:
bin/elasticsearch --node bench true
另一种方式是添加 node bench属性到 Elasticsearch.yml文件中,当然,要配置为true。
无论选择哪种方式,我们现在可以运行第一个基准测试了。
83.2进行基准测试
Elasticsearch提供了名为 bench的REST端点,允许我们定义在集群中允许基准测试
的节点上执行的任务。让我们通过一个简单的例子来学习怎么做。我们会向你展示一些实
际的东西,例如第2.4节中讨论过滤器时,我们试图使你相信,在大多数情况下,后向过滤
器是不好的。我们现在能够自己检验,看看带有后向过滤器的查询是否真的慢。能够验证
这点的命令如下(我们在 Wikipedia数据库中使用过)
curl-XPUT 'localhost: 9200/ bench/?pretty' -d 't
"name": "firstTest
"competitors":[
"name":"post filter",
requests":[t
post filter":I
term
"link":"Toyota Corolla第8章提高性能心257
"name ": "filtered"
"requests":[
n query
filtered"
query
match all":
f主1tern
term
' link": "Toyota Corolla"
向_ bench端点发送的请求的结构非常简单。它包含了一个竞争者列表, Elasticsearch
的基准测试功能会对它们相互比较。一个竞争者是一个查询或者一组查询(因为每个竞争者
都能有不止一个查询)。为了便于对结果进行分析,每个竞争者都有它自己的名字。现在来
看前面的请求所返回的结果:
status":COMPLETE",
errors":[]
competitors
filtered
i summary
INodes "
ree Spirit
total iterati
"completed iterations":5
total queries":5000
concurrent
multiplier":1000
avg warmup time " : 6,
statistics":I
Imin: 1
m
"mean":1.9590000000000019
"qps":510.4645227156713,
" std dev":0.6143244085137575,
"m111 is per hit":0.0009694501018329939,
percentile 10":1
"percentile 25 :2258◆深入理解 Elasticsearch
"percentile 50 :2,
" percentile 75 :2,
"percentile 90":3
"percentile 99 :4
st filter
"summary":I
iNodes": L
Free Spirit
n total iterations 5
"completed iterations":5,
"total queries:5000,
"concurrency :5,
"multiplier 1000
navg warmup time: 74,
statistics
"min":66,
"max":217,
mean":120.88000000000022
"cs":8.272667107875579,
" std dev":18.487886855778815,
"mi1 is per hit":0.05085254582484725
"percentile 10":98
" percentile_25":109.26595744680851,
percent1e50":120.32258064516128,
" percent1e75":131.3181818181818,
" percentile 90":143,
percent1e99":171.01000000000022
正如你所看到的,测试是成功的。 Elasticsearch返回了一个 errors项为空的表。对于
每个测试,我们都执行了 post filter和 filtered query,只有一个被命名为 Free Spirit的节
点被用来执行基准测试。对于这两种查询,都使用了相同的请求数(500和相同的并发
数(5)。对比预热时间和统计信息,你可以轻易地得出哪个查询更优的结论。我们会选择
filtered query,你会怎么选呢?
我们的例子相对简单(事实上是非常简单),但是它向你展示了基准测试的有效性。当
然了,我们初始的查询没有使用 Elasticsearch基准测试API暴露出来的全部配置项。为了
总结所有的选项,我们准备了一个 bench端点的全局可用的选项列表。
口name:基准测试的名称,它让我们很容易区分多个不同的基准测试(参考下一节)。
口 competitors: Elasticsearch将要执行的测试的定义。它是由描述测试的对象所组成的数组。第8章提高性能
259
J num executor nodes:在测试期间作为查询源的最大 Elasticsearch节点数。默认为1个。
u percentiles:定义 Elasticsearch应该计算并在结果中返回的关于查询执行时间的百分
数。默认值是[10,25,50,75,90,99。
口 Iteration: Elasticsearch应当为每个竞争者重复执行的次数,默认为5次。
d concurrency:每次迭代的并发数,默认是5,这意味着 Elasticsearch将会使用5个并
发线程。
multiplier:在一次迭代中每个查询重复执行的次数,默认重复执行1000次。
口 warmup:设置 Elasticsearch应该进行查询预热。默认执行预热,这意味着这个值被
设置为true
a clear caches:默认为 false,意味着在每次迭代前, Elasticsearch不会清理缓存。我
们通过设置为tue来改变这点。这个参数同一系列参数相关,这些参数决定哪些缓
存需要或者不需要清理。这些额外的参数是 clear caches filter过滤器缓存)、 clear
caches. field data(字段数据缓存)、 clear caches.id (ID缓存)和 clear caches recycler(回
收器缓存)。除此之外,还有两个参数接收名称数组,其中 clear caches. fields指定字
段的名称和哪个缓存应当被清理,而 clear_caches filter keys指定需要清理的 filter
key的名称。想要获得更多关于缓存的信息,可以参考6.6节的内容。
除了全局选项,每个竞争者对象还可以包含如下参数。
口name:同根级别的名称类似,用来区分不同的竞争者。
O requests:这项是每个竞争者需要运行的查询的列表。每个对象都是一个使用查询
DSL定义的标准的 Elasticsearch查询。
口 num slowest:需要跟踪的慢査询的数量,默认是1。如果我们希望 Elasticsearch跟
踪并记录不只一个慢查询,我们可以调高这个参数的值。
a search type:指定查询的类型,有限的选项是 query then fetch、 dfs query then
fetch和 count。默认值是 query then fetch
口 indices:索引名称数组,用来限制查询只能在数组中的索引上执行。
a types:索引类型数组,用来限制查询只能在数组中的类型上执行。
O iteration, concurrency, multiplier, warmup, clear caches:
这些参数用来覆盖其同名的全
局配置。
83.3控制运行中的基准测试
依赖于我们执行基准测试时使用的参数的不同,一个包含一些需要重复几千次的查询
的基准测试命令可以运行几分钟或者几个小时。要是能够检查测试运行得如何并预测需要
多久测试才能结束就好了。正如你说期望的那样, Elasticsearch提供了这些信息。为了得到260◆深入理解 Elasticsearch
这些信息,你需要做的仅仅是运行如下的命令:
curl-xGET localhost: 9200/ bench?pretty
上述命令产生的输出可能看起来是这样的(这是在我们用作例子的基准测试执行期间获
取的):
Mactive benchmarks
ufirstrest
status":"RUNN工NG"
errors":[]
"competitors":i
post filte
I summary
es":[
" James Proudstar I
n total iterations : 5.
I completed iterations:3,
total
queries
3000
" concurrency 5,
"multiplier": 1000,
"avg warmup time": 137.0,
ui statistics
"min":39,
I' max
146
"mean":78.95077720207264
"qps":32.81378178835111,
std dev":17.42543552392229
"mi1 is per hit":0.031591310251188054,
" percentile 10": 59.0,
" percent11e_25":66.86363636363637,
percentile 50":77.0
" percent11e75":89.22727272727272,
"percentile 90: 102.0
" percent.1e99":124.86000000000013
感谢这个功能,你能看到测试的进度,并尝试预估在测试完成并返回结果前需要等待
多长时间。如果想要放弃当前运行的基准测试(例如,它需要花费太长的时间,并且已经看
出测试查询并不是优化的), Elasticsearch有一个解决方案。例如,为了放弃名称为 firstTest
的基准测试,我们在
bench/abort
端口执行一个POST请求,如下所示:
1 -xPOST localhost: 9200/ bench/abort/firstTest?pretty第8章提高性能
261
Elasticsearch的响应会向你展示测试的部分结果。它几乎与前面例子的内容一样,除了
基准测试的状态会被设置为 ABORTED以外。
84热点线程
当你遇到了麻烦,例如你的集群比平时执行得缓慢,使用了大量的CPU资源时,那么你
需要做些什么来使集群恢复正常。这就是使用热点线程API的场景。热点线程API能向你提
供查找问题根源所必需的信息。这里的一个热点线程是一个Java线程,它使用大量CPU并
且执行了相当长的一段时间。有了这样的一个线程并不意味着 Elasticsearch本身出了什么问
题,它给出了什么可能是热点的信息,并使得你可以看出系统的哪个部分需要更深入的分析
例如查询的执行或者 Lucene段的合并。热点线程AP返回从CPU的角度来看, Elasticsearch
哪个部分的代码可能是热点的信息,或者由于某些原因 Elasticsearch卡在了哪里。
当使用热点线程API时,通过使用/ nodes/hot threads或者/ nodes/{ node or nodes
hot threads端点,你可以检查所有的节点、其中的一部分,或者其中一个。例如,为了查
看所有节点上的热点线程,我们会执行如下的命令
curl 'localhost: 9200/ nodes/hot threads
这个API支持如下参数。
口 threads:需要分析的线程数,默认为3个。 Elasticsearch通过查看由type参数决定
的信息来选取指定数量的热点线程。
a interval:为了计算线程在某项操作(由type参数指定)上花费的时间的百分比
Elasticsearch会对线程做两次检查。我们可以使用 interval参数来定义两次检查的间
隔时间。默认为500ms。
口type:需要检查的线程状态的类型,默认是cpu。这个API可以检查线程消耗的时
间,线程处于阻塞状态的时间,或者线程处于等待状态的时间。如果你想了解更
多关于线程状态的信息,请参考htt:/docs. oracle. com/javase/7/ docs/api/java/lang/
Thread. State. html。
口 snapshots:需要生成的堆栈跟踪(某一时刻方法调用的嵌入式序列)快照的数量。
使用热点线程APⅠ十分简单,例如,想要以1s为周期查看所有节点上处于等待状态的
热点线程,我们会执行如下的命令:
curl 'localhost: 9200/ nodes/hot threads? type=wait&interval=lg
84.1热点线程的使用说明
不同于 Elasticsearch其他的AP,你可以期待返回一个JSON数据,热点线程API返回262◆深入理解 Elasticsearch
格式化的、包含一系列段落的文本。在我们讨论响应的结构之前,我们想要告诉你一些关
于如何产生这个响应的逻辑。 Elasticsearch选取所有运行的线程,并收集关于在每个线程上
花费的CPU时间的各种信息,例如线程被阻塞或者处于等待状态的次数,处于阻塞或者等
待状态持续了多长时间等。然后它会等待一段时间(由 interval参数指定),之后再次收集同
样的信息。当这些完成后,对线程基于其消耗的时间进行排序。排序以降序方式进行,这
样消耗了最多时间的线程就排在列表的顶部。当然,时间是通过由type参数指定的操作类
型来衡量的。在这之后,前N个线程(N是由 threads参数指定的线程数)被 Elasticsearch
用来分析。 Elasticsearch做的工作是:每隔几毫秒,对上一步选择的线程获取一些堆栈的快
照(快照的数量由 snapshot参数指定)。最后需要做的事情是为了可视化线程状态的变化而
组合堆栈信息,然后返回响应给调用者。
842热点线程API的响应
现在,让我们深入了解一下热点线程API的响应。例如,下面的快照是热点线程API
为刚启动的 Elasticsearch生成的响应的片段:
curl 'localhost: 9200/ nodes/hot threads
:: IN'Gabthoth] [aBb5552UQvy FCk1PNCaJnAl [Banshee-3 locall[inet [/10.0, 1.3: 930011
1.4%(6.7msoutof500ms)cpuusagebythread'elasticsearch[n'gabthotH][http_server_boss][t#11newI/0serverboss#51]
10/10 snapshots sharing following 14 elements
sun nio ch. KQueueArraywrapper kevento(Native Method)
sun nio ch. KQueueArraywrapper poll(KQueueArraywrapper java: 200)
sunnio ch KQueue SelectorImpl doSelect(KQueue SelectorImpl java: 103)
sun nio ch. SelectorImpl lockAndDoSelect(SelectorImpl java: 87)
sun nio ch. SelectorImpl select( SelectorImpl java: 98)
sun nio ch. SelectorImpl select(Selector Impl. java: 102)
org. elasticsearch. common, netty channel socket, nio. NioserverBoss, select(NioServerBoss java: 163)
org. elasticsearch, common netty, channel socket nio. AbstractNioselector run(Abst ractNioSelector java: 212)
org. elasticsearch common netty channel socket nio. NioserverBoss, run(NioserverBoss, java: 42)
org. elasticsearch common netty, util. ThreadRenamingRunnable run (ThreadRenamingRunnable java: 108)
org. elasticsearch common netty, utiL.internal. DeadLockProofWorkers1 run( Dead Lock ProofWorker java: 42)
java util. concurrent. ThreadPoolExecutor runworker(ThreadPoo lExecutor java: 1145)
java, util. concurrent. ThreadPoo lExecutorsworker run(ThreadPoolExecutor java: 615)
java. lang Thread, run(Thread. java: 744)
0. 7%(3. 3ms out of 500ms) cpu usage by thread 'elasticsearch [N'Gabthothl [search [T#61
10/10 snapshots sharing following 10 elements
sun. misc. Unsafe. park(Native Method)
java, util. concurrent locks. LockSupport park(LockSupport java: 186)
java util. concurrent. LinkedTransferQueue awaitMatch(LinkedTrans ferQueue java: 735)
java util. concurrent. LinkedTrans ferQueue xfer (LinkedT ransferQueue java: 644)
java, util. concurrent. LinkedTransferQueue take(LinkedTransferQueue java: 1137)
org. e lasticsearch commonutil. concurrent. SizeBLockingQueue take(sizeB lockingQueue java: 162)
java util. concurrent Th readPoo lExecutor getTask(ThreadPoo lExecutor java: 1068)
java, util. concurrent. ThreadPoolExecutor runworker (ThreadPoo lExecutor java: 1130)
java util. concurrent Thread Poo lExecutorsworker run (ThreadPoolExecutor java: 615)
java. Lang Thread run(Thread. java: 744)
0.5(2. 7ms out of 500ms) cpu usage by thread 'elasticsearch IN'Gabthoth] [search][T#101
10/10 snapshots sharing following 10 elements
sun. misc. Unsafe. park(Native Method
java util. concurrent locks. LockSupport, park( LockSupport java: 186)
java util. concurrent. LinkedTransferQueue xfer(LinkedTransferQueue java: 64 a: 735)
java util. concurrent. LinkedTransferQueue, awaitMatch(LinkedTransferQueue java: 735)
java util. concurrent. LinkedTransferQueue take (LinkedTransferQueue java: 1137)
org.elasticsearch. common, util. concurrent SizeBlocking Queue take(SizeBlocking Queue java: 162)
java util. concurrent. ThreadPoolExecutor getTask(ThreadPoo lExecutor java: 1068)
java util. concurrent. ThreadPoo lExecutor runworker(ThreadPoolExecutor java: 1130)
java, utiL. concurrent. ThreadPoo lExecutorsworker, run(ThreadPoo lExecutor java: 615)
java. lang Thread run(Thread. java: 744)第8章提高性能心263
现在我们来解释响应的各个部分。为此我们会使用一个与前面展示的响应有轻微区别
的响应。我们这么做是为了更好地可视化在 Elasticsearch中发生了什么,请记住响应的总
体结构不会改变。
热点线程APⅠ响应的第1部分向我们展示线程在哪个节点上。例如,第1行的响应可
能是下面这样:
:: [N' Gabthoth] [aBb5552UQvyFCkIPNCaJnA] [Banshee
3.1oca1][inet[/10.0,1.3:9300]
我们能看到热点线程API返回的信息是关于哪个节点的,这在向多个节点发送热点线
程请求时非常有用。
热点线程AP响应接下来的内容可以分成多个小节,每个小节由类似下面的行开始
0. 5%(2. 7ms out of 500ms) cpu usage by thread
elasticsearch[N'Gabthoth] [search] [T#10]
在我们的例子中,我们看到一个名为 search的线程,在统计结束时,它消耗了百分
之0.5的CPU时间。其中的 cpu usage部分表明我们在使用type等于cpu的方式进行统
计。在这里你还可能会看到表示线程处于阻塞状态的 block usage和表示线程处于等待状
态的 waiting usage。这里线程的名称十分重要,因为通过查看线程名称,我们可以知道
Elasticsearch的哪个功能是热点。在我们的例子中,我们知道这个线程是关于搜索的(名称
中的“ search”)。你可以期望看到的其他值是 recovery stream(回复模块事件)、 cache(缓
存事件)、 merge(索引段合并线程)、 index(数据索引线程)等。
热点线程AP响应的下一个部分是以下面内容开头的小节:
10/10 snapshots sharing following 10 elements
这个信息后面会跟着一个堆栈跟踪信息。在我们的例子里,1010表示对同一个堆栈跟
踪生成了10个快照。通常,这意味着全部的检查时间被花费在了 Elasticsearch节点的同一
个部分。
85扩展 Elasticsearch
正如我们在本书和《 Elasticsearch server, Second edition》中多次说过的, Elasticsearch
是一个高度可扩展的搜索和分析平台。我们可以在水平和垂直方向上对 Elasticsearch进行
扩展。
8.51垂直扩展
当我们说到垂直扩展时,通常意味着向运行 Elasticsearch的服务器添加更多的资源:
可以添加内存,可以更换到有着更佳的CPU或者更快的磁盘存储的机器上。显然,使用更264◆深入理解 Elasticsearch
好的机器,我们可以期望性能的提升。依赖于我们的部署环境和它的瓶颈,可以有较小或
则较高的提升。然而,垂直扩展有着它的限制,例如,服务器上的最大可用物理内存或者
JVM需要使用的总内存。当你有足够多的数据和复杂的查询时,你会很快碰到内存问题,
添加新的内存也许帮不了你。
例如,由于垃圾回收和无法使用压缩选项(这意味着为了标记相同的内存空间,JVM
需要使用2倍的内存),你不会想要给VM分配超过31GB的物理内存。尽管这看起来是
个大问题,垂直扩展并不是唯一的解决方案
852水平扩展
对于 Elasticsearch用户来说,另一个解决方案是水平扩展。相对来说垂直扩展就像是
建造一个摩天大楼,而水平扩展就像在住宅区内建造多所房子。我们选择使用多台机器并
将数据分割存储在其上,以此来替代投资硬件和购买更好的机器。水平扩展给了我们几乎
无限的扩展能力。即便使用了最好的硬件,用一台机器来容纳数据和处理查询也是不够的。
如果一台机器容纳不下数据,我们会把索引分成多个分片( shard),并在集群中分散它们,
就像下图所展示的那样:
mastering
mastering
shard 1
shard 2
mastering
mastering
shard 3
shard 4
当没有足够的计算能力来处理查询时,总是可以为分片增加更多的副本。上图的集群
有4个节点,其上运行着由4个分片构成的 mastering索引。
如果想要增加集群处理査询的能力,只需增加额外的节点,例如4个。增加节点后
既可以创建有着更多分片的新索引来平衡负载,也可以给现有的分片增加副本。两种方案第8章提高性能◆265
都是可行的。当硬件容纳不下数据时,应该寻求更多的主分片。在这种情形下,我们通常
会碰到存储器溢出的情形、分片查询时间变长、内存交换或者大量的IO等待。第2个方
案在我们的硬件能够很好地处理数据,但是流量过高以致于节点无法跟上时使用。第1个
方案比较简单,我们来看看第2个。有着4个额外的节点,我们集群如下图所示:
mastering
mastering
shard 1
hard 2
mastering
mastering
shard 3
shard 4
现在,让我们通过执行下面的命令来添加一个副本:
curl-XPUT 'localhost: 9200/mastering/ settings'-d'i
index":
"number of replicas":1
我们的集群现在差不多是下面的样子
mastering
mastering
mastering
mastering
shard 1
shard 2
replica shard 1
replica shard 3
mastering
mastering
mastering
mastering
shard 3
shard 4
replica shard 4
replica shard 2
我们可以看到,每个构成 mastering索引的初始分片都有一个副本保存在其他节点上。266◆深入理解 Elasticsearch
于是 Elasticsearch便能够在分片和它们的副本间做负载均衡了,进而查询便不会总是命中
一个节点了。于是我们能够处理两倍于初始部署方式的查询负载。
1.自动创建副本
Elasticsearch允许我们在集群足够大时自动扩展副本数。你可能会奇怪,这个功能有
什么用呢?设想这样一个情形,你有一个很小的索引,你希望它存在于每个节点上,于是
你的插件就不用仅仅为了获得数据而执行分布式查询了。并且你的集群是动态变化的,你
可以增加和删除节点。实现这样一个功能的最简单的办法就是让 Elasticsearch自动扩展副
本。为了做到这点,我们需要设置 index. auto expand replicas为0-a,这表示索引在其
他节点上都会有其副本。所以如果我们的小索引的名称是 mastering meta,并且我们想让
Elasticsearch自动扩展它的副本,我们会使用以下的命令来创建索引
curl -XPOST ' localhost: 9200/mastering meta/,-d 't
"settings": I
"index":I
"auto expand replicas": 0-all"
如果索引已经存在,我们也可以使用下面的命令来更新索引的配置:
curl-XPUT 'localhost: 9200/mastering meta/ settings'-d I
windex
"auto expand replicas":0-all"
2.冗余和高可用
Elasticsearch的副本机不仅给了我们处理更高查询吞吐量的能力,同时也给了我们冗余
和高可用。假设一个 Elasticsearch集群上有唯一一个名为 mastering的索引,索引有两个分
片且没有副本。这样一个集群会是下面这样:
mastering
mastering
shard 1
shard 2第8章提高性能◆267
现在,当有一个节点岩掉后会发生什么呢?简单讲,我们会丢失50%的数据,且如果
故障是致命的,我们会永远丢失这些数据。即便有备份,我们也需要引入一个新节点并恢
复备份。这需要时间。如果你的业务依赖于 Elasticsearch,故障停机意味着金钱的损失。
现在,让我们看看同样的集群但是有一个副本的情况:
mastering
mastering
shard 1
shard 2
Node 1
clastcsearch
de 2
mastering
mastering
replica shard 2
replica shard 1
现在失去一个节点意味着我们仍然拥有完整可用的数据,且我们可以不停止服务就能
恢复完整的集群结构。并且这样部署的话,我们可以在某些情形下忍受2个节点同时失效。
例如,节点1和节点3或者节点2和节点4。在这两种情形下我们仍然可以访问全部数据。
当然这会降低性能,因为集群缺失了节点,但这仍然比完全不响应查询要好。
于是,当你在设计架构、决定节点数量、有多少个索引以及每个索引的分片数量时,
你需要把能接受的出现故障的节点数量考虑进去。当然了,你还需要考虑性能,只不过冗
余和高可用应该是进行扩展时的一个因数。
3.成本和性能的适应性
Elasticsearch天然的分布式特征和能够水平扩展的能力让我们在面对运行时的性能和成
本问题时很容易适应。首先,有着高性能的磁盘、众多的CPU和大量的内存的高端服务器
价格昂贵。并且云计算越来越流行,不仅允许我们在租来的机器上部署运行,还允许我们
按需进行扩展。我们只需要增加更多的机器,这只需点击几下鼠标或者经过一些配置,甚268◆深入理解 Elasticsearch
至可以被自动化。
综合以上内容,当 Elasticsearch有了水平扩展的解决方案后,我们可以降低运行集群
的成本。并且,如果成本对于我们的商业计划是最重要的因数,我们可以很容易地通过牺
牲性能来应对。当然,我们也可以选择其他的方式。如果我们能负担起庞大的集群,使用
适当的硬件和适当的分布式,我们可以向 Elasticsearch推送数百TB的数据,并且仍然能够
获得不错的性能。
4.持续更新
在讨论 Elasticsearch的扩展性时,高可用、成本、性能弹性和几乎无限的增长并不是
唯一需要讨论的。在某个时刻,你会希望你的 Elasticsearch集群升级到一个新版本,这
可能是由于bug修复、性能提升、新的功能或者其他你能想到的理由。问题是当每个分
片都只有唯一个实例时,升级意味着 Elasticsearch部分或者完全不可用,并可能意味着
使用 Elasticsearch的应用宕机。这是为什么水平扩展如此重要的另一个原因。对于类似
Elasticsearch这样支持水平扩展的软件,你可以对它们执行升级操作。例如,你可以通过滚
动重启把 Elasticsearch1.0升级到 Elasticsearch1.4,同时所有数据对于查询和索引操作仍然
是可用的。
5.一个物理机器上部署多个 Elasticsearch实例
尽管我们之前说过,由于一些原因(例如JVM堆栈超过31GB)你不应该寻求最高性能
的机器,但有时我们没有更多的选择。这个超出了本书的范围,但是由于我们在讨论扩展
性,我们认为提及一下在这种情况下应该怎么办是有益的。
在遇到我们正在讨论的情形时,当我们有高端的硬件,配备大量的内存、许多的高速
硬盘、众多的CPU等,我们需要考虑把物理服务器分割为多个虚拟机器,然后在每个虚拟
机器上运行一个 Elasticsearch实例。
法不运行多个虚拟机而是直接在一个物理机上运行多个 Elasticsearch实例也是可行
的。选择哪个方案取决于你。不过,我们喜欢把事情分开,由此,我们通常会把服
务器分割成多个小虚拟机。在把服务器分割为多个小虚拟机时需要记住,这些小虚
拟机会共享IO子系统。于是,为虚拟机恰当地分配磁盘是一个好的选择。
为阐明这样的部署,请看下图。它显示了你如何在3台大型服务器上以云的方式运
行 Elasticsearch,每台服务器都被分成了4个独立的虚拟机。每个虚拟机负责运行一个
Elasticsearch实例。第8章提高性能◆269
Elasticsearch
Elasticsearch
Elasticsearch
Elasticsearch
Efasticsearcl
Elasticsearch
Node
Node
ode
Node
Node
Elasticsearch
Elasticsearch
Elasticsearch
Elasticsearch
Elasticsearch
Elasticsearch
Node
N
Node
Node
Physical server
Physical server
Physical server
6.阻止分片及其副本部署在同一个节点上
还有一件事情需要讲一下。当有多个物理服务器被分割成虚拟机时,确保分片和它的
副本不在同一台物理机上十分重要。那样的话如果一个服务器出现故障或者重新启动就会
发生悲剧了。我们可以使用集群部署感知告诉 Elasticsearch分离分片和副本。对于前面的
例子,我们有3台物理服务器,分别命名为 serverl、 server2和 server3。
现在对于一个物理服务器上的每个 Elasticsearch,我们定义node. server name属性并设
置为服务器的标识符。于是对于在第1台物理服务器上的所有 Elasticsearch节点来说,我
们会在 Elasticsearch yml文件中设置如下属性:
node server name: serverl
除此之外,每个 Elasticsearch节点(无论在哪个物理服务器上)需要向 Elasticsearch
yml文件中添加如下属性:
cluster routing allocation awareness. attributes: server name
这告诉 Elasticsearch不要把主分片和它的副本放到具有相同node. server name属性的
节点上。我们只需完成这个就足够了, Elasticsearch会完成后续的工作。
7.为大规模集群设计节点的角色
我们还想告诉你一件事;事实上,我们已经在本书和《 Elasticsearch server, Second
Edition》中提过了,为了有一个完全容错和高可用的集群,我们应该区分节点,并给每个
节点一个设计好的角色。我们可以给每个 Elasticsearch节点指派的角色如下:
口查询聚合节点
口数据节点
口候选主节点
默认时,每个 Elasticsearch节点都是候选主节点(它可以成为主节点),能够容留数据,
以及作为査询聚合节点。查询聚合节点可以发送粒子查询到其他节点,收集和合并结果,
以及响应发出查询的客户端。你可能会奇怪为什么需要这个。让我们来举个简单的例子:
如果主节点有很大的压力,它可能不能及时处理集群状态相关的命令,于是集群将变得不270心深入理解 Elasticsearch
稳定。这只是一个简单的例子,你可以考虑其他的情形。
于是,多数大型的 Elasticsearch集群通常看起来如下图呈现的那样:
Data Node
Data Node
Dedicated
Master Node
I Non-data Non
Elasticsearch
master Node
Elasticsesrch
Application
Data Node
Data Node
Dedicated
Master Node
Non-data Non
master Node
Data Node
Data Node
Dedicated
Master Node
East useare
Elasticsearch Cluster
正如你所见到的,这个假设的集群包含两个聚合节点(因为我们知道不会有太多的查
询,但是我们希望有冗余),数十个数据节点(因为数据量非常大),以及至少3个候选主节
点(不应该做其他的事情)。 Elasticsearch在任意给定的时刻只需要使用一个主节点,为什
么这里有3个呢?这是用于冗余,同时通过设置 discovery.zen. minimum master nodes为
也能阻止脑分裂的发生。这使得我们很容易地处理集群中某个候选主节点出现故障的情形。
现在,让我们给你一些集群中每个节点类型的配置片段。虽然我们已经在7.1节中讨论
过了,但我们想再讲一次。
(1)查询聚合节点
查询聚合节点的配置十分简单。为了配置它们,我们只需要高 Elasticsearch我们不希
望这些节点成为候选主节点以及容纳数据。对应的 Elasticsearch yml中的配置如下:
node. master: false
node data: false
(2)数据节点
数据节点配置起来同样简单:我们只需要声明它们不应该是候选主节点即可。然而
我们不是默认配置的拥趸(因为默认配置趋于变化),因此数据节点的配置如下:
node. master: false
node data: true
(3)候选主节点
我们把候选主节点留到了通用扩展小节的最后。当然,这类的 Elasticsearch节点不应
该容纳数据,但是除此之外,在这类节点上禁用HTTP协议也是一个好的实践。这样做是
为了避免意外地在这些节点上执行查询。候选主节点相比数据节点和查询聚合节点可以使
用更少的资源,于是我们需要确保它们仅仅被用来处理与主节点相关的工作。所以候选主
节点的配置看起来大概是下面的样子:第8章提高性能◆271
node. master: true
node data: false
httpenabledfalse
8.53在高负载的场景下使用 Elasticsearch
现在我们已经知道了理论(以及一些 Elasticsearch扩展的例子),我们已经准备好讨论
为应对高负载需要对 Elasticsearch进行哪些方面的准备。我们决定把本章的这个部分分成3
个小节:一个专注于高索引负载,一个专注于高查询负载,一个同时考虑这两种情况。这
会给你一些在你准备你的集群时需要考虑什么的建议。
考虑在配置好为生产环境使用的集群后进行性能测试。不要直接使用从本书中得到的指
标。使用你的数据和你的査询进行尝试和调整,并观察它们的区别。记住给出对每个人都适
用的建议是不可能的,所以,应该把下面两部分当作一般的建议而不是可以使用的准则。
1. Elasticsearch优化的常规建议
在本节中,我们会讨论 Elasticsearch调优相关的常规建议。它们不是只与索引性能或
者查询性能相关,而是与它们都相关
(1)选择正确的存储
关键点之一是我们选择正确的存储实现。这在运行 Elasticsearch1.3.0之后的版本时尤
其重要。通常,如果你使用一个64位的操作系统,你应该使用 mmapfs。如果你没有使用
64位操作系统,那么,基于UNIX系的系统应该选择 nios,基于 Windows的系统应该选
择 simples。如果你能接受一个快速但是非持久化的存储,你可以看看 memory存储。它会
带给你最佳的索引访问性能,但是需要足够的内存来处理不仅全部的索引文件,还要处理
索引和查询请求。
随着 Elasticsearch1.3.0的发布,我们有了一个新的名为 default的存储类型,它是最新的默
认存储类型。正如 Elasticsearch开发者所说,它是一个混合的存储类型。它使用内存映射文件
来读取term字典和 doc values,而其他的文件则使用 NIOFSDIRECTORY实现来访问。在大多
数情况下,当使用 Elasticsearch1.30或者更高的版本时,应该使用 default存储类型。
(2)索引刷新频率
我们需要留意的第2件事情是索引刷新频率。我们知道索引刷新频率是指文档需要多
长时间才能出现在搜索结果中。规则非常简单:刷新频率越短,查询越慢,且索引文档的
昋吐量越低。如果我们能够接受一个较慢的刷新频率,例如10秒或者30s,那设置成这样
是十分有益的。这会减轻 Elasticsearch的压力,因为内部对象会以一个较慢的速度重新打
开,于是会有更多可用的资源来处理索引和查询请求。请记得,刷新频率默认是1s,这基
本上意味着索引查询器每1s重新打开一次。
为了让你了解对于我们正在讨论的问题有什么性能上的收获,我们做了一些性能272◆深入理解 Elasticsearch
测试,观察 Elasticsearch在不同的刷新频率下的性能。当刷新频率为ls时,使用一个
Elasticsearch节点我们大概每秒能够索引1000个文档。当提高刷新频率为5s时,索引吞吐
量提升了25%以上,我们大概每秒可以索引1280个文档。当设置刷新频率为25s时,相对
刷新频率1秒的情形吞吐量提升了超过70%,大约每秒索引1700个文档。同样值得一提的
是,无限增加刷新时间是没有意义的,因为超过一定值(取决于你的数据负载和数据量)之
后,性能提升变得微乎其微。
(3)线程池调优
这是与你的部署环境紧密相关的事情。一般而言, Elasticsearch默认的线程池配置就足
够优化了。然而,总有一些时候这些配置不能满足实际需要。你需要牢记,仅在遇到以下
的情形时才调整默认的线程池配置,即你看到节点正在填充队列并且仍然有计算能力剩余,
且这些计算能力可以被指定用于处理待处理操作。
例如,如果你在做性能测试时发现 Elasticsearch实例没有100%饱和,但是你却接到了
拒绝执行错误,那么这时就需要调整 Elasticsearch线程池了。你既可以增加同时执行的线
程数,也可以增加队列的长度。当然,你需要知道增加并发执行的线程数到一个很大的数
值时,会产生大量的CPU上下文切换(htt:. wikipedia. org/ wiki/context switch),进而
导致性能下降。当然,大量的队列也不是一个好主意,通常快速报错要比用队列中的成千
上万的请求来压垮 Elasticsearch要好。然而,这些都取决于你的特定的部署环境和使用场
景。我们很想给你一个精确的数字,但是对于这个问题,是无法给出的。
(4)调整合并过程
Lucene段合并的调整是另一件高度取决于你的使用场景和一些相关因素的事情。这些
因素,如你追加多少数据,多久追加一次等。对于 Lucene分段和合并需要记住两件事情。
在有多个段的索引上执行查询要比在只有少量段的索引上执行慢。性能测试显示在由多个
段构成的索引上执行查询比在只有一个段的索引上慢大约10%到15%。另一方面,尽管段
合并不是免费的,我们越希望有更少的段,就越需要配置激进的段合并策略。
一般的,如果你希望查询更快,就寻求更少的索引段。例如,设置 index merge, policy
merge factory低于默认值10,会导致更少的段,更低的RAM消耗,更快的查询执行速度
和更慢的索引速度。设置 index. merge policy. merge factory高于默认值10,会导致索引由
更多的段来构成,更高的RAM消耗,更慢的查询速度和更快的索引速度。
还有一件事:限流。默认条件下, Elasticsearch会限制合并的速度在20MB/s
Elasticsearch使用限流来避免合并过程过多的影响搜索。并且,如果合并过程不是足够快的
话, Elasticsearch会限制索引过程只使用一个线程,以此来确保合并过程能够顺利结束,且没
有大量的段存在。然而,如果你在使用SSD硬盘,那么限流20MB/s就不合适了,你可以把
它放大5到10倍。想要调整限流,我们需要在 Elasticsearch.ym文件里(或者使用集群配置第8章提高性能心273
APD设置 indices.store throttle. max bytes per sec属性为一个期望值,例如200MB/s。
通常而言,如果你想要更快的索引文档,就寻求个多的索引段。如果你想要查询更快
由于合并你的IO系统能完成更多的工作,且你能接受 Elasticsearch消耗多一点的内存,那
么就配置激进一些的合并策略。如果你希望 Elasticsearch索引更多的文档,就配置不那么
激进的合并策略,但是要记得这会影响査询的性能。如果你两个都想要,那么你需要寻找
一个平衡点,在这个点上合并既不会太频繁同时也不会导致大量的段。
(5)数据分布
我们已经知道, Elasticsearch的每个索引都可以被分成多个分片,并且每个分片都能有
多个副本。当你有不只一个 Elasticsearch节点和分割了分片的索引,适当的数据分布对于
均衡集群的负载以及没有节点做了比其他节点更多的工作就是十分重要的了。
让我们看下接下来的例子。假设我们有一个由4个节点构成的集群,其上有一个由3
个分片组成和一份副本的索引。集群看起来如下图:
mastering
mastering
mastering
shard 1
mastering
replica shard 2
shard 2
replica shard. 3
Elasticsearch Node 1
Elasticsearch Node 2
astering
replica shard
shard 3
Elasticsearch Node 3
Elasticsearch Node 4
从上图中可以看到,前两个节点上有两个分片部署在其上,而后两个只有一个分片。所以
实际的部署并不平均。当发送查询和索引数据时,会使得前两个节点比后两个做更多的工作。
这是我们希望避免的。我们可以让 mastering索引有两个分片和一个副本,于是看起来如下图:
mastering
mastering
shard 1
shard 2
Elasticsearch Node 1
Elasticsearch Node 2
mastering
replica shard 1
replica shard 2
Elasticsearch Node 3
Elasticsearch Node 4274心深入理解 Elasticsearch
或者,我们可以把 mastering索引分成4个分片和1个副本。
master
sterin
mastering
mastering
shard
replica shard 2
shard 2
replica shard 3
Elasticsearch Node 1
Elasticsearch Node 2
stering
stern
mastering
astering
shard 4
replica shard 1
shard 3
replica shard 4
Elasticsearch Node 3
Elasticsearch Node 4
对于以上两种方案,我们都得到了平均分布的分片和副本,每个节点都完成相似数量
的工作。当然,在有更多的索引(例如按日创建的索引)时,为了使数据平均分布就需要更
多的技巧了。也有可能我们无法实现分片平均分布,但我们应该努力实现这点。
对于数据分布、分片和副本还有一件事需要记得,在设计你的索引架构时,你需要记
得你的目标。如果是一个高索引量的使用场景,你可能想要把索引分散到多个分片上来降
低服务器的CPU和IO子系统的压力。对于复杂查询的场景这点同样适用,因为通过使用
更多的分片,你可以降低单个服务器上的负载。然而,对于查询,还有一件事:如果你的
节点无法处理查询带来的负载,你可以增加更多的 Elasticsearch节点,并增加副本的数量,
于是主分片的物理拷贝会被部署到这些节点上。这会使得文档索引慢一些,但是会给你同
时处理更多查询的能力
2.高查询频率场景下的建议
Elasticsearch的一个强大的功能是能够搜索和分析索引过的数据。然而,有时用户需要
调整 Elasticsearch,查询不仅要返回结果,还要尽快返回(或者在一个合理的时间内)。在
这部分,我们不仅讨论可行性,而且也对 Elasticsearch的高查询吞吐量场景进行优化。我
们还会对查询的性能优化给出常规性的建议。
(1)过滤器缓存和分片查询缓存
第1个有助于查询性能的缓存是过滤器缓存(如果查询使用过滤器,如果没使用,应该
适当地使用它们)。我们在24节中讨论过过滤器。当时我们没有谈到负责保存过滤器结果
的缓存:过滤器缓存。 Elasticsearch的默认过滤器缓存实现是在一个节点上的全部索引间共
享,我们可以使用 indices cache, filter size属性来控制缓存的大小。它表示在给定节点上能
够被过滤器缓存使用的全部的内存数量,默认是10%。通常,如果你的查询已经使用了过
滤器,你应该监控缓存的大小和逐出。如果你看到了许多的逐出,那么你的缓存大概太小第8章提高性能心275
了,你应该考虑增加缓存的大小。缓存过小可能会影响查询的性能。
Elasticsearch引入的第2个缓存是分片查询缓存。它在 Elasticsearch的1.4.0版时引
人,它的目的是缓存聚合、提示词结果和命中数(它不会缓存返回的文档,因此,它只在
search type= count时起作用)。当你的查询使用了聚合或者提示词,最好启用这个缓存(它
默认是关闭的),于是 Elasticsearch就能够重用保存在里面的数据了。关于这个缓存的最好
的一点是,它承诺与没有使用缓存时一样准实时搜索。
想要开启分片查询缓存,我们需要设置 index cache query enable属性为true。例如,想
要开启 mastering索引的缓存,我们可以使用如下的命令:
curl-xPUT localhost: 9200/ mastering/ gettings'-d
index cache query enable":true
请记得如果我们不使用聚合或者提示词,那么使用分片数据缓存就毫无意义。
还有一点需要注意,分片查询缓存默认使用不超过分配给 Elasticsearch节点的堆栈
的1%的内存。想要改变默认值,我们可以使用 indices cache. query.size属性。通过使用
indices cache query expire属性,我们可以指定缓存的过期时间,但是这不是必需的,在大
多数情况下,结果保存在缓存中,在每次索引刷新操作后失效
(2)关于查询的思考
我们能给出的最通用的建议是:你应该总是考虑到优化查询结构、过滤器的使用等。
我们在第2章中用大量篇幅讨论了这个,但是我们还想要再提及一次,因为我们认为它非
常重要。例如,我们看下面的查询:
lauer
l boliN
"must":
query string": I
"query" :"name: mastering AND department: it AND
category book I
n term
"tag": "popular t
l term
"tag":"2014276心深入理解 Elasticsearch
它返回了匹配查询条件的图书的名字。然而,对于前面的查询我们还有一些事情可以
优化。例如,我们可以移动一些东西到过滤器,于是下次我们再使用这个查询的某部分时,
我们节省了CPU并重用了缓存中保存的信息。例如,以下是优化后的查询的样子
query:
u filtered
"query "
"match":
name:"mastering '
filter:
boll
it must
term
"department":"it"
nterm
category i: "book"
terms
ntag":["popular",2014
你可以看到,我们做了一些改变。首先,我们使用 filtered查询来引入过滤器,我们移
动了绝大多数静态的、不分词的字段到过滤器。这使得我们很容易在执行下一个查询时重
用它们。由于进行了这样的查询重构,我们能够简化主查询,所以我们将 query string查询
改为 match查询,因为对于我们的例子来说 match查询就足够了。你在优化查询或者设计
它们是需要做的,就是在头脑中思考优化和性能并尽可能地做到最优
然而,对于查询的产出来说,性能并不是唯一的不同。你知道,过滤器不影响返回文第8章提高性能心277
档的打分,并且在计算得分时不被考虑进去。于是,如果你对比前面查询返回的文档的得
分,你会注意到它们是不同的。这点需要记住。
(3)使用路由
如果你的数据可以使用路由,你应该考虑使用它。有着相同路由值的数据都会保存到相同
的分片上。于是,我们可以避免在请求特定数据时查询所有的分片。例如,如果我们保存客户
的数据,我们可以使用客户⑩D作为路由。这会允许我们把同一客户的数据保存在同一个分片
上。这意味着在查询时, Elasticsearch只需从一个分片上获取数据,如同下图所展示的那样:
Node 1
Application
Non-data Non-L
Node 2
master Node
Elasticsearch
Node 3
Elasticsearch Cluster
如果我们假设数据保存在节点2上,我们可以看到 Elasticsearch只需要在特定的节点上执
行査询就能获取指定客户的所有数据。如果我们不使用路由,前面查询的执行起来就会如下:
Node 1
Application
Non-data Non
master Node
Node 2
Node 3
Elasticsearch Cluster278◆深入理解 Elasticsearch
在不使用路由的情形下, Elasticsearch先是需要搜索全部的分片。如果你的索引包含数
十个分片,如果使用路由,只要单个 Elasticsearch实例还能够容纳得下分片,性能的提升
就会非常明显。
洼请记得,不是每种情况都适合使用路由。想要使用它,你的数据需要是可分割的,
这样它们才能够分布在不同的分片上。例如,拥有数十个非常小的分片和一个庞大
的分片是没有意义的,因为对于这个庞大的分片性能不会很好。
(4)并行你的查询
通常被忘记的一件事是并行化查询的必要性。假设集群中有一打节点,但是索引只有
一个分片。如果索引很大,查询的性能可能比你期望的要差。当然,你可以增加副本的数
量,但是这没有什么帮助。一个查询还是会在索引的一个分片上执行,因为副本只不过是
主分片的副本,它们包含同样的数据(或者它们应该这样)。
真正有帮助的是把你的索引分成多个分片,分片的数量取决于硬件和部署方式。
般来说,建议把数据平均分配,于是节点可以有相同的负载。例如,如果我们有4
个 Elasticsearch节点和2个索引,你可能会想要每个索引有4个分片,就像下图所示
的那样:
itering
shard 1
shard 3
shard 2
shard 4
Elasticsearch Node 1
Elasticsearch Node 2
users
shard 3
ird
shard 4
shard 2
Elasticsearch Node 3
Elasticsearch Node 4
(5)字段数据缓存和断路
Elasticsearch的字段数据缓存默认是没有大小限制的。这样非常的危险,尤其是当你在
很多字段上使用分组和排序的时候。如果这些字段是较高基数的,那么你会遇到更大的麻
烦。我们说的麻烦是指内存溢出。
我们可以通过控制两件事情来确保我们不会陷入内存溢出的错误中。首先,我们可以
限制字段数据缓存的大小。其次,我们可以使用断路器。使用断路器我们可以轻易地配置第8章提高性能◆279
成直接抛出异常而不是加载过多的数据。结合这两种办法就能确保我们不会遇到内存溢出
的问题。
但是,我们也要记住, Elasticsearch在字段数据缓存的大小不够处理分组或者排序请求
时会逐出数据。这会影响查询的性能,因为加载字段数据信息的效率不是很高。然而,我
们认为让查询慢点总比让集群由于内存溢出错误而宕掉要好。
最后,如果你的查询大量使用字段数据缓存(例如聚合和排序,且你遇到了内存相关
的问题(例如内存溢出错误或者GC停顿,可以考虑使用我们讨论过的 oc Value. doc value
有着同字段数据缓存相似的性能,并且随着 Elasticsearch每次新版的发布对其的支持也越
来越好(对 doc value的改进是由 Lucene来实现的)。
(6)控制size和 shard size
在处理使用聚合的查询时,对于某些查询我们可以使用两个属性:size和 shard size
size参数定义最后的聚合结果会返回多少组数据。聚合最终结果的节点会从每个返回结果
的分片获取靠前的结果,且只会返回前se个结果给客户端。 shard size参数具有相同的含
义,知识其作用在分片层次上。增加 shard?size会导致聚合结果更加准确(例如对重点词
的聚合),代价是更大的网络开销和内存使用。降低这个参数会导致聚合的结果不那么精确,
但却有着网络开销小和内存使用低的好处。如果我们看到内存使用太多了,我们可以降低
问题查询的size和 shard size参数,看看结果的质量是否仍然可以接受。
3.高索引吞吐量场景
在此,我们会集中讨论索引吞吐量和速度的优化。一些是关于你每秒钟可以向
Elasticsearch推送多少数据的,另一些是与索引无关的。
(1)批量索引
这个建议十分明显,但是你可能会感到奇怪,很多人都忘记了用批量索引代替逐个的
索引文档。但是,需要注意,不要向 Elasticsearch发送过多的超出其处理能力的批量索引
请求。关注批量索引的线程池和它的大小(默认等于CPU核数,带有一个大小为50的队
列),并尝试调整你的索引程序来匹配它们,否则,如果 Elasticsearch不能处理它们的话,
先是会是请求排队,然后你很快就会开始看到拒绝执行的异常,并且你的数据不会被索
引。另一方面,记得不要让你的批量请求太大,否则 Elasticsearch会需要大量的内存来处
理它们。
为了举例说明,我会向你展示两种索引方式的区别。在第1张图中,展示的是正在逐
个索引文档时的索引吞吐量。在第2张图中,我们索引同样的数据,但是不是逐个索引,
而是每批10个。280
深入理解 Elasticsearch
Indexing-201411272356t02014112800
c Actions
口 indexed docs口 delete total回 dexing rate口 'deleting rate
cs/s
docs
docs
Indexing-2014200321020141280050
oE Actions
口 ndexed doc口 delete totaf indexing rate口 'deleting rate
dexing rate
如你所见,当逐个索引文档时,我们每秒能稳定地索引大约30个文档。在以10为批
量使用批量索引时发生了变化,我们每秒大约能索引200个多一点的文档,所以可以轻易
地看出它们的区别。
当然,这是索引速度的非常简单的对比,为了向你展示真实的区别,我们应该使用许
多线程来让 Elasticsearch达到它的极限。不过,关于使用批量索引对于索引吞吐量的提升,
前面的对比应该给了你一个基本的概念。
(2) doc values与索引速度的取舍
谈到索引速度时,我们不得不讨论 doc values就如我们在本书中多次说过的,在
Elasticsearch为了实现排序、聚合或分组,会需要反转字段,这需要巨大的内存,doc
values在这方面可以帮助我们。然而,记录 doc values在索引时需要一些额外的工作。一方
面,如果我们只关心最高的索引速度和最大的索引吞吐量,你应该考虑不使用 doc values
另一方面,如果你有大量的数据,为了使用聚合和排序功能而不产生内存相关的问题,使
用 doc values可能是唯一的办法了。
(3)控制文档的字段
索引量的不同是有区别的,这很好理解。然而,这不是唯一的因素。文档的大小和对第8章提高性能◆281
其的解析同样重要。对于较大的文档,你不仅能够看到索引的增长,还能看到索引速度有
所减慢。这就是为什么有时你会想要看看你正在索引和保存的字段。保持你存储的字段尽
可能地少,或者完全不使用它们,你在大多数情况下需要存储的字段是 source
除了 source字段,还有一件事, Elasticsearch默认索引al字段。提醒:al字
段是 Elasticsearch用来从其他文本字段收集数据的。在一些场景下,这个字段不被使
用,这时最好关闭它。关闭a1l字段十分简单,唯一需要做的是在类型映射中添加如下
的内容:
all":I"enabled": false]
在索引生成阶段,可做如下处理:
curl -xPOST .localhost: 9200/disabling all-d i
mappings
ntest type
all":I"enabled": false 3,
properties":
"name":I"type":"string"]
"tag":I "type": "string","index":"not analyzed"y
了333
减少文档的大小和其内文本字段的数量会让索引稍快一些。
还有一件事,在禁用al′字段时,设置一个新的默认搜索字段是一个好的实践。我们
可以通过设置 index. query default field属性来指定。例如,对于我们的例子,我们可以在
Elasticsearch yml文件中设置它,并将设置为前面映射里的name字段:
index query default field: name
(4)索引的结构和副本
在设计索引结构时,你需要考虑索引的分片和副本的数量,同时我们也需要考虑数据
在 Elasticsearch节点上的分布、性能、可用性、可靠性等。首先,把主分片部署到所有的
节点上,于是我们可以并行的进行索引文档,这会加快索引的速度。
第2件事情是数据复制。我们需要记住的是过多的副本会导致索引速度下降。多个原
因导致了这个问题。首先,你需要在主分片和副本间传递数据。其次,通常主分片和副本
被部署在相同的节点上(当然不是主分片和它的副本,而是其他主分片的副本)。例如,我
们来看看下图向我们展示了什么:282◆深入理解 Elasticsearch
caeervkgews
Gra9 Collectors Summary,溶H节的超到的是
indai statE
5游以
C容的感心
u& estar
慧ay
Garbage Collectors Tim器14的1221的4
材下he
v wg easedxiewn flerwe'y
C以群就e
因为这个原因, Elasticsearch需要主分片和副本的数据,而这会占用磁盘空间。取决于
集群的配置,索引吞吐量在这类情况下会降低(取决于磁盘、同时索引的文档数量等)。
(5)调整预写日志
我们已经在6.3节中讨论过事务日志。 Elasticsearch有一个内部模块叫作 translog。它
是一个基于分片的结构,用来实现预写日志(htp: wikipedia. org/wiki/ Write-ahead
logging)。基本上,它是用来让 Elasticsearch向GET请求暴露最新的更新,确保数据的持
久性,以及优化 Lucene索引的写入。
Elasticsearch默认在事务日志中保留最多5000个操作,或者最多占用200MB的空间。
然而,如果我们想要获得更大的索引吞吐量,愿意付出数据在更长的时间内不能被搜索到
的代价,我们可以调高这些默认值。通过配置 index translog flush threshold ops和 index.
translog flush threshold size属性(两者都是在索引级别生效并能通过 Elasticsearch的API
实时更新),我们可以设置存储操作的最大值数量和最大体积。我们曾经见到过把这个属性
设置为默认值的10倍的情况。
需要记得,一旦发生故障,拥有大量事务日志的节点其分片的初始化会慢一些。这是
因为 Elasticsearch需要在 shard生效前处理全部的事务日志。
(6)关于存储的思考
在应对高索引量的使用场景时,存储类型和其配置是一个关键点。如果你的公司能负
担的起SSD硬盘,那么买吧。与传统的机械硬盘相比,它们具有速度上的优势,但是,当
然是以更高的价格为代价的。如果你负担不起SSD硬盘,配置你的机械硬盘工作在RAID0
(https://en.wikipediaorg/wiki/raid)模式,或者配置Elasticsearch使用多个数据路径。
另外,不要使用共享的或者远程的文件系统来保存 Elasticsearch的索引,而是使用本第8章提高性能心283
地的存储。远程和共享文件系统通常比本地磁盘慢,会使得 Elasticsearch等待读写操作的
完成,因而造成整体性能的下降
(7)索引期间的内存缓存
还记得供索引缓存使用的可用内存越多(通过配置 indices. memeory index buffer_ size
属性), Elasticsearch在内存中容纳的文档就越多吗?当然了,我们不会让 Elasticsearch占用
100%的可用内存。默认使用10%,但是,如果你真的需要一个较高的索引效率,你可以
增加它。建议给每个在索引期间生效的分片分配512MB内存,但是,记住 indices. memory
index buffer size属性是设置节点的,而不是分片的。所以,如果你给 Elasticsearch20GB
的堆空间,且节点上有10个活动分片,那么 Elasticsearch默认会给每个分片大约200MB
内存用作索引缓存(20GB的10%,再除以10个分片)。
86小结
在本章中,我们聚焦在 Elasticsearch的性能和扩展,探讨了 doc values是如何帮助我们
提高查询性能的,垃圾回收器是如何工作的,以及在调整配置时需要关注什么。我们对查
询做了基准测试,看到了热点线程API是什么样的。最后,我们讨论了在应对高查询量和
索引量的使用场景时如何对 Elasticsearch进行扩展。
在下一章中,我们会编写一些代码,创建一个 Maven项目来实现一个 Elasticsearch插
件,编写一个自定义的REST行为来扩展 Elasticsearch的功能。除此之外,还会学习为
Elasticsearch引入新的分析插件需要做些什么,并且会创建一个这样的插件。器嚣囂
题瘟画磊圆■
题國
Cline?i第9章
开发 Elasticsearch插件
在上一章中,我们集中讨论了 Elasticsearch集群的性能和扩展。看到了 doc values如何
帮助我们提升查询性能和降低査询的内存开销,这是以轻微降低索引速度为代价来实现的。
我们查看了垃圾回收器如何工作的,以及在调整配置时需要关注什么。我们对查询做了基
准测试,看到了热点线程API是什么样的。最后,我们讨论了如何对 Elasticsearch进行扩
展。到本章结束时,将涵盖以下内容
口如何配置开发 Elasticsearch插件的 Maven项目
口如何开发一个自定义REST行为的插件
口如何开发一个扩展 Elasticsearch分析能力的自定义分析插件
91创建 Maven项目
在讲述如何开发 Elasticsearch自定义插件之前,我们先探讨一下插件的打包方式。打
包后的插件可以使用 plugin命令安装到 Elasticsearch中。为了实现这一目的,我们使用
Apache Maven(htp:/ maven. apache。org/)项目管理软件,它致力于使你的构建过程更简单、
提供统一的构建系统、管理依赖等。
本章是在 Elasticsearch1.4)本下编写并测试通过的。
另外请记住,你手中的这本书不是关于 Maven的,而是讲述 Elasticsearch的。我们会第9章开发 Elasticsearch插件◆285
尽可能少地讨论与 Maven相关的信息。
法 Apache Maven的安装是个简单任务。这里我们假定你已经安装好了 Maven。不过,
如果你对安装步骤有疑问,请查询htt:/ maven.apache. org/获取更多信息。
92了解基本知识
Maven构造过程的结果是一个 artifact。每个 artifact由ID、组织名、版本号来定义。
这一点在使用 Maven时至关重要,因为你将使用的每个依赖都由这3个属性唯一确定。
9.2.1 Maven java项目的结构
Maven的理念非常简单。创建好的结构类似如下快照
岛src
4 main
Ya
solr
sonrrver
I JSONRiver java
JSoNRiverModule. java
① JSONRiverPlugin. java
J URLChecker java
▲@ resources
lugin properties
C java
pom.xml
可见,代码被放到src文件夹下(普通代码在main文件夹下,而单元测试代码在test
文件夹下)。尽管你可以调整默认布局,但 Maven在默认布局下工作得更好
922POM的理念
除了代码之外,你可以在图中看到一个位于项目根目录下名为 pom.xml的文件。这是
个项目对象模型文件,可以描述项目本身、项目属性以及项目的依赖。不错,你不用手286心深入理解 Elasticsearch
工下载那些已经存在于某个可用 Maven仓库中的依赖。在 Maven工作过程中,它会自动下
载并使用所需的依赖。你唯一需要在意的是,编写一个合适的 pom.xml片段来告知 maven
需要哪些依赖。
比如,请看下面的 Maven pom.xm1文件:
sprojectxmlns="http://maven.apacheorg/pom/4.0.0"XmlnS:xSi=http://
www.w3.oRg/2001/xmlschema-instance"
xsi:schemalocation="http://maven.apacheorg/pom/4.0.0http://
maven.apache. org/xsd/maven-400.xsd">
<modelVersion>4.0.0</modelversions
<groupId>pl solr</groupId>
cartifactId>analyzers/artifactId>
version>l.0-SNAPSHOT</version>
<packaging>jar</packaging>
<name>analyzer</name>
urlshttp://solr.pl</url>
<properties>
<elasticsearch version>l4.1/elasticsearch version>
<project build source Encoding>UTF-8</project build
sourceEncoding>
</properties>
<dependencies>
<dependency>
<groupIdsorg. elasticsearch</groupId>
<artifactIdselasticsearch</artifactId>
<version>sfelasticsearch. version)</version>
</dependency>
</dependencies>
</project>
这是本章将要使用和扩展的 pom.Xm文件的简化版。可以看出,它以 project根标签作
为开始,然后定义了组织ID、 artifact ID、版本号及打包方式(本例中使用标准构建命令来
打包成jar文件)。除此之外,我们还定义了一个依赖:1.4.1版的 Elasticsearch类库。
9.23执行构建过程
为了运行构建过程,只需要简单地运行 pom.xml所在路径中的命令:
mvn clean package
这个命令将启动 Maven。它将清除工作目录下所有自动生成的内容,编译代码,然后
打包代码。当然,如果我们有单元测试,必须让它们运行通过才能打包。打包好的jar包将
被写入 Maven创建的 target目录第9章开发 Elasticsearch插件287
③
如果想要了解更多 Maven生命周期的信息,请访问htp:!/ maven. apache. org/guides
introduction/introduction-tothe-lifecycle html
924引入 Maven装配插件
我们需要压缩插件代码来生成ip压缩文件。 Maven默认不支持纯粹的zip打包,为了
支持这一功能,我们将使用 Maven装配插件(可以在如下网址找到更多该插件的相关信息:
htte: maven.apache.org/ plugins/maven- assembly- plugin/)。总的来说,这个插件可以把项目
的输出和项目的依赖、文档、配置文件等聚合在一起,生成一个单独的归档文件。
为了让装配插件工作起来,我们需要在 pom. xml中加入 build片段。这个片段包含装
配插件的信息、jar插件(负责生成合适的jar文件)以及编译插件。指定编译插件的目的是
让代码可被Java7支持。除此之外,我们希望把档案文件放到项目的 target/release目录下。
pom. xml文件的相关片段如下:
<build>
<plugins>
<plugin>
<groupId>org. apache maven plugins</groupId>
kartifactId>maven-jar-pluginc/artifactId>
<version>2.3</version>
<confiquration>
<finalNameselasticsearch-siproject name)
selasticsearch, version)</finaIName>
</configuration>
</plugin>
<plugin>
<groupIdsorg. apache maven plugins</groupId>
kartifactIdsmaven-assembly-plugin</artifactId>
<version>2.2.1</version>
<configuration>
<finalNameselasticsearch-sproject name)
selasticsearch. version)</finalName>
<appendAssemblyId>false</appendAssemblyId>
coutputDirectoryssfproject. build directory)/release/</
outputDirectory>
<descriptors>
<descriptor>assembly/release. xml</descriptor>
</descriptors>
</configuration>
<executions>
<execution>
<id>generate-release-plugin</id>
<phase>package</phase>
<goals>
<goal>single</goal>288◆深入理解 Elasticsearch
</goals>
</execution>
</executions>
</plugin>
<plugin>
cartifactId>maven-compiler-plugin</artifactId>
<confiquration>
<source>l7</source>
<target>l 7</target>
</configuration>
</plugIn>
</plugins>
</build>
就近查看装配插件的配置,你会发现我们在 assembly目录下设定了名为 release. xml的
装配描述符。这个文件将负责指示我们输出数据的文档类型。我们放到 assembly目录下的
release . xm1文件的内容如下:
< xml version=1.0?>
<assembly>
<id>bin</id>
<formats>
<format>zip</format>
</formats>
<includeBaseDirectory>falses/includeBaseDirectory>
<dependencySets>
<dependencyset>
<unpack>false</unpack>
coutputDirectory>/</outputDirectory>
cuseprojectArtifact>false</useProjectArtifact>
<useTransitiveFilteringstrue</useTransitiveFiltering>
<excludes>
<exclude>org.elasticsearch: elasticsearch</exclude>
</excludes>
</dependencyset>
</dependency Sets
<filesets>
<fileset>
<directory>s(project build directory)/</directory>
<outputDirectory>/</outputDirectory>
<includes>
sinclude>elasticsearch-slproject name
sfelasticsearch, version).jars/include>
</includes>
</fileset>
</fileSets>
</assembly>
同样,我们不需要了解所有细节,尽管知道正在发生些什么是一件好事。之前的代码
将通知 Maven装配插件把归档文件打包成zip(< format>zip</ format>)格式,并指出需要第9章开发 Elasticsearch插件◆289
排除JUnt和 Elasticsearch这两个库( exclude部分),因为它们已经在我们需要安装插件的
Elasticsearch中提供了。此外,我们还指定需要包含我们项目的jar文件( include部分)。
93刨建自定义REST行为
让我们从创建一个自定义REST行为来开始我们的扩展 Elasticsearch之旅。我们选择
它作为第一个扩展,是因为我们想要通过最简单的方式来介绍如何扩展 Elasticsearch。
法我们假定你已经如我们在9.1节中所做的那样创建了一个Java项目并使用 Maven
如果你想要使用现成可用的项目代码,请从 Packt网站上获取本书的代码。
93.1设定
为了演示如何开发一个自定义REST行为,我们需要了解它有怎样的功能。我们的
REST接口真的非常简单,它会返回所有节点的名称或匹配传递给它的特定前缀的节点的名
称。除此之外,它只在使用HTTP的GET请求时有效,所以,例如,POST请求是不允许的。
93.2实现细节
我们需要开发以下两个Java类:
口一个类扩展 Elasticsearch的 org. Elasticsearchrest包中的抽象类 Base resthandler,它
负责处理REST请求,我们把它叫作 CustomRestAction
日一个类被 Elasticsearch用来加载插件,这个类需要扩展 Elasticsearch的org
elasticsearch plugin包中的抽象类 AbstractPlugin,我们把它叫作 Customrest-
Action Plugin
除了以上两个,我们还需要一个简单的文本文件,在开发完我们提到的两个Java类后
我们会讨论它。
1.使用REST行为类
最有趣的类是那个我们用来处理用户请求的类,我们把它叫作 Custom Resection。
为了能够运转,它需要扩展 org. Elasticsearch rest包中的 Base Resthandler类,它是
Elasticsearch中处理REST请求的基类。为了扩展这个类,我们需要实现 handleRequest方
法,在这个方法中我们会处理用户请求。还要实现一个有着3个参数的构造器,它会用来
初始化基类和注册恰当的处理器,这样我们的REST行为就可见了。
CustomRestAction的完整代码如下:290◆深入理解 Elasticsearch
public class CustomRestAction extends BaseRestHandler I
@In]ect
public CustomRestAction(Settingssettings, Rest Controller
controller, client client)
super(settings, controller, client)i
ontroller registerHandler(Method GET, " mastering/nodes", this)i
@Override
public void handleRequest (RestRequest request, Restchannel
channel, Client client)I
final String prefix= request param("prefix", "")i
client admin().cluster(), prepareNodes Info().all(). execute(new
RestBuilderListener<NodesInfoResponse>( channel)
@Override
public RestResponse buildResponse(
NodesInfoResponse response, XContentBuilder builder)
throws Exception
List<String> nodes new ArrayList<String>()i
for (NodeInfo nodeInfo response. getNodes())
String nodeName= nodeInfo getNode(). getName()i
if (prefix isEmpty())t
nodes. add(nodeName)
3 else if (nodeName startswith(prefix))
nodes. add(nodeName)i
builder. startobject (
field("nodes", nodes
endobject (
return new BytesRestResponse(RestStatus. OK, builder)i
(1)构造器
对每一个自定义的REST类, Elasticsearch在创建这类对象时都会传递3个参数: Settings
类型的对象,它包含配置信息; RestController类型的对象,它用来绑定REST行为到REST
端点; Client类型的对象,它是一个 Elasticsearch的客户,也是同 Elasticsearch交互的入口点。
这3个参数也同样是它的超类所需要的,所以我们调用基类的构造器来传递它们。
还有一件事:@ iNject注解。它允许我们告知 Elasticsearch在创建对象期间把参数传
入构造器。想了解这个注解的更多信息,请参见Javadoc你可以在https://github.com
Elasticsearch/Elasticsearch/blob/master/src/main/java/org/Elasticsearch/common/inject/Inject
java找到。
现在,让我们关注下面这行代码
ontroller registerHandler(Method GET,"/mastering/nodes", this)第9章开发 Elasticsearch插件291
这行代码的作用是注册我们自定义的REST行为,并且把它绑定到我们选定的端点上。
第1个参数是HTTP方法类型,REST行为会支持这个方法。就如我们前面说过的,我们只
希望响应GET请求。如果我们想要响应多个HTTP方法,只需要对每个HTTP方法类型调
用 registerHandler方法。第2个参数指定我们自定义REST行为的确切端点。对于我们的
例子来说,它是/ mastering/ nodes。第3个参数告诉 Elasticsearch那个类需要负责响应我们
定义的端点。对于我们的例子,它是我们正在开发的类,因此我们传递this
(2)处理请求
尽管 handlerequest方法是代码中最长的一个,但是它并不复杂。我们从读取参数的代
码开始:
String prefix request param("prefix","")
我们把 prefix请求参数保存在名为 prefix的变量中。默认的,在没有prex参数传递给
请求时,我们希望给 prefix变量赋与一个空字符串值(默认值由 request对象 param方法的
第2个参数定义)。
接下来,我们使用 Elasticsearch的 client对象获取 NodesInfoResponse对象。 client
对象可以执行 Elasticsearch的管理命令。在这个例子里,我们可以使用异步的方式向
Elasticsearch发送请求。不调用 executeD. action Geto方法,这会一直等待直到有响应返
回;而是调用 execute方法,它接收一个 future对象作为参数,当查询结束时会通知这
个 future对象。于是, handlerequest方法的其他代码就都在 RestBuilderlistener对象的
buildResponse回调里。 NodesInfoResponse对象包含一个 Nodelnfo对象数据,我们用它来
取得节点的名称。我们需要做的是返回包含指定前缀的所有节点,如果没有给出 prefix参
数则返回全部节点。为了实现这个效果,我们创建一个数组:
List<String> nodes new ArrayList<String>()i
我们使用接下来的for循环来迭代可用的节点:
for (NodeInfo node Info response. getNodes()
我们使用 Discovery Node对象的 getName方法来取得节点的名称,在 NodeInfo对象上
调用 getNode方法可以得到 Discovery Node对象:
string nodeName node Info getNode(). getName ()
如果 prefix参数是空的,或者节点名称以其开头,把这个节点名称添加到我们创建的
数组中。当我们迭代完所有的NodeInfo对象,就开始构建响应,然后把它通过HTTP发送
出去
(3)构建响应
关于 CustomRestAction类的最后一件事情是处理响应,它是我们创建的
buildResponse)方法的最后一部分代码的职责。这段代码非常简单,因为 Elasticsearch已292◆深入理解 Elasticsearch
经通过 builder参数提供了恰当的响应构建器。它接收客户端调用时传递的 format参数
所以我们以恰当的JSON格式发送响应,正如 Elasticsearch默认的那样。我们也可以使用
YAML格式(htt:/en. wikipedia. org/wiki/YAML)。
现在,我们使用得到的 builder对象来开始构造 response对象(使用 startobject方法),
然后写入 nodes信息(因为 nodes的值是集合类型,它会被自动格式化为数组)。在 response
对象中创建了 nodes属性,我们使用它来返回匹配的节点名称。最后我们使用 endobject方
法来结束 response对象的构建。
在我们的对象准备好作为响应被发送后,我们返回 BytesRestResponse对象。我们用如
下的代码来完成这个:
return new BytesRestResponse(Reststatus. OK, builder)i
正如你所看到的,为了创建对象,我们需要传递两个参数: Reststatus和 XContent Builder
ⅹ ContentBuilder内保存着响应的内容, Reststatus使得我们可以指定响应的代码,在我们的例
子中是 Reststatus.OK,因为一切都很顺利。
2. plugin类
CustomRestAction plugin类包含着 Elasticsearch用来初始化插件的代码。它集成至org
elasticsearch plugin包中的 AbstractPlugin类。因为我们正在创建一个扩展,我们必须实现
如下代码部分。
口 constructor:这是标准的 constructor,它接收一个参数,对于我们的例子,什么也不
需要实现。
口 onmodule方法:它包含了添加我们自定义的REST行为的代码,以便 Elasticsearch
能够知道这点。
口name方法:插件的名称。
口 description方法:插件的说明。
整个类的完整代码如下
public class CustomRestActionPlugin extends AbstractPlugin I
@Inject
public CustomRestActionPlugin(Settings settings)I
public void onModule(RestModule module)(
module. addRestAction( CustomRestAction class)i
@Override
public String name()I
return "CustomRestActionPlugin"第9章开发 Elasticsearch插件心293
@Override
public String description()
eturn custom rest action
constructor、name和 description方法都非常简单,我们略过不说,我们会聚焦在
on Module方法上。这个方法接收一个参数: RestModule类型的对象,它是使得我们可以注
册自定义REST行为的类。 Elasticsearch会在所有可用的模块上调用 on module方法。我们
做的仅仅是调用 Restmodule的 addRestAction方法,传入我们的 Custom restaction作为参
数。对于Java开发的部分来说到这里就结束了。
3.向 Elasticsearch声明自定义REST行为
我们的代码已经准备好了,但是我们还需要做一件事:我们需要让 Elasticsearch知道注
册我们插件的类是 CustomRestAction Plugin。为实现这个,我们在sr/main/ resources目录
下新建一个 es-plugin properties文件,写入如下内容:
plugin=pl solr rest. CustomRestActionPlugin
我们只是指定了 plugin属性,它需要赋值为我们用来注册插件的类(继承至
Elasticsearch的 AbstractPlugin的那个类)。这个文件会在构建过程中包含到jar文件里,
Elasticsearch在加载插件时会用到它。
4.测试时间
当然了,我们可以到这里就结束了,但是我们不准备这样,我们想要向你展示如何构
建每个插件、安装它,最后测试一下它是否能正常工作。让我们从构建插件开始。
(1)构建插件
我们从最容易的部分开始,构建插件。为了构建它,我们执行一个简单的命令:
nvn compile package
我们告诉 Maven我们想要代码被编译和打包。在命令执行完毕后,我们会在 target
release目录(假设你使用了与我们在本章开头描述的项目相同的配置)中发现包含插件的压
缩包。
(2)安装插件
为了安装这个插件,我们会使用 Elasticsearch发布包的bin目录下的 plugin命令。假设
我们的自定义插件包保存在/ home/install/es/ plugins目录中,我们会执行如下的命令(我们
从 Elasticsearch的根目录来执行)
bin/plugin --install rest --url
file: /home/install/es/plugins/elasticsearch-rest-141.zip294◆深入理解 Elasticsearch
我们需要在集群的所有节点上安装这个插件,因为我们希望在每个 Elasticsearch上运
行自定义的REST行为。
注想了解更多关于安装 Elasticsearch插件的信息,请参见我们前一本书《 Elasticsearch
Server,SecondEditiony或者查看Elasticsearch的官方文档,地址是http://www
Elasticsearch. org/guide/reference/modules/plugins/
安装完插件后,我们需要重新启动这些 Elasticsearch实例。重启后,我们应该在日志
中看到同下面类似的信息:
[2014-12-1221:04:48,348][INFO][p1 giNs
[Archer] loaded [CustomRestActionPlugin], sites [
正如你所看到的, Elasticsearch通知我们,一个叫作 CustomRestAction Plugin的插件被
加载了。
(3)检验REST行为插件是否工作
终于,我们可以检验插件是否工作了。为了做到这个,我们会运行以下的命令:
curl -XGET localhost: 9200/ mastering/nodes?pretty
执行后,我们应该可以得到集群中全部的节点,因为我们并没有提供 prefix参数。下
面是 Elasticsearch的响应:
I nodes":["Archer l 1
因为我们的集群只有一个节点,所以我们的节点数组中只有一个元素。
现在,我们试试如果添加 prefix=Are到请求中会发生什么。我们使用的命令如下:
curl -XGET localhost: 9200/ mastering/nodes ?prefix=Are&pretty
Elasticsearch的响应如下
nodes":[]
如你所见,节点数据是空的,因为我们的集群中,没有任何节点的名称是以Are为前
缀的。最后,我们测试另一种响应格式:
curl -XGET 'localhost: 9200/ mastering/nodes ?pretty&format=yaml'
现在响应不再是JSON格式了。看下一个由两个节点组成的集群其输出的内容:
nodes
mAtalon
"Slapstick"第9章开发 Elasticsearch插件心295
如你所见,我们的REST插件并不复杂,但是已经有一些功能了。
94创建自定义分析插件
关于 Elasticsearch自定义插件的最后一个话题是自定义分析插件。我们之所以选择展示自
定义分析插件的开发过程,是因为这在某些情况下将非常有用,比如当你需要在公司项目中引
入定制化的分析过程时,或者想要使用 Lucene支持而 Elasticsearch没有提供的分析器和过滤
器时。由于创建一个分析器扩展相对之前的案例更加复杂,我们决定把它放到本章最后讨论。
94.1实现细节
不管是从 Elasticsearch自身视角来说,还是从需要开发的类数量来说,开发一个自定义
分析插件是一件复杂的工作。相对上一个案例我们需要做更多的事。需要开发的任务如下:
口 Token filter类(来自org, apache lucene. analysis包)的扩展实现。该实现命名为
Custom filter,它将反转 token的内容。
口 AbstractToken Filter Factory(来自 org. Elasticsearch index. analysis包)的扩展实现类。
该实现类将向 Elasticsearch提供 Custom Filter实例。我们把它命名为 Custom Filter
Factory
口自定义分析器,扩展自 org. apache. lucene. analysis. Analyzer类,提供 Lucene分析器
的各项功能。我们称之为 CustomAnalyzer
口 Analyzer Provider,扩展自 AbstractIndex Analyzer Provider类(来自 org. Elasticsearch
index analysis包),我们称之为 Custom Analyzer Provider。它负责向 Elasticsearch提
供 Analyzer实例。
口 AnalysisModule. AnalysisBinderProcessor(来自 org. Elasticsearch index analysis包)的
扩展类。它将向 Elasticsearch提供分析插件的名称。我们称之为 CustomAnalysis
Binderprocessoro
口AbstractComponent(来自orgElasticsearch.common.component包)的扩展类,它负
责告知 Elasticsearch使用哪个工厂类来创建自定义的分析器和过滤器。我们称之为
CustomAnalyzerIndices Component
口 Abstractmodule(来自 org. Elasticsearch common inject包)的扩展类,它将告知
Elasticsearch为 Custom AnalyzerIndices Component类生成一个单例。我们称其为
Custom AnalyzerModule
口最后是 AbstractPlugin(来自 org. Elasticsearch plugins包)的扩展类,我们称之为
CustomAnalyzerPlugin296心深入理解 Elasticsearch
接下来让我们看看实现代码。
1.实现 Token Filter
本插件最有趣的部分是整个分析工作都是在 Lucene层面完成的,我们所要做的仅仅
是编写一个org. apache lucene. analysis. Token filter扩展,我们称之为 Custom filter。为了
实现这个扩展,我们需要初始化基类并覆盖( override) increment Token方法。我们希望在
Custom filter类中实现反转 token内容的逻辑。整个 Custom filter类的实现代码如下:
public class CustomFilter extends TokenFilter
private final CharTermAttribute termAttr
addAttribute( CharTermAttribute. class)
protected CustomFilter(TokenStream input)
super(input)i
@Override
public boolean incrementToken()throws IOException i
if (input increment Token()1
char [ originalTerm= termAttr buffer(
if (originalTerm length >0)(
StringBuilder builder new StringBuilder(new
String(originalTerm)trim()). reverse()
termAttr. setEmpty ()i
termAttr. append (builder. tostring ())i
return truei
y else i
return false i
在这段代码中我们发现如下语句
private final CharTermAttribute termAttr
addAttribute( CharTermAttribute. class)
该语句允许我们检索出目前正在处理的 token的文本内容。如果要访问 token的其他信
息,则需要使用类似的其他属性( attribute),可以通过查看 Lucene代码中 org. apache lucene
util.attrIbutetA(http://lucene.apache.org/core/410o/core/org/apache/lucene/utiL/attribute.html)
的实现类来弄清到底有哪些可用属性类。你现在需要了解的是,使用 addAttribute静态方法
可以绑定不同的属性类,以供我们在 token处理阶段使用。
接下来是构造函数,它的实现很简单,仅仅用于初始化基类,因此我们略去不谈。
最后需要注意的是 incrementTokenO方法。如果 token流中还有未处理的 token,该方
法将返回true,否则返回 false。我们首先要做的就是调用 Input对象的 incrementToken(方第9章开发 Elasticsearch插件心297
法检查 token流中是否还有待处理的 tokeno input对象是存储于基类中的一个 Token stream
类型的实例。然后我们调用之前绑定好的属性的 buffer方法获取trm文本。如果term
拥有文本(文本字符串长度大于0),则使用 String Buffer对象来反转文本内容,然后清除
tem缓冲区中的内容(通过调用属性的 setEmpty0方法),再把反转后的文本追加到已经清
空的term缓冲区中(使用属性的 append方法)。最后我们返回true,因为反转后的 token
已经准备好接受进一步处理(在词项过滤器级别,我们不知道 token是否还会被进一步处
理,因此需要确保返回正确的值,以防万一)。
2.实现 Token Filter factory
Token FilterFactory是这个插件中最简单的类之一。我们需要做的仅仅是创建一个
AbstractToken FilterFactory类(来自 org. Elasticsearch index analysis包)的扩展类,重写一
个 create方法,并在该方法中创建我们自己的词项过滤器。代码如下:
public class CustomFilterFactory extends
AbstractTokenFilterFactory i
@Inject
public CustomFilterFactory(Index index, @IndexSettings Settings
indexSettings, @Assisted string name, @Assisted Settings settings
super(index, indexSettings, name, settings)i
@Override
public Tokenstream create(TokenStream tokenstream
return new CustomFilter( tokenstream
可见,整个类非常简单。我们首先编写了构造函数,它将用于对基类进行初始化。然
后,我们添加了 create方法,在该方法中使用由参数传入的 Token stream对象创建了我们
自定义的 CustomFilter类实例。
在继续之前,我们还想提及两个事情:@ Index Setings和@ Assisted注解。第一个会把
索引配置信息以 Setings对象的方式注入到构造函数中,当然这个过程是自动的。而被@
Assisted注解标记的参数则会通过工厂方法的参数来注入。
3.实现 analyzer indices component
我们希望本例的实现越简单越好,因此决定不在分析器的实现部分增加复杂性。为
了实现一个分析器,我们需要扩展 Lucene的 Analyzer抽象类(来自 org. apache lucene
analysis包)。 CustomAnalyzer类的完整代码如下:
public class CustomAnalyzer extends Analyzer
public CustomAnalyzer()I298心深入理解 Elasticsearch
@Override
protected TokenstreamComponents createComponents(String field
Reader reader)
final Tokenizer src new Whitespace Tokenizer(reader);
return new TokenstreamComponents(src, new CustomFilter(src))
潜如果你想要看看更复杂的分析器实现,请查看 Apache Lucene、 Apache Solr和
Elasticsearch的源代码。
我们还需要实现 create Component方法。该方法根据指定的字段(方法的第1个参数,
String类型)和数据(方法的第2个参数, Reader类型)返回一个 Token Stream Components
对象(来自 org.apache lucene. analysis包)。在方法中,我们使用
Lucene
的 Whitespace-
Tokenizer类创建了一个 Tokenizer实例,该实例将按空格切分输入数据。随后我们创建
了一个 Token Stream Components对象,传人 Tokenizer对象和 Custom filter对象,这样
Custom Analyzer就可以使用 CustomEilter类了。
4.实现 AnalyzerProvider
nalyzerProvider是本插件中除词项过滤器的工厂类之外的另一个 provider实现。在
这里我们需要扩展 AbstractIndex Analyzer Provider类(来自 org. Elasticsearch index analysis
包),以便于 Elasticsearch创建我们自定义的分析器。实现代码非常简单,我们只需要实现
一个用于返回分析器的get方法即可。 Custom Analyzer Provider的代码如下
public class CustomAnalyzerProvider extends
bstractIndexAnalyzerProvider< CustomAnalyzer>
private final CustomAnalyzer analyzer
@Inject
public CustomAnalyzerprovider(Index index, @IndexSettings
Settings indexSettings, Environment env, @Assisted string name
@Assisted Settings settings)(
super(index, indexSettings, name, settings);
analyzer new CustomAnalyzer()
@Override
public CustomAnalyzer get()
return this analyzer
我们首先实现了构造函数,用于初始化基类。然后创建了自定义分析器的单例,供
Elasticsearch使用。请注意,该分析器类依赖于 Lucene的 Version类。因为我们自定义的这
个分析器是线程安全的,一个单例可被反复重用,所以请不必担心。在get方法中,我们直第9章开发 Elasticsearch插件299
接返回已经创建好的分析器。
5实现 analysis binder
binder是我们自定义插件的一部分,用于告知 Elasticsearch分析器和词项过滤器的可用名称。
Custom Analysis Binder Processor扩展自 org. Elasticsearch index analysis包中的 AnalysisModule
Analysis BinderProcessor)。我们覆写了两个方法。一个是 processAnalyzers,用于注册分析器,
另一个是 processToken Filters,用于注册词项过滤器。如果只有 Analyzer或者只有词项过滤器
则只需要覆写其中的一个方法。 CustomAnalysis BinderProcessor类的代码如下
public class CustomAnalysisBinderprocessor extends
AnalysisModule. AnalysisBinderProcessor
@Override
public void processAnalyzers (AnalyzersBindings
analyzersBindings)
analyzersBindings. processAnalyzer ("mastering analyzer i
CustomAnalyzerProvider class)i
@Override
public void processTokenFilters(TokenFiltersBindings
tokenFiltersBindings)
tokenFiltersBindings. processTokenFilter("mastering filter ",
CustomFilterFactory class)i
代码中第1个方法是 processAnalyzerso。它的输入是一个 Analysis Binding对象。该对
象的 processAnalyzer方法可以把我们自定义的分析器注册到指定名称下。注册时,需要传
递一个可用名称和 AbstractIndex Analyzer Provider的实现类。该实现类负责创建分析器,在
本例中,它是 Custom Analyzer Provider
代码中第2个方法是 proces Token Filters。它的输入是一个 Token Filters Bindings类对
象。该对象的 process TokenFilter方法可以把我们自定义的词项过滤器注册到指定名称下。
注册时,需要传递一个可用名称和词项过滤器工厂的实现类,由该实现类来创建词项过滤
器。在本例中,这个实现类是 Custom FilterFactory。
6.实现 analyzer indices component
analyzer indices component是一个节点级的组件。它允许重用分析器和词项过滤
器。不过,在这里我们只想在索引级别重用我们的 analyzer,而不是在全局范围内(之所
以要这样做只是为了演示)。我们需要扩展 org. Elasticsearch common component包中的
Abstractcomponent类,子类命名为 CustomAnalyzerIndices Component。实际上,在子类中
只需要实现一个构造函数。全部代码如下:300◆深入理解 Elasticsearch
public class CustomAnalyzerIndicesComponent extends
Abstractcomponent
@In]ect
public CustomAnalyzerIndices Component(Settings settings,
IndicesAnalysisservice indicesAnalysisService)
super(settings)i
indicesAnalysisservice. analyzerproviderFactories(). put(
mastering analyzer "
new PreBuiltAnalyzerProviderFactory("mastering analyzer
AnalyzerScope. INDICES, new CustomAnalyzer()))i
indicesAnalysisService. tokenFilterFactories (). put("mastering filt
new PreBuiltTokenFilterFactory Factory(new
TokenFilterFactory()I
@Override
public String name()I
return mastering filter I
@Override
public TokenStream create(Tokenstream tokenstream)(
return new CustomFilter( tokenstream
))
首先,我们传递给父类必要的参数用于父类的初始化。然后我们使用如下代码片段创
建了一个 Custom Analyzer类的分析器:
indicesAnalysisService. analyzerProviderFactories().put
l mastering analyzer,
new PreBuiltAnalyzerproviderFactory ("mastering analyzer
AnalyzerScope INDI CES, new CustomAnalyzer()))i
从代码中可见,我们使用 indices Analysis Service对象的 analyzer Provider Factories获
取了一个 Pre BuiltAnalyzer ProviderFactory类(对象作为键值,对象名称作为键名)的
Map。我们向Map中放入一个新建的 PreBuiltAnalyzer ProviderFactory对象,命名为
mastering analyzer而为了创建这个 PreBuiltAnalyzer ProviderFactory对象,我们需要使
用 CustomAnalyzer和枚举值 AnalyzerScope INDICES(来自 org. Elasticsearch index. analysis
包)。 Analyzer Scope枚举变量的其他值还有 GLOBAL和 INDEX。如果你想要在全局范围
内共享分析器,可以使用 Analyzer Scope. GLOBAL。而如果想要为每个索引单独生成分析
器,则需要使用 Analyzer Scope. INDEX。
我们使用相似的方法添加了自定义的词项过滤器。这里使用的是 indices Analysis Service
对象的 token Filter Factories方法,该方法返回一个 PreBuiltToken Filter Factory Factory对象
的Map,对象名称作为Map的键名,对象本身作为键值。我们向Map中放入了一个名为第9章开发 Elasticsearch插件301
mastering filter的 Token FilterFactory对象。
7.实现 analyzer module
analyzer module非常简单。它扩展自 org. Elasticsearch common inject包中的 Abstract
Module类。它的职责是告知 Elasticsearch,我们的 Custom AnalyzerIndices Component类将作
为单例来使用(对于这个类来说,使用单例就足够了)。它的代码如下:
public class CustomAnalyzerModule extends AbstractModule
oVerride
protected void configure()
bind(CustomAnalyzerIndices Component class). asEagersingleton ()i
从代码中可见,我们实现了一个简单的 configure方法,该方法把 Custom- Analyzer-
Indices Component类绑定为一个单例。
8.实现 analyzer plugin
analyzer plugin是一个具体的 Elasticsearch插件实现。它的职责是提供 Elasticsearch关
于插件自身的一些信息。它需要扩展 org. Elasticsearch, plugins包中的 AbstractPlugin类,并
至少实现name和 description方法。在这里,我们还实现了另外两个方法,用来注册我们的
自定义分析插件。代码如下:
public class CustomAnalyzerplugin extends Abstractplugin
@Override
public Collection<Class<? extends Module>> modules()
return Immutablelist. <Class<? extends
Module>>of( CustomAnalyzerModule class)i
public void onModule(AnalysisModule module)
module. addProcessor (new CustomAnalysisBinderprocessor())i
@Override
public String name()
return "Analyzerplugin"i
@Override
public String description()
return "Custom analyzer plugin"i
name和 description方法的职责显而易见,一个用来返回插件名称,另一个用来返回插
件的描述信息。 on module方法负责把 Custom Analysis BinderProcessor对象添加到由外部传302◆深入理解 Elasticsearch
人的 AnalysisModule对象中。
最后一个方法是 modules,我们目前还未接触过:
public Collection< Class<? extends Module>> modules ()
return Immutablelist <Class<? extends
Module>>of( CustomAnalyzerModule class)i
我们在这里覆写了父类的对应方法,用于返回一个自定义插件所注册模块的集合。本
例中,我们注册了一个单独的模块类 Custom Analyzer Module,并返回一个拥有唯一入口的
列表。
9.把自定义分析器告知 Elasticsearch
旦准备好所有代码,我们还需要做一件事:想办法让 Elasticsearch知道,到底哪个类
注册了我们的自定义插件 Custom AnalyzerPlugin。为此,我们在src/main/ resources目录下
创建一个 es-plugin, properties文件。文件内容如下:
plugin=pl solr analyzer. CustomAnalyzerplugin
我们在此只需要指定 plugin参数。参数值为用于注册我们自定义插件的类(扩展自
AbstractPlugin类)的名称。这个文件将在工程构建时被打包放进jar压缩包中,然后在插件
加载过程中被 Elasticsearch使用。
94.2测试自定义分析插件
现在我们需要测试我们的插件,确保一切工作正常。为此,需要先构建好这个插件,
然后把它安装到集群中的所有节点上,最后再使用 Admin Indices Analyze API来验证它的
运行情况。很好,着手去干吧!
1.构建自定义分析插件
首先开始最简单的部分:构建插件。为此,执行如下命令:
mvn compile package
该命令让 Maven编译并打包相关代码。命令执行完毕后,我们可以在 target/release目
录下找到打包好的文件(假定你使用的项目结构和我们在本章开始时描述的一样)。
2.安装自定义插件
为了安装插件,我们需要如之前那样再次使用 plugin命令。假定我们已经把插件包存
放在 /home/install/es/plugins目录下。执行如下命令来安装插件(我们在 Elasticsearch主目
录下运行本命令)
bin/plugin -install analyzer --url
file: /home/install/es/plugins/elasticsearch-analyzer-141.zip第9章开发 Elasticsearch插件°303
我们需要在集群的所有节点上安装该插件,因为我们需要 Elasticsearch能够在所有节
点上找到我们自定义的分析器和过滤器,不管分析工作发生在哪个节点上。如果不这么做,
肯定会遇到各种问题。
害如果想要了解更多关于 Elasticsearch插件安装的知识,请参考前书《 Elasticsearch
Server, Second edition》,或者阅读 Elasticsearch的官方文档。
插件安装成功后,需要重启所有执行了安装操作的 Elasticsearch节点。重启后,应该
可以在日志中发现如下信息:
[2014-12-0322:39:11,231][INFo][ plugins
[Tattletale] loaded [AnalyzerPlugin], sites [
这条信息表明,名为 AnalyzerPlugin的插件已经成功地被 Elasticsearch加载。
3.检查自定义插件工作情况
最后我们需要检查一下自定义插件的工作情况是否和预期一样。首先我们创建一个名
为test的空索引(实际上索引名称无所谓)。执行如下代码:
curl -xPOST localhost: 9200/analyzetest/'
在此之后,我们使用 Admin Indices Analyze API(htp:// /ww. Elasticsearch org/ guider
reference/ api/admin- - indices- analyze/)查看我们的分析器是如何工作的。可执行如下命令:
curl - localhost: 9200/analyzetest/ analyze? analyzer=mastering
analyzer&pretty -d 'mastering elasticsearch'
在响应中,我们应该可以看到两个被反转的 token: mastering, gniretsam和 hcraescitsale
( Elasticsearch的反转表示)。 Elasticsearch的响应大致如下:
u tokens
n token":"gniretsam",
nstart offset: 0
Wend offset": 9
"type ":word",
"position":1
token": hcraescitsale
u start offset: 10
"end offset": 23,
"type : "word"
"position ":2
可见,最终结果跟我们的期望一模一样。因此,看起来自定义插件工作得与预期的一样好。304◆深入理解 Elasticsearch
95小结
在本章中,我们聚焦在开发 Elasticsearch的自定义插件上。我们学习了如何建立合适
的 Maven项目来自动化构建 Elasticsearch插件。我们了解到如何开发一个自定义的REST
行为插件,最后,我们开发了一个包括自定义过滤器和分析器的插件,进一步扩展了
Elasticsearch的分析能力。
我们已经到了本书末尾。有鉴于此,我们想要写一段简短的总结,向那些坚持阅读到
最后的勇敢读者表达一下我们的心声。在出版《 Elasticsearch Server, Second edition》之
后我们决定写作本书,我们觉得有太多的主题没有被覆盖,我们希望在本书中讨论它们。
我们介绍了 Apache Lucene和 Elasticsearch,并从 Lucene索引和 Elasticsearch两个角度探
讨了查询和数据处理。我们希望此时你已经明白了 Lucene的工作原理以及 Elasticsearch如
何使用 Lucene。希望你会觉得学习这个优秀的搜索引擎的旅程是值得的。我们讨论了当出
现热点时会有所帮助的主题,例如IO瓶颈、热点线程API,以及如何缩短查询时间。我们
还讨论了诸如根据应用场景来选择恰当的查询以及扩展 Elasticsearch。
最后,我们用两章探讨了Java开发:如何使用自定义插件来扩展 Elasticsearch的功能。
在本书的上一版中,我们还简单地描述了 Java API,但是我们认为这没有意义。AP值得专
门写一本关于其使用的书籍,仅仅展示一些与之有关的东西是不够的。我们希望,你已经
可以开发自己的插件,尽管我们并没有把所有可能的知识点都列出来。我们希望你能够自
己找到所需的信息
感谢你阅读本书。希望你能够喜欢它。希望它给你提供了一些你正在苦苦寻找的知识,
并能够为你所用,不管你是在专业工作中使用 Elasticsearch或者仅仅出于兴趣爱好而使用它。
最后,请时不时访问一下htp:/Elasticsearchserverbook.com/。除了我们写的日常博客
我们还会发布一些没有加入本书或被删掉的内容片段,因为我们不想让本书变得无所不包。Mastering Elasticsearch
Second Edition
Elasticsearch在美团有着广泛的应用,该搜索引擎框架功能强大,支持分布式,实时索引、搜
索,插件丰富,使用简单便捷,是检索、广告计算、海量数据分析等领域的一把利器。本书第2版保
持了一贯的品质,内容深入浅出,示例丰富,是大家进行 Elasticsearch实践的必备资料。
陈华良博士美团广告技术负责人
很高兴看到本书第2版面市, Elasticsearch版本更新很快,新特性不断出现,新增内容很好地折
射了 Elasticsearch的变化。本书既有对底层技术的深入剖析,又有生动翔实的示例,能帮助读者快
速提升在该领域的技术水平。
高剑林腾讯(架构平台部)资深技术专家
Elasticsearch是目前市场占有率最大的开源搜索引擎之一,国美线上搜索服务使用了该框架。
该框架支持分布式,实时数据处理,容灾能力强,能灵活嵌λ排序算法。本书第2版适时增加了很多
新特性,同时又保留了第1版的精华内容,理论性与实践性结合得很好。
宋洋博士国美大数据研究院副总监
除了用于搜索, Elasticsearch也是日志存储、离线数据分析挖掘的利器。本书深入浅出,案例
丰富,在信息检索模型、准实时搜索、分布式架构、系统优化等诸多方面都有精彩的论述。
——李伟博士微软(bing)数据挖掘组高级工程师
尽管京东搜索引擎是自主研发的,但其架构原理与 Elasticsearch有很多相似之处,如分布式、
实时索引与检索、容灾处理、 Ranking算法插件化等。本书对 Elasticsearch的系统架构、底层技术
原理有深入的阐述,非常适合中高级搜索引擎研发人员阅读。
李洁京东搜索与大数据部高级架构师
上架指导:计算机程序设计
ISBN978-7-111-56825-4
PACKT
PUBLISHING
投稿热线:(010)88379604
华章网站:www.hzbook.co
97871111568254
客服热线:(010)8837942688361066
网上购书:www.china-pub.con
购书热线:(010)683262948837964968995259数字阅读:www.hzmedia.com.cn
定价:79.00元