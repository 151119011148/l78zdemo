畅销书全新升级,第1版广获好岬ρ深Mφ@口家損獨!全球知名 My SQL数据库服务
提供商 Personas公司CTo作序推荐,国内多位数据库专家联袂推荐
π基于MysL5.6,结合源代码,从存储引擎内核角度对 nncDB的整体架构、核心实现和工
华章科技作机制进行深入剖析
据库技术丛书
Inside MySQL: InnoDB Storage Engine, Second Edition
MYSQL技术内幕
InnoDB存储引擎
第2版
姜承尧◎著
Q
机械工业出版社
China machine presshttpblegc
数据库技术丛书
5
部拼没
Inside MySQL: InnoDB Storage Engine, Second Edition
MySQL技术内幕
noDE存储引擎
第2版
姜承尧◎著
机械工业出版社
China machine prehttp://blog.csdn.net/jiongyi1
5.
图书在版编目(CP)数据
部拼爱要
MSQL技术内幕:mD情装/姜承尧著2版,一北京,机城工业出版:,2036垂
ISBN978-7-ll!-422068
L.M…,Ⅱ.差…I.关系数据库系统IVTP311l38
中国版本图书馆CP数据核字(2013)第079001号
版权所有·侵权必究
封底无防伪标均为盗版
本书法律顾问北京市展达律师事务所
本书由国内资深 MySQL专家亲自执笔,国内外多位数据库专家联袂推荐。作为国内唯一一本关于
InnoDB的专著,本书的第1版广受好评,第2版不仅针对最新的 MySQL56对相关内容进行了全面的补
充,还根据广大读者的反馈意见对第1版中存在的不足进行了完善,全书大约重写了50%的内容。本书
从源代码的角度深度解析了 InnoDB的体系结构、实现原理、工作机制,并给出了大量最佳实践,能帮助
你系统而深入地掌握 InnoDB,更重要的是,它能为你设计管理高性能、高可用的数据库系统提供绝佳的
指导。
全书一共10章,首先宏观地介绍了 MySQL的体系结构和各种常见的存储引擎以及它们之间的比较;
接着以 Inno DB的内部实现为切入点,逐一详细讲解了 InnoDB存储引擎内部的各个功能模块的实现原理,
包括nD存储引擎的体系结构、内存中的数据结构、基于 InnoDB存储引擎的表和页的物理存储、索
引与算法、文件、锁、事务、备份与恢复,以及 InnoDB的性能调优等重要的知识:最后对 InnodB存储
引擎源代码的編译和调试做了介绍,对大家阅读和理解 InnoDB的源代码有重要的指导意义。
本书适合所有希望构建和管理高性能、高可用性的 MySQL数据库系统的开发者和DBA阅读。
机械工业岀版社(北京市西城区百万庄大街22号邮政编码10007
贲任编辑:荬影
北京市荣盛彩色印刷有限公司印刷
2013年5月第2版第1次印刷
86mmx240mm·27.25印张
标准书号:ISBN978-7-1142206-8
定价:7900元
凡购本书,如有缺页、倒页、脱页,由本社发行龆调換
客服热线:(010)8837899188361066
投稿线:(0l0)88379604
购书热线:(010)683262948837964968995259读者信葙:hzj@ hzbnok coimhttp://blog.csdn.net/jiongyi1
BI
部拼
推荐序
It's fair to say that MySqL is the most popular open source database. It has a very large
installed base and number of users. Let's see what are the reasons MySQL is so popular, where
it stands currently, and maybe touch on some of its future(although predicting the future is rarely
successful)
Looking at the customer area of MySQL, which includes Facebook, Flickr, Adobe (in
Creative Suite 3), Drupal, Digg, LinkedIn, Wikipedia, eBay, You Tube, Google AdSense(source
http://mysql.com/customers/andpublicresources),it'sobviousthatMysqliseverywhere
When you log in to your popular forum (powered by Bulleting or blog(powered by WordPress),
most likely it has MySQL as its backend database. Traditionally, two MySQL's characteristics
simplicity of use and performance, were what allowed it to gain such popularity. In addition to that
availability on a very wide range of platforms(including Windows)and built-in replication, which
pravides an easy scale-out solution for read-only clients, gave more user attractions and production
deployments. There is simple evidence of MySQL's simplicity: In 15 minutes or less, you really
can get installed, have a working database, and start running queries and store data. From its early
stages MySQL had a good interface to most popular languages for Web development-PHP and
Perl. and also jaya and odBc connectors
There are two best known storage engines in MySQL: MyIsAM and InnoDB(I don't cover
NDB cluster here; it's a totally different story ). MyISAM comes as the default storage engine
and historically it is the oldest, but InnoDB is ACID compliant and provides transactions, row
level locking, MVCC, automatic recovery and data corruption detection. This makes it the
storage engine you want to choose for your application. Also, there is the third-party transaction
storage engine PBXT, with characteristics similar to InnoDB which is included in the MariaDB
distribution
MySQL's simplicity has its own drawback, Just as it is very easy to start working with it, it is
very easy to start getting into trouble with it. As soon as your website or forum gets popular,you
may figure out that the database is a bottleneck, and that you need special skills and tools to fix ithttp://blog.csdn.net/jiongyi1
5.
部拼吾
The author of this book is a My SQL expert, especially in InnoDB storage engine B. Hence
highly recommend this book to new users of InnoDB as well as uers who already have well-tuned
InnoDB-based applications but need to get internal out of them
Vadim Tkachenko
全球知名 MySQL数据库服务提供商 Percona公司CTO
知名 MySQL数据库博客 MySQLPerformanccBlog. com作者
《高性能 MySQL(第2版)》作者之http://blog.csdn.net/jiongyi1
6I
部拼吾
你
前言
为什么要写这本书
过去这些年我一直在和各种不同的数据库打交道,见证了 MySQL从一个小型的关系型
数据库发展为各大企业的核心数据库系统的过程,并且叁与了一些大大小小的项目的开发工
作,成功地帮助开发人员构建了可靠的、健壮的应用程序。在这个过程中积累了一些经验,
正是这些不断累积的经验赋予了我灵感,于是有了这本书。这本书实际上反映了这些年来我
儆了哪些事情,其中汇集了很多同行每天可能都会遇到的一些问题,并给出了解决方案。
MysαL数据库独有的插件式存储引擎架构使其和其他任何数据库都不同。不同的存储
引擎有着完全不同的功能,而 InnodB存储引擎的存在使得 MySQL跃入了企业级数据库领
域。本书完整地讲解了 InnoDB存储引擎中最重要的一些内容,即 InnoDB的体系结构和工
作原理,并结合 InnoDB的源代码讲解了它的内部实现机制。
本书不仅讲述了 InnoDB存储引擎的诸多功能和特性,还阐述了如何正确地使用这些功
能和特性,更重要的是,还尝试了教我们如何 Think Different。 Think Different是20世纪90
年代苹果公司在其旷日持久的宣传活动中提出的一个口号,借此来重振公司的品牌,更重要
的是,这个口号改变了人们对技术在日常生活中的作用的看法。需要注意的是,苹果的口号
不是 Think Differently,是 Think Different, Different在这里做名词,意味该思考些什么。
很多DBA和开发人员都相信某些“神话”,然而这些“神话”往往都是错误的。无论
计算机技术发展的速度变得多快,数据库的使用变得多么简单,任何时侯Why都比What重
要。只有真正理解了内部实现原理、体系结构,才能更好地去使用。这正是人类正确思考问
题的原则。因此,对于当前出现的技术,尽管学习其应用很重要,但更重要的是,应当正确
地理解和使用这些技术。
关于本书,我的头脑里有很多个目标,但最重要的是想告诉大家如下几个简单的观点:
口不要相信任何的“神话”,学会自己思考:
口不要墨守成规,大部分人都知道的事情可能是借误的
口不要相信网上的传言,去测试,根据自己的实践做出决定;
口花时间充分地思考,敢于提出质疑。http://blog.csdn.net/jiongyi1
6I
部拼没
当前有关 MySQL的书籍大部分都集中在教读者如何使用 MySQL,例如S语句的使
用、复制的搭建的、数据的切分等。没错,这对快速掌握和使用 MySQL数据库非常有好处,
但是真正的数据库工作者需要了解的不仅仅是应用,更多的是内部的具体实现
MySQL数据库独有的插件式存储引擎使得想要在一本书内完整地讲解各个存储引擎变
得十分困难,有的书可能偏重对 MyISAM的介绍,有的可能偏重对 InnoDB存储引擎的介
绍。对于初级的DBA来说,这可能会使他们的理解变得更困难。对于大多数 MySQL DBA
和开发人员来说,他们往往更希望了解作为 MySQL企业级数据库应用的第一存储引擎的
InnoDB,我想在本书中,他们完全可以找到他们希望了解的内容。
再强调一遍,任何时候Why都比What重要,本书从源代码的角度对 InnoDB的存储引
擎的整个体系架构的各个组成部分进行了系统的分析和讲解,剖析了 InnoDB存储引擎的核
心实现和工作机制,相信这在其他书中是很难找到的。
第1版与第2版的区别
本书是第2版,在写作中吸收了读者对上一版内容的许多意见和建议,同时对于最新
MySQL56中许多关于 InnoDe存储引擎的部分进行了详细的解析与介绍。希望通过这些改
进,给读者一个从应用到设计再到实现的完整理解,弥补上一版中深度有余,内容层次不够
丰富、分析手法单一等诸多不足。
较第1版而言,第2版的改动非常大,基本上重写了50%的内容。其主要体现在以下
几个方面,希望读者能够在阅读中体会到。
口本书增加了对最新 MySQL56中的 InnoDB存储引擎特性的介绍。 MySQL56版本是
有史以来最大的一次更新, InnoDB存储引擎更是添加了许多功能,如多线程清理线
程、全文索引、在线索引添加、独立回滚段、非递归死锁检测、新的刷新算法、新的
元数据表等。读者通过本书可以知道如何使用这些特性、新特性存在的局限性,并明
白新功能与老版本 InnoDB存储引擎之间实现的区别,从而在实际应用中充分利用这
些特性。
口根据读者的要求对于 InnoDB存储引擎的redo日志和undo日志进行了详细的分析。
读者应该能更好地理解 InnoDB存储引擎事务的实现。在undo日志分析中,通过
InnoSQL自带的元数据表,用户终于可对undo日志进行统计和分析,极大提高了
DBA对于 InnODB存储引擎内部的认知。http:/blog.csdnnet/jiongyi11
51.6
部密
口对第6章进行大幅度的重写,读者可以更好地理解InDB存储引擎特有的xe
locking箅法,并且通过分析锁的实现来了解死锁可能产生的情况,以及 InnoDB存储
引擎内部是如何来避免死锁问题的产生的。
口根据读者的反馈,对 InnoDB存储引擎的 insert buffer模块实现进行了更为详细的介
绍,读者可以了解其使用方法以及共内部的实现原理。此外还增加了对 insert buffer
的升级版本功能— change buffer的介绍
读者对象
本书不是一本面向应用的数据库类书籍,也不是一本参考手册,更不会教你如何在
MySQL中使用SQL语句。本书面向那些使用 MySQL InnoDB存储引鼙作为数据库后端开发
应用程序的开发者和有一定经验的 MySQL DBA。书中的大部分例子都是用SOL语句来展示
关键特性的,如果想通过本书来了解如何启动 MySQL、如何配置 Replication环境,可能并
不能如愿。不过,在本书中,你将知道 InnoDB存储引擎是如何工作的,它的关键特性的功
能和作用是什么,以及如何正确配置和使用这些特性。
如果你想更好地使用 InnoDB存储引擎,如果你想让你的数据库应用获得更好的性能,
就请阅读本书。从某种程度上讲,技术经理或总监也要非常了解数据库,要知道数据库对于
企业的重要性。如果技术经理或总监想安排员工参加 MySQL数据库技术方面的培训,完全
可以利用本书来“充电”,相信你一定不会失望的
要想更好地学习本书的内容,要求具备以下条件:
口掌握SQL。
口掌握基本的 MYSQL操作
口接触过一些高级语言,如C、C+、 Python或Java
口对一些基本算法有所了解,因为本书会分析 InnoDB存储引擎的部分源代码,如果你
能看懂这些算法,这会对你的理解非常有帮助。
如何阅读本书
本书一共有10章,每一章都像一本“迷你书”,可以单独成册,也就说你完全可以从书
中任何一章开始阅读。例如,要了解第10章中的 InnoDB源代码编译和调试的知识,就不必
先去阅读第3章有关文件的知识。当然,如果你不太确定自己是否已经对本书所涉及的内容http://blog.csdn.net/jiongyi1
BI
部拼爱要
完全掌握了,建议你系统性地阅读本书
本书不是一本入门书籍,不会一步步引导你去如何操作。倘若你尚不了解 InnoDB存
储引擎,本书对你来说可能就显得沉重一些,建议你先查阅官方的API文档,大致掌握
nodE的基础知识,然后再来学习本书,相信你会领略到不同的风景。
为了便于大家阅读,本书在提供源代码下载(下载地址:www.hzbookcom)的同时也将
源代码附在了书中,因此占去了一些篇幅,还请大家理解。
勘误和支持
由于作者对 InnoDB存储引擎的认知水平有限,再加上写作时可能存在疏漏,书中还存
在许多需要改进的地方。在此,欢迎读者朋友们指出书中存在的问题,并提出指导性意见,
不甚感谢。如果大家有任何与本书相关的内容需要与我探讨,请发邮件到 jiangchengyao@
gmail.con,或者通过新浪微博 @insidemysql与我联系,我会及时给予回复。最后,衷心地
希望本书能给大家带来帮助,并祝大家阅读愉快!
致谢
在编写本书的过程中,我得到了很多朋友的热心帮助。首先要感谢 Pecora公司的CEO
Peter Zaitsev和 CTO Vadim tkachenko,通过和他们的不断交流,使我对 InnoDB存储引擎有
了更进一步的了解,同时知道了怎样才能正确地将 InnoDB存储引擎的补丁应用到生产环境。
其次,要感谢网易公司的各位同事们,能在才华橫溢、充满创意的团队屮工作我感到非
常荣幸和兴奋。也因为在这个开放的工作环境中,我可以不断进行研究和创新。
此外,我还要感谢我的母亲,写本书不是一件容易的事,特别是这本书还想传达一些思
想,在这个过程中我遇到了很多的困难,感谢她在这个过程中给予我的支持和鼓励。
最后,一份特别的感谢要送给本书的策划编辑杨福川和姜影,他们使得本书变得生动和
更具有灵魂。此外还要感谢出版社的其他歇默工作的同事们。
姜承尧http://blog.csdn.net/jiongyi1
5
部拼吾费
目录
推荐序
52 InnoDB I2x版本之前的
前言
Master thread
253 Innode12x版本的 Master thread…45
第1章 MySQL体系结构和存储引擎…
26 InnoDB关键特性
……45
1.1定义数据库和实例
26.1插人缓冲
………6
12 MYSQL体系结构
262两次写
53
1.3 MySQL存储引擎
t·mr??曹m
263自适应哈希索引
55
1.3.1 InnoDB存储引擎……
2.6.4异步Io
…57
132 MyISAM存储引擎
7
26.5刷新邻接页
…58
13.3NDB存储引擎
7
27启动、关闭与恢复
………58
134 Memory存储引擎
3.5 Archive存储引擎……
2.8小结
3.6 Federated存储引擎
第3章文件…
…62
.3.7 Maria存储引擎……
3.1参数文件
62
1.3.8其他存储引擎
什么是参数
63
14各存储引擎之间的比较
3.,2参数类型
1翻L1。mi“d
64
15连接 MySQL
133.2日志文件……
65
1.5.1TCPP…………………………3
3.2.1错误日志
……6
1.52命名管道和共享内存
5
3,2,2慢耷询日志
67
1.53UNX域套接字
5
323查询日志……
72
1.6小结
5
324二进制日志
…73
第2章 InnoDB存储引擎
7
33套接字文件
…83
21 InnodB存储引擎概述
…:17
22 InnoDB存储引擎的版本
83
8
34pid文件…………
23 InnODB体系架构…
9
35表结构定义文件
………84
23.1后台线程
9
3.6 InnoDB存储引擎文件……………84
232内存
22
36.1表空间文件
…85
24 Checkpoint技术
32
362重做日志文件
86
25 Master thread工作方式…………36
3.7小结…
90
25. I InnoDB1.0x版本之前的
第4章表
Master thread
36
4.1索引组织表http://blog.csdn.net/jiongyi1
5
X
部拼没
42 InnoDB逻辑存储结构……
…93
48.分区概述
4.2.1表空间
…………93
4.82分区类型……………55
42,2段
…………95
483子分区
…168
4.23区
95
484分区中的NULL值
………72
4.24页
0
485分区和性能
176
4.2.5行
l01
486在表和分区间交换数据
80
4.3 InnoDB行记录格式
l02
49小结……………………………………182
4.3.1 Compact行记录格式…
103第5章索引与算法
83
432 Redundant行记录格式
106
51 InnodB存储引擎索引概述………l83
433行溢出数据
10
52数据结构与算法
84
434 Compressed和 Dynamic行记录
521二分查找法…
…84
格式
777
522二又查找树和平衡二又树
l85
43.5CHAR的行结构存储
…117
53P+树…
l87
44 InnoDB数据页结构
……120
53.1B+树的插入操作
……l87
4.4.1 File header……………
…12
532B+树的删除操作……
……90
4.4.2 Page Header.
122
54B+树索引
………-19r
44.3 Infimum和 Supremum records…l23
54.1聚集索引
4;44+++++++m-ttm
92
4.4.4 User Records H Free Space
123
542辅助索引……
96
4.4.5 Page directory
24
543B+树索引的分裂
……200
446 File trailer………124
544B+树索引的管理
……202
447 InnoDe数据页结构示例分析……125
55 Cardinality值…
20
4.5 Named File formats机制
732
5.51什么是 Cardinality……………2l0
4.6约束
134
552 InnoDB存储引擎的 Cardinality
4.6.l数据完整性
134
统计……
212
462约束的创建和查找
35
56B+树索引的使用……………
…215
463约束和索引的区别
37
561不同应用中B+树索引的使用……2l5
4.64对错误数据的约束…137
562联合索引
215
46.5FNUM和SET约束…
139
563覆盖索引…
28
4.6.6触发器与约束
l39
564优化器选择不使用索引的情况……219
46.7外键约束…
142
565索引提示
…22
4.7视图-………………
44
566 Multi- Range Read优化
223
47.1视图的作用……
……1-+4
5.6.7 Index Condition Pushdown (ICP)
472物化视图…
147
优化……
…226
48分区表
…152
57哈希算法
227http:/blog.csdnnet/jiongyi11
5.C
XI
拼吾没
571哈希表………………………………228
71.1概述
85
572 InnoDB存储引擎中的哈希算法…229
712分类
287
573自适应哈希素引…
……230
7,2事务的实现
294
58全文检索…
23l
72,1redo-……………
nun r tt
294
5.81概述
23l
7.2.2undo…
305
5.82倒排索引
………………232
7.2.3 purge
317
583 InnoDB全文检索
……233
724 group commit………319
584全文检索
240
7.3事务控制语句
323
59小结
…….248
74隐式提交的SQL语句
328
第6章锁
24975对于事务操作的统计…
329
6.1什么是锁…
……249
75事务的隔离级别……
330
62lock与 latch…
250
77分布式事务…………m…
335
63 InnoDB存储引擎中的锁…………252
771 MySQL数据库分布式事务………335
6.31锁的类型
……252
772内部XA事务
…340
6.32一致性非锁定读
258
7.8不好的事务习惯
34l
633一致性锁定读
…26I
781在循环中提交
34l
6.34自增长与锁……………
…262
782使用自动提交………………
343
6.35外键和锁
…1264
783使用自动回滚
344
64锁的算法
2657.9长事务……………
347
641行锁的3种算法
265
70小结
349
642解决 Phantom problem
269第8章备份与恢复……
…350
6.5锁问题…………………………………27l
81备份与恢复概述……………………………350
651脏读
271
82冷备
352
652不可重复读
273
83逻辑备份
353
653丢失更新…
274
8.3.1 mysqldump.
……353
66阻塞
276
83.2 SELECTINTO OUTFILE…………360
6.7死锁
278
833逻辑备份的恢复
362
671死锁的概念
278
8.3. 4 LOAD DATA INFILE
362
672死锁概率…
…280
8.3.5 mysqlimport
364
673死锁的示例
……28184二进制日志备份与恢复
……366
68锁升级
……2838.5热备………………
要围中,着着
367
69小结
284
8.5.1 ibbackup
367
第7章事务
…285
8.5.2 XtraBackup
368
71认识事务
……285
853 Xtra Backup实现增量备份………370http://blog.csdn.net/jiongyi1
5
XII
部拼吾费
86快照备份
372
96不同的文件系统对数据库性能的影响:9
87复制…
…………376
97选择合适的基准测试工具
399
87.1复制的工作原理………………………376
971 sysbench……
399
872快照+复制的备份架构
380
97.2mysq1-pc…………
………405
88小结
……382
98小结…
4l0
第9章性能调优
383第10章 InnoDB存储引擎源代码的
91选择合适的CPU
383
编译和调试…
92内存的重要性…………
……384
10.1获取 InnoDB存储引擎源代码………”4ll
93硬盘对数据库性能的影响
387
10.2 InnoDB源代码结构
43
931传统机械硬盘
387
10.3 MySQL5.1版本编译和调试 InnoDB
932固态硬盘…………
387
源代码
415
94合理地设置RAID……
…389
103.1 Windows下的调试
……45
941RAID类型……
389
1032 Linux下的调试…………………4l8
942 RAID Write Back功能
392
104 cmake方式编译和调试 InnoDB存储
943RAID配置T具
394
引擎…
…423
9.5操作系统的选择………………
397
10.5小结
424http://blog.csdnnet/jiongyi1
&AGOn
部拼没
第1章 MySQL体系结构和存储引擎
MySQL被设计为一个可移植的数据库,几乎在当前所有系统上都能运行,如
Linux, Solaris、 FreeBSD、Mac和 Windows。尽管各平台在底层(如线程)实现方面都
各有不同,但是 MySQL基本上能保证在各平台上的物理体系结构的一致性。因此,用
户应该能很好地理解 MySQL数据库在所有这些平台上是如何运作的。
1.1定义数据库和实例
在数据库领域中有两个词很容易混淆,这就是“数据库”( database)和“实例”
( Instance)。作为常见的数据库术语,这两个词的定义如下。
口数据库:物理操作系统文件或其他形式文件类型的集合。在 MySQL数据库中,数据
库文件可以是fm、MYD、MYjd结尾的文件。当使用NDB引擎时,数据库的
文件可能不是操作系统上的文件,而是存放于内存之中的文件,但是定义仍然不变。
口实例: MySQL数据库由后台线程以及一个共享内存区组成。共享内存可以被运行
的后台线程所共享。需要牢记的是,数据库实例才是真正用于操作数据库文件的。
这两个词有时可以互换使用,不过两者的概念完全不同。在 MySQL数据库中,实
例与数据库的关通常系是一一对应的,即一个实例对应一个数据库,一个数据库对应
个实例。但是,在集群情况下可能存在一个数据库被多个数据实例使用的情况。
MySQL被设计为一个单进程多线程架构的数据库,这点与 SQL Server比较类似,
但与 Oracle多进程的架构有所不同( Oracle的 Windows版本也是单进程多线程架构的)。
这也就是说, MySQL数据库实例在系统上的表现就是一个进程。
在Liux操作系统中通过以下命令启动 MySQL数据库实例,并通过命令p观察
MySQL数据库启动后的进程情况:
Iroctexen-server bin]f,/mysyld safe&
roctaxen-server bin]# ps -ef i grep mysqldhttp://blog.csdn.net/jiongyi1
BI
2弟1* MySQL体系绐构和存储引
部拼没
root
34413258010:23pts/300:00:00/bin/sh,/mysq1 d safe
mysq135783441010:23pts/300:0c:00
垂
/usr/local/ mysql/libexec/mysqld --basedir=/usr/local/mysql
-datadir=/usr/local/mysql/var -user=mysql
-log-error=/usr/local/mysql/var/xen-servererr
-pic-file=/usr/local/mysql/var/xen-serverpid
socket=/tmp/mysql sack --port=3306
36163258010;27pts/3
00: 00:00 grep mysgld
注意进程号为3578的进程,该进程就是 MySQL实例。在上述例子中使用了
mysqld safe命令来启动数据库,当然启动 MySQL实例的方法还有很多,在各种平台下
的方式可能义会有所不同。在这里不一一赘述。
当启动实例时, MySQL数据库会去读取配置文件,根据配置文件的参数来启动数
据库实例。这与 Oracle的参数文件( spfile)相似,不同的是, Oracle中如果没有参数文
件,在启动实例时会提示找不到该参数文件,数据库启动失败。而在 MySQL数据库中,
可以没有配置文件,在这种情况下, MySQL会按照编泽时的默认参数设置启动实例。用
以下命令可以查看当MysαL数据库实例启动时,会在哪些位置查找配置文件。
[。。ten- server bin]# mysql-- help grep my cnf
order of preference, r y cnf, $MYSQL TCP PORT,
/etc/my enf /etc/mysql/my cnf /usr/local/mysql/etc/my cnf */,my,cnf
可以看到, MySQL数据库是按! etc/my.cnf→etc/ mysql/my.cnf→/ usr/loca/mysq
etc/ my cnf→~/ my cnf的顺序读取配置文件的。可能有读者会问;“如果几个配置文件
中都有同一个参数, MySQL数据厍以哪个配置文件为准?”答案很简单, MySQL数据
库会以读取到的最后一个配置文件中的参数为准。在 Linux环境下,配置文件一般放在
ete/ my cnf下。在 Windows平台下,配置文件的后缀名可能是,cnf,也可能是inis例
如在 Windows操作系统下运行 mysql-hep,可以找到如下类似内容:
Default options are read from the following files in the given order
C: Windows\my. ini C:\windows\my, cnf C:\my ini C: \my, cnf c:\Program Files\
MYSQL\M
\MY SQL Server 5.1\mycnf
配置文件中有一个参数 datadir,该参数指定了数据库所在的路径。在Liux操作系
统下默认 datadir为/usr/ ocal/mysql/data,用户可以修改该参数,当然也可以使用该路
径,不过该路径只是一个链接,具体如下http:/blog.csdnnet/jiongyi11
5I.A
1.2MSQL体乐结构令
拼吾
mysql>SHOW VARIABLES LIKe 'datadir!\G;
★★★★★★★★★*★肃★★安女★★★★★★★★★t1row青★青内★★★★★★★★★★★★★★★
Variable name: datadir
value: /usr/local/mysql/data/
1r。 w in set(o,005e:)1
⊥nset(0.C0sec)
mysql>system 1s-1h /usr/local/mysql/data
total 32K
drwxr-xr-x 2 root mysql 4.OK Aug 6 16: 23 bin
drwxr-xr-x 2 root mysql 4. OK Aug 6 15: 23 docs
drwxr-xr-x 3 root mysql 4, OK Aug 6 15: 04 include
drwxr-xr-x 3 root mysql 4.oK Aug 6 16: 04 lib
drwxr-xr-x 2 root mysql 4,OK Aug 6 16:23 libexec
drwxr-xr-x _0 root mysq_ 4.0K Aug 616:23 mysql-test
drwxr-xr-x 5 root mysql 4, OK Aug 6 16: 04 share
drw上--X5r。 ot mysc4.0KAug616:23sq1- bench
lrwxrwxrwx 1 root mysql 16 Aug 616: 05 data ->/opt/mysql data/
从上面可以看到,其实data目录是一个链接,该链接指向了/ opt/mysql data目录。
当然,用户必须保证/ opt/mysql data的用户和权限,使得只有mysq用户和组可以访问
(通常 MySQL数据库的权限为myql: mysql)
12 MySQL体系结构
由于工作的缘故,笔者的大部分时间需要与开发人员进行数据库方面的沟通,并对
他们进行培训。不论他们是DBA,还是开发人员,似乎都对 MySQL的体系结构了解得
不够透彻。很多人喜欢把 MySQL与他们以前使用的 SQL Server、 Oracle、DB2作比较。
因此笔者常常会听到这样的疑问:
口为什么 MySQL不支持全文索引?
口 MySQL速度快是因为它不支持事务吗?
口数据量大于1000万时 MySQL的性能会急剧下降吗?
对于 MySQL数据库的疑问有很多很多,在解释这些问题之前,笔者认为不管对于
使用哪种数据库的开发人员,了解数据库的体系结构都是最为重要的内容
在给出体系结构图之前,用户应该理解了前一节提出的两个概念:数据库和数据
库实例。很多人会把这两个概念混淆,即 MySQL是数据库, MySQL也是数据库实例http://blog.csdn.net/jiongyi1
5
4郭章 MySQL体系结构和存储引擎
这样来理解Orae和 Microsoft SQL Server.数据库可能是正确的,但是这会给以后理解
MySQL体系结构中的存储引擎带来问题。从概念上来说,数据库是文件的集合,是依
照某种数据模型组织起来并存放于二级存储器中的数据集合;数据库实例是程序,是位
于用户与操作系统之间的一层数据管理软件,用户对数据库数据的任何操作,包括数据
库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的,应用程
序只有通过数据库实例才能和数据库打交道。
如果这样讲解后读者还是不明白,那这里再换一种更为直白的方式来解释:数
据库是由一个个文件组成〔一般来说都是二进制的文件)的,要对这些文件执行诸如
SELECT、 INSERT、 UPDATE和 DELETE之类的数据库操作是不能通过简单的操作文
件来更改数据库的内容,需要通过数据库实例来完成对数据库的操作。所以,用户把
Oracle、 SQL Server、 MySQL简单地理解成数据库可能是有失偏颇的,虽然在实际使用
中并不会这么强调两者之间的区别。
好了,在给出上述这些复杂枯燥的定义后,现在可以来看看 MySQL数据库的体系
结构了,其结构如图1-1所示(摘自 MySQL官方手册)。
Connectors
Native C APl, JDBC, ODBC, NET, PHP, Perl, Python, Ruby, Cobol
MySQL Server
Management
Connection pool
Service
Authentication, Thead Reuse, Connection Limits, Check Memory, Caches ta
Utilit
SOL Interface
Parser
Optimizer
Cathes buffers
Backup
DML, DDL, Stored I Quary Translation
Access Paths
Globai and Engine
Rocowcry, Socurity Procedures views
Statistics
Specific Caches
Cluster
Triggers, etc
Buffers
administration
onfiguration,
Migration
Metadata
Pluggable Storage Engines
Memory, Index &e storage Management
MyIsAM InnoDB NDB Archive Federated Memory Merge Partner Community Custon
ale system
NTFS, ufs, ext2/3
NFS. SAN NAS
Binary, Erro; query and sle5、
Files logs
Redo, Undo, Data, Index
图1-1 MySQL体系结构http://blog.csdn.net/jiongyi1
45I.
1.3MSQL余引乎5争
部拼没
从图1-1可以发现, MySQL由以下几部分组成
口连接池组件
口管理服务和工具组件
口SQL接口组件
口查询分析器组件
口优化器组件
口缓冲( Cache)组件
口插件式存储引擎
口物理文件
从图1-1还可以发现, MySQL数据库区别于其他数据库的最重要的一个特点就是其
插件式的表存储引擎。 MySQL插件式的存储引擎架构提供了一系列标准的管理和服务支
持,这些标准与存储引擎本身无关,可能是每个数据库系统本身都必需的,如SQL分析
器和优化器等,而存储引擎是底层物理结构的实现,每个存储引擎开发者可以按照自己
的意愿来进行开发。
需要特别注意的是,存储引擎是基于表的,而不是数据库。此外,要牢记图1-1的
MySQL体系结构,它对于以后深人理解 MySQL数据库会有极大的帮助
1.3 My SQL存储引擎
通过12节大致了解了 MySQL数据库独有的插件式体系结构,并了解到存储引擎
是 MySQL区别于其他数据库的一个最重要特性。存储引擎的好处是,每个存储引擎都
有各自的特点,能够根据具体的应用建立不同存储引擎表。对于开发人员来说,存储引
擎对其是透明的,但了解各种存储引擎的区别对于开发人员来说也是有好处的。对于
DBA来说,他们应该深刻地认识到 MySQL数据库的核心在于存储引擎
由于MysαL数据库的开源特性,用户可以根据 MySQL预定义的存储引擎接口编
写自己的存储引擎。若用户对某一种存储引擎的性能或功能不满意,可以通过修改源
码来得到想要的特性,这就是开源带给我们的方便与力量。比如,eBay的工程师lgor
Chernyshev对MySQLMemory存储引擎的改进(http://code.googlecom/p/mysql-heap
dynamic-rows/)并应用于eBay的 Personalization Platform,类似的修改还有 Google和
Facebook等公司。笔者曾尝试过对noDB存储引擎的缓冲池进行扩展,为其添加了基http://blog.csdn.net/jiongyi1
BI
6第1幸MSQL体系结构和存储引擎
部拼没
于SSD的辅助缓冲池,通过利用SD的高随机读取性能来进一步提高数据库本身的性
能。当然, MySQL数据库自身提供的存储引擎已经足够满足绝大多数应用的需求。如果
用户有兴趣,完全可以开发自己的存储引擎,满足自己特定的需求。 MySQL官方手册的
第16章给出了编写自定义存储引擎的过程,不过这已超出了本书所涵盖的范围。
由于 MySQL数据库开源特性,存储引擎叮以分为 MySQL官方存储引擎和第三方
存储引擎。有些第三方存储引擎很强大,如大名鼎鼎的 InnoDB存储引擎(最早是第
三方存储引擎,后被 Oracle收购),其应用就极其广泛,甚至是 MYSQL数据库OLTP
( Online Transaction Processing在线事务处理)应用中使用最广泛的存储引擎。还是那
句话,用户应该根据具体的应用选择适合的存储引擎,以下是对一些存储引擎的简单介
绍,以便于读者选择存储引擎时参考。
13.1 InnoDB存储引擎
InnoDB存储引擎支持事务,其设计目标主要面向在线事务处理(OLTP)的应用。
其特点是行锁设计、支持外键,并支持类似于 Oracle的非锁定读,即默认读取操作不会
产生锁。从MysαL数据库5.58版本开始, InnoDB存储引擎是默认的存储引擎。
InnoDB存储引擎将数据放在一个逻辑的表空间中,这个表空问就像黑盒一样由
InnoDB存储引擎自身进行管理。从 MySQL4.1(包括41)版本开始,它可以将每个
InnoDB存储引擎的表单独存放到一个独立的ibd文件中。此外, InnoDB存储引擎支持
用裸设备( row disk)用来建立其表空间。
InnoDB通过使用多版本并发控制(MvcC)来获得高并发性,并且实现了SQL
标准的4种隔离级别,默认为 REPEATABLE级别。同时,使用一种被称为 next-key
lockiπg的策略来避免幻读( phantom)现象的产生。除此之外, InnoDB储存引擎还提
供了插入缓冲( insert buffer)、二次写( double write)、自适应哈希索引( adaptive hash
indeκx)、预读( read ahead)等高性能和高可用的功能。
对于表中数据的存储, InnoDB存储引擎采用了聚集( clustered)的方式,因此每张
表的存储都是按主键的顺序进行存放。如果没有显式地在表定义时指定主键, InnoDB存
储引擎会为每一行生成一个6字节的 ROWID,并以此作为主键。
eifl:http://code.google.com/p/david-mysql-tools/wiki/innodbsecondarybufferpoolhttp:/blog.csdnnet/jiongyi11
5L.
13 MySQL存引学7
InnoDB存储引擎是 MySQL数据库最为常用的一种引擎,而 Facebook Google
Yahoo!等公司的成功应用已经证明了 InnoDB存储引擎具备的高可用性、高性能以及
高可扩展性。
1.32 MyISAM存储引擎
MyISAM存储引擎不支持事务、表锁设计,支持全文索引,主要面向一些OLAP
数据库应用。在 MySQL558版本之前 MyISAM存储引擎是默认的存储引擎〔除
Windows版本外)。数据库系统与文件系统很大的一个不同之处在于对事务的支持,然
而 MyISAM存储引擎是不支持事务的。究其根本,这也不是很难理解。试想用户是否在
所有的应用中都需要事务呢?在数据仓库中,如果没有ETL这些操作,只是简单的报表
查询是否还需要事务的支持呢?此外, MyISAM存储引擎的另一个与众不同的地方是它
的缓冲池只缓存( cache)索引文件,而不缓冲数据文件,这点和大多数的数据库都非常
不同
MyISAM存储引擎表由MYD和MY组成,MYD用来存放数据文件,MYI用来存
放索引文件。可以通过使用 myisampack工具来进一步压缩数据文件,因为 myisampack
工具使用赫夫曼( Huffman)编码静态算法来压缩数据,因此使用 myisampack工具压缩
后的表是只读的,当然用户也可以通过 myisampack来解压数据文件。
在 MySQL5,版本之前, MyISAM默认支持的表大小为4GB,如果需要支持大
于4GB的 MyISAM表时,则需要制定 MAX ROWS和 AVG ROW LENGTH属性。从
MySQL5.0版本开始, MyIsAM默认支持256TB的单表数据,这足够满足一般应用需求
注意对于 MyISAM存储引擎表, MySQL数据库只缓存其索引文件,数据文
件的缓存交由操作系统本身来完成,这与其他使用LRU算法缓存数据的大部
分数据库大不相同。此外,在 MySQL5123版本之前,无论是在32位还是64
位操作系统环境下,缓存索引的缓冲区最大只能设置为4GB。在之后的版本
中,64位系统可以支持大于4GB的索引缓冲区
1.33NDB存储引擎
2003年, MySQL AB公司从 Sony Ericsson公司收购了NDB集群引擎(见图1-1)http://blog.csdn.net/jiongyi1
6I
8郭!亨MSQL体系结构和存儲引学
部拼没
NDB存储引擎是一个集群存储引擎,类似于 Oracle的RAC集群,不过与 Oracle r4C
share everytiMe
g架构不同的是,其结构是 share nothing的集群架构,因此能提供更高
的可用性。NDB的特点是数据全部放在内存中(从 MySQL5版本开始,可以将非索
引数据放在磁盘上),因此主键查找( primary key lookups)的速度极快,并且通过添加
NDB数据存储节点( Data node)可以线性地提高数据库性能,是高可用、高性能的集
群系统。
关于NDB存储引擎,有一个问题值得注意,那就是NDB存储引擎的连接操作
JOIN)是在 MySQL数据库层完成的,而不是在存储引擎层完成的。这意味着,复杂的
连接操作需要巨大的网络开销,因此査询速度很慢。如果解决了这个问题,NDB存储引
擎的市场应该是非常巨大的。
注意 MySQL NDB Cluster存储引擎有社区版本和企业版本两种,并且NDB
Cluster已作为 Carrier grade edition单独下载版本而存在,可以通过htp:/dev.
mysql. com/downloads./ cluster/index htm获得最訢版本的 NDB Cluster存储引擎
1.34 Memory存储引擎
Memory存储引擎(之前称HEAP存储引擎)将表中的数据存放在内存中,如果数
据库重启或发生崩溃,表中的数据都将消失。它非常适合用于存储临时数据的临时表
以及数据仓库中的纬度表。 Memory存储引擎默认使用哈希索引,而不是我们熟悉的B+
树索引。
虽然 Memory存储引擎速度非常快,但在使用上还是有一定的限制。比如,只支持
表锁,并发性能较差,并且不支持TEXT和BLOB列类型。最重要的是,存储变长字段
( varchar)时是按照定常字段(char)的方式进行的,因此会浪费内存(这个间题之前已
经提到,eBay的工程师 Igor Chernyshev已经给出了 patch解决方案)
此外有一点容易被忽视,MyQL数据库使用 Memory存储引擎作为临时表来存放查
询的中间结果集( intermediate result)。如果中间结果集大于 Memory存储引擎表的谷量
设置,又或者中间结果含有TEXT或BLOB列类型字段,则 MySQL数据库会把其转换
到 MyISAM存储引擎表而存放到磁盘中。之前提到 MyISAM不缓存数据文件,因此这
时产生的临时表的性能对于查询会有损失。http:/blog.csdnnet/jiongyi11
5
13 MySQL存储引擎9
13.5 Archive存储引擎
Archive存储引擎只攴持 INSERT和 SELECT操作,从 MySQL5.1开始支持索
引。 Archive存储引擎使用zlib算法将数据行(row)进行压缩后存储,压缩比一般可
达1:10。正如其名字所示, Archive存储引擎非常适合存储归档数据,如日志信息。
Archive存储引擎使用行锁来实现高并发的插人操作,但是其本身并不是事务安全的存
储引擎,其设计目标主要是提供高速的插入和压缩功能。
1.3.6 Federated存储引擎
Federated存储引擎表并不存放数据,它只是指向一台远程 MySQL数据库服务器上
的表。这非常类似于 SQL Server的链接服务器和 Oracle的透明网关,不同的是,当前
Federated存储引擎只支持 MySQL数据库表,不支持异构数据库表。
137Mara存储引擎
Maria存储引擎是新开发的引擎,设计目标主要是用来取代原有的 MyISAM存储引
擎,从而成为 MySQL的默认存储引擎。Maia存储引擎的开发者是 MySQL的创始人之
的 Michael widenius。因此,它可以看做是 MyISAM的后续版本。 Maria存储引擎的
特点是:支持缓存数据和索引文件,应用了行锁设计,提供了MVC功能,支持事务和
非事务安全的选项,以及更好的BLOB字符类型的处理性能
1.38其他存储引擎
除了上面提到的7种存储引擎外, MySQL数据库还有很多其他的存储引擎,包括
Merge、CSV、 Sphinx和 Infobright,它们都有各自使用的场合,这里不再一一介绍。在
了解 MySQL数据库拥有这么多存储引擎后,现在我可以回答1.2节中提到的问题了。
日为什么 MySQL数据库不支持全文索引?不! MySQL支持, MyISAM、 InnoDB
(L.2版本)和 Sphinx存储引擎都支持全文索引。
口 MySQL数据库速度快是因为不支持事务?错!虽然 MySQL的 MyISAM存储引
擎不支持事务,但是 InnoDB支持。“快”是相对于不同应用来说的,对于ETL
这种操作, MyISAM会有其优势,但在OLTP环境中, InnoDB存储引擎的效率http:/blog.csdnnet/jiongyi11
0第章 MySQL体系结构和存储引擎
更好。
擦器
口当表的数据量大于1000万时 MySQL的性能会急剧下降吗?不! MySQL是数
据库,不是文件,随着数据行数的增加,性能当然会有所下降,但是这些下降不
是线性的,如果用户选择了正确的存储引擎,以及正确的配置,再多的数据量
MySQL也能承受。如官方手册上提及的, Matrix和nc.在 InnoDB上存储超过
ITB的数据,还有一些其他网站使用 InnoDE存储引擎,处理插入/更新的操作
平均800次/秒
4各存储引擎之间的比较
通过1.3节的介绍,我们了解了存储引擎是 MySQL体系结构的核心。本节我们
将通过简单比较几个存储引擎来让读者更直观地理解存储引擎的概念。图1-2取自于
MySQL的官方手册,展现了一些常用 MySQL存储引擎之间的不同之处,包括存储容量
的限制、事务支持、锁的粒度、MVCC支持、支持的索引、备份和复制等。
Feature
MyISAM BDB
Memony
Inno DB Archie NDB
「 Storage Limits
NO
No
Yes
64TE
N
Yes
Transactions (commit, rollback, etc.)
Locking granularity
Table Fage Table
ROw
Row
ROw
MVCC/ Snapshot Read
Geospatial support
日 Tree indexes
Hash indexes
Full text search index
Clustered index
Data caches
Index caches
ompressed data
Encrypted data (via tunction)
Storage cost (space used)
LOW
NIA
veryLOw
Memory cos
LowLow Medium
High
LOW
Bulk Insert speed
High
High
OW
Very High
High
Cluster database support
Replication support
Foreign key support
Backup/point-in-time recovery
Query cache support
Update Statistics for Data Dictionary
图1-2不同 MySQL存储引擎相关特性比较http://blog.csdn.net/jiongyi1
6I
14各存篇引学之间制比较11
可以看到,每种存储引擎的实现都不相同。有些竟然不支持事务,相信在任何本
关于数据库原理的书屮,可能都会提到数据库与传统文件系统的最大区别在于数据库是
支持事务的。而 MySQL数据库的设计者在开发时却认为可能不是所有的应用都需要事
务,所以存在不支持事务的存储引擎。更有不明其理的人把 MySQL称做文件系统数据
库,其实不然,只是 MySQL数据库的设计思想和存储引擎的关系可能让人产生了理解
上的偏差。
可以通过 SHOW ENGINES语句查看当前使用的 MySQL数据库所支持的存储引擎
也可以通过查找 information schema架构下的 ENGINES表,如下所示:
mysql>SHOW ENGINES\G;
请k★★★★★★大★青★大青★*青内南青害實青1,rw
會胄宫皆冒皆当;女专★★★★★此
Engine: Inno DB
Support: YES
Conment: Supports transactions, raw-level locking, and foreign keys
T工 ansactlons:YEs
XA: YES
Savepoints: YES
唐古★有有古本古*★青★★★★★★2。○w*★*曹*皆***啬*女★★★★★★*★★★★
Engine MRG MY ISAM
Support: YES
Comment:: Collection of identical MyISAM tables
Transactions: No
A: NO
saver。ints:No
★古*古古青古★青★来★★★*★肯实★黄★★3,r。w★★青★★★★★★★★★★★★实实★实★★★★★★
Engine: BLACKHOLE
Support: YES
Comment: /dev/null storage engine (anything you write to it disappears)
Transacti。rs:No
A: NO
Savepoints: N
★★★★★★青★★大木古**★肯卖★★★4。rw六*★★南★*★★★★★★女★女★★★★女★★★
Engine: Csv
Support: YES
Comment: csv storage engine
Transacti。ns:NO
XA, NO
savepoints: NO
★★责★★★★为古★肯;古诸★★★★★★古★
row肯青青言请面☆貴★★★★食★★★★★实青家胄
Engine: MEMORY
Support: YEShttp://blog.csdn.net/jiongyi1
5
12葬l莩 MySQL体系结构和存儲引孳
Comment: Hash based, stored in memory, useful for temporary tables
Transactions: NO
XA: NO
Savepoints: NO
★★★★★★★★★实女★★六★★★★★★如★*6,rOW★★★★★★★★南★知★*★★★★k★★★★★囊★
Engine: FEDERATED
Support: NO
Comment: Federated My sQL storage engin
Transactions: NULL
XA: NULL
Savepoints: NOLL
AkA而kkk★;k太古★古★六青古青太**7
rUw青★★六★t言需★★青肯★青★★★青古青★★★
Engine: ARCHIVE
SUPPO〓t:YEsS
Comment: Archive storage engine
Transactions: NO
XA NO
savepoints: NO
★声内★★★★★青六★内内青古★六古内★舟★★8,￥QW舟内如南走如★〓内共青卉共青青舞六去内六
Engine: MYISAM
suppo=t: DEFAULT
Comment: Default engine as of My SQL 3.23 with great Ferformance
Transactions: NO
XA: NO
Savepoints: NO
8 rows in set (0.00 sec)
下面将通过 My SQL提供的示例数据库来简单显示各存储引擎之间的不同。这里将
分别运行以下语句,然后统计每次使用各存储引擎后表的大小。
mysql>CREATE TABLE mytest Engine=MyISAM
>AS SELECT FROM salaries:
Query oK, 2844047 rows affected (4. 3 sec)
Records: 2844047 Duplicates: o Warnings:
mysql>ALTER TABLE mytest Engine=InnoDB;
Query oK, 284404T rows affected (15.86 sec)
Records: 2844047 Duplicates: 0 Warnings: 0
mysql>ALTER TABLE mytest Engine=ARCHIVE;
Query OK, 2844047 rows affected (16.03 sec)
Records: 2844047 Duplicates: 0 Warnings: 0http:/blog.csdnnet/jiongyi11
15连甚MSQL3
通过每次的统计,可以发现当最初表使用 MyISAM存储引擎时,表的大小为
40.7MB,使用 InnoDB存储引擎时表增大到了113.6MB,而使用 Archive存储引擎
时表的大小却只有20MB。该例子只从表的大小方面简单地揭示了各存储引擎的不
同
注意MyQL提供了一个非常好的用来演示 MySQL各项功能的示例数据库
如 SQL Server提供的 Adventure Works示例数据库和 Oracle提供的示例数据库。
据我所知,知道 MySQL示例数据库的人很少,可能是因为这个示例数据库没
有在安装的时候提示用户是否安装(如 Oracle和 SQL Server)以及这个示例数
据库的下载竟然和文档放在一起。用户可以通过以下地址找到并下载示例数据
库:http://dev.mysqlcom/doc/o
1.5连接 MySQL
本节将介绍连接 MySQL数据库的常用方式。需要理解的是,连接 MySQL操作是
一个连接进程和MySQ数据库实例进行通信。从程序设计的角度来说,本质上是进程
通信。如果对进程通信比较了解,可以知道常用的进程通信方式有管道、命名管道、命
名字、TCPP套接字、UNX域套接字。 MySQL数据库提供的连接方式从本质上看都
是上述提及的进程通信方式
1.5.1TCP/P
TCP/IP套接字方式是 MySQL数据库在任何平台下都提供的连接方式,也是网络中
使用得最多的一种方式。这种方式在TCPP连接上建立一个基于网络的连接请求,一
般情况下客户端( client)在一台服务器上,而 MySQL实例( server)在另一台服务器
上,这两台机器通过一个TCP/P网络连接。例如用户可以在 Windows服务器下请求
台远程 Linux服务器下的 MySQL实例,如下所示:
C:\>mysq-h192.168.0.101- u david-1
Enter password:
Welcame to the MySQL monitor, Commands end with i or \g
Your My SQL connection 1d 1s 18358http://blog.csdn.net/jiongyi1
SL
14弟!章MSQ体系结构和存儲引学
Server version: 5.0.77-log My SQL Community Server (GPL)
冷银
Type help; 1 or i\hfor help Type ' \cto clear the current input statement
ysl>
这里的客户端是 Windows,它向一台 Host IP为1921680.01的 MySQL实例发起
了TCPP连接请求,并且连接成功。之后就可以对 MySQL数据库进行一些数据库操
作,如DDL和DML等。
这里需要注意的是,在通过TCP/P连接到 MySQL实例时, MySQL数据库会先检
查一张权限视图,用来判断发起请求的客户端IP是否允许连接到 MySQL实例。该视图
在mysq1架构下,表名为user,如下所示:
mysql>USE mysql
Database changed
mysql>SELECT host, user, password FROM user;
★★★食安★女变★★★★★★★★★★★★★★★★1,E。w★★★★★女★★量★食货★★★★★支★史★★★★★
hos":192.168.24詈
user: root
password: *75DBD4FA548120B54FE693C06C41AA9Al 6DE8FBE
青★★安★青安★内★贵★★青★★卡夹*2.rw★★★青★★青★贵青★★★★★青★★★★六六t★★青
host: nineyotl0l-4.
use工:root
password: *75DBD4EA548120B54FE693C06C41AA9Al6DE8FBE
青★★★青吉古吉安出责古★★青*古****3.OW*古者故古古青皆击贵皆青★★★古面青古责★青
host:127,0.0.1
user: LUUL
password: *75DBD4EA548120B54FE693006C41AA9Al 6DE8 FBE
青古★青古古我古青古古古害皆★皆青青去4.Ew★★★古★古者昔★★★音★★★★★★★★★★★★★
host:192.168.C。100
user: zlm
password: *DAEC939275CC7CD8E0293812A31735DA9CE0953C
青★青★★卖女去青☆★古卖★*★*★★★5。rcw★★★★★★★★★★★★★女★★★丈★★丈灾★*肯实
host:
user david
password
5 rows in set【0.00sec)
从这张权限表中可以看到, MySQL允许davd这个用户在任何IP段下连接该实例,
并且不需要密码。此外,还给出了rot用户在各个网段下的访问控制权限。http:/blog.csdnnet/jiongyi11
5L
16小始15
152命名管道和共享内存
在 Window2000、 Windows xp、 Windows2003和 windowsⅤit以及在此之上的平台
上,如果两个需要进程通信的进程在同一台服务器上,那么可以使用命名管道, Microsoft
SQL Server数据库默认安装后的本地连接也是使用命名管道。在 MySQL数据库中须在配
置文件中启用- enable- named-pipe选项。在 MySQL41之后的版本中, MySQL还提供了
共享内存的连接方式,这是通过在配置文件中添加- shared- memory实现的。如果想使用
共享内存的方式,在连接时, MySQL客户端还必须使用- protocol= memory选项。
1.53UNX域套接字
在 Linux和UNIX环境下,还可以使用UNX域套接字。UNIX域套接字其实不是
一个网络协议,所以只能在 MySQL客户端和数据库实例在一台服务器上的情况下使用。
用户可以在配置文件中指定套接字文件的路径,如- socket/ tmp/mysql. sock。当数据库
实例启动后,用户可以通过下列命令来进行UNX域套接字文件的查找
mysql>SHOW VARIABLES LIKE 'socket'i
★青大青★肃★古肃青大尢大古古古古古青★青青★★青★1,W肃青★肃★古★★★★言★言青欧★青★肯言青★六★★
Variable name: socket
Value: /tmp/mysql sack
I row in set〔0.00sec)
在知道了UNIX域套接字文件的路径后,就可以使用该方式进行连接了,如下所示
Irootestargazer ]f mysql -udavid-s /tmp/mysql. sock
Welcome to the My sQL monitor, Commands end with ;or \g
Your My SQL connection id is 20333
Server version: 5.0. 77-log MySQL Community Server (GPL)
ype help:! or h for help. Type '\c. to clear the buffer
ysl
16小结
本章首先介绍了数据库和数据库实例的定义,紧接着分析了 MySQL数据库的体系http://blog.csdn.net/jiongyi1
BL
16第1章 MySQL体系结构和存储引擎
结构,从而进一步突出强调了“实例”和“数据库”的区别。相信不管是 MySQL DBA
还是 MySQL的开发人员都应该从宏观上了解了 MySQL体系结构,特别是 MySQL独有
的插件式存储引擎的概念。因为很多 MySQL用户很少意识到这一点,这给他们的管理、
使用和开发带来了困扰
本章还详细讲解了各种常见的表存储引擎的特性、适用情况以及它们之间的区别,
以便于大家在选择存储引擎时作为参考。最后强调一点,虽然 MySQL有许多的存储引
擎,但是它们之间不存在优劣性的差异,用户应根据不同的应用选择适合自己的存储引
擎。当然,如果你能力很强,完全可以修改存储引擎的源代码,甚至是创建属于自己特
定应用的存储引擎,这不就是开源的魅力吗?http://blog.csdn.net/jiongyi1
5
部拼吾
你
第2章 InnoDB存储引擎
InnoDB是事务安全的 MySQL存储引擎,设计上采用了类似于 Oracle数据库的架
构。通常来说, InnoDB存储引擎是OTP应用中核心表的首选存储引擎。同时,也正是
因为 InnoDB的存在,才使 MySQL数据库变得更有魅力。本章将详细介绍 InnoDB存储
引擎的体系架构及其不同于其他存储引擎的特性。
2.1 InnoDB存储引擎概述
InnoDB存储引擎最早由 Innobase Oy公司开发,被包括在 MySQL数据库所有的
二进制发行版本中,从 MySQL5.5版本开始是默认的表存储引擎(之前的版本 InnoDB
存储引擎仅在widσws下为默认的存储引擎)。该存储引擎是第一个完整支持ACID事
务的 MySQL存储引擎(BDB是第一个支持事务的 MySQL存储引擎,现在已经停止开
发),其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读,同时被设计
用来最有效地利用以及使用内存和CPU。
Heikki tuuri(1964年,芬兰赫尔辛基)是 InnoDB存储引擎的创始人,和著名的
Linux创始人 Linus是芬兰赫尔辛基大学校友。在1990年获得赫尔辛基大学的数学逻辑
博士学位后,他于1995年成立 Innobase Oy公司并担任CEO。同时,在 InnoDB存储
引擎的开发团队中,有来自中国科技大学的 Calvin sun。而最近又有一个中国人Jmmy
Yang也加入了 InnoDB存储引擎的核心开发团队,负责全文索引的开发,其之前任职于
Sybase数据库公司,负责数据库的相关开发工作。
InnoDB存储引擎已经被许多大型网站使用,如用户熟知的Goge、 Yahoo!!
Facebook、 YouTube、 Flickr,在网络游戏领域有《魔兽世界》、《 Second life》、《神兵玄奇》
等。我不是 MySQL数据库的布道者,也不是 InnoDB的鼓吹者,但是我认为当前实施
一个新的OLTP项日不使用 MySQL InnoDB存储引擎将是多么的愚蠢
2006年该公司已经被Orac公司收购。http:/blog.csdnnet/jiongyi11
51.6
18第2幸 InnoDB存储引擎
从MyoL数据库的官方手册可得知,著名的 Internet新闻站点 Slashdot. org连行
在 InnoDB上。Myti、lnc,在 InnoDB上存储超过1TB的数据,还有一些其他站点在
InnoDB上处理插入/更新操作的速度平均为800次/秒。这些都证明了 InnoDB是一个
高性能、高可用、高可扩展的存储引擎。
InnoDB存储引擎同 MySQL数据库一样,在 GNU GPL2下发行。更多有关 MySQL
证书的信息,可参考ht:/wwwmysql.com/about/legal/,这里不再详细介绍。
22 InnoDB存储引擎的版本
InnoDB存储引擎被包含于所有MyQL数据库的二进制发行版本中。早期其版本随
着 MySQL数据库的更新而更新。从 MySQL5.1版本时, MYSQL数据库允许存储引擎
开发商以动态方式加载引擎,这样存储引擎的更新可以不受 MySQL数据库版本的限制
所以在 MySQL51屮,可以支持两个版本的 InnoDB,一个是静态编译的 InnoDB版本,
可将其视为老版本的 InnODB;另一个是动态加载的 InnoDB版本,官方称为 InnODB
Plugin,可将其视为 InnoDB10x版本。 MySQL5.5版本中又将 InnoDB的版本升级到了
11x。而在最近的 MySQL56版木中 InnoDB的版木也随着升级为12.x版木。表2-1显
示了各个版本中 InnoDB存储引擎的功能。
表2-1 InnoDB各版本功能对比
版本
功能
老版本 InnoDB
支持ACID、行锁设计、MVCC
InnoDB 1.0.x
继承了上述版本所有功能,增加了 compress和 dynamic页格式
InnoDB llx
继承了上述版本所有功能,增加了 Linux AIO、多回液段
InnoDB 1.2x
继承了上述版本所有功能,增加了全文索引支持、在线索引添加
在现实工作中我发现很多 MySQL数据库还是停留在 MySQL51版本,并使用
InnoDB Plugin很多DBA错误地认为 InnoDB Plugin和 InnoDB11版木之间是没有区
别的。但从表2-1中还是可以发现,虽然都增加了对于 compress和 dynamic页的支持,
但是 InnoDB Plugin是不支持 Linux native alt功能的。此外,由于不支持多回滚段,
InnoDB Plugin支持的最大支持并发事务数量也被限制在1023。而且随着 MySQL55版
本的发布, InnoDB Plugin也变成了一个历史产品。http:/blog.csdnnet/jiongyi11
5L
2.3mnDB体飛架构19
23 InnoDB体系架构
擦器
通过第1章读者已经了解了 MySQL数据库的体系结构,现在可能想更深入地了解
InnoDB存储引擎的架构。图2-1简单显示了 InnoDB的存储引擎的休系架构,从图可
见, InnoDB存储引擎有多个内存块,可以认为这些内存块组成了一个大的内存池,负责
如下工作:
口维护所有进程/线程需要访问的多个内部数据结构。
口缓存磁盘上的数据,方便快速地读取,同时在对磁盘文件的数据修改之前在这里
缓存。
口重做日志( redo log)缓冲
后台线程(后台线程(后台线程(后台线程(后台线程
InnoDB存储引擎内存池
文件文件文件
图2-1 InnoDE存储引擎体系架构
后台线程的主要作用是负责刷新内存池中的数据,保证缓冲池中的内存缓存的是最
近的数据。此外将已修改的数据文件刷新到磁盘文件,同时保证在数据库发生异常的情
况下 InnoDB能恢复到正常运行状态。
2.3.1后台线程
InDB存储引擎是多线程的模型,因此其后台有多个不同的后台线程,负责处理不http://blog.csdn.net/jiongyi1
5
20第2章moDB存储引擎
部拼没
同的任务。
你图函令
1. Master Thread
Master Thread是一个非常核心的后台线程,主要负责将缓冲池中的数据异步刷新
到磁盘,保证数据的一致性,包括脏页的刷新、合并插人缓冲(Ⅰ NSERT BUFFER)、
UNDO页的回收等。25节会详细地介绍各个版本中 Master Thread的工作方式。
2. O Thread
在 InnoDB存储引擎中大量使用了AO( Async IC)来处理写IO请求,这样可以极
大提高数据库的性能。而 Io Thread的工作主要是负责这些Io请求的回调( call back)
处理。IoDB1.0版本之前共有4个 IO Thread,分别是 write、read、 insert buffer和log
Io thread。在 Linux平台下, IO Thread的数量不能进行调整,但是在 window平台下
可以通过参数 innodb file io threads来增大 Io Thread。从 InnoDB1.0x版本开始,read
thread和 write thread分别增大到了4个,并且不再使用 innodb file io threads参数,而
是分别使用 innodb read io threads和 innodb write io threads参数进行设置,如:
mysql>SHOW VARIABLES LIKE 'innodb version'\G:
南南吉南青责古南南青由由内由由古吉由青1.x。w南青吉香由皆由安由★★安安安安责
Variable name: innodb version
Value: 1.0.6
1x⊙ w In set(0.00sec
mysql>SHON VARIABLES LIkE innodb io threads\G
★★★★★★★★责★★★★★★t★★★★★★★★★★1y。H★★★★★太★★★★★★★★★★★★★★★★古实★★★
Variable name innodb read io threads
Value: 4
k★内赏青脔青青青青青大青青★青青★青★言古责青青2,。w★责言盲言古责责古责★★★★t青南青吉责★
Variable name: innodb write io threads
value: 4
2 rows in set (0.00 sec)
可以通过命令 SHOW ENGⅠ NE INNODB STATUS来观察 InnoDB中的 IO Thread:
mysql>SHOW ENGINE INNODB STATUS\G;
★黄★★★★貴贵★曲贵★★★食★★★★★宽★★史貴*1。row★黄★★★☆南★★★★内★★★★★★★★★★
Type: InnoDB
Name
status
三三三三〓〓一〓一〓〓〓〓〓〓一〓〓国〓〓〓〓〓〓〓〓〓〓=
100719 21:55:26 INNODB MONITOR OUTPUThttp:/blog.csdnnet/jiongyi11
EL
23 InnoDB体系架构21
Per second averages calculated from the last 36 seconds
FILE I/O
I/o thread 0 state: waiting for i/a request (insert buffer thread)
I/o thread 1 state: waiting for i/o request (log thread)
I/o thread 2 state: waiting for i/a request (read thread)
I/o thread 3 state: waiting for i/G request (read thread)
Iyo thread 4 state: waiting for i/o request (read thread)
I/o thread 5 state: waiting for i/o request (read thread)
I/o thread 6 state: waiting for i/a request (write thread
Iyo thread 7 state: waiting for i/a request (write thread
I/o thread g state: waiting for i/o request (write thread
I/o thread 9 state: waiting for i/o request (write thread
END OF INNODB MONITOR OUTPUT
二〓三二二〓〓〓三三三三三回塑三三塑
1r。 w ln set(0.01sec)
可以看到 Io Thread0为 insert buffer thread. Io thread1为 log thread之后就是根
据参数 innodb read io threads及 innodb write io threads来设置的读写线程,并且读线
程的ID总是小于写线程。
3. Purge Thread
事务被提交后,其所使用的 undolog可能不再需要,因此需要 PurgeThread来回收
已经使用并分配的undo页。在 InnoDB11版本之前,puge操作仅在 InnoDB存储引擎
的 Master Thread中完成。而从 InnoDB1.1版本开始, purge操作可以独立到单独的线
程中进行,以此来减轻 Master Thread的工作,从而提高CPU的使用率以及提升存储引
擎的性能。用户可以在 MySQL数据库的配置文件中添加如下命令来启用独立的 Purge
Thread
.mysqld]
innodb purge threads=l
在 InnoDB1.1版本中,即使将 innodb purge threads设为大于1, InnoDB存储引擎
启动时也会将其设为l,并在错误文件中出现如下类似的提示:
120529 22: 54: 16 [Warningl option 'innodb-purge-threads': unsigned value 4 adjusted to 1http://blog.csdn.net/jiongyi1
5.
22第2章IODB存储引擎
部拼
从 InnoDB1.2版本开始, InnoDB支持多个 Purge Thread,这样做的目的是为了进多
步加快undo页的回收。同时由于 Purge Thread需要离散地读取undo页,这样也能更进
步利用磁盘的随机读取性能。如用户可以设置4个 Purge Thread;
mysl> SELECT VERSION()\G;
太★量★★★★★★★★★★★☆该☆★★★★★贵kt1,y。w★*★★★★★k言★k★★★★★★k★k★★
VERSION(): 5.6.6
l row in set (0.00 sec)
mysql> SHCW VARIABLES LIKE 'innodb purge threads '\G;
大★大★★大贵★★★内大言古六古古★青1,。W青★★宽★★定龙定★烹宵★★卿胄责★密卖卖安
variable name: innodb purge threads
Value: 4
l row in set (0.00 sec,
4. Page Cleaner Thread
Page Cleaner Thread是在 InnoDB12x版本中引入的。其作用是将之前版本中脏页
的刷新操作都放入到单独的线程中来完成。而其目的是为了减轻原 Master Thread的工作
及对于用户査询线程的阻塞,进一步提高 InnoDB存储引擎的性能。
232内存
1.缓冲池
InnoDB存储引擎是基于磁盘存储的,并将其中的记录按照页的方式进行管理。因此
可将其视为基于磁盘的数据库系统(Dsk- basc Database)在数据库系统中,由于CPU
速度与磁盘速度之间的鸿沟,基于磁盘的数据库系统通常使用缓冲池技术来提高数据库
的整体性能。
缓冲池简单来说就是一块内存区域,通过内存的速度来弥补磁盘速度较慢对数据库
性能的影响。在数据库中进行读取页的操作,首先将从磁盘读到的页存放在缓冲池中,
这个过程称为将页“FIX”在缓冲池中。下一次再读相同的页时,首先判断该贞是否在
缓冲池中。若在缓冲池中,称该页在缓冲池中被命中,直接读取该页。否则,读取磁盘
上的页。
对于数据库中页的修改操作,则首先修改在缓冲池中的页,然后再以一定的频率刷
新到磁盘上。这里需要注意的是,页从缓冲池刷新回磁盘的操作并不是在每次页发生更http://blog.csdn.net/jiongyi1
5
2.3 InnoDB体系架构23
新时触发,而是通过一种称为 Checkpoint的机制刷新回磁盘。同样,这也是为了提高数
据库的整体性能。
综上所述,缓冲池的大小直接影响着数据库的整体性能。由于32位操作系统的限
制,在该系统下最多将该值设置为3G。此外用户可以打开操作系统的PAE选项来获得
32位操作系统下最大64GB内存的支持。随着内存技术的不断成熟,其成本也在不断下
降。单条8GB的内存变得非常普遍,而PC服务器已经能支持512GB的内存。因此为
了让数据库使用更多的内存,强烈建议数据库服务器都采用64位的操作系统。
对于 InnoDB存储引擎而言,其缓冲池的配置通过参数 innodb buffer pool size来
设置。下面显示一台 MySQL数据库服务器,其将 InnoDB存储引擎的缓冲池设置为
15GB。
mysql>SHOW VARIABLES LIKe innodb buffer pool size'\G;
★★實★★丈貴史走★史灾’實實熏隶★★
1.r。W★*★走★★★★★★★★★★★贵★★★★★★**
Variable name: innodb buffer pool size
Value:16106177360
1 row in set (0.00 sect
具体来看,缓冲池中缓存的数据页类型有:索引页、数据页、undo页、插入缓冲
( insert buffer)、自适应哈希索引( adaptive hash index)、 InnoDB存储的锁信息(ock
info)、数据字典信息( data dictionary)等。不能简单地认为,缓冲池只是缓存索引页和
数据页,它们只是占缓冲池很大的一部分而已。图2-2很好地显示了 InnoDB存储引擎
中内存的结构情况。
重做日志缓冲
缓冲池( innodb buffer pool)
redo log buffer
数据页( data page)
插入缓冲
锁信息
insert buffer)
Clock info)
额外内存池
索引页 index page)
自适应哈希
数据字典
Innodb additional
索引
信息
nem pool SIZe
图2-2 InnoDB内存数据对象
从 InnoDB1.0x版本开始,允许有多个缓冲池实例。每个页根据哈希值平均分配到
不同缓冲池实例中。这样做的好处是减少数据库内部的资源竞争,增加数据库的并发处http:/blog.csdnnet/jiongyi11
6.e
24第2章nDB存储引孳
理能力。可以通过参数 innodb buffer pool instances来进行配置,该值默认为↓g事
mysql> SHOW VARIABLES LIKe 'innodb buffer pool instances\G;
青青方★青肯★食★南★古声内内六内内A1,rovx★★啸★★★★★★青★★★★★★★★青叶蚰蚰
Variable naite: innodb buffer pool instances
Value: 1
l row in set (0.00 sec)
在配置文件中将 innodb buffer pool instances设置为大于1的值就可以得到多个缓
冲池实例。再通过命令 SHOW ENGⅠ NE INNODB STATUS可以观察到如下的内容:
mysql> SHOW ENGINE INNODB STATUS\G;
1.Yow*爽
★它;:柬柬虫虫
Type: InnoDB
INDIVIDUAL BUFFER POOL INEO
- BUFFER卫。0
Buffer p。o1size65535
Free buffers
65451
Database pages
84
old database pages 0
Modified db pages 0
Pending reads D
Pending writes: LRU 0, flush listo single page 0
Pages made young 0, not young 0
0.o0 yours/s,0.00 non-youngs/s
Pages read 84, created o, written 1
9.33 reads/s 0.00 creates/ 0.11 writes/s
Buffer pool hit rate 764 /1000, young-making rate 0/100C not 0/1000
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0,00/s
LRU len: 84, unzip LRu len: 0
C/o sum[C]: cur[o], unzip sum[0]: cur[o]
ETR卫oT1
Buffer pool size 65536
Free buffers
65473
Database pages
63
old database pages 0
Modified db pages 0
Pending reads o
Pending writes: IRU 0, flush list o single page o
Pages made young 0, not young o
0.00 youngs/s,0.00 nor-youngs/shttp:/blog.csdnnet/jiongyi11
23mDB体须集构259
Pages read 63 created or written o
7.00 reads/s, 0.00 creates/s, 0.oo writes/
Buffer pool hit rate 500 / 1000, young-making rate 0 /10c0 not o/1000
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRu len: 63, unzip LRU len: 0
I/O sum[0]: cur[0], unzip sum[o]: cur [o
这里将参数 innodb buffer pool instances设置为2,即数据库用户拥有两个缓冲池
实例。通过命令 SHOW ENGⅠ NE INNODB STATUS可以观察到每个缓冲池实例对象运行
的状态,并且通过类似- BUFFER POOL0的注释来表明是哪个缓冲池实例。
从 MySQL56版本开始,还可以通过 information schema架构下的表 INNODB
BUFFER POOL STATS来观察缓冲的状态,如运行下列命令可以看到各个缓冲池的使
用状态:
mysl> SELECT POol ID, POOL SIZEr
FREE BUFFERS DATABASE PAGES
FROM INNODB BUEEER POOL STATS\G
吉☆古去青去女齿责专齿;皆“安*世齿*出:1.rOw*☆青★☆*专*青宴*计站声害出内★
POOL ID: 0
POOL SIZE: 65535
FREE BUEFERS: 65451
DATABASE PAGES: 84
古大古古★青大青★★k大古大大x十古木★**古古大2,工w大青★青★★k★肯大古大★x古青**古青大古古青
POOL ID: 1
POOL SIZE: 65536
FREE BUFFERS: 65473
DATABASE PAGES: 63
2. LRU List、 Free lis和 Flush list
在前一小节中我们知道了级冲池是一个很大的内存区城,其中存放各种类型的页
那么 InnodB存储引擎是怎么对这么大的内存区域进行管理的呢?这就是本小节要告诉
读者的。
通常来说,数据库中的缓冲池是通过LRU( Latest recent used,最近最少使
用)算法来进行管理的。即最频繁使用的页在LRU列表的前端,而最少使用的页在
LRU列表的尾端。当缓冲池不能存放新读取到的页时,将首先释放LRU列表中尾
端的页
在 InnoDB存储引擎中,缓冲池中页的大小默认为16KB,同样使用LRU算法对缓http:/blog.csdnnet/jiongyi11
5I
262亨moDB存儲引
冲池进行管理。稍有不同的是ImDB存储引擎对传统的LRU算法做了一些优化在
InnodB的存储引擎中,LRU列表中还加入了 midpoint位置。新读取到的页,虽然是最
新访问的页,但并不是直接放入到LRU列表的首部,而是放入到LRU列表的 midpoint
位置。这个算法在 InnoDB存储引擎下称为 midpoint insertion strategy。在默认配置下,该
位置在LRU列表长度的5/8处。 midpoint位置可由参数 innodb old blocks pct控制,如:
myst l> SHOW VARIABLES LIKe innodb old blocks pct\G:
t★★★x★★★★★★★★★★★★大★青★★★1,。w青★★青★青古青青★古古★古请青★;责声★★
Variable name: innodb old blocks pct
Value: 37
1 row in set (0.00 sec)
从上面的例子可以看到,参数 innodb old blocks pct默认值为37,表示新读取的页
插人到LRU列表尾端的37%的位置(差不多38的位置)。在 InnoDB存储引擎中,把
midpoint之后的列表称为od列表,之前的列表称为new列表。可以简单地理解为new
列表中的页都是最为活跃的热点数据。
那为什么不采用朴素的LRU算法,直接将读取的页放入到LRU列表的首部呢?这
是因为若直接将读取到的页放入到LRU的首部,那么某些SQL操作可能会使缓冲池中
的页被刷新出,从而影响缓冲池的效率。常见的这类操作为索引或数据的扫描操作。这
类操作需要访问表中的许多页,甚至是全部的页,而这些页通常来说又仅在这次查询操
作中需要,并不是活跃的热点数据。如果页被放入LRU列表的首部,那么非常可能将
所需要的热点数据页从LRU列表中移除,而在下一次需要读取该页时, InnoDE存储引
擎需要再次访问磁盘。
为了解决这个问题, InnoDE存储引擎引人了另一个参数来进一步管理LRU列表,
这个参数是 innodb old blocks time,用于表示页读取到md位置后需要等待多久才会被
加入到LRU列表的热端。因此当需要执行上述所说的SQL操作时,可以通过下面的方
法尽可能使LRU列表中热点数据不被刷出。
mysql> SET GLOBAL innodb old blocks time=1000;
Query OK, o rows affected (0.00 sec)
f data or index scan operation
mysql> SET GLOBAL innodb old blocks time=0http:/blog.csdnnet/jiongyi11
5L.
2.3DoDB体系架构27
Query Ok, 0 rows affected (0.00 sec)
擦器
如果用户预估自己活跃的热点数据不止63%,那么在执行SQL语句前,还可以通过
下面的语句来减少热点页可能被刷出的概率。
mysql> SET GlOBAL inncdh old blocks pct=20;
Query OK, 0 rows affected (0.00 sec
LRU列表用来管理已经读取的页,但当数据库刚启动时,LRU列表是空的,即没
有任何的页。这时页都存放在Free列表中。当需要从缓冲池中分页时,首先从rree列
表中查找是否有可用的空闲页,若有则将该页从Free列表中删除,放人到LRU列表中。
否则,根据LRU算法,淘汰LRU列表末尾的页,将该内存空间分配给新的页。当页从
LRU列表的od部分加入到new部分时,称此时发生的操作为 page made young,而因
为 innodb old blocks time的设置而导致页没有从old部分移动到new部分的操作称为
page not made young可以通过命令 SHOW ENGINE INNODB STATUS来观察LRU列
表及Free列表的使用情况和运行状态。
mysql> SHOW ENGINE INNODB STATUS\G;
食★★南★貴★★责史★★★★★★★卖★★★专*★宽*1,r。W★史★★★★★安★走★★★女安★★★★
Type: InnoDB
ame:
Status
〓〓〓〓二〓〓〓〓〓二二〓〓〓〓〓〓〓〓〓三〓〓〓〓〓〓〓〓〓三〓〓
12072522: 04: 25 INNODB MONITOR OUTPUT
〓回〓〓〓〓出出二出出〓出二二二〓二二二〓
〓苎三〓〓〓
Per second averages calculated from the last 24 seconds
Buffer pool size 327679
Free butters
Database pages
307717
old database pages 113570
Modificd db pages 24673
Pending reads D
Pending writes: LRU 0, flush list 0, single page 0
Pages made young 6448526, not ycung 0
48.75 youngs/sr000 non -youngs/s
Pages redd 5354420 created 239625, written 3486063
55.68 reads/s, 81.74 creates/s, 955. 88 writes/s
Buffer pool hit rate 1000/1000, young -making rate 0/ 1000 nct 0/1000http://blog.csdn.net/jiongyi1
6I
28第2亨血DB存储引孳
通过命令 SHOW ENGINE INNODB STATUS可以看到:当前 Buffer pool size;有
327679个页,即327679*16K,总共5GB的缓冲池。 Free buffers表示当前Free列表
中页的数量, Database pages表示LRU列表中页的数量。可能的情况是 Free buffers与
Database pages的数量之和不等于 Buffer pool size。正如图22所示的那样,因为缓冲池
中的页还可能会被分配给自适应哈希索引、Lock信息、 Insert Buffer等页,而这部分页
不需要LRU算法进行维护,因此不存在于LRU列表中
pages made young显示了LRU列表中页移动到前端的次数,因为该服务器在运行阶
段没有改变 innodb old blocks time的值,因此 not young为0。 youngs/s、 non-youngst/s
表示每秒这两类操作的次数。这里还有一个重要的观察变量— Buffer pool hit rate,表
示缓冲池的命中率,这个例子中为100%,说明缓冲池运行状态非常良好。通常该值不
应该小于95%。若发生 Buffer pool hit rate的值小于95%这种情况,用户需要观察是否
是由于全表扫描引起的LRU列表被污染的问题。
注意执行命令 SHOW ENGⅠNEⅠ NNODB STATUS显示的不是当前的状态,而
是过去某个时间范围内 InnoDB存储引擎的状态。从上面的例子可以发现,Per
second averages calculated from the last24 seconds代表的信息为过去24秒内的
数据库状态
从 InnoDe12版本开始,还可以通过表 INNODB BUFFER POOL STATS来观察
缓冲池的运行状态,如:
mysql> SELECT POOL ID,HIT RATE,
PAGES MADE YOUNG, PAGES NOT MADE YOUNG
->FROM information schema. INNODB BUFFER POOL STATS\G:
古★皆青★古★★古站害安音★食肯女★★1.rOw★青★t★★大★肉青★肯★★★★★★★★★★
FOOL ID: 0
HIT RATE: 980
PAGES MACE YOUNG: 450
PAGES NOT MADE YOUNG: 0
此外,还可以通过表 INNODB BUFFER PAGE LRU来观察每个LRU列表中每个页的
具体信息,例如通过下面的语句可以看到缓冲池LRU列表中 SPACE为1的表的页类型:
mysql> SELECT TABLE NAME, SPACE, PAGE NUMEER, PAGE TYPE
FROM INNODB BUFFER PAGE LRU WHERE SPACE =1http://blog.csdn.net/jiongyi1
5
2.3 InnoDB体架构29
拼爱翻
====一++
TABLE NAME| SPACE「 PAGE NUMBER|PAG三TYPE
你图函令
I NULL
0|FL三 SPACE HEADER
I NULL
1|工 BUF BITMAR
I NULL
2|工NoDE
I test/tI
1
3 I INDEX
4 rows in set (0.00 sec)
InnoDB存储引擎从1.0x版本开始支持压缩页的功能,即将原本16KB的页压缩
为KB、2KB、4KB和8KB。而由于页的大小发生了变化,LRU列表也有了些许的改
变。对于非16KB的页,是通过 unzip_LRU列表进行管理的。通过命令 SHOW ENGINE
INNODB STATUS可以观察到如下内容:
mysql> SHOW ENGINE INNODB STATUS\Gi
Buffer pool hit rate 999 / 1000, yaung-making rate 0/1000 not 0/1500
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRU len: 1539, unzip IRU len: 156
I/o sum[0]:cur[o] unzip sum[O]: cur[OI
可以看到LRU列表中一共有1539个页,而 zip LRU列表中有156个页。这里需
要注意的是,LRU中的页包含了 unzip lru列表中的页。
对于压缩页的表,每个表的压缩比率可能各不相同。可能存在有的表页大小为
8KB,有的表页大小为2KB的情况。 unzip LRU是怎样从缓冲池中分配内存的呢?
首先,在 unzip_ LRU列表中对不同压缩页大小的页进行分别管理。其次,通过伙伴
算法进行内存的分配。例如对需要从缓冲池中申请页为4KB的人小,其过程如下:
1)检查4KB的 unzip LRU列表,检查是否有可用的空闲页;
2)若有,则直接使用;
3)否则,检查8KB的 unzip Lru列表
4)若能够得到空闲页,将页分成2个4KB页,存放到4KB的 unzip lrt列表
5)若不能得到空闲页,从LRU列表中申请一个16KB的页,将页分为1个8KB的
页、2个4KB的页,分别存放到对应的 unzip LRU列表中。
同样可以通过 information schema架构下的表 INNODB BUFFER PAGE LRU来观
察 unzip lru列表中的页,如:http://blog.csdn.net/jiongyi1
BI
30弟2章mODB存储引季
mysql> SELECt
TABLE NAME, SPACE PaGE NUMBER, COMPRESSED SIZE
- FROM INNODB BUFFER PAGE LRU
HERE COMPRESSED SIZE <>0:
十
I TABLE NAME SPACE PAGE NUMBER I COMPRESSED SIZE
I sbtest/t
134
8192
I sbtest/t
9
135
8192
I sbtest/t I
96
8192
I sbtest/t
136
8192
I sbtest/t
32l
8192
I sbtest/t I
9
8192
I sbtest/t I
1371
8192
sbt巳st/t
98
8192
在LRU列表中的页被修改后,称该页为脏页( dirty page),即缓冲池中的页和磁盘
上的页的数据产生了不一致。这时数据库会通过 CHECKPOINT机制将脏页刷新回磁盘,
而Fush列表中的页即为脏页列表。需要注意的是,脏页既存在于LRU列表中,也存在
丁Flus列表中。LRU列表用来管理缓冲池中页的可用性, Flush列表用来管理将页刷新
回磁盘,二者互不影响。
同LRU列表一样, Flush列表也可以通过命令 SHOW ENGINE INNODB STATUS
来查看,前面例子中 Modified db pages24673就显示了脏页的数量。 information
schema架构下并没有类似 INNODB BUFFER PAGE LRU的表来显示脏页的数量及
脏页的类型,但正如前面所述的那样,脏页同样存在于LRU列表中,故用户可以通过
元数据表 INNODB BUFFER PAGE LRU来查看,唯一不同的是需要加入 OLDEST
MODIFICATION大于0的SQL查询条件,如:
mysql> SELECT TABLE NAME, SPACE, PAGE NUMBER, PAGE TYPE
FROM INNODB BUFFER PAGE LRU
WHERE OLDEST MODIFICATION> 0
十=========---+一----=+
TABLE NAME. SPACE PAGE NUMBER I PAGE TYPE
NULL
0010
56 SYSTEM
NUT工
0 I FILE SPACE HEADER I
I test/t
3 INDEX
I NULL
320|工NoDEhttp:/blog.csdnnet/jiongyi11
5L.A
3mnDB体系来构31争
NULL
325
UNDO LOG
召盛
5 rows in sct (0.00 sec)
可以看到当前共有5个脏页及它们对应的表和页的类型。 TABLE NAME为NULL
表示该页属于系统表空间。
3.重做日志缓冲
从图22可以看到, InnoDB存储引擎的内存区域除了有缓冲池外,还有重做日志缓
冲( redo log buffer,。 InnoDB存储引擎首先将重做日志信息先放人到这个缓冲区,然后
按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大,因为一般
情况下每一秒钟会将重做日志缓冲刷新到日志文件,因此用户只需要保证每秒产生的事
务量在这个缓冲大小之内即可。该值可由配置参数 innodb log buffer size控制,默认为
8MB:
mysql> SHOW VARIABLES LIKE 'inngdh log buffer size\G;
★★★★★★★★当★★★央★★★★如★中★★★★1,r。W★★★★★★★★★★来★来★★★★★★★★★★
Variable name: innodb log buffer size
Va1ue:8388608
1 row in set (0.00 sec)
在通常情况下,8MB的重做日志缓冲池足以满足绝大部分的应用,因为重做日志在
下列三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中。
口 Master thread每一秒将重做日志缓冲刷新到重做日志文件;
口每个事务提交时会将重做日志缓冲刷新到重做日志文件;
口当重做日志缓冲池剩余空间小于1/2时,重做日志缓冲刷新到重做日志文件
4额外的内存池
额外的内存池通常被DBA忽略,他们认为该值并不十分重要,事实恰恰相反,该
值同样十分重要。在 InnoDB存储引擎中,对内存的管理是通过一种称为内存堆(heap)
的方式进行的。在对一些数据结构本身的内存进行分配时,需要从额外的内存池中进行
申请,当该区域的内存不够时,会从缓冲池中进行申请。例如,分配了缓冲池〔 innodb
buffer_ pool),但是每个缓冲池中的帧缓冲( frame buffer)还有对应的缓冲控制对象
buffer control block),这些对象记录了一些诸如LRU、锁、等待等信息,而这个对象的
内存需要从额外内存池中申请。因此,在申请了很大的 InnODB缓冲池时,也应考虑相http://blog.csdn.net/jiongyi1
6I
322幸皿DB存储引孳
部拼没
应地增加这个值。
24 Checkpoint技术
前面已经讲到了,缓冲池的设计目的为了协调CPU速度与磁盘速度的鸿沟。因此页
的操作首先都是在缓冲池中完成的。如果一条DML语句,如 Update或 Delete改变了页
中的记录,那么此时页是脏的,即缓冲池中的页的版本要比磁盘的新。数据库需要将新
版本的页从缓冲池刷新到磁盘。
倘若每次一个页发生变化,就将新页的版本刷新到磁盘,那么这个开销是非常大
的。若热点数据集中在某几个页中,那么数据库的性能将变得非常差。同时,如果在从
缓冲池将页的新版本刷新到磁盘时发生了宕机,那么数据就不能恢复了。为了避免发生
数据丢失的问题,当前事务数据库系统普遄都采用了 Write Ahead Log策略,即当事务提
交时,先写重做日志,再修改页。当由于发生岩机而导致数据丢失时,通过重做日志来
完成数据的恢复。这也是事务ACID中D( Durability持久性)的要求。
思考下面的场景,如果重做日志可以无限地增大,同时缓冲池也足够大,能够缓冲
所有数据库的数据,那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生岩机
时,完全可以通过重做日志来恢复整个数据库系统中的数据到岩机发生的时刻。但是这
需要两个前提条件
口缓冲池可以缓存数据库中所有的数据;
口重做日志可以无限增大。
对于第一个前提条件,有经验的用户都知道,当数据库刚开始创建时,表中没有任
何数据。缓冲池的确可以缓存所有的数据库文件。然而随着市场的推广,用户的增加,
产品越来越受到关注,使用量也越来越大。这时负责后台存储的数据库的容量必定会不
断增大。当前3TB的 MySQL数据库已并不少见,但是3TB的内存却非常少见。目前
Oracle exadata旗舰数据库一体机也就只有2TB的内存。因此第一个假设对于生产环境
应用中的数据库是很难得到保证的。
再来看第二个前提条件:重做日志可以无限增大。也许是可以的,但是这对成本的
要求太高,同时不便丁运维。DBA或SA不能知道什么时候重做日志是否已经接近于磁
盘可使用空间的阈值,并且要让存储设备支持可动态扩展也是需要一定的技巧和设备支http:/blog.csdnnet/jiongyi11
24 Checkpoin技术33
持的。
好的,即使上述两个条件都满足,那么还有一个情况需要考虑:宕机后数据库的恢
复时间。当数据库运行了几个月甚至几年时,这时发生宕机,重新应用重做日志的时间
会非常久,此时恢复的代价也会非常大。
因此 Checkpoint(检查点)技术的目的是解决以下几个问题:
口缩短数据库的恢复时间
口缓冲池不够用时,将脏页刷新到磁盘
口重做日志不可用时,刷新脏页。
当数据库发生宕机时,数据库不需要重做所有的日志,因为 Checkpoint之前的页都
已经刷新回磁盘。故数据库只需对 Checkpoint后的重做日志进行恢复。这样就大大缩短
了恢复的时间
此外,当缓冲池不够用时,根据LRU算法会溢出最近最少使用的页,若此页为脏
页,那么需要强制执行 Checkpoint,将脏页也就是页的新版本刷回磁盘
重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循
环使用的,并不是让其无限增大的,这从成本及管理上都是比较困难的。重做日志可以
被重用的部分是指这些重做日志已经不再需要,即当数据库发生宕机时,数据库恢复操
作不需要这部分的重做日志,因此这部分就可以被覆盖重用。若此时重做日志还需要使
用,那么必须强制产生 Checkpoint,将缓冲池中的页至少刷新到当前重做日志的位置。
对于 InnoDB存储引擎而言,其是通过LSN( Log Sequence Number)来标记版本
的。而LSN是8字节的数字,其单位是字节。每个页有LSN,重做日志中也有LSN,
Checkpoint t也有LSN。可以通过命令 SHOW ENGINEⅠ NNODB STATUS来观察;
mysql> SHOW ENGINE INNODB STATUS\G
LOG
Log sequence number 92561351052
Log flushed up to 92561351052
Last checkpoint at 92561351052
在 InnoDB存储引擎中, Checkpoint发生的时间、条件及脏页的选择等都非常复杂。http:/blog.csdnnet/jiongyi11
34茅2幸oDB存储引学
研者静
而 Checkpoint所做的事情无外乎是将缓冲池中的脏页刷回到磁盘。不同之处在于每次刷
新多少页到磁盘,每次从哪里取脏页,以及什么时间触发 Checkpoint。在 InnoDB存储
引擎内部,有两种 Checkpoint,分别为:
口 Sharp Checkpoint
日 Fuzzy Checkpoint
Sharp Checkpoint发生在数据库关闭时将所有的脏页都刷新回磁盘,这是默认的工作
方式,即参数 innodb fast shutdown=1。
但是若数据库在运行时也使用 Sharp Checkpoint,那么数据库的可用性就会受到很大
的影响。故在 InnoDB存储引擎内部使用 Fuzzy Checkpoint进行页的刷新,即只刷新
部分脏页,而不是刷新所有的脏页回磁盘
这里笔者进行了概括,在 InnoDB存储引擎中可能发生如下几种情况的 Fuzzy
Checkpoint
U Master Thread Checkpoint
O FLUSH LRU LIST Checkpoint
O Async/Sync Flush Checkpoint
a Dirty Page too much Checkpoint
对于 Master Thread(25节会详细介绍各个版本中 Master thread的实现)中发生的
Checkpoint,差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回
磁盘。这个过程是异步的,即此时 InnoDB存储引擎可以进行其他的操作,用户查询线
程不会阻塞。
FLUSH LRU LIST Checkpoint是因为 InnoDB存储引擎需要保证LRU列表中需要
有差不多100个空闲页可供使用。在 InnoDB11x版本之前,需要检查LRU列表中是否
有足够的可用空间操作发生在用户查询线程中,显然这会阻塞用户的查询操作。倘若没
有100个可用空闲页,那么 InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页
中有脏页,那么需要进行 Checkpoint,而这些页是来自LRU列表的,因此称为FLUH
LRU LIST Checkpoint。
而从 MySQL5.6版本,也就是noDB12x版本开始,这个检查被放在了一个单独
的 Page Cleaner线程中进行,并且用户可以通过参数 innodb lru scan depth控制LRU列
表中可用页的数量,该值默认为1024,如:http:/blog.csdnnet/jiongyi11
5
2.4 Checkpoin术35
研翻
mysql> SHON VARIABlES LIke inncdb -ru scan depth\Gi
女★☆寅赏害肃★青大★★★★★南★A贞1,工ow青★青青★南★幽南南南南有南w古青★为★古★
Variable name: innodb lru scan depth
Value: 102 4
1 row in set. (0.00 sec)
Async/Sync Flush Checkpoint指的是重做日志文件不可用的情况,这时需要强制将一
些页刷新回磁盘,而此时脏页是从脏页列表巾选取的。若将已经写人到重做日志的LSN
记为redo_lsn,将已经刷新回磁盘最新页的LSN记为 checkpoint Isn,则可定义:
checkpoint age redo Isn -checkpoint Isn
再定义以下的变量:
async water mark =75*total redo log file size
sync water mark =90%* total redo log file size
若每个重做日志文件的大小为lGB,并且定义了两个重做日志文件,则重做日志文
件的总大小为2GB。那么 async water mark=1.5GB, sync water mark=1.8GB。则:
口当 checkpoint age< async water mark时,不需要刷新任何脏页到磁盘;
口当 async water mark< checkpoint age<sync water mark时触发 Async Flush,从 Flush
列表中刷新足够的脏页回磁盘,使得刷新后满足 checkpoint age< async water
mark
口 checkpoint age> sync water mark这种情况一般很少发生,除非设置的重做日
志文件太小,并且在进行类似 LOAD DATA的 BULK INSERT操作。此时触
发 Sync Flush操作,从 Flush列表中刷新足够的脏页回磁盘,使得刷新后满足
checkpoint agesasync water mark
可见, Async/ Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。在
InnoDB12x版本之前, Async Flush Checkpoint会阻塞发现问题的用户查询线程,而
Sync Flush Checkpoint会阻塞所有的用户查询线程,并且等待脏页刷新完成。从 InnoDB
1.2x版本开始——也就是MyQL56版本,这部分的刷新操作同样放入到了单独的
Page Cleaner Thread中,故不会阻塞用户查询线程。
MySQL官方版本并不能查看刷新页是从Fush列表中还是从LRU列表中进行
Checkpoint的,也不知道因为重做日志而产生的 Async/Sync Flush的次数。但是 InnoSQL
版本提供了方法,可以通过命令 SHOW ENGINE INNODB STATUS来观察,如:http://blog.csdn.net/jiongyi1
5
36第2亨moDB存儲引擎
折者
mysql> SHOW ENGINE INNODB STATUS \G;
★★★★实★★★★女★★★★古★★★★★女★★★责请1.r。w青★★*★★审★★贵★★★★责★★★★★★
Type InnoDB
hinth
LRU len: 112902, unzip lRU len: 0
I/osum【oj:cux[0], unzIp sun【0j:cux[0
AsynC Flush: 0, Sync Flush: 0, IRU List Flush: 0, Flush List Flush: 111736
1 row in set(0.01sec〕
根据上述的信息,还可以对 InnoDE存储引擎做更为深入的调优,这部分将在第9
章中讲述。
最后一种 Checkpoint的情况是 Dirty Page too much,即脏页的数量太多,导致
InnoDB存储引擎强制进行 Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可
用的页。其可由参数 innodb max dirty_ pages_pct控制
mysq->SHOW VARIABLES LIKE 'innodb max dirty pages pct\G
★★★实★★★★★★★★★★★★★★青★★★★★★1,工口w★大★★青责k肯吉k南k古素k六去贵古古★内舟★
Variable name: innodb_max dirty pages_pct
Value: 75
l row in set (0.00 sec)
innodb max dirty_ pages pct值为75表示,当缓冲池中脏页的数量占据75%时,强
制进行 Checkpoint,刷新一部分的脏页到磁盘。在 InnoDB1.0x版本之前,该参数默认
值为90,之后的版本都为75。
25 Master Thread工作方式
在23节中我们知道了, InnoDB存储引擎的主要工作都是在一个单独的后台线
程 Master thread屮完成的,这一节将具体解释该线程的具体实现及该线程可能存在
的问题。
25.1 InnoDB1.0x版本之前的 Master Thread
Master Thread具有最高的线程优先级别。其内部由多个循环(loop)组成:主循环
loop)、后台循环( backgroup loop)、刷新循环( fush loop)、暂停循环( suspend loop)
Master thread会根据数据库运行的状态在loop、 background loop、 flush loop
和 suspendhttp://blog.csdn.net/jiongyi1
5
25 Master Thre作式37e
部拼吾
loop中进行切换
Loop被称为主循环,因为大多数的操作是在这个循环中,其中有两大部分的操
作—每秒钟的操作和每10秒的操作。伪代码如下:
void master thread(】
for (int i=0; i<l0; 1++)
do thing once per second
sleep 1 second if necessary
do things once per ten seconds
goto loop;
可以看到,lop循环通过 thread slee来实现,这意味着所谓的每秒一次或每10秒
一次的操作是不精确的。在负载很大的情况下可能会有延迟( delay),只能说大概在这
个频率下。当然, InnoDB源代码中还通过了其他的方法来尽量保证这个频率。
每秒一次的操作包活:
口日志缓冲刷新到磁盘,即使这个事务还没有提交(总是
口合并插入缓冲(可能);
口至多刷新100个 InnoDB的缓冲池中的脏页到磁盘(可能);
口如果当前没有用户活动,则切换到 background loop(可能)。
即使某个事务还没有提交, InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷
新到重做日志文件。这一点是必须要知道的,因为这可以很好地解释为什么再大的事务
提交( commit)的时间也是很短的。
合并插入缓冲( Insert Buffer)并不是每秒都会发生的。 InnoDB存储引擎会判断当
前一秒内发生的1O次数是否小于5次,如果小于5次, InnoDB认为当前的IO压力很
小,可以执行合并插入缓冲的操作。
同样,刷新100个脏页也不是每秒都会发生的。 InnODB存储引擎通过判断当前缓
冲池中脏页的比例( buf get modified ratio pct)是否超过了配置文件中 innodb max
dirty pages pct这个参数(默认为90,代表90%),如果超过了这个阈值, InnoDB存储
引擎认为需要做磁盘同步的操作,将100个脏页写人磁盘中。
总结上述操作,伪代码可以进一步具体化,如下所示:http://blog.csdn.net/jiongyi1
BI
38韩2章 InnoDB存儲引擊
拼
voic master thread(t
to-o°pF
1°
for(int=0;i<10;i++){
thread sleep(1)// sleep 1 second
co log buffer fush to disk
if (last one second ios 5)
do merge at most 5 insert buffer
f buf get modified ratio pct innodb max dirty pages pct y
do buffer pool flush 100 dirty page
if no user activity
got。 backgr。ud1oop
do things once per ten seconds
background loa
do something
goto loop:
接着来看每10秒的操作,包括如下内容:
口刷新100个脏页到磁盘(可能的情况下);
口合并至多5个插入缓冲(总是);
口将日志缓冲刷新到磁盘(总是);
口删除无用的Undo页(总是);
口刷新100个或者10个脏页到磁盘(总是)。
在以上的过程中, InnoDB存储引擎会先判断过去10秒之内磁盘的IO操作是否小
于200次,如果是, InnoDB存储引擎认为当前有足够的磁盘IO操作能力,因此将100
个脏页刷新到磁盘。接着, InnoDB存储引擎会合并插人缓冲。不同于每秒一次操作时
可能发生的合并插入缓冲操作,这次的合并插入缓冲操作总会在这个阶段进行。之后,
InnoDB存储引擎会再进行一次将日志缓冲刷新到磁盘的操作。这和每秒一次时发生的操
作是一样的。
接着InDB存储引擎会进行一步执行 full purge操作,即删除无用的Undo
页。对表进行 update、 delete这类操作时,原先的行被标记为删除,但是因为一致性
读( consistent read)的关系,需要保留这些行版本的信息。但是在 full purge过程中,
InnoDB存储引擎会判断当前事务系统中已被删除的行是否可以删除,比如有时候可能还
有查询操作需要读取之前版本的undo信息,如果可以删除, InnoDB会立即将其删除。http:/blog.csdnnet/jiongyi11
5I.
25 Master thread t作方式39
拼吾
从源代码中可以发现, InnoDB存储引擎在执行 full purge操作时,每次最多学试回收20
个undo页。
然后, InnoDB存储引擎会判断缓冲池中脏页的比例( buf_ get modified ratio pct),
如果有超过70%的脏页,则刷新100个脏页到磁盘,如果脏页的比例小于70%,则只需
刷新10%的脏页到磁盘。
现在我们可以完整地把主循环( main loc)的伪代码写出来了,内容如下:
void master thread〔}
goto loop;
loop
for(int i=0: 1<10: i++)f
thread sleep(l)//sleep 1 second
do log buffer flush to disk
if (last one second los <5)
do merge at most 5 insert buffer
if buf get modified ratio pct innodb max dirty pages pct j
do buffer pool flush 100 dirty page
if(n。 user activity
got。 backgroud1o。p
if t last ten second ios 200
do buffer pool flush 100 dirty pag
do merge at most 5 insert buffer
do log buffer flush to disk
do full purge
if buf get modified ratio pct >70%)
d buffer pool flush 100 dirty page
else
buffer pool flush 10 dirty page
goto loop
background loop
co something
goto loop
接着来看 background loop,若当前没有用户活动(数据库空闲时)或者数据库关闭
( shutdown),就会切换到这个循环。 background loop会执行以下操作:
口删除无用的Undo页(总是)
口合并20个插入缓冲(总是);
口跳回到主循环(总是);http://blog.csdn.net/jiongyi1
6I
402字 InnoDB存储引擎
部拼没
口不断刷新100个页直到符合条件(可能,跳转到 flush lo中完成)。
若fush1oop中也没有什么事情可以做了, InnoDB存储引擎会切换到 suspend
lop,将 Master thread挂起,等待事件的发生。若用户启用( enable)了 Innode存储
引擎,却没有使用任何 InnodB存储引擎的表,那么 Master thread总是处于挂起的
状态。
最后, Master Thread完整的伪代码如下:
void master thread ()(
goto1°p
for (int i =0: 1<10:; i++)t
thread sleep(l)//sleep 1 second
do log buffer flush to disk
i=( last one second ios 5
d。 merge at most5 insert buffe工
i=(buf get modified ratio pct innodb max dirty pages pct
do buffer pool flush 100 dirty page
i=( no user activity y
goto backgroud loop
if( last ten second ios 200
do buffer pool flush 100 dirty page
do merge at most 5 insert buffer
do log buffer fush to disk
d。fu1 purge
if( buf get modified ratio pct 708)
do buffer pool flush 100 dirty page
else
buffer pool flush 10 dirty page
goto loop
background loop:
o full purge
do merge 20 insert buffer
if not idle
goto loop:
else
goto flush lo°F
flush -oop
do buffer pool flush 100 dirty page
if buf get modified ratio pct>innodb ax dirty pages pct
goto flush lo。p
goto suspend1o。Fhttp://blog.csdn.net/jiongyi1
FI
2.5 Master Thread I作方式4
suspend1。p:
suspend thread()
waiting event
got1。°p;
2.5.2 Inno De12x版本之前的 Master Thread
在了解了1.0x版本之前的 Master Thread的具体实现过程后,细心的读者会发现
InnoDB存储引擎对于IO其实是有限制的,在缓冲池向磁盘刷新时其实都做了一定的硬
编码( hard coding)。在磁盘技术飞速发展的今天,当固态磁盘(SsD)出现时,这种规
定在很大程度上限制了 InnoDB存储引擎对磁盘IO的性能,尤其是写入性能。
从前面的伪代码来看,无论何时, InnodB存储引擎最大只会刷新100个脏页到磁
盘,合并20个插入缓冲。如果是在写入密集的应用程序中,每秒可能会产生大于100
个的脏页,如果是产生大于20个插人缓冲的情况, Master Thread似乎会“忙不过来”,
或者说它总是做得很慢。即使磁盘能在1秒内处理多于100个页的写人和20个插入缓
冲的合并,但是由于 hard coding, Master thread也只会选择刷新100个脏页和合并20
个插入缓冲。同时,当发生宕机需要恢复时,由于很多数据还没有刷新回磁盘,会导致
恢复的时间可能需要很久,尤其是对于 insert buffer来说。
这个问题最初由Goge的工程帅 Mark Callaghan提出,之后 InnoDB官方对其进行
了修正并发布了补丁( patch)。 InnoDB存储引擎的开发团队参考了 Google的 patch,提
供了类似的方法来修正该问题。因此 InnoDB Plugin(从 InnoDB10x版本开始)提供了
参数 innodb io capacity,用来表示磁盘Io的吞吐量,默认值为200。对于刷新到磁盘
页的数量,会按照 innodb_io_capacity的百分比来进行控制。规则如下:
口在合并插人缓冲时,合并插入缓冲的数量为 innodb io capacity值的5%;
口在从缓冲区刷新脏页时,刷新脏页的数量为 innodb io capacity
若用户使用了SSD类的磁盘,或者将几块磁盘做了RAID,当存储设备拥有更高的
IO速度时,完全可以将 innodb 1o capacity的值调得再高点,直到符合磁盘IO的吞吐量
为止。
另一个问题是,参数 innodb max dirty pages pct默认值的问题,在noDB10x
版本之前,该值的默认为90,意味着脏页占缓冲池的90%。但是该值太大”了,因http://blog.csdn.net/jiongyi1
BL
42第2幸加oDB存储引擎
精者哪
为 InnoDB存储引擎在每秒刷新缀冲池和 lush loop时会判断这个值,如果值起争
innodb max dirty pages pct,才刷新100个脏页,如果有很大的内存,或者数据库服务
器的压力很大,这时刷新脏页的速度反而会降低。同样,在数据库的恢复阶段可能需要
更多的时间。
在很多论坛上都有对这个问题的讨论,有人甚至将这个值调到了20或10,然后测
试发现性能会有所提高,但是将 innodb max dirty pages pct调到20或10会增加磁盘
的压力,系统的负担还是会有所增加的。 Google在这个问题上进行了测试,证明20并
不是一个最优值°。而从noDB1.0x版本开始, innodb max dirty pages pct默认值变
为了75,和 Google测试的80比较接近。这样既可以加快刷新脏页的频率,又能保证了
磁盘IO的负载。
InnoDB1.0x版本带来的另一个参数是 innodb adaptive flushing(自适应地刷新),
该值影响每秒刷新脏页的数量。原来的刷新规则是:脏页在缓冲池所占的比例小于
innodb max dirty_ pages_pct时,不刷新脏页;大于 innodb max dirty pages_pct时,刷
新100个脏页。随着 innodb adaptive flushing参数的引入, InnoDB存储引擎会通过一个
名为 buf fush get desired fush rate的函数来判断需要刷新脏页最合适的数量。粗略地
翻阅源代码后发现 buf fush_ get desired flush_ rate通过判断产生重做日志( redo log)的
速度来决定最合适的刷新脏页数量。因此,当脏页的比例小于 innodb max dirty_ pages
pct时,也会刷新一定量的脏页
还有一个改变是:之前每次进行 full purge操作时,最多回收20个Undo页,从
InnoDB10x版本开始引人了参数 innodb purge batch size,该参数可以控制每次ful
purge回收的Undo页的数量。该参数的默认值为20,并可以动态地对其进行修改,具
体如下:
mysq-> SHOW VARIABLES LIKe innodb purge batch size\G;
青古*x;*古★*青者★★计责贵★★;1。xoW★*六;*为★★大k★者k大太青言言内k古k
Variable name: innodb purge batch size
Valte: 20
mysql> SET GLOBAL innodb purge batch size=50
Query OK, c rows affected (0.00 sec)
⊙有兴趣的读者可参考:http://code.google.com/p/google-mysql-tools'wiki/InnodblooItpDiskhttp:/blog.csdnnet/jiongyi11
51.6
2.5 Master7 hread工作方式43
通过上述的讨论和解释我们知道,从 InnoDB1.0x版本开始, Master Thread的伪代
码必将有所改变,最终变成:
void master threaded
goto loop;
loop:
for (int i =0:i<l0; 1++)[
thread sleep(1)// sleep 4 second
do log buffer flush to disk
if(1 ast one second l。s<5旨 innodb io capacity)
do merge 5 innodb io capacity insert buffer
if buf get modified ratio pct >innodb max dirty pages pct
do buffer pool flush 100s innodb io capacity dirty page
else if enable adaptive flush
do buffer pool flush desired amcunt dirty page
if no user activity
goto backgroud lo。p
if last ten second ios <innodb io capacity)
do buffer pool flush 100% innodb ia capacity dirty page
do merge 5s innodb io capacity insert buffer
do log buffer flush to disk
do full purge
if buf get modified ratio pct>70%)
do buffer pool flush 100% innodb io capacity dirty page
else
dobuffer pool flush 103 innodb io capacity dirty page
goto loop
background 1。。p
dc full purge
dc merge 100% innodb io capacity insert buffer
if not idle.
got。1op:
lse
goto flush loop
nuah1a°p
do buffer pool flush 1008 innodb io capacity dirty page
if buf get mod
dified ratio pct>innodb max dirty pages pct
go to flush loop
got。 suspend1o。p
suspend loop:
suspend thread (
walting event
goto1。°p;http://blog.csdn.net/jiongyi1
BL
44第2亨 nnoDB存儲引擎
拼者
很多测试都显示, InnoDB10x版本在性能方面取得了极大的提高,其实这和前
提到的 Master thread的改动是密不可分的,因为 InnoDB存储引擎的核心操作大部分都
集中在 Master Thread后台线程中
从 InnoDB1.0x开始,命令 SHOW ENGINE INNODB STATUS可以查看当前 Master
Thread的状态信息,如下所示:
mysql>SHOW ENGINE INNODB STATUS\G;
★★★★★★★★女★★★★★宽★灾灾寅★★★1
rew★★★★t★★t☆"贸责W★窗案害宽實害
Type: InnoDB
Name i
status
090921 14:24:56 INNODB MONITOR OUTPUT
≡芒≡≡≡≡≡≡≡三
Per second averages calculated from the last 6 seconds
BACKGRQUND THREAD
srv master thread loops: 45 1 second, 45 sleeps, 4 10 second, 6 background, 6 flush
grv master thread log fush and writes: 45 log writes only: 69
这里可以看到主循环进行了45次,每秒挂起(seep)的操作进行了45次(说明负
载不是很大),10秒一次的活动进行了4次,符合1:10。 background loop进行了6次,
Rush loop也进行了6次。因为当前这台服务器的压力很小,所以能在理论值上运行。如
果是在一台压力很大的 MySQL数据库服务器上,看到的可能会是下面的情景:
mysql> show engine innodb status\G;
★★卖★央★★肯央★★★★★★★★★★★★★★“★★1,Y●W
Type: InnoDB
Name
status
三三三三三二三二〓
091009 10:14:34 INNODB MONI TOR OUTPUT
〓〓〓〓〓〓二二二〓〓三〓〓〓〓出二出出出出〓
Per second averages calculated from the last 42 seconds
BACKGROUND THREAD
srv master thread loops: 2188 1 second, 1537 sleeps, 218 1c second, 2
background, 2 flushhttp:/blog.csdnnet/jiongyi11
2.6DoDB关键特性45
srv master thread log flush and writes: 1777 log writes only: 5816
可以看到当前主循环运行了2188次,但是循环中的每秒挂起(slep)的操作只运
行了1537次。这是因为 InnoDe对其内部进行了一些优化,当压力大时并不总是等待1
秒。因此,并不能认为1 second和 sleeps的值总是相等的。在某些情况下,可以通过两
者之间差值的比较来反映当前数据库的负载压力。
253 InnoDB12X版本的 Master thread
在: InnodB12.x版本中再次对 Master Thread进行了优化,由此也可以看出 Master
Thread对性能所起到的关键作用。在 InnoDB1.2x版本中, Master Thread的伪代码
如下:
if InnoDB is idle
srv master do idle tasks i:
e⊥se
srv master do active tasks(i
其中 srv master do_idle_ tasks(O就是之前版本中每10秒的操作, sry master do
active tasks(处理的是之前每秒中的操作。同时对于刷新脏页的操作,从 Master Thread
线程分离到一个单独的 Page Cleaner Thread,从而减轻了 Master Thread的工作,同时进
一步提高了系统的并发性。
2.6 InnoDB关键特性
InnoDB存储引擎的关键特性包括:
口插入缓冲( Insert Buffer)
口两次写( Double write)
口自适应哈希索引( Adaptive Hash Index)
异步IO( Async IC
日刷新邻接页( Flush Neighbor Page)
上述这些特性为 InnoDB存储引擎带来更好的性能以及更高的可靠性。http://blog.csdn.net/jiongyi1
5
46第2章moDB存储引擎
26.1插入缓冲
1. Insert Buffer
Insert Buffer可能是 InnoDB存储引擎关键特性中最令人激动与兴奋的一个功能。不
过这个名字可能会让人认为插人缓冲是缓冲池中的一个组成部分。其实不然, InnoDB缓
冲池中有 Insert Buffer信息固然不错,但是 Insert Buffer和数据页一样,也是物理贞的
个组成部分
在 InnoDB存储引擎中,主键是行唯一的标识符。通常应用程序中行记录的插入顺
序是按照主键递增的顺序进行插入的。因此,插入聚集索引( Primary Key)一般是顺序
的,不需要磁盘的随机读取。比如按下列SQL定义表:
CREATE TABLE t
a INT AUTO INCREMENT,
b VARCHAR(30)
PRIMARY KEY【a)
其中a列是自增长的,若对a列插入NULL值,则由于其具有 AUTO INCREMENT
属性,其值会自动增长。同时页中的行记录按a的值进行顺序存放。在一般情况下,不
需要随机读取另一个页屮的记录。因此,对于这类情况下的插入操作,速度是非常快的
注意并不是所有的主键插入都是顺序的。若主键类是UUID这样的类,那么
插入和辅助索引一样,同样是随机的。即使主键是自増类型,但是插入的是指
定的值,而不是NULL值,那么同样可能导致插入并非连续的情况
但是不可能每张表上只有一个聚集索引,更多情况下,一张表上有多个非聚集的辅
助索引( secondary index)。比如,用户需要按照b这个字段进行查找,并且b这个字段
不是唯一的,即表是按如下的SQL语句定义的
CREATE TABLE t
a INT AUTO INCREMENT,
h VARCHAR(30)
PRIMARY KEY (a)
key(b
在这样的情况下产生了一个非聚集的且不是唯一的索引。在进行插入操作时,数据http:/blog.csdnnet/jiongyi11
26 InnoDB关健特性47
页的存放还是按主键a进行顺序存放的,但是对于非聚集索引叶子节点的插入不再是顺
序的了,这时就需要离散地访问非聚集索引页,由于随机读取的存在而导致了插入操作
性能下降。当然这并不是这个b字段上索引的错误,而是因为B+树的特性决定了非聚
集索引插入的离散性。
需要注意的是,在某些情况下,辅助索引的插人依然是顺序的,或者说是比较顺序
的,比如用户购买表中的时间字段。在通常情况下,用户购买时间是一个辅助索引,用
来根据时间条件进行查询。但是在插入时却是根据时间的递增而插入的,因此插入也是
“较为”顺序的。
InnoDB存储引擎开创性地设计了 Insert buffer,对于非聚集索引的插入或更新操作,
不是每一次直接插入到索引页中,而是先判断插入的非聚集索引页是否在缓冲池中,若
在,则直接插入;若不在,则先放人到一个 Insert buffer对象中,好似欺骗。数据库这
个非聚集的索引已经插到叶子节点,而实际并没有,只是存放在另一个位置。然后再以
定的频牽和情况进行 Insert Buffer和辅助索引页子节点的 nerge(合并)操作,这时通
常能将多个插入合并到一个操作中(因为在一个索引页中),这就大大提高了对于非聚
集索引插入的性能
然而 Insert buffer的使用需要同时满足以下两个条件:
口索引是辅助索引( secondary index)
口索引不是唯一( unique)的。
当满足以上两个条件时, InnodB存储引擎会使用 Insert Buffer,这样就能提高插入
操作的性能了。不过考虑这样一种情况:应用程序进行大量的插入操作,这些都涉及了
不唯一的非聚集索引,也就是使用了 Insert Buffer若此时 MySQL数据库发生了宕机,
这时势必有大量的 Insert Buffer并没有合并到实际的非聚集索引中去。因此这时恢复可
能需要很长的时间,在极端情况下甚至需要几个小时。
辅助索引不能是唯一的,因为在插入缓冲时,数据库并不去查找索引页来判断插入
的记录的唯一性。如果去查找肯定又会有离散读取的情况发生,从而导致 Insert Buffer
失去了意义。
用户可以通过命令 SHOW ENGⅠ NE INNODB STATUS来查看插入缓冲的信息:
mysql>SHOW ENGINE INNODB STATUS\G:
“★★★★★大★★★共★1.xoW古*南古幽古★幽★★★★★★女★★女*★★为★★http://blog.csdn.net/jiongyi1
BL
48第2章loDB存储引擎
折考翻
Type: InnoDB
Nare
Sta七us:
〓〓〓〓〓〓出〓一三三三三一一三三三三篇
10072722: 21: 48 INNODB MONITOR OUTPUT
=〓〓〓三=〓〓〓
Per second averages calculated from the last 44 seconds
INSERT BUFFER AND ADAPTIVE HASH INDEX
Ibuf: size 7545, free list len 3790, seg size 11336,
8075308 inserts, 7540969 merged recs, 2246304 merges
END OF INNODB MONITOR OUTPU
三三名≡三三三三三三三三三三兰三三三三三
1 row in set(0.00 secI
seg size显示了当前 Insert Buffer的大小为11336×16KB,大约为177MB; free list
len代表了空列表的长度;size代表了已经合并记录页的数量。而黑体部分的第2行
可能是用户真正关心的,因为它显示了插入性能的提高。 Inserts代表了插人的记录数;
merged recs代表了合并的插入记录数量; merges代表合并的次数,也就是实际读取页的
次数。 merges: merged recs大约为1:3,代表了插入缓冲将对于非聚集索引页的离散Io
逻辑请求大约降低了2/3。
正如前面所说的,目前 Insert Buffer存在一个问题是:在写密集的情况下,插入缓
冲会占用过多的缓冲池内存( innodb buffer_ pool),默认最大可以占用到1/2的缓冲池内
存。以下是 InnoDB存储引擎源代码中对于 insert buffer的初始化操作:
/* Buffer pool size per the maximum insert buffer size *
define BUf Pool sIZE PER MAX siZe
ibuf->max size buf pool get curr size()/ UNIV PAGE SIZE
A IBUF POOL SIZE PER MAX SIZE;
这对于其他的操作可能会带来一定的影响。 Percona上发布一些 patch来修正插入
缓冲占用太多缓冲池内存的情况,具体可以到 Percona官网进行查找。简单来说,修改
IBUF POOL SIZE PER MAX SIZE就可以对插入缓冲的大小进行控制。比如将IBUFhttp:/blog.csdnnet/jiongyi11
51.6
26 innoDB关健特性49
部拼吾
POOL SIZE PER MAX SIZE改为3,则最大只能使用1/3的缓冲池内存
2. Change Buffer
InnoDB从1.0x版本开始引入了 Change Buffer,可将其视为 Insert Buffer的升级。
从这个版本开始, InnoDB存储引擎可以对DML操作— INSERT、 DELETE、 UPDATE
都进行缓冲,他们分别是: Insert buffer、 Delete Buffer、 Purge buffer
当然和之前 Insert Buffer一样, Change Buffer适用的对象依然是非唯的辅助索引。
对一条记录进行 UPDATE操作可能分为两个过程:
口将记录标记为已删除;
口真正将记录删除。
因此 Delete Buffer对应 UPDATE操作的第一个过程,即将记录标记为删除。 Purge
Buffer对应 UPDATE操作的第二个过程,即将记录真正的删除。同时, InnoDB存储引
擎提供了参数 innodb change buffering,用来开启各种 Buffer的选项。该参数可选的值
为: Inserts、 deletes、 purges、 changes、all、 nones inserts、 deletes、 purges就是前面讨
论过的三种情况。 changes表示启用 Inserts和 deletes,al表示启用所有,none表示都不
启用。该参数默认值为all。
从 InnoDB1.2x版本开始,可以通过参数 innodb change buffer max size来控制
Change Buffer最大使用内存的数量
mysql> SHOW VARIABLES LIKe innodb change buffer max size'\G:
害青青吉青青实责实曹责★卖度★★1.工。W*责青實★青责害安★责★责肯☆发★☆★文女★
Variable name: innodb change buffer max size
Value: 25
1 row ln set〔0.00sec
innodb change buffer max_size值默认为25,表示最多使用1/4的缓冲池内存空间。
而需要注意的是,该参数的最大有效值为50
在 MySQL55版本中通过命令 SHOW ENGINEⅠ NNODB STATUS,可以观察到类似
如下的内容
mysql> SHOW ENGINE INNODB STATUS\G:
★安灾*安史害贵害责责★★★青★★★1,row★★舞肉★★肉★★★★★★★★★舟★t★★★实
Type:nn。DB
INSERT BUFFER AND ADAPTIVE HASH INDEXhttp:/blog.csdnnet/jiongyi11
EI
50郭2章DB存倍引擎
Ibuf: size l free list len 34397, seg size 34399,10875 merges
merged operations
usert 20452, delete mark 20158, delete 4215
discarded operations:
insert o, delete mark o, delese 0
可以看到这里显示了 merged operations和 discarded operation,并且下面具体显
示 Change Buffer中每个操作的次数 Insert表示 Insert buffer; delete mark表示 Delete
Buffer; delete表示 Purge Buffer; discarded operations表示当 Change buffer发生 merge
时,表已经被删除,此时就无需再将记录合并( merge)到辅助索引中了。
3. nsert Buffer I的内部实现
通过前一个小节读者应该已经知道了 Insert buffer的使用场景,即非唯一辅助索引
的插入操作。但是对于 Insert buffer具体是什么,以及内部怎么实现可能依然模糊,这
正是本节所要阐述的內容。
可能令绝大部分用户感到吃惊的是, Insert Buffer的数据结构是一棵B+树。在
MySQL41之前的版本中每张表有一棵 Insert Buffer b+树。而在现在的版本中,全局只
有一棵 Insert Buffer B树,负责对所有的表的辅助索引进行 Insert Buffer。而这棵B+树
存放在共享表空间中,默认也就是 iodate1中,因此,试图通过独立表空间ibd文件恢复
表中数据时,往往会导致 CHECK TABLE失败。这是因为表的辅助索引中的数据可能还
在 Insert Buffer中,也就是共享表空间中,所以通过ibd文件进行恢复后,还需要进行
REPAIR TABLE操作来重建表上所有的辅助索引。
Insert Buffer是一棵B+树,因此其也由叶节点和非叶节点组成。非叶节点存放的是
查询的 search key(键值),其构造如图2-3所示。
marker
offset
图23 Insert buffer非叶节点中的 search key
search key一共占用9个字节,其中 space表示待插入记录所在表的表空间id,在
InnodB存储引擎中,每个表有一个唯一的 space id,可以通过 space id查询得知是哪张
表。pace占用4字节。 marker占用I字节,它是用来兼容老版本的 Insert Buffer。 offset
表示页所在的偏移量,占用4字节。http:/blog.csdnnet/jiongyi11
51.6
26mDB关分性5f
拼吾
当一个辅助索引要插人到页( space,oset)时,如果这个贞不在缓冲池中,那
InnoDB存储引擎首先根据上述规则构造一个 search key,接下来查询 Insert Buffer这棵
B+树,然后再将这条记录插入到 Insert Buffer b+树的叶子节点中。
对于插入到 Insert Buffer B+树叶子节点的记录(如图24所示),并不是直接将待插
人的记录插人,而是需要根据如下的规则进行构造
space marker offset metadata
secondary index record
图24 Insert Buffer叶子节点中的记录
space、 marker、 page no字段和之前非叶节点中的含义相同,一共占用9字节。第
4个字段 metadata占用4字节,其存储的内容如表22所示。
表2-2 metadata字段存情的内容
名称
字节
IBUF REC OFFSET COUNT
?
IBU REC OFFSET TYPE
IBUF REC OFFSET FLAGS
IBUF REC OFFSET COUNT是保存两个字节的整数,用来排序每个记录进入
Insert buffer的顺序。因为从 InnoDB1.0.x开始支持 Change Buffer.,所以这个值同样记录
进入 Insert Buffer的顺序。通过这个顺序回放( replay)才能得到记录的正确值。
从 Insert Buffer叶子节点的第5列开始,就是实际插入记录的各个字段了。因此较
之原插人记录, Insert Buffer+树的叶子节点记录需要额外13字节的开销。
因为启用 Insert Buffer索引后,辅助索引页( space, page no)中的记录可能被插入
到 Insert Buffer B+树中,所以为了保证每次 Merge Insert Buffer页必须成功,还需要有
个特殊的页用来标记每个辅助索引贞( space, page no)的可用空间。这个页的类型
为 Insert Buffer Bitmap
每个 nsert Buffer Bitmap页用来追踪16384个辅助索引页,也就是256个区
Extent)。每个 Insert Buffer Bitmap页都在16384个页的第二个页中。关于 Insert Buffer
Bmap页的作用会在下一小节中详细介绍。
每个辅助索引页在 Insert Buffer Bitmap页中占用4位(bit),由表2-3中的三个部分http://blog.csdn.net/jiongyi1
BI
52茅2乎加nDB存儲引擎
部拼没
组成。
表23每个辅助索引页在 nsert Buffer Bitmap中存储的信息
名称
大小(bi)
说明
表示该辅助索引页中的可用空间数量,可取值为:
口0表示无可用剩余空间
IBUF BITMAP FREE
口1表示剩余空间大于1/32页(512字节)
口2表示剩余空间大于116页
口3表示剩余空间大于18页
IBUF BITMAP BUFFERED
1表示该辅助索引页有记录被缓存在 Insert Buffer b+树中
IBUF BITMAP BUF
L表示该页为 Insert Buffer B+树的索引页
4. Merge Insert Buffer
通过前面的小节读者应该已经知道了 Insert/Change Buffer是一棵B+树。若需要实
现插入记录的辅助索引页不在缓冲池中,那么需要将辅助索引记录首先插入到这棵B+
树中。但是 Insert Buffer中的记录何时合并( merge)到真正的辅助索引中呢?这是本小
节需要关注的重点。
概括地说, Merge Insert Buffer的操作可能发生在以下几种情况下;
口辅助索引页被读取到缓冲池时;
口 Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时;
口 Master Thread
第一种情况为当辅助索引页被读取到缓冲池中时,例如这在执行正常的 SELECT查
洵操作,这时需要检查 Insert Buffer Bitmap页,然后确认该辅助索引页是否有记录存放
于 Insert Buffer b+树中。若有,则将 Insert Buffer b+树中该页的记录插入到该辅助索引
页中。可以看到对该页多次的记录操作通过一次操作合并到了原有的辅助索引页中,因
此性能会有大幅提高。
Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间,并至少有/32页的空
间。若插入辅助索引记录时检测到插人记录后可用空间会小于1/32页,则会强制进行一
个合并操作,即强制读取辅助索引页,将 Insert Buffer B+树中该页的记录及待插人的记
录插人到辅助索引页中。这就是上述所说的第二种情况。
还有一种情况,之前在分析 Master thread时曾讲到,在 Master Thread线程中每秒
或每10秒会进行一次 Merge Insert Buffer的操作,不同之处在于每次进行 merge操作的
页的数量不同。http:/blog.csdnnet/jiongyi11
5I.A
2.6moDB关健特性53
拼吾
在 Master Thread中,执行mg操作的不止是一个页,而是根据 srv inno
capactiy的百分比来决定真正要合并多少个辅助索引页。但 InnoDB存储引擎又是根据怎
样的算法来得知需要合并的辅助索引页呢?
在 Insert Buffer B+树中,辅助索引页根据( space,oset)都已排序好,故可以
根据( space, offset)的排序顺序进行页的选择。然而,对于 Insert Buffer页的选择,
InnoDB存储引擎并非采用这个方式,它随机地选择 Insert Buffer B+树的一个页,读取
该页中的 space及之后所需要数量的页。该算法在复杂情况下应有更好的公平性
时,若进行 merge时,要进行 merge的表已经被删除,此时可以直接丢弃已经被nser
Change Buffer的数据记录。
2.62两次写
如果说 Insert Buffer带给 InnoDB存储引擎的是性能上的提升,那么 doublewrite(两
次写)带给 InnoDe存储引擎的是数据页的可靠性。
当发生数据库宕机时,可能 InnoDB存储引擎正在写入某个页到表中,而这个页只
写了一部分,比如16KB的页,只写了前4KB,之后就发生了岩机,这种情况被称为部
分写失效( partial page write。在 InnoDB存储引擎未使用 doublewrite技术前,曾经出
现过因为部分写失效而导致数据丢失的情况。
有经验的DBA也许会想,如果发生写失效,可以通过重做日志进行恢复。这是一
个办法。但是必须清楚地认识到,重做日志中记录的是对页的物理操作,如偏移量800,
写'aa'记录。如果这个页本身已经发生了损坏,再对其进行重做是没有意义的。这
就是说,在应用( apply)重做日志前,用户需要一个页的副本,当写入失效发生时,先
通过页的副本来还原该页,再进行重做,这就是 doublewrite。在 InnoDB存储引擎中
doublewrite的体系架构如图25所示。
doublewrite由两部分组成,一部分是内存中的 doublewrite buffer,大小为2MB,另
部分是物理磁盘上共享表空间中连续的128个贞,即2个区( extent),大小同样为
2MB。在对缓冲池的脏页进行刷新时,并不直接写磁盘,而是会通过 memcpy函数将
脏页先复制到内存中的 doublewrite buffer,之后通过 doublewrile buffer再分两次,每次
IMB顺序地写人共享表空间的物理磁盘上,然后马上调用fyne函数,同步磁盘,避免
缓冲写带来的问题。在这个过程中,因为 doublewrite页是连续的,因此这个过程是顺序http://blog.csdn.net/jiongyi1
6I
54募2章加oDB存储引
部拼没
doublewrite butier
(2MB)
Pe
copy
内存实例
write
doublewrite
doublewrite
〔IMB)
(IMB)
recovery
共亨表空间
数据文件(bd)
图2-5 InnoDB存储引擎 doublewrite架构
写的,开销并不是很大。在完成 doublewrite页的写人后,再将 doublewrite buffer中的页
写人各个表空间文件中,此时的写入则是离散的。可以通过以下命令观察到 doublewritc
运行的情况:
mysql>SHON GLCBAL STATUS LIKE 'innodb dblwr&' \G
青青实青害责青责★六★内★★大肯古青青南南肉1.工w★★卉★青
Variable name: Innodb dblwr pages written
Value:6325194
★女★贵文贵大发女宽★史★★★2,roW★★章★★★★★管★世文★史史★女攻★★★女★
Variable name: Innodb dblwr writes
Va1ue:100399
2 rows in set (0.00 sec)
可以看到, doublewrite一共写了6325194个页,但实际的写入次数为100399,基
本上符合64:1。如果发现系统在高峰时的 Innodb dblwr pages written: Innodb dblwr
writes远小于64:l,那么可以说明系统写入压力并不是很高。
如果操作系统在将页写人磁盘的过程中发生了崩溃,在恢复过程中, InnoDB存储引
擎可以从共享表空间中的 doublewrite中找到该页的一个副本,将其复制到表空间文件,
再应用重做日志。下面显示了一个由 doublewrite进行恢复的情况:
090924 11: 36: 32 mysgld restarted
090924 11: 36: 33 InnoDB: Database was not shut down normally!
InnoDB: Starting crash recovery
Inno DB: Reading tablespace information from the ibd files
InnoDB Crash recovery may have failed for some . ibd fileshttp:/blog.csdnnet/jiongyi11
2.6 anoDE类健特性55
拼翻
InnoDB: Restoring possible half-written data pages from the doublewrite
Innodb buffer.
若查看 MySQL官方手册,会发现在命令 SHOW GLOBAL STATUS中 Innodb
buffer pool pages hushed变量表示当前从缓冲池中刷新到磁盘页的数量。根据之前的
介绍,用户应该了解到,在默认情况下所有页的刷新首先都需要放入到 doublewrite中,
因此该变量应该和 Innodb dblwr pages written-致。然而在 MySQL5524版本之前,
Innodb buffer pool pages flushed总是为 Innodb dblwr_ pageswritten的2倍,而此Bug
直到 MySQL5524才被修复。因此用户若需要统计数据库在生产环境中写入的量,最安
全的方法还是根据 Innodb dblwr pages written来进行统计,这在所有版本的 MySQL数
据库中都是正确的。
参数 skip innodb doublewrite可以禁止使用 doublewrite功能,这时可能会发生
前面提及的写失效问题。不过如果用户有多个从服务器( slave server),需要提供较
快的性能(如在s! aves erver上做的是RAID0),也许启用这个参数是一个办法。不过
对于需要提供数据高可靠性的主服务器( master server),任何时候用户都应确保开启
doublewrite功能。
注意有些文件系统本身就提供了部分写失效的防范机制,如ZFS文件系统。
在这种情况下,用户就不要启用 doublewrite了。
263自适应哈希索引
哈希(hash)是一种非常快的查找方法,在一般情况下这种查找的时间复杂度为
O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数,取决于B+树的高
度,在生产环境中,B+树的高度一般为3~4层,故需要3~4次的查询。
InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带
来速度提升,则建立哈希索引,称之为自适应哈希索引( Adaptive Hash Index,AH)。
AHI是通过缓冲池的B+树页构造而来,因此建立的速度很快,而且不需要对整张表构
建哈希索引。 InnoDE存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立
哈希索引。
AHI有一个要求,即对这个页的连续访问模式必须是一样的。例如对于(a,b)这http://blog.csdn.net/jiongyi1
BI
56第2章⑩ODB存储引擎
研鲫
样的联合索引页,其访问模式可以是以下情况:
口 WHERE a=xxx
O whERE a=xxx and b=XXX
访问模式一样指的是查询的条件一样,若交替进行上述两种查询,那么 Inon dB存
储引擎不会对该页构造AHI。此外A还有如下的要求:
口以该模式访问了100次
口页通过该模式访问了N次,其中N=页中记录*1/16
根据 InnoDB存储引擎官方的文档显示,启用AHI后,读取和写入速度可以提高2
倍,辅助索引的连接操作性能可以提高5倍。毫无疑问,AH是非常好的优化模式,其
设计思想是数据库自优化的( self-tuning),即无需DBA对数据库进行人为调整
通过命令 SHOW ENGINE INNODB STATUS可以看到当前AH的使用状况:
mysql>SHOW ENGINE INNODB STATUS \G;
★★南★内南由古内古计古古古肯古★★★★青★★1,r○w★★★★★·★★★★甘音由甘当出
status
一〓兰兰三〓三二〓
090922 11: 52: 51 INNODB MONI TOR OUTPUT
〓二〓〓二二〓二二二二二〓-〓〓一三≡≡無無無≡
Per second averages calculated from the last 15 seconds
INSERT BUEFER AND ADAPTIVE HASH INDEX
Ibuf: size 2249, free list len 3346, seg size 5596
374650 inserts, 5189 merged recs, 14300 merges
Hash table size 4980499, node heap has 1246 buffer(s)
1640.60 hash searches/a, 3709. 46 non-hash searches/a
现在可以看到AHI的使用信息了,包括AH的大小、使用情况、每秒使用AHI搜
索的情况。值得注意的是,哈希索引只能用来搜索等值的査询,如 SELECT* FROM table
WhERE index col=xX而对于其他查找类型,如范围查找,是不能使用哈希索引的,
因此这里出现了non- hash searches/s的情况。通过 hash searches:non- hash searches可以大
概了解使用哈希索引后的效率。
由于AH是由 InnoDB存储引擎控制的,因此这里的信息只供用户参考。不过用户
可以通过观察 SHOW ENGINE INNODB STATUS的结果及参数 innodb adaptive hashhttp://blog.csdn.net/jiongyi1
5
2.6mDB关健特姓57
index来考虑是禁用或启动此特性,默认AHI为开启状态
2.64异步|
为了提高磁盘操作性能,当前的数据库系统都采用异步I( Asynchronous IO,
AIO)的方式来处理磁盘操作。 InnoDB存储引擎亦是如此。
与AIO对应的是 Sync I0,即每进行一次⑩o操作,需要等待此次操作结束才能继续
接下来的操作。但是如果用户发出的是一条索引扫描的查询,那么这条SQL查询语句可
能需要扫描多个索引页,也就是需要进行多次的IO操作。在每扫描一个页并等待其完
成后再进行下一次的扫描,这是没有必要的。用户可以在发出一个IO请求后立即再发
出另一个1O请求,当全部IO请求发送完毕后,等待所有IO操作的完成,这就是AIO
AIO的另一个优势是可以进行 IO Merge操作,也就是将多个IO合并为1个IO,这
样可以提高IOPS的性能。例如用户需要访问页的( space, page no)为:
(8,6)、(8,7),(8,8)
每个页的大小为16KB,那么同步IO需要进行3次10操作。而AIO会判断到这三
个页是连续的(显然可以通过( space, page no)得知)。因此Ao底层会发送一个Io
请求,从(8,6)开始,读取48KB的页。
若通过 Linux操作系统下的 lestat命令,可以通过观察mqm/和wrqm/,例如:
avg-cpu:usex影nice号 system告⊥wait8stea1idLe
4.70
0,00
1,603,20
0,0080,50
Devlce
rrgm/s
wram/s
r/s
w/s
rMB/s
wMB/s avgrq-sz avgqu-sz
await systm告uti1
sdc
3905.67172.00910.33466.67168.81
18.15
51,9
19.17
2.590.1397.73
在 InnoDB11x之前,AIO的实现通过 InnoDB存储引擎中的代码来模拟实现。而从
InnoDB1.1.x开始( InnoDB Plugin不支持),提供了内核级别AIO的支持,称为 Native
AIO。因此在编译或者运行该版本 MySQL时,需要ibao库的支持。若没有则会出现如
下的提示:
/usr/local/mysql/bin/mysqld: error while loading shared libraries: libai.so. 1
cannot open shared object file: No such file or directory
需要注意的是, Native AIo需要操作系统提供支持。 windows系统和 Linux系统都http://blog.csdn.net/jiongyi1
5
58第2幸moDB存储引擎
提供 Native alo支持,而 Mac OSX系统则未提供。因此在这些系统下,依旧尽能使用
原模拟的方式。在选择 MySQL数据库服务器的操作系统时,需要考虑这方面的因素。
参数 innodb usc native aio用来控制是否启用 Native Alo,在 Linux操作系统下,
默认值为ON:
mysql> SHOW VARIABLES LIKE 'innodb use native aio'\G;
★★★青★★★实★★★★★★★★肉★★★典*1,。w·★★★★★★★★★★★★南南南★★★★★★★★
Variable name: innodb use native aio
Value: ON
1 row in set (0.00 sec)
用户可以通过开启和关闭 Native aio功能来比较 InnoDB性能的提升。官方的测试
显示,启用 Native aic,恢复速度可以提高75%。
在 InnoDB存储引擎中, read ahead方式的读取都是通过AIO完成,脏页的刷新,
即磁盘的写人操作则全部由AIO完成
2.65刷新邻接页
InnoDb存储引擎还提供了 Flush Neighbor Page(刷新邻接页)的特性。其工作原理
为:当刷新一个脏页时, InnoDB存储引擎会检测该页所在区( extent)的所有页,如果
是脏页,那么一起进行刷新。这样做的好处显而易见,通过AIO可以将多个1O写人操
作合并为一个⑩O操作,故该工作机制在传统机械磁盘下有着显著的优势。但是需要考
虑到下面两个问题:
口是不是可能将不怎么脏的页进行了写人,而该页之后又会很快变成脏页?
口固态硬盘有着较高的IOPs,是否还需要这个特性?
为此, InnoDB存储引擎从12x版本开始提供了参数 innodb fush neighbors,用
来控制是否启用该特性。对于传统机械硬盘建议启用该特性,而对于固态硬盘有着超高
IOPS性能的磁盘,则建议将该参数设置为0,即关闭此特性。
27启动、关闭与恢复
InnoDB是 MySQL数据库的存储引擎之一,因此 InnoDB存储引擎的启动和关闭,
更准确的是指在 MySQL实例的启动过程中对 InnoDB存储引擎的处理过程。http:/blog.csdnnet/jiongyi11
51.6
27启动、类闭与恢复59
在关闭时,参数 innodb fast shutdown影响着表的存储引擎为ImDB的行为该参
数可取值为0、1、2,默认值为1。
口0表示在 MySQL数据库关闭时, InnoDB需要完成所有的 full purge和 merge
insert buffer,并且将所有的脏页刷新回磁盘。这需要一些时间,有时甚至需要几
个小时来完成。如果在进行 InnoDB升级时,必须将这个参数调为0,然后再关
闭数据库
口I是参数 innodb fast shutdown的默认值,表示不需要完成上述的 full purge和
merge insert buffer操作,但是在缓冲池中的一些数据脏还是会刷新回磁盘。
口2表示不完成 full purge和 merge insert buffer操作,也不将缓冲池中的数据脏页
写回磁盘,而是将日志都写人日志文件。这样不会有任何事务的丢失,但是下次
MYSQL数据库启动时,会进行恢复操作( recovery)。
当正常关闭 MySQL数据库时,下次的启动应该会非常“正常”。但是如果没有正常
地关闭数据库,如用ki命令关闭数据库,在 MySQL数据库运行中重启了服务器,或
者在关闭数据库时,将参数 innodb fast shutdown设为了2时,下次 MYSQL数据库启动
时都会对 InnoDE存储引擎的表进行恢复操作。
参数 innodb force recovery影响了整个 InnoDB存储引擎恢复的状况。该参数值默认
为0,代表当发生需要恢复时,进行所有的恢复操作,当不能进行有效恢复时,如数据页
发生了 corruption, MySQL数据库可能发生宕机( crash),并把错误写入错误日志中去。
但是,在某些情况下,可能并不需要进行完整的恢复操作,因为用户自己知道怎
么进行恢复。比如在对一个表进行 alter table操作时发生意外了,数据库重启时会对
InnoDB表进行回溶操作,对于一个大表来说这需要很长时间,可能是几个小时。这时用
户可以自行进行恢复,如可以把表删除,从备份中重新导入数据到表,可能这些操作的
速度要远远快于回滚操作。
参数 innodb force_ recovery还可以设置为6个非零值:1~6。大的数字表示包含了
前面所有小数字表示的影响。具体情况如下:
彐1( SRV FORCE_ IGNORE CORRUPT):忽略检査到的 corrupt页。
日2( SRV FORCE NO BACKGROUND):阻止 Master Thread线程的运行,如 Master
Thread线程需要进行 full purge操作,而这会导致 crash
凵3( SRV FORCE NO TRX UNDO):不进行事务的回滚操作。http://blog.csdn.net/jiongyi1
5
60第2幸 InnoDB存储引擎
口4( SRV FORCE NO IBUF MERGE):不进行插人缓冲的合并操作。齟
口5( SRV FORCE NO UNDO LOG SCAN):不查看撤销日志( Undo Log), InnoDB
存储引擎会将未提交的事务视为已提交。
口6( SRV FORCE NO LOG REDO):不进行前滚的操作。
需要注意的是,在设置了参数 innodb force recovery大于0后,用户可以对表进行
select、 create和drop操作,但 insert、 update和 delete这类DML操作是不允许的。
现在来做一个实验,模拟故障的发生。在第一个会话中( session),对一张接近
1000万行的 InnoDB存储引擎表进行更新操作,但是完成后不要马上提交:
mysql>START TRANSACTION;
Query OK, 0 rcws affected (0.00 sec)
mysql>UPDATE Profile set password=''i
Query OK, 9587770 rows affected (7 min 55.73 sec)
Rows matched: 9999248 Changed: 9587770 Warnings: 0
START TRANSACTION语句开启了事务,同时防止了自动提交( auto commit)的
发生, UPDATE操作则会产生大量的UNDO日志( undo log)。这时,人为通过k'命令
杀掉 MySQL数据库服务器:
lrootenineyoud-43]f ps -ef i grep mysqld
r。t
28007
1 0 13: 40 pts/1 00: 00: 00 /bin/sh /bin/mysgld safe --datadir
usr/local/mysql/data --pid-file=/usr/local/mysql/data/nineyou0-43pid
mysql 28045 28007 42 13: 40 pts/1 00: 04: 23 /usr/local/mysql/bin/mysqld - basedir
=/usr/local/mysql --datadir=/usr/local/mysql/data --user=mysql --pid-file=/usr/
local/mysql/data/nineyou0-43-pid --skip-external-locking --port=3306 --socket=/tmp/
mysql, sock
root
2811026963013:50pts/1100:00:00 grep mysqld
[rootenineyoud-43 M ]f kill -9 28007
[raotenineyou -43 N]# kill -9 28045
通过kl令可以模拟数据库的宕机操作。下次 MySQL数据库启动时会对之前的
UPDATE事务进行回滚操作,而这些信息都会记录在错误日志文件(默认后缀名为er
中。如果查看错误日志文件,可得如下结果:
090922 13: 40: 20 InnoDB: Started; log sequence number 6 2530474615
InnoDB: Starting in background the rollback of uncommitted transactions
090922 13: 40: 20 InnoDB: Rolling back trx with id 0 5281035, 8867280 rows to undo
InnoDB: Progress in percents: 1090922 13: 40: 20http://blog.csdnnet/jiongyi1
BL
2.8小结61
090922 13: 40: 20 [Notel /usr/local/mysql/bin/mysqld: ready for connections.
version: 5.0.45-log socket: */tmp/mysql, sock port: 3306 MySQI, Community
Server ' GPL)
23456789101112131415161718192021222324252627282930
31323334353637383940414243444546474849505152535455565758
59606162636465666768697071727374757677787980818283848586
87888990919293949596979899100
InnoDB: Rolling back of trx id0 5281035 completed
090922 13:49:21 InnoDB: Rollback of non-prepared transactions completed
可以看到,采用默认的策略,即将 innodb force recovery设为0, InnoDB会在每次
启动后对发生问题的表进行恢复操作。通过错误日志文件,可知这次回滚操作需要回滚
8867280行记录,差不多总共进行了9分钟。
再做一次同样的测试,只不过这次在启动 MySQL数据库前,将参数 innodb force
recovery设为3,然后观察 nodE存储引擎是否还会进行回滚操作。査看错误F志文
件,可得:
090922 14: 26: 23 InncDB: started: log sequence number 7 2253251193
InnoDB: !!innodb force recovery is set to 3!!
090 22 14: 26: 23 INotel /usr/local/mysql/bin/mysgld: ready for connections
Version: 5.0. 45-log socket: /tmp/mysql. sock'
port
3306
My SQL Community
server (GPL)
这里出现了“!!y,moDB警告已经将 innodb_force_recovery设置为3,不会进行
回滚操作了,因此数据库很快启动完成了。但是用户应该小心当前数据库的状态,并仔
细确认是否不需要回滚事务的操作。
28小结
本章对 InnoDb存储引擎及其体系结构进行了概述,先给出了 InnoDB存储引擎的
历史、 InnoDB存储引擎的体系结构(包括后台线程和内存结构);之后又详细介绍了
InnoDB存储引擎的关键特性,这些特性使 InnoDB存储引擎变得更具“魅力”;最后介
绍了启动和关闭 MYSQL时一些配置文件参数对 InnoDB存储引擎的影响
通过本章的铺垫,读者在学习后面的内容时就会对 InnoDB引擎理解得更深入和更
全面。第3章开始介绍 MySQL的文件,包括 MySQL本身的文件和与 InnoDB存储引擎
本身有关的文件。之后本书将介绍基于 InnoDB存储引擎的表,并揭示内部的存储构造http:/blog.csdnnet/jiongyi11
5I.A
部拼没要
第3章文件
本章将分析构成 MySQL数据库和 InnoDB存储引擎表的各种类型文件。这些文件
有以下这些。
口参数文件:告诉 MySQL实例启动时在哪里可以找到数据库文件,并且指定某些
初始化参数,这些参数定义了某种内存结构的大小等设置,还会介绍各种参数的
类型
口日志文件:用来记录 MySQL实例对某种条件做出响应时写人的文件,如错误日
志文件、二进制日志文件、慢査询日志文件、查询日志文件等。
口 socket文件:当用UNIX域套接字方式进行连接时需要的文件。
口pid文件: MySQL实例的进程I文件。
口 My SQL表结构文件:用来存放 MySQL表结构定义文件。
口存储引擎文件:因为 MySQL表存储引擎的关系,每个存储引擎都会有自己的文
件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍
与 InnoDB有关的存储引擎文件。
3.1参数文件
在第1章中已经介绍过了,当 MySQL实例启动时,数据库会先去读一个配置参数
文作,用来寻找数据库的各种文件所在位置以及指定某些初始化参数,这些参数通常定
义了某种内存结构有多大等。在默认情况下, MYSQL实例会按照一定的顺序在指定的位
置进行读取,用户只需通过命令mysq-help| grep my cnf来寻找即可。
MySQL数据库参数文件的作用和 Oracle数据库的参数文件极其类似,不同的是,
Oracle实例在启动时若找不到参数文件,是不能进行装载( mount)操作的。 MySQL稍
微有所不同, MySQL实例可以不需要参数文件,这时所有的参数值取决于编译 MySQL
时指定的默认值和源代码中指定参数的默认值。但是,如果 MySQL实例在默认的数据http:/blog.csdnnet/jiongyi11
5I
3.参数文件63
库目录下找不到mysq架构,则启动同样会失贩,此时可能在错误国志文件找到如形
内容:
090922 16:25: 52 mysqld started
090922 16: 25: 53 InnODB: Started; lcg sequence number 8 2801063211
InnoDB: !! innodb force recovery is set to 1!!!
090922 16:25:53 [ERROR] Fatal error: Can't open ard lock privilege tables
Table mysql. host t exist
090922 16: 25: 53 mysqld ended
MySQL的 mysql架构中记录了访问该实例的权限,当找不到这个架构时, MySQL
实例不会成功启动。
MySQL数据库的参数文件是以文本方式进行存储的。用户可以直接通过一些常用
的文本编辑软件(如ⅵ和 emacs)进行参数的修改
3.11什么是参数
简单地说,可以把数据库参数看成一个键/值(key/ value)对。第2章已经介绍
了一个对于 InnoDB存储引擎很重要的参数 innodb buffer pool size。如我们将这个参
数设置为1G,即 innodb buffer_ pool size=1G。这里的
是 innodb buffer pool
size,“值”是1G,这就是键值对。可以通过命令 SHOW VARIABLES查看数据库中
的所有参数,也可以通过LIKE来过滤参数名。从 My SQL51版本开始,还可以通过
information schema架构下的 GLOBAL VARIABLES视图来进行查找,如下所示。
mysql> SELECT FROM
> GLOBAL VAR工 ABLES
- WHERE VARIABLE NAME LIKE innodb buffer%1G
皆吉★专女★贵宴曾贵★青★青曹★责青★1,r。w曹實★*文★世责贵责★★★★★读安灾★★★责
VARLABLE NAME: INNODB BUFFER FOOL SIZE
VARIABLE VALUE: 1073741824
1 row in set (0.00 secy
mysql>SHOW VARIABLES LIKE innodb buffer&'\G;
内青★★青责去责★★★★★★★★★实★★★1.rw★★★★★丈★★★★★实★★守★女定实火★★*★★★
Variable name: innodb buffer pocl size
va1ue:1073741824
1r。 w in set(0.00sec)
无论使用哪种方法,输出的信息基本上都一样的,只不过通过视图 GLOBALhttp://blog.csdn.net/jiongyi1
FI
64第3章文件
VARIABLES需要指定视图的列名。推荐使用命令 SHOW VARIABLES,因为这个命玲
使用更为简单,且各版本的 MySQL数据库都支持。
Oracle数据库存在所谓的隐藏参数( undocumented parameter),以供 Oracle“内部
人士”使用, SQL Server也有类似的参数。有些DBA曾问我, MySQL中是否也有这类
参数。我的回答是:没有,也不需要。即使 Oracle和 SQL Server中都有些所谓的隐藏参
数,在绝大多数的情况下,这些数据库厂商也不建议用户在生产环境中对其进行很大的
调垫
3.1.2参数类型
MySQL数据库中的参数可以分为两类
态( dynamic)参数
口静态( static)参数
动态参数意味着可以在 My SQL实例运行中进行更改,静态参数说明在整个实例生
命周期内都不得进行更改,就好像是只读( read only)的。可以通过SET命令对动态的
参数值进行修改,SET的语法如下:
SET
i [global I session] system var name= expr
I [global, I c@session, I @0]system var name=expr
这里可以看到 global和 session关键字,它们表明该参数的修改是基于当前会话还是
整个实例的生命周期。有些动态参数只能在会话中进行修改,如 autocommit;而有些参
数修改完后,在整个实例生命周期中都会生效,如 binlog cache size;而有些参数既可
以在会话中又可以在整个实例的生命周期内生效,如 read buffer size举例如下
mysql>sET read buffer size=524288
Query oK, 0 rows affected (0.00 sec)
mysql>seLEct (@session. read buffer size\gi
★青★青青大青大古害责内青言★"1.y。W胄實宦宝出蜜皆当出音☆昏t甘
gasession. read buffer size: 524288
1r。 ww ln set(0.00sec
my sql>SELECT e@global read buffer size\G
害★背肯青★★女★背安害宝蜜囊齿业皆**1.￥Ow飞女古女★古实女★★★女女★★★★★★★★whttp:/blog.csdnnet/jiongyi11
EL
3.2日志文件65
eeglobal. read buffer size: 2093056
1 row in set(3.00sec〕
上述示例中将当前会话的参数 read buffer size从2MB调整为了512KB,而用户
可以看到全局的 read buffer size的值仍然是2MB,也就是说如果有另一个会话登录
到 MySQL实例,它的 read buffer size的值是2MB,而不是51KB。这里使用了set
globallsession来改变动态变量的值。用户同样可以直接使用SET@@glob@@ session来
更改,如下所示:
mysql>set @@global read buffer size=1048576
Query ok, o rows affected (0.00 sec
mysql>SELECT session. read buffer size\Gi
青安卖安卖吉出责责责责卖卖★卖★卖宫★贵1工⊙w责责卖责★★青责☆★★专*★安★☆*责青
aesession, read buffer size: 524288
1 row in set (0.00 sec)
mysql>SELECT aglobalread buffer size\Gi
★★★★★★丈★丈★★★★大★★★大★★★★★★★★1r。W*★★★★★大★★★★★★★大★★x为大x★★★六肯
global read buffer size: 1048576
row in set (0.00 sec)
这次把 read buffer size全局值更改为1MB,而当前会话的 read buffer size的值还
是512KB。这里需要注意的是,对变量的全局值进行了修改,在这次的实例生命周期内
都有效,但 MySQL实例本身并不会对参数文件屮的该值进行修改。也就是说,在下次
启动时 MySQL实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是
保留为当前修改的值,那么用户必须去修改参数文件。要想知道 MySQL所有动态变量
的可修改范围,可以参考 MySQL官方手册的 Dynamic System Variables的相关内容。
对于静态变量,若对其进行修改,会得到类似如下错误:
mysql>SET GLCBAL datadir='/db/mysql;
ERROR 1238(HY000): Variable 'datadir is a read only variable
32日志文件
日志文件记录了影响 MySQL数据库的各种类型活动。 MySQL数据库中常见的日志
文件有:http:/blog.csdnnet/jiongyi11
66第3幸文
口错误日志( error log)
口二进制日志( binlog)
口慢查询日志( slow query log)
口查询日志(log)
这些日志文件可以帮助DBA对 MySQL数据库的运行状态进行诊断,从而更好地进
行数据库层面的优化。
32.1错误日志
错误H志文件对 MySQL的启动、运行、关闭过程进行了记录。 MySQL DBA在遇
到问题时应该首先查看该文件以便定位问题。该文件不仅记录了所有的错误信息,也记
录一些警告信息或正确的信息。用户可以通过命令 SHOW VARIABLES LIKE log error'
来定位该文件,如:
mysql> SHOW VARIA3LES LIKE 'log error\Gi
★★k★★★★害★★★★★★★夹南★来★来内*脚内为1,rOw★★★青★青★内肯六南六六★大★★古内*女*★*谢
Variable name: log error
Value: /mysql data 2/stargazer. log
1 rew in set (0.00 sec)
mysql> system hostname
stargazer
可以看到错误文件的路径和文件名,在默认情况下错误文件的文件名为服务器的主
机名。如上面看到的,该主机名为 stargazer,所以错误文件名为 stargazer. erT当出现
MySQL数据库不能正常启动时,第一个必须查找的文件应该就是错误日志文件,该文
件记录了错误信息,能很好地指导用户发现问题。当数据库不能重启时,通过查错误日
志文件可以得到如下内容:
[rootOnineyou0-43 data]# tail -n 50 nineyou0-43err
090924 11:31: 18 mysqld started
090924 11:31: 18 InnoDB: Started; log sequence number 8 2E01063331
090924 11: 31: 19 [ERROR] Fatal error: Can't apen and lock privilege tables:
Table 'mysql. host doesn't exist
09092411:31:19mysq1 d ended
这里,错误日志文件提示了找不到权限库mysq,所以启动失败。有时用户可以直http:/blog.csdnnet/jiongyi11
51.6
32日感文件67令
挤吾
接在错误志文件中得到优化的帮助,因为有些警告( warnIng)很好地说明了问题所
在。而这时可以不需要通过查看数据库状态来得知,例如,下面的错误文件中的信息可
能告诉用户需要增大 InnoDB存储引擎的 redo log
090924 11: 39:44 InnoDB: ERROR: the age of the last checkpoint is 9433712
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If you are using big BLOB or TEXT rows, you must set the
InnoDB: combined size of lcy files dL least 10 tines bigger than the
InnoDB: largest such row.
090924 11: 40: 00 InnoDB: ERROR: the age of the last checkpoint is 9433823
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If you are using big BLOB or TEXT rows, you must set the
InnoDB: combined size of lcg files at least 10 times bigger than the
InnoDB: largest such row
090924 11: 40: 16 IlnIUDB: ERROR: Lhe aye uf the last checkpoint is 9433645
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If you are using big BLOB or TEXT rows, you must set the
InnoDB: combined size of log files at least l0 times bigger than the
InnoDB: largest such row
322慢查询日志
321小节提到可以通过错误日志得到一些关于数据库优化的信息,而慢查询日志
( slow log)可帮助DBA定位可能存在问题的SQL语句,从而进行SQL语句层面的优
化。例如,可以在 MySQL启动时设一个阈值,将运行时间超过该值的所有SQL语句都
记录到慢查询日志文件中。DBA每天或每过一段时间对其进行检查,确认是否有SQL
语句需要进行优化。该阈值可以通过参数 long query time来设置,默认值为10,代表
0秒。
在默认情况下, MySQL数据库并不启动慢查询日志,用户需要手工将这个参数设
为ON:
mysql> SHOW VARIABLES LIKE lorig query time'G:
宽宽官害“下t由古南古★★★★★★★★1.Ywt★★★★实★内青内内肯青★曹安安安安旋读★
Variable name: long query time
Value:10.000000
1 row in set (0.00 sec)
mysql> SHOW VARIABLES LIKE 'log slow queries'\G;
走出卖皆责★青实青★★會女女★★★责1.row★★★★★★★★★★女★★★★★★★内★★★★★★★http://blog.csdn.net/jiongyi1
6I
68躬3≠文斧
部拼没
Variable name: log slow queries
Value: oN
1 row in set (0.00 sec)
这里有两点需要注意。首先,设置 long query_time这个阈值后, MySQL数据库会
记录运行时间超过该值的所有SQL语句,但运行时间正好等于 long query time的情况
并不会被记录下。也就是说,在源代码中判断的是大于1 ong query time,而非大于等
于。其次,从 MySQL51开始, long query_time开始以微秒记录SQL语句运行的时间,
之前仅用秒为单位记录。而这样可以更精确地记录SQL的运行时间,供DBA分析。对
DBA来说,一条SQL语句运行0.5秒和0.05秒是非常不同的,前者可能已经进行了表
扫,后面可能是进行了索引。
另一个和慢查询日志有关的参数是 log queries not using_indexes,如果运行的SQL
语句没有使用索引,则 MySQL数据库同样会将这条SQL语句记录到慢查询日志文件。
首先确认打开了 log_ queries_ not_using indexes:
mysql> SHOW VARIABLES LIKE 'log queries not using indexes '\G;
★★★★大★★★女★★★★★肯安实肃青1.rc★★★古★才★南内★青青★古大★★青大大青青
Variab1 e name;1cg_ queries no山Sin立 dexes
Value: o
1 row in set 0.co sec
MySQL5.65版本开始新增了一个参数 log throttle queries not using indexes,用
来表示每分钟允许记录到 slow log的且未使用索引的SQL语句次数。该值默认为0,表
示没有限制。在生产环境下,若没有使用索引,此类SL语句会频繁地被记录到slow
log,从而导致 slow log文件的大小不断增加,故DBA可通过此参数进行配置。
DBA可以通过慢查询日志来找出有问题的SQL话句,对其进行优化。然而随着
MySQL数据库服务器运行时间的增加,可能会有越来越多的SQL査询被记录到了慢查
询日志文件中,此时要分析该文件就显得不是那么简单和直观的了。而这时 MySQL数
据库提供的 mysqldumpslow命令,可以很好地帮助DBA解决该问题:
[roatenh122-190 data]# mysqldumpslow nh122-190-slow log
Reading my sq slow query log from nh122--90-8lowlog
c。unt:11Time=10,00s(110s)I。ck=0.00s(0s】Rows=0.0〔0), bother[db。ther]a
localhost
insert into test. DbStatus select now(),[N-com select)/(N-uptime)r(N-com insert)/
(N-uptime),(N-com update)/(N-uptime),(N-com delete)/(N-cptime),N-(N/N), N-(N/N),N-N/
N,N-N/(N*N), GetCPULoadInfo(N) from test. CheckDbStatus order by check id desc limit Nhttp://blog.csdn.net/jiongyi1
BL
3.2日志文仵69
Count:653 Time=0. 00s (Os) Lock=0. 00s (Os) Rows=0.0 (0), 9Y0Ugs-scL9Yougs2
sc]e[192,168,43·71
select custom name one from 'low game schema. 'role details where role id='s
rse and summarize the My SQL slow query log. Options are
-verbose
verbose
-debug
debug
-help
write this text to standard output
verbose
ebug
e。RDER
what to sort hy (al, at, ar, c,l,r, t)'at'is default
a1: average l。 ck time
ar: average rows sent
at: average query time
c: count
1:1。 ck time
r: rows sent
t: query time
reverse the sort order (largest last instead of first)
-t NUM
just show the top n queries
don't abstract all numbers to N and strings to ' s
n NUM
abstract numbers with at least n digits within names
g PatTERN grep: only consider stmts that include this string
h HOSTNAMe hostname of db server for *-slow, log filename (can be wildcard,
default is i*i i.e. match all
I NAME
name of server instance (if using mysql, server startup script)
don t subtract lock time from total time
如果用户希望得到执行时间最长的10条SQL语句,可以运行如下命令:
frootenh119-141 data] mysqldumpslow -s al -n 10 david log
Reading mysql slow query log from david log
Count: 5 Time=0.00s (Os) Lock=0. 20s (ls) Rows=4.4(22) Audition [Audition]e
192.168.30.108]
select Others, State from wait friend info WHere Users N
Count:1 Time=0.oOs (Os) Lcck=0.oos (Os) Rows=l0(1), audition-kr [audition-
kr]@[192.168.30.105
SELECT COUNT(N) FROM famverifycode wHeRE UserSN-N AND verifycode=
MySQL51开始可以将慢查询的日志记录放入一张表中,这使得用户的查询更加方
便和直观。慢查询表在mysq架构下,名为 slow log,其表结构定义如下http:/blog.csdnnet/jiongyi11
5.e
70菜3章文件
ysql>SHOW CREATE TABLE mysql. slow log\Gi
食言言害言古言★古青★责青★青责★★曹t1.rOw青青★青★★青*中★青青由南青南南w南南青
Table: slow log
Create Table: CREATE TABLE 'slow log(
tart time timestamp NOT NULL DEFAULT CURRENT TIME STAME ON UPDATE CURRENT
TIMESTAMP
luser host mediumtext NOT NULL
query time time NOT NULLr
lock time time NCT NULLa
M rows scnt int(ll NOT NULLi
rows examined int(11) NOT NULLr
db varchar(512)NOT NULLr
last insert ic int(11) NOT NULLE
insert id int(11 NOT NULLe
server id int (111 NOT NULl
sql text mediumtext NOT NULL
ENGINE=CSV DEFAULT CHARSET=utf8 COMMENT='Slow log
1 row in set(0·00sec)
参数 log_ output指定了慢查询输出的格式,默认为FILE,可以将它设为 TABLE,
然后就可以查询 mysql架构下的 slow log表了,如
mysql>SHOW VARIABLES LIKE log output '\Gi
I Variable name value I
I log output
E工LE
l row in set (0.00 sec)
mysql>SET GLCBAL log output=TABLE'
Query OK ,0 rows affected (0.o0 sec)
mysql>SHOW VARIABLES LIKE ' log output\G;
I variable name value
log output I TABLE
一=+===
1 row in set (0.00 sec)
mysql> select sleep(10)\G;
sleep(10)Ihttp:/blog.csdnnet/jiongyi11
5L.
3.2日志又件71
1 row in set (10.0 sec)
myscI> SELECT
FROM mysql. slow log\G;
實實责寅责责★賣★灾★女★★★★置★★丈量★★★
上。w★★责青★★★*t
食官升食★雪
start time:2009-09-2513:44:29
user host: davidldavid] e localhost [
query time: 00:00:09
lock time: 00: 00:00
rows sent: 1
rows examined: 0
db: mysql
last insert id: 0
insert id: 0
server id: o
sql text: select sleep(10)
1 row in set (0.00 sec
参数 log output是动态的,并且是全局的,因此用户可以在线进行修改。在上表中
人为设置了睡眠(slep)10秒,那么这句SQL语句就会被记录到 slow log表了。
查看 slow log表的定义会发现该表使用的是CSv引擎,对大数据量下的查询效率
可能不高。用户可以把slow_log表的引擎转换到 MyISAM,并在 start time列上添加索
引以进一步提高查询的效率。但是,如果已经启动了慢查询,将会提示错误
mysql>ALTER TABLE my sql. slow log ENGINE-MYISM;
ERROR 1580(HY000): You cannot ALTER a log table if logging is enabled
mysql>SET GLOBAL slow query log=off
Query OK, o rows affected (0.00 sec)
mysqL>ALTER TABLE mysql. slow log ENGINE=My ISAM:
Query OK, row affected (0.00 sec)
Records: 1 Duplicates:0 Warnings: 0
不能忽视的是,将 slow log表的存储引擎更改为 MyISAM后,还是会对数据库造
成额外的开销。不过好在很多关于慢查询的参数都是动态的,用广可以方便地在线进行
设置或修改。
MySQL的 slow log通过运行时间来对SQL语句进行捕获,这是一个非常有用的优
化技巧。但是当数据库的容量较小时,可能因为数据库刚建立,此时非常大的可能是数http://blog.csdn.net/jiongyi1
5I
72茅3幸文仵
据全部被缓存在缓冲池中,SQL语句运行的时间可能都是非常短的,一般都是Q5秒命
InnoSQL版本加强了对于sL语句的捕获方式。在原版 MySQL的基础上在sow
lg中增加了对于逻辑读取( logical reads)和物理读取( physical reads)的统计。这里的
物理读取是指从磁盘进行IO读取的次数,逻辑读取包含所有的读取,不管是磁盘还是
缓冲池。例如:
#Time;1122723:49:16
User@Host: root[root] localhost [127.0.0.11
H Query time: 6.081214 Lock time: 0.046800 Rows sent: 42 Rows examined: 727558
Logical reads: 91584 Physical reads: 19
Ise tucci
SeT timestamp=13250009561
SELECT orderid, customerid, employeeid, orderdate
FROM orders
Where orderdate In
I SELECT MAX (orderdate
FROM orders
GROUE BY( DATE EURMAT( derate,'暑Y岩M'】
);
从上面的例子可以看到该子查询的逻辑读取次数是91584次,物理读取为19次。
从逻辑读与物理读的比例上看,该SQL语句可进行优化。
用户可以通过额外的参数long_ query 10将超过指定逻辑Io次数的SQL语句记录到
slow log中。该值默认为100,即表示对于逻辑读取次数大于100的SQL语句,记录到
slow log中。而为了兼容原 MySQL数据库的运行方式,还添加了参数sow_ query type,
用来表示启用 slow log的方式,可选值为:
口0表示不将SQL语句记录到 slow log
口1表示根据运行时间将SQL语句记录到 slow log
口2表示根据逻辑IO次数将SQL语句记录到 slow log
口3表示根据运行时间及逻辑IO次数将SQL语句记录到 slow log
323查询日志
查询日志记录了所有对 MySQL数据库请求的信息,无论这些请求是否得到了正确
的执行。默认文件名为:主机名log。如查看一个查询日志:http://blog.csdn.net/jiongyi1
3.2日文件73
[rootenineyou0-43 data]f tail nineyou0-43log
09092511:C0:2444 Connect
z-m192.168,0,100。n
44 Query
SET AUTOCOMMIT=O
44 Query
set autocommit=0
44 Quit
090925 11: 02: 37 45 Connect Access denied for user roct '2 localhost(using
password: No)
090925 11: 03: 51 46 Connect Access denied for user root localhost (using
password:ⅳQ
09092511:C4:3823 Query
rollback
通过上述查询日志会发现,查询日志甚至记录了对 Access denied的请求,即对于未
能正确执行的SoL语句,查询日志也会进行记录。同样地,从MySQ51开始,可以
将查询日志的记录放廴 mysql架构下的 general log表中,该表的使用方法和前面小节提
到的 slow log基本一样,这里不再赘述。
324二进制日志
二进制日志( binary log)记录了对 MySQL数据库执行更改的所有操作,但是不包
括 SELECT和SHOW这类操作,因为这类操作对数据本身并没有修改。然而,若操作
本身并没有导致数据库发生变化,那么该操作可能也会写人二进制日志。例如
mysql> UPDATE t seT a=1 WHERE a =27
Query OK, 0 rows affected (0.00 sec)
Rows matched: 0 Changed 0 Warnings: D
mysql> SHOW MASTER STATUS\G;
责★★★读★★贵★量★★★女★女★★★★★★★★★★★1,工。w*★★*肉★*内大★内★★★★女黄★★★★淹★南★★★
File: mysqld. 000008
Position: 383
Bin1agD。DB:
Binlog ignore dB:
Executed Gtid set
1row⊥nset(0.00sec)
mysql> SHOW BINLOG EVENTS IN 'mysgld.000008\G
★★★★★来★★★★实★★★★★★★★★★★★★1,xow★青★★★青÷★★★★★★★★★★★★*★★★★★★★
Log name mysqld, 000008
Pos: 4
Event type: Format desc
Server id: 1http://blog.csdn.net/jiongyi1
5
y43草文件
End log pos: 120
Info: Server ver: 5.6.6-m9-log, Binlog ver: 4
★★★★★★★★古*古古古青青六贵★★t★青★*2.r。w*★★★★女★★★★为走k★*★★★史★★★
Lcg name: mysald. 000008
Pos: 120
Event type: Query
server id: 1
End log pos: 199
Info: BEGIN
*★女如熏如女★女士晋女士士士誓★士古*3,r。w★肃★肃烹★*★忠★★★*★宴*★★★
Lag name: mysgld.000008
Pos: 199
Event type: Query
Server·d:1
End log pos: 303
Info: use ' i update t set a =1 where a =2
青宽★青青实t青★宵★青大青青大贵大★t★青*4,r。w*★★★大★大★古★大★★★★★内★★古需★青大大
Lcg name: mysqld.000008
Pos: 303
Event type: Query
Server d: 1
End log pos: 383
工nfo: COMMIT
4 rows in set (0.00 sec)
从上述例子中可以看到, MySQL数据库首先进行 UPDATE操作,从返回的结果
看到 Changed为0,这意味着该操作并没有导致数据库的变化。但是通过命令SHOW
BⅠ NLOG EVENT可以看出在二进制日志中的确进行了记录。
如果用户想记录 SELECT和SHOW操作,那只能使用查询日志,而不是二进制日
志。此外,二进制日志还包括了执行数据库更改操作的时间等其他额外信息。总的来
说,二进制日志主要有以下几种作用。
口恢复( recovery):某些数据的恢复需要二进制日志,例如,在一个数据库全备文
件恢复后,用户可以通过二进制日志进行 point-in-time的恢复。
口复制( replication):其原理与恢复类似,通过复制和执行二进制日志使一台远程
的 MySQL数据库(一般称为 slave或 standby)与一台 My SQL数据库(一般称
为 master或 primary)进行实时同步。
口审计(aud):用户可以通过二进制日志中的信息来进行审计,判断是否有对数
据库进行注入的攻击http:/blog.csdnnet/jiongyi11
51.6
32日志文件75
通过配置参数log-in[=name]可以启动二进制日志。如果不指定mame,则默认
进制日志文件名为主机名,后缀名为二进制日志的序列号,所在路径为数据库所在目录
( datadir),如
mysa> show variables like ' datadir'i
I Variable name I value
一十
I datadir
/usr/local/ mysql/data/I
1 row in set (0.00 sec)
mysql> sys Lemm ls -lh /usr/local/ mysql/data/
total 2.1G
Tw-Iw
1 mysqlmysql 6.5M Sep 25 15: 13 bin log.000001
q mysa
17 Sep 2500: 32 bin log index
Tw-IwN--
1 mysqlmysql 300M Sep 25 15: 13 ibdatal
l mysql mysql 256M Sep 25 15: 13 ib logfile
rw-rw--=-1 mysql mysql 256M Sep 25 15: 13 ib logfilel
drwxr-xr-x 2 mysql lysyl 4. OK May 7 10: 08 mysql
mysql mysql 4.OK May 7 10:09 test
这里的 bin log000即为二进制日志文件,我们在配置文件中指定了名字,所以没
有用默认的文件名。bin_ log index为二进制的索引文件,用来存储过往产生的二进制日
志序号,在通常情况下,不建议手工修改这个文件。
二进制日志文件在默认情况下并没有启动,需要手动指定参数来启动。可能有人会
质疑,开启这个选项是否会对数据库整体性能有所影响。不错,开启这个选项的确会影
响性能,但是性能的损失十分有限。根据MyQL官方手册中的测试表明,开启二进制
日志会使性能下降1%但考虑到可以使用复制( replication)和 point-in-time的恢复,
这些性能损失绝对是可以且应该被接受的。
以下配置文件的参数影响着二进制日志记录的信息和行为:
口 max binlog_size
口 binlog cache size
口 sync binlog
口 binlog-do-db
口 binlog-ignore-dbhttp://blog.csdn.net/jiongyi1
5
76茅3幸文件
部拼没
口 log-slave- update
你
日 binlog_ format
参数 max binlog size指定了单个二进制日志文件的最大值,如果超过该值,则产生
新的二进制日志文件,后缀名+1,并记录到 index文件。从 MySQL50开始的默认值
为1073741824,代表1G(在之前版本中 max binlog size默认大小为11G)。
当使用事务的表存储引擎(如 InnoDB存储引擎)时,所有未提交( uncommitted
的二进制日志会被记录到一个缓存中去,等该事务提交( committed时直接将缓冲中
的二进制日志写人二进制日志文件,而该缓冲的大小由 binlog cache size决定,默认大
小为32K。此外, binlog cache_size是基于会话( session)的,也就是说,当一个线程
开始一个事务时, My SQL会自动分配一个大小为 binlog cache size的缓存,因此该值
的设置需要相当小心,不能设置过大。当一个事务的记录大于设定的 binlog cache_size
时, MySQL会把缓冲中的日志写入一个临时文件中,因此该值又不能设得太小。通过
SHOW GLOBAL STATUS命令查看 binlog cache use、 binlog cache_ disk use的状态,可
以判断当前 binlog cache_size的设置是否合适。 Binlog cache use记录了使用缓冲写二
进制日志的次数, binlog cache disk use记录了使用临时文件写二进制日志的次数。现
在来看一个数据库的状态
mysql> show variables like 'binlog cache size';
I Variable name I value I
I binlog cache size I 32760 I
十一一一一
1 row in set Co0 sec]
mysql> show global status like 'binlog cache%';
I variable name I value
I binlog cache disk use I 0
I binlog cache use
133553
2 rows in set (0.00 sec)
使用缓冲次数为33553,临时文件使用次数为0。看来32KB的缓冲大小对于当前
这个 MySQL数据库完全够用,暂时没有必要增加 binlog cache size的值http:/blog.csdnnet/jiongyi11
5I
3.2日患文件77
在默认情况下,二进制日志并不是在每次写的时候同步到磁盘(用户可以理解为缓
冲写)。因此,当数据库所在操作系统发生宕机时,可能会有最后一部分数据没有写入
二进制日志文件中,这会给恢复和复制带来问题。参数 sync binlog=[N]表示每写缓冲
多少次就同步到磁盘。如果将N设为1,即syn_ binlog=1表示采用同步写磁盘的方式来
写二进制日志,这时写操作不使用操作系统的缓冲来写二进制日志。 sync binlog的默认
值为0,如果使用 InnoDB存储引擎进行复制,并且想得到最大的高可用性,建议将该值
设为ON。不过该值为ON时,确实会对数据库的IO系统带来一定的影响。
但是,即使将 sync binlog设为1,还是会有一种情况导致问题的发生。当使用
InnoDB存储引擎时,在一个事务发出 COMMIT动作之前,由于 sync binlog为1,因
此会将二进制日志立即写人磁盘。如果这时已经写入了二进制日志,但是提交还没有发
生,并且此时发生了宕机,那么在 MYSQL数据库下次启动时,由于 COMMIT操作并没
有发生,这个事务会被回滚掉。但是二进制日志已经记录了该事务信息,不能被回滚。
这个问题可以通过将参数 innodb support xa设为1来解决,虽然 innodb support xa与
XA事务有关,但它同时也确保了二进制日志和 InnoDE存储引擎数据文件的同步。
参数 binlog-do-db和 binlog- ignore-b表示需要写人或忽略写人哪些库的日志。默认
为空,表示需要同步所有库的日志到二进制日志。
如果当前数据库是复制中的 slave角色,则它不会将从 master取得并执行的二进制
口志写入自己的二进制口志文件中去。如果需要写入,要设置 log-slave-update。如果需
要搭建 master→> slave=> slave架构的复制,则必须设置该参数
binlog format参数十分重要,它影响了记录二进制日志的格式。在 MySQL5.1版本
之前,没有这个参数。所有二进制文件的格式都是基于SQL语句( statement)级别的,
因此基于这个格式的二进制日志文件的复制( Replication)和 Oracle的逻辑 Standby有
点相似。同时,对于复制是有一定要求的,如在主服务器运行rand、uuid等函数,又或
者使用触发器等操作,这些都可能会导致主从服务器上表中数据的不一致( not sync)
另一个影响是,会发现 InnoDB存储引擎的默认事务隔离级别是 REPEATABLE READ。
这其实也是因为二进制日志文件格式的关系,如果使用 READ COMMITTED的事务隔
离级别(大多数数据库,如 Oracle, Microsoft SQL Server数据库的默认隔离级别),会
出现类似丢失更新的现象,从而出现主从数据库上的数据不一致。
MySQL5.1开始引入了 binlog_ format参数,该参数可设的值有 STATEMENThttp://blog.csdn.net/jiongyi1
6I
78第3亨文”斧
部拼吾
ROW和 MIXEL
(1) STATEMENT格式和之前的 MySQL版本一样,二进制日志文件记录的是日志
的逻辑SQL语句。
(2)在ROW格式下,二进制日志记录的不再是简单的SQL语句了,而是记录表的
更改情况。基于ROW格式的复制类似于 Oracle的物理 Standby(当然,还是有些区
别)。同时,对上述提及的 Statement格式下复制的问题予以解决。从 MySQL5版本
开始,如果设置∫ binlog_ format为RoW,可以将 InnoDB的事务隔离基本设为READ
COMMITTED,以获得更好的并发性。
(3)在 MIXED格式下, MySQL默认采用 STATEMENT格式进行二进制日志文件
的记录,但是在一些情况下会使用ROW格式,可能的情况有
1)表的存储引擎为NDB,这时对表的DML操作都会以ROW格式记录。
2)使用了 UNIDO、 USER、 CURRENT USERO、 FOUND ROWS0、 ROW COUNTO
等不确定函数。
3)使用了 INSERT DELAY语句
4)使用了用户定义函数(UDF)。
5)使用了临时表( temporary table)。
此外, binlog format参数还有对于存储引擎的限制,如表3-所示。
表3-1存储引对二进制日志格式的支持情况
存储引擎
RoW格式
Statement格式
InnoDB
Yes
Yes
MyIsAM
Yes
Yes
HEAP
Yes
Yes
MERGE
Yes
Yes
NDB
Yes
N
Archive
Yes
Yes
CSV
Yes
Yes
Federate
Yes
Yes
Blockhole
No
Yes
binlog format是动态参数,因此可以在数据库运行环境下进行更改,例如,我们可
以将当前会话的 binlog format设为ROW,如:
mysql>SET session. binlog format=ROWihttp://blog.csdn.net/jiongyi1
5
32日慈文件79争
Query OK, 0 rows affected (0.00 sec)
mysql>SELEcTeesession binlog_ formati
t session. binlog format I
I ROW
1r。 w in set〔0.00sec)
当然,也可以将全局的 binlog_ format设置为想要的格式,不过通常这个操作会带来
问题,运行时要确保更改后不会对复制带来影响。如
mysql>sET GLOBAL binlog format='ROW':
Query ok, o rows affected (aoo sec)
mysql>seleCt @dglobal, binlog formati
I e@global binlog format
I ROw
1 row in set【0.00sec)
在通常情况下,我们将参数 binlog format设置为RoW,这可以为数据库的恢复
和复制带来更好的可靠性。但是不能忽略的一点是,这会带来二进制文件大小的增加,
有些语句下的ROW格式可能需要更大的容量。比如我们有两张一样的表,大小都为
100W,分别执行 UPDATE操作,观察二进制日志大小的变化
mysql>sELECT @Session. binlog format\G;
害★宙审音★青青★★★★*1。r。w六★★★★审内青★肯青内★青★★★★★古
eesession binlog format: STATEMENT
l raw in set (0.00 sec)
mysql>SHOW MASTER STATUS\G:
★青吉咖声诗★★★★★1。 ECw Kkk古kλ如真南幽★★舞★★★★★★★★★★實
File: test. 000003
Position: 106
Bin1ogD。DB:
Binlog Ignore DB:
1 row in set (0.00 sec)
mysql>UPDATE tl seT username=UPPER (username )ihttp://blog.csdn.net/jiongyi1
FI
80韩了幸文件
Query OK,39279 rows affected【1·83sec)
Rows matched: 100000 Changed: 89279 Warnings: 0
mysql>SHOW MASTER STATUS \G:
南肯内南声肯脚审皆审青中中中W青南1.row南青★诗内青由‘中宙皆皆计诗卉★青青★
File: test. 000003
Position: 306
Binlog Do dB:
Bin1 og Ign。reDB:
1 row in set (0. 00 sec)
可以看到,在 binlog format格式为 STATEMENT的情况下,执行 UPDATE语句后
二进制日志大小只增加了200字节(306-106)。如果使用ROW格式,同样对坦表进行
操作,可以看到
mysqL>SET SESSTON binlog format=ROWi
Query OK, 0 rows affected (0.00 sec)
mysql>SHOW MASTER STATUS\G:
★★★青★肯★大★★★★★害★肯*青★★1,rwt★★★★★★★实★★★女案★★★安★卖安
File: test.000003
Pasition: 306
Binlog do db:
Binlog Ignore DB:
1 row in set【0.00sec
mysql>UPDATE t2 SET username=UPPER(username)i
Query ok,89279 rows affected (2.42 sec)
Rows matched: 100000 Changed: 89279 Warnings: 0
mysql>SHOW MASTER STATUS\G;
★實★★★★★實★★★★★★★★责隶★★
貴★★★★背★走★★实*★≠
★★★★★★古
File: test. 000003
Position: 13782400
Binlog Do DB
Bin】 og Ignore da:
I rcw in set (0.00 sec)
这时会惊讶地发现,同样的操作在ROW格式下竟然需要1378209字节,二进制
日志文件的大小差不多增加了13MB,要知道t2表的大小也不超过17MB。而且执行时
间也有所增加(这里我设置了sync_ binlog=1)。这是因为这时 MySQL数据库不再将逻
辑的SQL操作记录到二进制日志中,而是记录对于每行的更改。http:/blog.csdnnet/jiongyi11
文将
3,2日忐
件81
上面的这个例子告诉我们,将参数 binlog_ format设置为ROW,会对磁盘空间要求
有一定的增加。而由于复制是采用传输二进制日志方式实现的,因此复制的网络开销也
有所增加。
二进制日志文件的文件格式为二进制(好像有点废话),不能像错误日志文件、慢
查询日志文件那样用cat、head、tail等命令来查看。要査看二进制日志文件的内容,必
须通过 MySQL提供的工具 mysqlbinlog。对于 STATEMENT格式的二进制日志文件,在
使用 mysqlbinlog后,看到的就是执行的逻辑SQL语句,如
[rootanineyouo-43 data]f mysglbinlog --start-position=203 test. 000004
/* 40019 SET G@session. max insert delayed threads=0*/i
090927 15: 43: 11 server id 1 end log pos 376 Query thread id=188 exec
time=l
error code=0
SET TIMESTAMP=1254037391/*!*/
update t2 set username=upper(username)where id-1
/A!h!
at376
F090927 15: 43:11 server id 1 end log pos 403 xid=1009
COMMIT/*!*/:
DEL IMITER i
上ndf1oqf1e
ROLLBACK added by mysqlbinlog */
/* 50003 SET COMPLETION TYPE=COLD COMPLETION TYPE*/
通过SQL语句 UPDATE t2 SET uSername= UPPER( username) WhERE id=1可以看
到,二进制日志的记录采用SQL语句的方式(为了排版的方便,省去了一些开始的信
息)。在这种情况下, mysqlbinlog和 Oracle LogMiner类似。但是如果这时使用ROW格
式的记录方式,会发现 mysqlbinlog的结果变得“不可读”( unreadable),如:
irootenineyouo-43 datalt mysqlbinlog --3tart-position-1065 test. 000004
/*140019 seT Eesession max insert delayed threads=0*/
1at1135
at1198
#090927 15: 53: 52 server id 1 end log_ pos 1198 Table map: 'member1.'t2'Illapped
to number 58
#090927 15: 53: 52 server id 1 end_log_pos 1378 Update rows: table id 58 flags:
STMT END F
BINLOGhttp:/blog.csdnnet/jiongyi11
5L.
82第3幸文件
EBq/ShMBAAAAPWAAAK4EAAAAADoAAAAAAAAABm1lbWJIcgACdDIACgMPDw/+cgsPAQuKJAAoAEAA
gJAAAAA
EBy/shgBAAAAtAAAAGIFAAAQADoAAAAAAAEACv////8A/AEAAAALYWxleDk5oDh5b30EOXIvdSA3
Y2JiMzI1MmJhNmI3ZTljNDIyZmFjNTMzNGQYMjAlNAFNLacPAAAAAABJEnpxPBIAAAD8AQAAAAtE
TevYotk40FlPVQQ5eW91IDdjYmIzM] UyYmE2Y3dloWMOMjJmYWMiMzMO Z DIyMDUOAUOtpw8AAAAA
AGMSenESEqAA
at1378
509092715: 53: 52 server id 1 end log pos 1405 Xid 1110
CoMMIT/*!+/;
DEL工工TER
舞 End of1∞gf1e
ROLLBACk / added by mysglbinlog */
* 50003 SET COMPLETION TYPE-GOLD COMPLETION TYPE */
这里看不到执行的SQL语句,反而是一大串用户不可读的字符。其实只要加上参
数或w就能清楚地看到执行的具体信息了。-V会比v多显示出更新的类型。加
上-w选项,可以得到
(rootenineyou0-43 data]# mysqlbinlog -v --start-position-1065 test. 000004
BINLOG
EBq/shMBAAAAPWAAAK4EAAAAADOAAAAAAAAABm1lbWJIcgACdDIACgMPDW/ +Cgs PAOWKJAAOAEAA
/gJAAAAA
EBy/ShgBAAAAtAAAAGI FAAAQADOAAAAAAAEACv////8A/AEAAAALYWxleDk5oDh5b3UEOXlVdSA3
Y2JiMzIIMmJhNmI3ZT1NDIyZmFjNTMzNGQyMiAlNAFNLacPAAAAAABJEnpxPB-AAAD8AQBAAAtB
TEVYOTk4OFIPVOQ5eW91IDdjYmI zMjUyYmE2YdlCWMOMiUmYWMIMzMOZDIYMDUOAUOtpwEAAAAA
AGMSenEBEgAA
1★★
世昔井 UPDATE member.t2
#+# Where
## @1=1 / INT netd=0 nullable=o is null=0 *
## @2=david/* VARSTRING(36) meta=36 nullable=o is null=0*/
f## 3=family/* vARSTRING (40)meta=40 nullable=d is null=0 */
### Q4=7cbb3252ba6b7e9c422fac5334d22054/* VARSTRING (64)meta=64 nullable=0
is null=0 */
# @5='M/ STRING(2) meta 6502E nullable=o is null=0
#86="2009:09:13·!* DATE the ta=0mu1lab1e=0isnu11=0-/
##抨87="00:00:00/* TIME meta=0nu1ab1e=0isnu11=0*
H## @8=./* VARSTRING (64)met a=64 nullable=0 is null=0 *
f## 99=0/* TINYINT meta=0 nullable=0 is null=0
群##10=2009-08-1116:32:35/* DATETIME meta=0 nulla⊥e=0⊥snu11=0*
早#甚SET
f#t 01=1 /* INt meta=o nullable=o is null=0*/http://blog.csdn.net/jiongyi1
BL
3.4pid文件8
普#普2= DAVID’/* VARSTRING(36)meta=36nu1ab1e=0isnu11=0*/
番普普Q3=fami1y/* VARSTRING(40)meta=40nu11ab1e=0isnu11=0*/
暑普鲁4=17cbb3252ba6b7e9c422fac5334d22054/* VARSTRING(64)meta=64nu⊥ Lable=0
is null=0 *
普暑85="M"/* STRING【2)meta=65026 nulla1e=0isnu⊥⊥=0★
普吾6=′2009:09:13/* DATE meta=0 nullable=0isnu11=0*
### 07=00: 00: 00/* TIME meta=0 nullable=0 is null=0 *
普择靜88=!/* VARSTRING(64)meta=64nu1lab1e=0isr:u1=0*
## 29=0 /* TINYINT meta=0 nullable=0 is null=0 *
普普(10=2009-08-1116:32:35/* DATETIME meta=0nu11ab1e=0isnu11=0★
at1378
409092715: 53: 52 server id 1 end log pos 14105 xid =1110
c。MIT/*!*;
DELIMITER
H End of log file
ROLLBACK / added by mysglbinlog */
/*!50003 SET COMPLETION TYPB=@OLD COMPLETION TYPE*/:
现在 mysqlbinlog向我们解释了它具体做的事情。可以看到,一句简单的 update2
set username= rupper()where id=1语句记录了对于整个行更改的信息,这也解释了
为什么前面更新了10W行的数据,在ROW格式下,二进制日志文件会增大13MB。
33套接字文件
前面提到过,在UNX系统下本地连接 MySQL可以采用UNX域套接字方式,这
种方式需要一个套接字( socket)文件。套接字文件可由参数 socket控制。一般在/mp
目录下,名为 mysql. sock
mysql>SHOW VARIABLES LIKE socket \G:
★★赏青内★★*实南去请★★★★★★t★★★1,xow青★★★★★★肃★★★★★★★★★★★*★*古古★★★
Variable name: soket
Value: /tmp/mysql. sock
1 row in set (0.05 sec)
34pid文件
当 MySQL实例启动时,会将自已的进程I写人一个文件中—该文件即为pi文
件。该文件可由参数 pid file控制,默认位于数据库目录下,文件名为主机名pidhttp:/blog.csdnnet/jiongyi11
843章文件
mysql> show variables like 'pid file\G;
南★古大★大大女大大为★★★*甘专甘甘1,￥●W
k青★★言古古肯大古肯★青★★★为★★★太
Variable name: pid file
value: /usr/local/mysql/data/xen-server pid
1 row in set 0,o0 sec)
35表结构定义文件
因为 MySQL插件式存储引擎的体系结构的关系, MySQL数据的存储是根据表进行
的,每个表都会有与之对应的文件。但不论表采用何种存储引擎, MySQL都有一个以
frm为后缀名的文件,这个文件记录了该表的表结构定义。
frm还用来存放视图的定义,如用户创建了一个va视图,那么对应地会产生
个ⅴa.fm文件,用来记录视图的定义,该文件是文木文件,可以直接使用cat命令进行
查看:
[rootexen-server test]# cat v afrm
YPE=V工Ew
query=select test.a.b As bfrom test,a
md5=4eda70387716a4d6c96f3042dd68b74
updatable=1
a gori thm=D
definer user=￥ot
definer host=⊥oca⊥host
suic=2
with check option=0
timestamp=2010-08-04c7:23:36
create-version=1
source=select from a
client cs name=utf8
connection cl name=utt8 general ci
view body utf8=select test.a.b as b from test.a
3.6 InnoDB存储引擎文件
之前介绍的文件都是 MySQL数据库本身的文件,和存储引擎无关。除了这些文件
外,每个表存储引擎还有其自己独有的文件。本节将具体介绍与 InnoDB存储引擎密切
相关的文件,这些文件包括重做日志文件、表空间文件。http:/blog.csdnnet/jiongyi11
5.e
3.6nODB存储引件85
3.6.1表空间文件
InnoDB采用将存储的数据按表空间( tablespace)进行存放的设计。在默认配置
下会有一个初始大小为10MB,名为 ibdatal的文件。该文件就是默认的表空间文件
( tablespace file),用户可以通过参数 innodb data file path对其进行设置,格式如下
innodb data file path=datafile specl[; datafile spec2]
用户可以通过多个文件组成一个表空间,同时制定文件的属性,如:
[mysgldI
innodb data file path =/db/ibdatal: 2000M;/dr2/db/ibdata2: 2000M: autoextend
这里将/ db/ibdatal和/dr2/ db/ibdata2两个文件用来组成表空间。若这两个文件位于
不同的磁盘上,磁盘的负载可能被平均,因此可以提高数据库的整体性能。同时,两个
文件的文件名后都跟∫属性,表示文件 idbdatal的大小为2000MB,文件 iodate2的大小
为2000MB,如果用完了这2000MB,该文件可以自动增长〔 autoextend
设置 innodb data_ file path参数后,所有基于 InnoDB存储引擎的表的数据都会
记录到该共享表空间中。若设置了参数 innodb file per table,则用广可以将每个基于
InnoDB存储引擎的表产生一个独立表空间。独立表空间的命名规则为:表名ibd通过
这样的方式,用户不用将所有数据都存放于默认的表空间中,下面这台 MySQL数据库
服务器设置了 innodb file per table,故可以观察到
mysql>SHOW VARIABLES LIKe 'innodb file per tab-c1\G7
實言大责大★★★青肯*青肯*直害★青★1,rW;太★★肯★★★★x★★★★★肯★t责支★★
variable name: innodb file per table
Value: oN
1 row in set【0.00sec
mysql> system ls-ih /usr/local/mysql/data/member/*
Cw"=-
1 mysql mysql 8.7k 2009-02-24 /usr/local/mysql/data/member/
Profile frm
1 mysql mysql 1.7G 9 A 25 11: 13 /usr/local/mysql/data/member/
Profile, ibd
w-"一
1 mysql mysql 87K 9 A 27 13: 38 /usr/local/mysql/data/member/
tl. frm
Eh-Fy-
sq1mysql 17M 9 A 27 13: 40 /usr/local/mysql/data/member/
ti.ibd
W=上w
1 mysqlmysql 8 7K 9A 27 15:42 /usr/local/mysql/data/member/
t2. frmhttp://blog.csdn.net/jiongyi1
5
86募3幸文件
rw-rWw---- 1 mysql mysql 17M 9 A 27 15: 54 /usr/local/mysql/data/member
t2. ibd
表 Profile、tl和t都是基于 InnoDB存储的表,由于设置参数 innodb file per
table=ON,因此产生了单独的bd独立表空间文件。需要注意的是,这些单独的表空间
文件仅存储该表的数据、索引和插入缓冲 BITMAP等信息,其余信息还是存放在默认的
表空间中。图3-1显示了 InnoDB存储引擎对于文件的存储方式
InnoDB Tables
-------L
InnoDB
frm
tablespace
innodb file per table
ibd files
图3-1 InnoDB表存储引擎文件
3.62重做日志文件
在默认情况下,在 InnoDb存储引擎的数据目录下会有两个名为 ib logfile0和j
logfile的文件。在 MySQL官方手册中将其称为 InnoDB存储引擎的日志文件,不过更
准确的定义应该是重做日志文件( redo log file)。为什么强调是重做日志文件呢?因为
重做日志文件对于 InnoDB存储引擎至关重要,它们记录了对于 InnoDB存储引擎的事
务日志。
当实例或介质失败( media failure)时,重做日志文件就能派上用场。例如,数据库
由于所在主机掉电导致实例失败, InnoDB存储引擎会使用重做日志恢复到掉电前的时
刻,以此来保证数据的完整性。
每个 InnoDB存储引擎至少有1个重做日志文件组( group),每个文件组下至少有
重做日志文件,如默认的j_ logfile0和 1b logfile。为了得到更高的可靠性,用户
可以设置多个的镜像日志组( mirrored log groups),将不同的文件组放在不同的磁盘上,
以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致,并以循环写http:/blog.csdnnet/jiongyi11
5.e
36mODB存儲引文件87
研
人的方式运行。 InnoDB存储引擎先写重做日志文件1,当达到文件的最后时,会切换
至重做日志文件2,再当重做日志文件2也被写满时,会再切换到重做日志文件1中。
图3-2显示了一个拥有3个重做日志文
件的重做日志文件组。
ib logfile
下列参数影响着重做日志文件的
属性:
口 innodb log file size
U innodb log files in group
ib logfile
innodb mirrored log groups
O innodb log_group home dir
图3-2日志文件组
参数 innodb log file size指定每个重做日志文件的大小。在 InnoDB12.x版木之前,
重做日志文件总的大小不得大于等于4GB,而12x版本将该限制扩大为了512GB。
参数 innodb log files in group指定了日志文件组中重做日志文件的数量,默认为
2。参数 innodb_mirrored log groups指定了日志镜像文件组的数量,默认为1,表示只
有一个日志文件组,没有镜像。若磁盘本身已经做了高可用的方案,如磁盘阵列,那么
可以不开启重做日志镜像的功能。最后,参数 innodb log group home dir指定了日志文
件组所在路径,默认为,表示在 MySQL数据库的数据目录下。以下显示了一个关于
重做口志组的配置:
mysq1> SHOW VARIABLES L工KE1 innodb告1og号\G;
中s中中
青黄害★青★★★*实世★共★★文★★★★★*4.r。回走太★★★★★★★★k★★★*★★幽★★★★★★★★
Variable name: innodb log file size
Va1ue;5242880
★安★害火发安置实灾丈實★向k★★★★南★*5.y。w★★为★★★★★为*女去害**★★
Variable name: innodb log files in group
Value: 2
史史★史★史女史实史★★★★★★★★★★★块6,rγ★*★★★★实女★女★★★女*★专★★肃青古责
Variable name: innodb log group home dir
Value: .
k★★★★**大大肯★★内★★★★青☆*★★梦7。ow★★★*★*★***★★★★*★★★★★★★★★古
Variable name: innodb mirrored loq groups
Value: 1
了 rows n set(0.00scc)
重做日志文件的大小设置对于 InNODB存储引擎的性能有着非常大的影响。一方面http:/blog.csdnnet/jiongyi11
88韩3幸文件
重做目志文件不能设置得太大,如果设置得很大,在恢复时可能需要很长的时安
方面又不能设置得太小了,否则可能导致一个事务的日志需要多次切换重做日志文件。
此外,重做日志文件太小会导致频繁地发生 async checkpoint,,导致性能的抖动。例如,
用户可能会在错误日志中看到如下警告信息
090924 11: 39: 44 InnoDB: ERROR: the age of the last checkpoint is 9433712,
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If you are using big BlOb or TEXT rows you must set the
InnoDB: comBined sizc of log files at least 10 times bigger than the
InnoDB: largest such row
090924 11: 40: 00 InnoDB: ERROR: the age of the last checkpoint is 9433823
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If you are using big BlOB or TEXT rows, you must set the
InnoDB: combined size of log files at least 10 times bigger than the
InnoDB; largest such row
090924 11: 40: 16 InnoDB: ERROR: the age of the last checkpoint is 9433645
InnoDB: which exceeds the log group capacity 9433498
InnoDB: If ycu arc using big BLoB or TEXT rowS, you must set the
InnoDB: combined size of log files at least 10 times bigger than the
InnoDB: largest such row
上由错误集中在 InnoDB: ERROR: the age of the last checkpoint is9433645, InnoDB: which
exceeds the log group capacity9433498。这是因为重做日志有一个 capacity变量,该值
代表了最后的检查点不能超过这个阈值,如果超过则必须将缓冲池( innodb buffer pool)
中脏页列表( flush list)中的部分脏数据页写回磁盘,这时会导致用户线程的阻塞。
也许有人会问,既然同样是记录事务日志,和之前介绍的二进制日志有什么区别?
首先,二进制H志会记录所有与 MySQL数据库有关的日志记录,包括 InnoDB、
MyISAM、Heεap等其他存储引擎的日志。而 InnoDB存储引擎的重做日志只记录有关该
存储引擎本身的事务日志。
其次,记录的内容不同,无论用户将二进制日志文件记录的格式设为 STATEMENT
还是ROW,又或者是 MIXED,其记录的都是关于一个事务的具体操作内容,即该日志
是逻辑日志。而 InnoDB存储引擎的重做日志文件记录的是关于每个页(Page)的更改
的物理情况。
此外,写入的时间也不同,二进制H志文件仅在事务提交前进行提交,即只写磁
盘一次,不论这时该事务多大。而在事务进行的过程中,却不断重做日志条目(redo
entry)被写入到重做志文件中http:/blog.csdnnet/jiongyi11
36moDB存储引擎件89
在 InnoDB存储引擎中,对于各种不同的操作有着不同的重做日志格式。到oDB
12x版本为止,总共定义了51种重做日志类型。虽然各种重做日志的类型不同,但是
它们有着基本的格式,表3-2显示了重做日志条目的结构:
表32重做日志条目结构
redo log type
space
page no
redo log body
从表3-2可以看到重做日志条目是由4个部分组成:
口redo_ log type占用1字节,表示重做日志的类型
口spac表示表空间的ID,但采用压缩的方式,因此占用的空间可能小于4字节
口 page no表示页的偏移量,同样采用压缩的方式
口 redo log body表示每个重做日志的数据部分,恢复时需要调用相应的函数进行
解析
在第2章中已经提到,写入重做日志文件的操作不是直接写,而是先写入一个重做
日志缓冲( redo log buffer)中,然后按照一定的条件顺序地写入日志文件。图3-3很好
地诠释了重做日志的写入过程。
redo log buffer
redo log files
ib logfile I
ab logfile
图3-3重做日志写入过程
从重做日志缓冲往磁盘写入时,是按512个字节,也就是一个扇区的大小进行写
人。因为扇区是写入的最小单位,因此可以保证写入必定是成功的。因此在重做日志的
写入过程中不需要有 doublewrite
前面提到了从日志缓冲写人磁盘上的重做日志文件是按一定条件进行的,那这些条
件有哪些呢?第2章分析∫主线程( master thread),知道在主线程中每秒会将重做日忐
缓冲写人磁盘的重做日忐文件中,不论事务是否已经提交。另一个触发写磁盘的过程是
由参数 innodb fush log at trx commit控制,表示在提交( commit)操作时,处理重做
日志的方式。http://blog.csdn.net/jiongyi1
5
90第3章文件
参数 innodb flush log at trx commit的有效值有0、1、2。0代表当提交事务时
不将事务的重做日志写入磁盘上的日志文件,而是等待主线程每秒的刷新。1和2不同
的地方在于:1表示在执行 commit时将重做目志缓冲同步写到磁盘,即伴有 fsync的调
用。2表示将重做日志异步写到磁盘,即写到文件系统的缓存中。因此不能完全保证在
执行comm时肯定会写入重做日志文件,只是有这个动作发生。
因此为了保证事务的ACID中的持久性,必须将 innodb flush log at trx commit设
置为1,也就是每当有事务提交时,就必须确保事务都已经写入重做日志文件。那么当
数据库因为意外发生岩机时,可以通过重做日志文件恢复,并保证可以恢复已经提交的
事务。而将重做日志文件设置为0或2,都有可能发生恢复时部分事务的丢失。不同之
处在于,设置为2时,当 MySQL数据库发生宕机而操作系统及服务器并没有发生宕机
时,由于此时未写入磁盘的事务日志保存在文件系统缓存中,当恢复时同样能保证数据
不丢失。
3.7小结
本章介绍了与 MySQL数据库相关的一些文件,并了解了文件可以分为 MySQL数
据库文件以及与各存储引擎相关的文件。与 MYSQL数据库有关的文件中,错误文件和
二进制日志文件非常重要。当 MySQL数据库发牛任何错误时,DBA首先就应该去查看错
误文件,从文件提示的内容中找出问题的所在。当然,错误文件不仅记录了错误的内容,
也记录了警告的信息,通过一些警告也有助于DBA对于数据库和存储引擎进行优化。
二进制日志的作用非常关键,可以用来进行 point in time的恢复以及复制
( replication)环境的搭建。因此,建议在任何时候时都启用二进制日志的记录。从
My SQL51开始,二进制日志支持 STATEMENT、ROW、MIX三种格式,这样可以更
好地保证从数据库与主数据库之间数据的一致性。当然DBA应该十分清楚这三种不同
格式之间的差异。
本章的最后介绍了和 InnoDB存储引擎相关的文件,包括表空间文件和重做日志文
件。表空间文件是用来管理 InnoDB存储引擎的存储,分为共享表空间和独立表空间
重做日忐非常的重要,用来记录 InnoDB存储引擎的事务目志,也因为重做日志的存在,
才使得 InnoDB存储引擎可以提供可靠的事务。http://blog.csdn.net/jiongyi1
BI
部拼
第4章表
夲章将从 InnoDe存储引擎表的逻辑存储及实现开始进行介绍,然后将重点分析表
的物理存储特征,即数据在表中是如何组织和存放的。简单来说,表就是关于特定实体
的数据集合,这也是关系型数据库模型的核心
4.1索引组织表
在 InnoDB存储引擎中,表都是根据主键顺序组织存放的,这种存储方式的表称
为索引组织表( index organized table)。在 InnodB存储引擎表中,每张表都有个主键
Primary Key),如果在创建表时没有显式地定义主键,则mnDB存储引擎会按如下方
式选择或创建主键:
口首先判断表中是否有非空的唯一索引( Unique NOT NULL),如果有,则该列即
为主键。
口如果不符合上述条件, InnoDB存储引擎自动创建一个6字节大小的指针。
当表中有多个非空唯一索引时, InnoDB存储引擎将选择建表时第一个定义的非空唯
索引为主键。这里需要非常注意的是,主键的选择根据的是定义索引的顺序,而不是
建表时列的顺序。看下面的例子
mysql> CREATE TABLE z 4
a INT NOT NUI. p
>b INT NULLI
C INT NOT NULLE
>d INT NOT NULL
UNIQUE KEY (b)r
UNIqUE KEY (d),UNIQUE KEY (c));
Query oK, 0 rows affected (0.02 sec)
mysql> INSERT INTo Z SELECT 1,2r3, 4
Query oK 1 row affected (0.00 sec)
Records
Duplicates: 0 Warnings: 0http://blog.csdn.net/jiongyi1
5
92第4章衣
部拼没
mysql> INSERT INTO 2 SELECT 5,6,7,3
Query OK, row affected (0. 00 sec)
Records: 1 Duplicates: o warnings: 0
mysql> INSERT INTO Z SELECT 9,1011 12
Query oK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0
上述示例创建了一张表z,有a、b、cd四个列。b、c、d三列上都有唯一索引,
不同的是b列允许NULL值。由于没有显式地定义主键,因此会选择非空的唯一索引,
可以通过下面的SQL语句判断表的主键值:
mysql> SElECT a, b, C,d, rowid FROM Z;
==--
三
wid I
---一+
4
56|7|8
l9|10|11
12
士
+一一-一+
3 rows in set (0.00 sec)
rowd可以显示表的主键,因此通过上述查询可以找到表z的主键。此外,虽然c、
d列都是非空唯一索引,都可以作为主键的候选,但是在定义的过程中,由于d列首先
定义为唯一索引,故 InnoDB存储引擎将其视为主键。
另外需要注意的是, rowid只能用于查看单个列为主键的情况,对于多列组成的主
键就显得无能为力了,如:
mysql> CREATE IABLE a
>a工NT,
>b正NT
PRIMARY KEY (ar b
>ENGINE=InnoDB;
Query OK, o rows affected (0.03 sec)
mysq2>工 NSERT工 NTo a sElECT1,1;
Query OK, 1 row affected (0.01 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> SELECT a, rowid from a
ERROR 1054(42522): Unknown column rowid in field listhttp:/blog.csdnnet/jiongyi11
5I.
4.2 InnoDB逻搏存储结构93
爸拼吾
42 InnoDB逻辑存储结构
从IoDB存储引擎的逻辑冇储结构看,所有数据都被逻辑地存放在一个空间中,称
之为表空间( tablespace),表空间又由段( segment)、区( extent)、页(page)组成。页在
些文档中有时也称为块( block), InnoDB存储引擎的逻辑存储结构大致如图4-1所示
Tablespace
Segnent
Extent
Leafnode segment
Extent
Non-Leaf node segment
rollback segment
Extent
Page
Ro
Ro
Ro
Irx id
Ro
Roll Pointer
ROY
Roll Pointer
ColI…
CoIn
口口口囗口口口
图4-1 InnoDB逻辑存储结构
421表空间
表空间可以看做是InDB存储引擎逻辑结构的最高层,所有的数据都存放在表空
间中。第3章中已经介绍了在默认情况下 InnoDB存储引擎有一个共享表空间 ibdatal,
即所有数据都存放在这个表空间内。如果用户启用了参数 innodb file per table,则每张
表内的数据可以单独放到一个表空间内。
如果启用了 innodb file per table的参数,需要注意的是每张表的表空间内存放的只
是数据、索引和插入缓冲 Bitmap页,其他类的数据,如回滚(undo)信息,插人缓冲
索引页、系统事务信息,二次写缓冲( Double write buffer)等还是存放在原来的共享表
空间内。这同时也说明了另一个问题:即使在启用了参数 innodb_file_ per tab之后,共
享表空间还是会不断地增加其大小。可以来做一个实验,在实验之前已经将 innodb file
per table设为ON了。现在看看初始共享表空间文件的大小:http://blog.csdn.net/jiongyi1
5
94第4表
mysql> SHCW VARIABLES LIKe 'innodb file per table'\Gi
南;胄肯霄食★肯★★肯大★士女★★★★★★★责★★
w★k古k言言言古玄言古古古身★★★★★★★★★★★
你
variable name: innodb file per table
Value: ON
1 row in set (0.00 secy
mysql> system ls -Ih /usr/local/mysql/data/ibdata
-rw-rw----1 mysqlmysql 58M Mar 11 13: 58/usr/local/mysql/data/ibdatal
以看到,共亨表空间 ibdatal的大小为58MB,接着模拟产生undo的操作,利用
第1章已生成的表 mytest,并把其存储引擎更改为 InnodB,执行如下操作:
mysql>seT autocommit=0;
Query OK, 0 rows affected (0.o0 sec)
mysql> UPDATE mytest sET salary=0
Query OK, 2844047 rows affected (19.47 sec)
Rows matched: 2844047 Changed: 2844047 Warnings: 0
mysql> system ls -lh /usr/local/mysql/data/ibdata*
w----l mysql mysql 114M Mar 11 14: 00 /usr/local/mysql/data/ibdatal
这里首先将自动提交设为0,即用户需要显式提交事务(注意,在上面操作结束时
并没有对该事务执行 cornmit或 rollback)。接着执行会产生大量undo操作的语句 update
mytest set salary=0,完成后再观察共享表空间,会发现 ibdata1已经增长到了14MB
这个例子虽然简单,但是足以说明共享表空间中还包含有undo信息。
有用户会问,如果对k这个事务执行 rollback, ibdata1这个表空间会不会缩减至原
来的大小(58MB)?这可以通过继续运行下面的语句得到验证:
mysql> ROLLBACK
Query OK, 0 rows affected (0.00 sec)
mysql> system ls -lh /usr/local/mysql/data/ibdata
rw-rw----1 mysql mysql 114M Mar 11 14: 00 /usr/local/mysql/data/ibdatal
很“可惜”,共享表空间的大小还是14MB,即 InnoDB存储引擎不会在执行 rollback
时去收缩这个表空间。虽然 InnoDB不会回收这些空间,但是会自动判断这些undo信息是
否还需要,如果不需要,则会将这些空间标记为可用空间,供下次undo使用。
回想一下,在第2章中提到的 master thread每10秒会执行一次的 full purge操作,
很有可能的一种情况是:用户再次执行上述的 UPDATE语句后,会发现 ibdatal不会再http://blog.csdn.net/jiongyi1
FI
42 InnoDB逻存諾结构95
增大了,那就是这个原因了。
冷能
我用 python写了一个 py innodb page info小工具,用来查看表空间中各贞的类
型和信息,用户可以在code. google. com上搜索davd- mysql- tools进行查找。使用方法
如下:
[rootenincyou0-43 py]# python py innodb page info. py /usr/local/mysql/data/
ibdatal
Total nunber of page: 83584:
Insert Buffer free list: 204
Freshly Allocated Page: 5467
Und。 Log page:38675
File segment inode: 4
Bt工 ee node:39233
File space Header: 1
可以看到共有83584个页,其中插人缓冲的空闲列表有204个页、5467个可用页、
38675个undo页、39233个数据页等。用户可以通过添加v参数来查看更详细的内容
由于该工具还在开发之中,因此并不保证在本书出版时此工具最终显示结果的变化
422段
图41中显示了表空间是由各个段组成的,常见的段有数据段、索引段、回滚段等
因为前面已经介绍过了 InnoDB存储引擎表是索引组织的( index organized),因此数据
即索引,索引即数据。那么数据段即为B+树的叶子节点(图41的 Leaf node segment),
索引段即为B+树的非索引节点(图4-1的Non- -leaf node segment)。回滚段较为特殊,
将会在后面的章节进行单独的介绍。
在 InnoDB存储引擎中,对段的管理都是由引擎自身所完成,DBA不能也没有必要
对其进行控制。这和 Oracle数据库中的自动段空间管理(ASSM)类似,从一定程度上
简化了DBA对于段的管理。
4.2.3区
区是由连续页组成的空间,在任何情况下每个区的大小都为1MB。为了保证区中页
的连续性, InnoDB存储引擎一次从磁盘申请4~5个区。在默认情况下, InnoDB存储
引擎页的大小为16KB,即一个风中一共有64个连续的页。http://blog.csdn.net/jiongyi1
BI
96第4表
InnoDb l.x版本开始引入压缩页,即每个页的大小可以通过参数 KEY BLOCK
SZE设置为2K、4K、8K,因此每个区对应页的数量就应该为512、256、128
nDB12x版本新增了参数 innodb page size,通过该参数可以将默认页的大小设
置为4K、8K,但是页中的数据库不是压缩。这时区中页的数量同样也为256、128。总之,
不论页的大小怎么变化,区的大小总是为1M
但是,这里还有这样一个问题:在用户启用了参数 innodb file per talbe后,创建的
表默认大小是96KB。区中是64个连续的页,创建的表的大小至少是1MB才对啊?其
实这是因为在每个段开始时,先用32个页大小的碎片页( fragment page)来存放数据,
在使用完这些页之后才是64个连续页的申请。这样做的目的是,对于一些小表,或者
是undo这类的段,可以在开始时申请较少的空间,节省磁盘容量的开销。这里可以通
过一个很小的示例来显示 InnoDB存储引擎对于区的申请方式:
mysql> CREATE TABLE. t1 4
Co11 INT NOT NULL AUTC INCREMENT
COl2 VARCHAR(7000
PRIMARY KEY col1)ENGINE=InnoDB
mysql> system Is -Ih /usr/local/mysql/data/test/tl ibd;
rw-rw----1 mysqlmysql 96K 10 F 12 14: 59 /usr/local/mysql/data/test/tlibd
上述的SQL语句创建了tl表,将col2字段设为 VARCHAR(7000,这样能保证一
个页最多可以存放2条记录。通过ls命令可以发现,初始化并创建t表后,表空间默认
大小为96KB,接着运行如下SQL语句:
mysql> INSERT t1 SELECT NULL, REPEAT('a'r7000)i
Query oK, 1 row affected (0.04 sec)
Records: 1 Duplicates:0 Warnings: 0
mysql> INSERT into tI SELECT NULL, REPEAT(a7000)
Query OK, l row aftected (0.01 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> system ls -lh /usr/local/mysql/data/test/tlibd
l mysql mysql 96K 10 F 12 16: 24 /usr/local/mysql/data/test/tlibd
插入两条记录,根据之前对表的定义,这两条记录应该位于同一个页中。如果这时
通过 py innodb_ page info工具来查看表空间,可以看到:
Irootanineyou0-43 py] ./py innodb page info. py -V/usr/local/mysql/data/test/
L1.ibdhttp:/blog.csdnnet/jiongyi11
5I.A
42mnDB逻解存储结灼97争
page offset 00000000, page type <File Space Header>
擦器
page offset 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page typc <Fiie segment inode>
page offset 00000003, page type <B-tree Node>, page level <0000>
page offset 00000000, page type <Freshly Allocated Page>
page offset 00000000, page type <Freshly Allocated Page>
Total [lumier of page: 6:
Freshly Allocated Page: 2
Insert Buffer Bitmap: 1
File Space Header: 1
B-tree Node: 1
File segment inode: 1
这次用v详细模式来看表空间的内容,注意到了 page offset为3的页,这个就是数
据贞。 page level表示所在索引层,0表示叶子节点。因为当前所有记录都在一个页中
因此没有非叶节点。但是如果这时用户再插入一条记录,就会产生一个非叶节点:
mysql> INSeRt into tl SElECt NULL, REPEAt(a,7000)i
Query OK, 1 row affected (c.01 sec)
Records: 1 Duplicates: 0 Warnings: 0
[rootGnineyou0-43 py]t ./py innodb page info. py -v /usr/ocal/mysql/data/test/
t1. ibd
page offset 00000000, page type <File Space Header>
page offsct 00000001, pagc typc <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>, page level <0001>
page offset 00000004, page type <B-tree Node>, page level <o000>
page offset 00000005, page type <B-tree Node>, page level <0000>
Total number of page: 6:
Insert Buffer Bitmap: 1
File space Header: 1
B-tree node 3
上 ile segment inode:⊥
现在可以看到 page offset为3的页的 page level由之前的0变为了1,这时虽然新插
入的记录导致了B+树的分裂操作,但这个页的类型还是 B-tree Node
接着继续上述同样的操作,再插入60条记录,也就是说当前表t中共有63条记
录,32个页。为了导入的方便,在这之前先建立个导入的存储过程
mySqL> DELIMITER//
mysql> CREATE PROCEDURE load tl(count INT UNSIGNED)http://blog.csdn.net/jiongyi1
5.
98第4幸表
拼没
BEGIN
DECLARE S INT UNSIGNED DEFAULT 1:
你
DECLARE C VARCHAR[7000)DEFAULT REPEAT('a,7000)i
WHILE S<= count DO
>INSERT INTo tl SElECt NULL,ci
SET S= S+1:
≥ END PHILE;
- ENd S
Query OK, 0 uws affected (0.04 sec)
mysql> DELIMITER i
mysql> CALL load t1(60)i
Query ok, 1 row affected (1. 59 sec)
mysql> SELECT COUNT (*)FROM t1 \ Gi
★★★★★★★安★内★★★★爽★★★★★★宴★★★1.r。w★★★★度★★★貴★★簧★★★★★★★史★定史★
count(*):63
l row in set (0.00 sec)l row in set (0. 00 sec)
mysql> system ls -lh /usr/local/mysql/data/test/tlibd;
Eh-Ew
1 mysql mysql 576k 10 F 12 16: 56 /usr/local/mysql/data/test/tlibd
可以看到,在导人了63条数据后,表空间的大小还是小于1MB,即表示数据空间
的申请还是通过碎片页,而不是通过64个连续页的区。这时如果通过py_ innodb page
inf工具再来观察表空间tbd文件,可得:
I eni neyou0-43 py]+-/py innodb page info.py -v /usr/local/mysql/data/test/
t1 ibd
page offset 00000000, page type <File Space Header>
page offset o0oc000l, page type <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>, page level <0001
page offset 00000004, page type <B-tree Node>, page level <0000>
page offset 000C0005, page type <B-tree Node>, page level <0000>
Page offset 000c0006, page type <B-tree Node>, page level <0000>
page offset 00000007, page type <B-tree Node>r page level <0000>
Page￡￡$e00000008, Page type<B-t工 Be node,aq日⊥eve1<0000>
page offset 00000009, page type <B-tree Node>, page level <0000>
page offset 0000000a, page type <B-tree Node>, page level <0000>
page offset 0000000b, page type <B-tree Node>, page level <0000>
page offset 0000000c, page type <B-tree Node>, page level <0000>
page offset 000c000d, page type <B-tree Node, page level <0000>http:/blog.csdnnet/jiongyi11
5I
42皿oDB逻抨存儲结构9
2°
page offset 0000000e, page type <B-tree Node>, page level <0000>
page offset 000000of, page type <B-tree Node>, page level <0000>
page offset 00000010, page t ype <B-tree Node>, page level <0000>
page offset 00000oll, page type <B-tree Node>, page level <0000>
page offset 00000012, Page type sB-tree Node>, page level <0000>
page offset 00000013, page type <B-tree Node>, page level <0000>
page offset 00000014, page type <B-tree Node>, page level <0000>
page offset 00000015, page type <B-tree Node>, page level <o000>
page o￡fset00000016, page type<B- tree node>,page⊥eve⊥<0000>
page offset 00000017, page type <B-tree Node>, page level <0000>
page offset 00000c18, page type <B-tree Node>, page level <0000>
page offset 00000019, page type <B-tree Node>, page level <0000>
page offset 00000cla, page type <B-tree Node>, page level <o000>
mage offset 000000 1b, page type <B-tree Node>, page level <0000>
page offset 00000clc, page type <B-tree Node>, page level<0000>
page offset 00000dld, page type <B-tree Node>, page level <0000>
page offset 00000ale, page type <B-tree Node>, page level <0000>
page offset 000000lf, page type <B-trcc Nodc>, page level <0000>
page offset 00000020, page type <B-tree Node>, page level <0000>
page offset 0000002l, page type <B-tree Node>, page level <0000>
page offset 00000022, page type <B-tree Node>, page level<0000>
page offset 00000023, page type <B-tree Node>, page level <0000>
Total nunber of page: 36:
Insert Buffer Bitmap: 1
File space Header: 1
B-tree Node: 33
ile Segment inode: 1
可以观察到B- ree Node页一共有33个,除去一个 page level.1的非叶节点页,
共有32个 page level为0的页,也就是说,对于数据段,已经有32个碎片页了。之
后用户再申请空间,则表空间按连续64个页的大小开始增长了。好了,接着就这样来
操作,插入一条数据,看之后表空间的大小:
rysq1> CALL load t1【1)
cuery oK, 1 row af=ected 0.10 sec)
mysql> system ls -ih /usr/local/mysql/data/test/tl, ibd;
1 mysql mysql 2. OM 10 A 12 17: 02 /usr/ local/ mysql/data/test/tl,ibd
因为已经用完了32个碎片页,新的页会采用区的方式进行空间的申请,如果此时
用户再通过 py innodb page info工具来看表空间文件t1bd,应该可以看到很多类型为
Freshly Allocated Page r yt:
[rootenineyou0-43 test2]#-/py,py innodb page info. py tl ibd -vhttp:/blog.csdnnet/jiongyi11
5I.A
I00韩4章表
page offset 00000000, page type <File Space Header>
page offset 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>, page level <0001>
page offset 00000004, page type <B-tree Node>, page level <0000>
page offset 00000005, page type <B-tree Node>, page level <0000>
page offset 00000006, pagc type <B-tree Node>, page level 40000>
page offset 00000007, page type <B-tree Node>, page level <0000>
age offset 00000008, page type <B-tree Node>, page level <0000>
page offset 00000009, page type <B-tree Node>, page level <0000>
page offset 0000000a, page type <b-tree Node>, page level <0000>
page offset 0000000b, page type <B-tree Node>, page level <0000>
page offset 0000000c, page type <B-tree Node>, page level <0000>
page offset o000000d, page type <B-tree Node>, page level <0000>
page offset 0000000e, page type <B-tree Node>, page level <0000>
page offset 0000000f, page type <B-tree Node>, page level <0000>
page offset 00000010, page type <B-tree Node>, page level <0000>
page offset 0000001l, page type <B-tree Node>, page level <0000>
page offset 00000012, page type <B-tree Node>, page level <0000>
page offset 00000013, page type <B-tree Node>r page level <0000>
page offset 00000014, page type <B-tree Node>, page level <oD00>
page offset 00000015, page type <B-tree Node>, page level <0000>
page offset 00000016, page type <B-tree Node>, page level <0000>
page offset 00000017, page type <B-tree Node>, page level <0000>
page offset 00000018, page type <B-tree Node>, page level <0000>
page offset 00000019, page type <B-tree Node>r page level <0000>
page offset 000000la, page type sB-tree Node>, page level <0000>
page offset 000000lb, page type <B-tree Node>, page level <0000>
page offset 000000lc, page type <B-tree Node>, page level <0000>
page offset 000000ld, page type <B-tree Node>, page level <0000>
page offset 000000le, page type <B-tree Node>, page level <0000>
page offset 0000001f, page type <B-tree Node>, page level <0000>
page offset 00000020, page type <B-tree Node>, page level <0000>
page offset 00000021, page type <B-tree Node>, page level <0000>
page offset 00000022, page type <B-tree Node>, page level < 0000>
Paye offseL 00000023, paye type <B-tree Node,, page level co0c02
page offset 00000000, page type <Freshly Allocated Page>
page offset 00000000, page type <Freshly Allocated Page>
page offset 00000000, page type <Freshly Allocated Page>
page offset 00000000, page type <Freshly Allocated Page>
Total number of page: 128:
Freshly Allocated Page: 91
Insert Buffer bitmap: 1http:/blog.csdnnet/jiongyi11
51.A
42moDB逻轷存储结构l0l
研
File Space Header: 1
B→ tree Node:34
File Segment inode: 1
4.2.4
页
同大多数数据库一样, InnoDB有页(Page)的概念(也可以称为块),页是 InnoDB
磁盘管理的最小单位。在 InnoDB存储引擎中,默认每个页的大小为16KB。而从
InnoDB12x版本开始,可以通过参数 innodb page_size将页的大小设置为4K、8K
16K。若设置完成,则所有表中页的大小都为 innodb page size,不可以对其再次进行修
改。除非通过 mysqldump导人和导出操作来产生新的库
在 InnoDe存储引擎中,常见的页类型有
口数据页(B- tree Node)
口undo页( undo Log Page)
口系统页( System Page)
口事务数据页( Transaction system Page)
口插入缓冲位图页( Insert Buffer Bitmap)
口插入缓冲空闲列表页( Insert Buffer Free List)
日未压缩的二进制大对象页( Uncompressed BLOB Page)
口压缩的二进制大对象页( compressed BLOB Page)
425行
InnoDB存储引擎是面向列的(row- oriented),也就说数据是按行进行存放的。每个
页存放的行记录也是有硬性定义的,最多允许存放16KB/2-200行的记录,即7992行
记录。这里提到了 row-oriented的数据库,也就是说,存在有 column- oriented的数据库。
MySQL infobright存储引擎就是按列来存放数据的,这对于数据仓库下的分析类SQL语
句的执行及数据压缩非常有帮助。类似的数据库还有 Sybase IQ、 Google Big Table。面
向列的数据库是当前数据库发展的一个方向,但这超出了本书涵盖的内容,有兴趣的读
者可以在网上寻找相关资料。http://blog.csdn.net/jiongyi1
5
1024幸夜
蜜者要
43 InnoDB行记录格式
InnoDB存储引擎和大多数数据库一样(如 Oracle和 Microsoft SQL Server数据库),
记录是以行的形式存储的。这意味着页中保存着表中一行行的数据。在 InnoDB10x版
本之前, InnoDB存储引擎提供了 Compact和 Redundant两种格式来存放行记录数据,这
也是目前使用最多的一种格式。 Redundant格式是为兼容之前版本而保留的,如果阅读
过 InnoDB的源代码,用户会发现源代码中是用 PHYSICAL RECORD( NEW STYLE
和 PHYSICAL RECORD( OLD STYLE)来区分两种格式的。在 MySQL51版本中,默
认设置为 Compact行格式。用户可以通过命令 SHOW TABLE STATUS LIKE' table
name'来查看当前表使用的行格式,其中 row format属性表示当前所使用的行记录结构
类型。如
mysql> SHOW TABLE STATUS like mytest8 \G
★★十★★★★★青★★★言★x大“;★★★★1,r。W實★青★★★★★★★青★★青★★★★青古★★青赏
Name: nytest
Engine: -nnoDB
Ersion: 10
R。 w format: Compact
ROWs: 6
Avg row length: 2730
Data length: 16384
Max data length: 0
Index length: 0
Data free: o
Auto increment: NULL
Create time:2009-03-1713:33:50
Update time: NULL
Check time: NULL
Collation: latin swedish ci
checksum: NULL
Create options
Cemment
★读害★宝★实*;害x害實;★胄青★育2,row青實★實★赏★背大定青实常言宽常★定我胄★言
Name: mytest2
Engine: IIlIODB
Version: 10
R。。七: Redundan七
R。ws:0
Av row length
Data length: 16384http://blog.csdn.net/jiongyi1
6I
43ⅠmoDB行记求式103
Max data length: 0
Index length: 0
Data free: 0
Auto increment: NULL
Create time:2009-03-1713:57:23
Update time: NULL
check time: NULL
collation: latini swedish ci
Checksum: NULL
Create options: row format=REDUNDANT
Comment
2 rows in set(0。00sec
可以看到,这里的 mytest表是 Compact的行格式, mytest2表是 Redundant的行格
式。通过之前的介绍可以知道,数据库实例的作用之一就是读取页中存放的行记录。如
果用户自己知道页中行记录的组织规则,也可以自行通过编写工具的方式来读取其中的
记录,如之前介绍的 py innodb page info工具。本节的其余小节将具体分析各格式存放
数据的规则
43.1 Compact行记录格式
Compact行记录是在 MySQL50中引入的,其设计目标是高效地存储数据。简单来说,
个页中存放的行数据越多,其性能就越高。图42显示了 Compact行记录的存储方式:
变长字段长度列表NUL标志位
记录头信息
列撒据列2数据
图42 Compact行记录的格式
从图4-2可以观察到, Compact行记录格式的首部是一个非NULL变长字段长度列
表,并且其是按照列的顺序逆序放置的,其长度为:
口若列的长度小于255字节,用1字节表示;
口若大于255个字节,用2字节表示
变长字段的长度最大不可以超过2字节,这是因在 MySQL数据库中 VARCHAR类
型的最大长度限制为65535。变长字段之后的第二个部分是NLL标志位,该位指示了
该行数据中是否有NULL值,有则用1表示。该部分所占的字节应该为1字节。接下来
的部分是记录头信息( record header),固定占用5字节(40位),每位的含义见表4-1。http:/blog.csdnnet/jiongyi11
5.e
04募4幸表
考实
表4-1 Compact记录头信息
督份令
名称大小()
描述
未知
未知
deleted flag
该行是否已被删除
Inin rec flag
为1,如果该记录是预先被定义为最小的记录
n owned
该记录拥有的记录数
heap_ no
13索引堆中该条记录的排序记录
记录类型,000表示普通,001表示B树节点指针,010表示 Infimum,O1表示
record type
Supremum,1xx表示保留
next record
16
页中下一条记录的相对位置
Total
40
最后的部分就是实际存储每个列的数据。需要特别注意的是,NULL不占该部分任
何空间,即NULL除了占有NULL标志位,实际存储不占有任何空间。另外有一点需要
注意的是,每行数据除了用户定义的列外,还有两个隐藏列,事务ID列和回滚指针列
分别为6字节和7字节的大小。若 InnoDB表没有定义主键,每行还会增加一个6字节
的 rowid列。
接下去用一个具体示例来分析 Compact行记录的内部结构:
mysql> CREATE TABLE mytest
x tl VARCHAR(l0)
>t2 VARCHAR【10),
> t3 CHAr(10
t4 VARCHAR(10)
->)ENGINE=INNODB CHARSET=LATINI ROW FORMAT=COMPACT:
Query OR, 0 rows affected (0.00 sec)
mysql> INSERT INTo mytest
->VALUEs (a,'bb'bb'ccc):
Query oK, 1 row affccted (0.01 cc)
mysqL> INSERT INTo mytest
> VALUES【'd"';"ee"r"ee";"fff"》;
Query OK, l row affected (0.00 sec)
mysql> INSERT INTo mytest
VALUeS (d NUlL, NULL,fff.)
luery OK, 1 row affected (0.00 sec)
mysqL> SELECT FROM mytest\G
★走★★★★★★★古大青青★青青青★青言1.￥ow★★★★★★★*★*k责★★★★k★★★★★★★★http:/blog.csdnnet/jiongyi11
5I.A
43moDB行记录裕式l05
t1
t2: bb
t3: bb
t4: ccc
★青k肃★肃实★★★女为卖★*t★★有★2,row南为大大内为★有★★★★★★★青★★★★★★★★
t1:
t2: ee
t3: ee
t4: fff
★实★★实★丈实女★★★★★★★★★女★★★*3.yw青★★青言★害读★★★★★吉t★★青言★青言
t 1: d
t2: NULL
t3: NULL
t4: Eff
rows in sct (0.d0 sec)
在上述示例中,创建表 mytest,该表共有4个列。t1、t2、t4都为Ⅵ ARCHAR变长
字段类型,t3为定长度类型CHAR。接着插入了3条有代表性的数据,然后将打开表
空间文件 mytest ibd(这里启用了 innodb file_ per table,若没有启用该选项,打开默认
的共享表空间文件 ibdata l)。
在 Windows操作系统下,可以选择通过程序 ULtraedit打开该二进制文件。在 Linux
环境下,使用命令 hexdump-C- v mytestibd> mytest. txt。这里将结果重定向到了文件
mytest. txt,打开 mytest. txt文件,找到如下内容:
c000c0707375707265675∈d0302010000001000| supremum
c000c0802c0000002b6800C00000000605800000
cooc09000320110616262626220202020202020|.2. albbb
0000c0d020636363030201C0000018002b000000|ccc.......+.
0000c0b02b630100000000060680000000320110|+h
0000c0c064656565652020202020202020666666| deeeefir
0000c0d0030106000020ff980000002b68020000
0000c0e0000006078000000032011064666666001......2..dfff
该行记录从0000078开始,若整理一下,相信用户会有更好的理解:
030201/*变长宇段长度列表,逆序*
00/*NULL标志位,第一行没有NULL值*
000010002c/* Record header,固定5字节长度*
UU0Uυ02b6800/* ROwID InnoDe自动创建,6字节*/
000000 0605/*TransactionID*/
80000000320110/*R11 Pointer*
61/*列1数据"a1*http://blog.csdn.net/jiongyi1
I
106第4幸表
6262/*列2数据"bb!★/
62622020202020202020/*列3数据·bb!+!
636363/*列4数据'cce糞
现在第一行数据就展现在用户眼前了。需要注意的是,变长字段长度列表是逆序存
放的,因此变长字段长度列表为030201,而不是010203。此外还需要注意 InnoDB每
行有隐藏列 Transaction和 Roll pointer。同时可以发现,固定长度CHAR字段在未能
完全占用其长度空间时,会用0x20来进行填充
接着再来分析下 Record header的最后两个字节,这两个字节代表 next recorder,
0x2c代表下一个记录的偏移量,即当前记录的位置加上偏移量0x2c就是下条记录的
起始位置。所以 InnoDe存储引擎在页内部是通过一种链表的结构来串连各个行记
录的。
第二行将不做整理,除了 ROwIN不同外,它和第一行大同小异,有兴趣的读者可以
用上面的方法自己试试。现在来关心有NULL值的第三行:
0301/★变长字段长度列表,逆序*!
06/*NULL标志位,第三行有NULL值*
00 20 ff 98/*Record Header+/
00o00002b6802/*R。wTD*
000000 000607/*TransactionID*/
80000000320110/*Ro11 Fainter*/
64/*列1数据
666666/*列4数据'￡￡f*
第三行有NULL值,因此NULL标志位不再是00而是06,转换成二进制为
0000010,为1的值代表第2列和第3列的数据为NULL。在其后存储列数据的部分,
用户会发现没有存储NULL列,而只存储了第1列和第4列非NUL的值。因此这个例
子很好地说明了:不管是CHAR类型还是 VARCHAR类型,在 compact格式下NULL
值都不占用任何存储空间。
432 Redundant行记录格式
Redundant是 MySQL50版本之前ImoB的行记录存储方式, MySQL50支持
Redundant是为了兼容之前版本的页格式。 Redundant行记录采用如图43所示的方式存储。http:/blog.csdnnet/jiongyi11
51.6
4.3nODB行记录式107
强拼没翻
字段长度偏移列表
记录头信息
列1数据
列款据列数据矿B
图4-3 Redundant行记录格式
从图43可以看到,不同于 Compact行记录格式, Redundant行记录格式的首部是
个字段长度偏移列表,同样是按照列的顺序逆序放置的。若列的长度小于255字节
用1字节表示;若大于255字节,用2字节表示。第二个部分为记录头信息、( record
header),不同于 Compact行记录格式, Redundant行记录格式的记录头占用6字节(48
位),每位的含义见表42。从表4-2中可以发现, n fields值代表一行中列的数量,占用
10位。同时这也很好地解释了为什么 MySQL数据库一行支持最多的列为1023。另一个
需要注意的值为1byte_ofs_fags,该值定义了偏移列表占用1字节还是2字节。而最后
的部分就是实际存储的每个列的数据了。
表4-2 Redundant记录头信息
名称
大小(bi)
描述
未知
未知
deleted flag
该行是否已被删除
min rcc fiag
为1,如果该记录是预先被定义为最小的记录
n owned
该记录拥有的记录数
heap_ no
13
索引堆中该条记录的索引号
n fields
10
记录中列的数量
I byte offs flag
偏移列表为I字节还是2字节
next record
16
页中下一条记录的相对位置
Total
48
接着创建一张和431节中表 mytest内容完全一样但行格式为 Redundant的表 mytest2
mysql> CREATE TABLE mytest2
ENGINe= InnodB row forMat-Redundant
AS
SELECT X EROM mytesti
Query OK, 3 rcws affected (0.00 sec)
Records:3 Duplicates: 0 Warnings: 0
mysql> SHOW TABLE S-ATUS LIKE mytest2 \G;
★★★★青★★★★食★★★★★★了★实★★1.￥。w*★★青★★肃★青大大青古古大★古★★★言青青
Name: mytest2
Engine: Inno DBhttp:/blog.csdnnet/jiongyi11
5I
1084幸夜
Version: 10
Row format: Redundant
ROWs: 3
Avg row length: 5461
Data length: 16384
Max data length: o
Index length: o
Data free: 0
Auto increment: NULL
Create time:2009-03-1815:49:42
Update time: NUlL
Check time:NUL工
Collation: latin swedish ci
Checksum: NULL
Create options: row format REDUNDANT
lent
1 row in set (0.c0 sec)
mysql> SElECt FROM mytest2\Gi
★★★★啬★古古古吉古青青古青大青共大★大★★1r◎w
tl
t2: bb
t3: bb
t4: ccc
★★典卖★★★★★★★★★★灾★实背★★★★★2。rw★★★★★★★★★害青青t青言青育南育青青
1:d
t2: ee
L3: ee
t4: fff
★★★★★★★★★★★★女★★★★★★★★★女3.r。w★★★★★
北史责责★★★々★★
t1: d
t2: NULL
t3: NULL
t4: fff
3 rows in set (0.00 sec)
可以看到,现在 row format变为 Redundant。同样通过 hexdump将表空间 mytest2
ibd导出到文本文件 mytest2.xt打开文件,找到类似如下行:
0000c0700803000073757072656d756d002320161..8 urenui,,
00c0c08014130c0ξ0000100f00ba0000002b680b|,,,,,,,,,+h,l
0000c09000000000065380000000320110616262
2. abb
0000c0a062622020202020202020636363232016bb
c:.http://blog.csdn.net/jiongyi1
5.
4.3 InnoDB行记乘格式109争
部拼没
0000c0b014130c060000180f00ea00c3002b680c
h
00coo65652020202020202020666666219e94le∴…s,,el
0000c0c00000000006538000000032011e646565
fff!. I
0000c0e014130c06000020000740000002b680d
0000c0f00000000006538000000032012c640000
0000c100
00000000000000006666660000000000
,.,,...fff
整理可以得到如下内容:
23201614130c06/*长度偏移列表,逆序*
000010cf00ba/* Record header,固定6个字节*
0000002b680b!* ROWID*
00000005 0653/*TransactionID*/
800000c0320110/*R。11 Point*
61/列1数据'a'*/
6262/*列2数据”bb!
62622020202020202020/*列3数据" bb Caar类型*/
636363/*列4数据tcce1
23201614130c06逆转为06,0c,13,14,16,20,23,分别代表第一列长度6,第
二列长度6(6+6-0x0C),第三列长度为7(6+6+7=0x13),第四列长度1(6+6+7+1=0x14),
第五列长度2(6+6+7+1+2-0x16),第六列长度10(6+6+7+1+2+10=0x20),第七列长度3
(6+6+7+1+2+10+3=0x23)。
在接下来的记录头信息( Record header)中应该注意48位中的第22~32位,为
0000001表示表共有7个列(包含了隐藏的3列),接下来的第33位为1,代表偏
移列表为一个字节。
后面的信息就是实际每行存放的数据了,这同 Redundant行记录格式大致相同,注
意是大致相同,因为如果分析第三行,会发现对于NULL值的处理两者是非常不同的:
219e9414130c06/*长度偏移列表,逆序*
0000200f0074/* Record header,固定6字节*
0000002b680d/* ROWID*
000000 000653/*TrarsactionID*/
80000000320110/*Ro11Poim
64/*列1数据!d!*
00c00000000000000000/*列3数据NULL*
666666/*列4数据fff·☆/
这里与之前 Compact行记录格式有着很大的不同了,首先来看长度偏移列表,逆序
排列后得到060c1314949e21,前4个值都很好理解,第5个NULL值变为了94,接http://blog.csdn.net/jiongyi1
5
110邦4表
部拼没
着第6个CHAR类型的NULL值为9e(94+10-0x9e),之后的21代表(143=0x21
可以看到对于 VARCHAR类型的NULL值, Redundant行记录格式同样不占用任何存储
空间,而CHAR类型的NULL值需要占用空间。
当前表 mytest的字符集为 Latin1,每个字符最多只占用1字节。若用户将表
test的字符集转换为ut8,第三列CHAR固定长度类型不再是只占用10字节了,而
是10×3-30字节。所以在 Redundant行记录格式下,CHAR类型将会占用可能存放的最
大值字节数。有兴趣的读者可以自行尝试。
433行溢出数据
InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外。一般认
为BLOB、LOB这类的大对象列类型的存储会把数据存放在数据页面之外。但是,这个
理解有点偏差,BLOB可以不将数据放在溢出页面,而且即便是 VARCHAR列数据类型,
依然有可能被存放为行溢出数据
首先对 VARCHAR数据类型进行研究。很多DBA喜欢 MySQL数据库提供的
VARCHAR类型,因为相对于 Oracle VARCHAR最大存放4000字节, SQL Server最大
存放8000字节, MySQL数据库的Ⅵ ARCHAR类型可以存放65535字节。但是,这是真
的吗?真的可以存放65535字节吗?如果创建 VARCHAR长度为65535的表,用户会
得到下面的错误信息:
mysql> CREATE TABLE test
a VARCHAR(65535)
)CHARSET=latin ENGINE=InnoDB i
ERROR 1118 (42000]: Row size too large. The maximum row size for the used table
type, not counting BLOBs, is 65535. You have to change some columns to TEXT or
BLOBS
从错误消息可以看到 InnoDB存储引擎并不支持65535长度的 VARCHAR。这是因
为还有别的开销,通过实际测试发现能存放 ARCHAR类型的最大长度为65532。例
如,按下面的命令创建表就不会报错了
mysql> CREATE TABLe test
a VARCHAR(65532
) CHARSET=latin1 ENGINE=InnoDB
Query OK, 0 rows affected (0.15 sec)http:/blog.csdnnet/jiongyi11
5.e
4.3moDB行记录格式Ill
需要注意的是,如果在执行上述示例的时候没有将 SQL MODE设为严格模式或
许可以建立表,但是 MySQL数据库会抛出一个 warnIng,如
my sql> CREATE TABLE test
a VARCHAR(65535)
>)CHARSET=latin ENGINE=InnoDB i
Query OK, 0 rows affected, 1 warning (0.14 sec)
mysql> SHOW WARNINGS\Gi
大青★古青青肯六青青★青★青青害卖责★★★1.rOW“;古古计★六古★★★★★★女★大★★★★★青
Leyel: note
Code 1246
Message: Converting column 'a from VARCHAR to TEXT
1 row in set (0.00 sec)
waning信息提示了这次可以创建是因为 MySQL数据库白动地将 VARCHAR类型
转换成了TEXT类型。查看test的表结构会发现:
mysql> SHCW CREATE TABle test\Gi
★★责★南卖密曹★★★★貴★★★★★★爽★★★1,工W读★★★★★★★走女★女★★★女★★★★★★★★★★★
Table: test
Create Table: CREATE TABLE Itest.
a mediumtext
ENGINE= Inno DB DEFAUT T CHARSET=ut fB
1 row in set (0.00 seck
还需要注意上述创建的 ARCHAR长度为65532的表,其字符类型是1atin的,如
果换成GBK又或UTF-8的,会产生怎样的结果呢?
mysql> CREATE TABLE test
a VARCHAR(65532
->)CHARSET=GBK ENGINE=InnoDB
ERROR 1074(42000):Column length too big for column 'a (max = 32767): use
BLOB O￥ TExT instead
mysql> mysql> CREATE TABlE test
a VARCHAR《65532
)CHARSET=UTF8 ENGINE";
ERROR 1074(420000:Column length too big for column F
(maXm21845):u8e
BLoB。 TEXT instead
这次即使创建列的 VARCHAR长度为65532,也会提示报错,但是两次报错对max
值的提示是不同的。因此从这个例子中用户也应该理解 VARCHAR(N)中的N指的是
字符的长度。而文档中说明 ARCHAR类型最大支持65535,单位是字节http:/blog.csdnnet/jiongyi11
51.6
12第4章表
挤吾
此外需要注意的是, MySQL官方手册中定义的65535长度是指所有 VARCHAR
的长度总和,如果列的长度总和超出这个长度,依然无法创建,如下所示
mysql> CREATE TABLE test2
a VARChAr(22000),
b VARCHAR (22000)
C VARCHAR(22000)
>)CHARSET=latin ENGINE-InnoDB;
ERROR 1118(42000): Row size too large, The maximum row size for the used table
typer not counting BLOBs is 55535, You have to change some columns tc TEXT or
BLOBS
3个列长度总和是66000,因此 InnoDB存储引擎再次报了同样的错误。即使能存放
65532个字节,但是有没有想过, InnoDb存储引擎的页为16KB,即16384字节,怎么
能存放65532字节呢?因此,在一般情况下, InnoDB存储引擎的数据都是存放在页类
型为 B-tree node中。但是当发生行溢出时,数据存放在页类型为 Uncompress BLOB页
中。来看下面一个例子:
mysql> CREATE TAble t
->a vArchar(65532)
>)ENGINE=InnoDB CHARSET=latini;
Query oK,0 rows affected (0.15 sec)
mysql> INSERT INTo t
- SELECT REPEAT('a65532):
Query oK, 1 row affected (0.08 sec
Records: 1 Duplicates: 0 Warnings: 0
在上述例子中,首先创建了一个列a长度为65532的 VARCHAR类型表t,然后插
入了列a长度为65532的记录,接着通过工具 py innodb page info看表空间文件,可
以看到的页类型有:
trootenineyou-43 mytest]f py innodb page info. py -v t lbd
page offset 0c000000, page type <File Space Header>
page offset oC000001, page type <Insert Buffer Bitmap>
page ottset C000002, page tyre <File Segment inode>
Page offset 0C000003, page type <B-tree Node>, page level<0000>
page offset 00000004, page type <Uncompressed BLOB Page>
page offset 00000005, page type <Uncompressed BLOB Page>
page offset 00000006, page type <Uncompressed BLOB Page>
page offset 00000007, page type <Uncompressed BLOB Page>
Total number cf page: 8
Insert Buffer Bitmap: 1http://blog.csdn.net/jiongyi1
5
43mDB行记灭式13
Uncompressed BLOB Page: 4
File Space Header: 1
B-tree Node: 1
File segment inade: 1
通过工具可以观察到表空间中有一个数据页节点B- tree Node,另外有4个未压缩的
二进制大对象页 Uncompressed BLOB Pagc,在这些页中才真正存放了65532字节的数
据。既然实际存放的数据都在BLOB页中,那数据页中又存放了些什么内容呢?同样通
过之前的 hexdump来读取表空间文件,从数据页c000开始查看:
0000c000 67 ce fc Oh 00 00 03 ffff ff ffffff ff ff g..1
0000c0100000000a6ad9c08945bf000000000000
00000200000000000c3000203a7800300000000
0000≈0300080000505000001000000000000000
0000040000000000300000001a1000000c300001,,,,,,,,,,,
0000:050000200f2000000c30000000200320100
2.,
0000≈06002001d696e66696d756d0002000b0000|... infimum.
0000c07073757072656d756d14c30000Q010￡f0 I supremum。,,,,,l
0000c080000000b62b00000000514b0680000000
,,oR
00000902d011061616161616161616161616161|-. aaaaaaaaaaaaa l
0000≈0a061616161616161616161616161616161| aaaaaaaaaaaaaaaa l
0000c0b061616161616161616161616161616161| aaaaaaaaaaaaaaaa l
0000-0c061616161616161616161616161616161 aaaaaaaaaaaaaaaa l
0000c0d061616161616161616161616161616161| aaaaaaaaaaaaaaaa l
0000≈0e061616161616161616161616161616161| aaaaaaaaaaaaaaaa l
00000f061616161616161616161616161616161| aaaaaaaaaaaaaaaa
0000≈10061616161616161616161616161616161| aaaaaaaaaaaaaaaa
0000:11061616161616161616161616161616161 aaaaaaaaaaaaaaaa l
0000c390616161000000c3000000040000002600|aaa.,,
0000c3a00000000000fc三c000000000000000000|,,。:,...。:...
可以看到,从0x000093到0x000c392数据页面其实只保存了 VARCHAR(65532)
的前768字节的前缀( prefix)数据(这里都是a),之后是偏移量,指向行溢出页,也就
是前面用户看到的 Uncompressed BLOB Page。因此,对于行溢出数据,其存放采用图44
的方式
InnoDB行
申曲
prefix768 bytes●
BLOB Page
图44行溢出数据的存储http://blog.csdn.net/jiongyi1
FI
I14笫4章衣
那多长的 VARCHAR是保存在单个数据页中的,从多长开始又会保存在BLQB
呢?可以这样进行思考: InnoDB存储引擎表是索引组织的,即B+Tee的结构,这样每
个页中至少应该有两条行记录(否则失去了B+ Tree的意义,变成链表了)。因此,如果
页中只能存放下一条记录,那么 InnoDB存储引擎会自动将行数据存放到溢出页中。考
虑下面表的一种情况:
mysc1> CREATE TALBE t【
a VARCHAR (9000
>ENGINE=InnoDE F
Query oK;0r。wsa￡ testes(0,13sec)
mysql> INSERT INTo t
->SELECT REPEAT('a,9000)i
Query oK 1 row affected (0.04 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysc1>工 NSERT INTO t
- SELECT REPEAT (a,9000)7
Query ok, 1 row affected[ 0.04sec
Records: 1 Duplicates: 0 Warnines: 0
表t变长字段列a的长度为9000,故能存放在一个数据中,但是这并不能保证两条
长度为9000的记录都能存放在一个页中。若此时通过 py innodb page info工具查看,
可知行数据是否存放在BLOB页中
Iroctenineyou0-43 mytest]t py innodb page info. py -w t, ibd
page offset 00000000, page type <File space Header>
page offset 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page type <file segment inode>
page offset 00000003, page type <e-tree Node>, page level <00002
page offset 00000004, page type <Uncompressed BLOB Page>
page offset 00c00005, page type <Uncompressed BLOB age>
Total number of page: 6
Insert Buffer Bitmap: 1
Uncompressed BlOB Page: 2
File Space Header: 1
B-tree Node: 1
File segment inode: 1
注意因为 py innodb page info工县查看的是磁盘文件,故运行上迷示例时,
需妥确保缓冲池中的页都刷回到磁盘。http:/blog.csdnnet/jiongyi11
43mDB行记录式5
但是,如果可以在一个页中至少放入两行数据,那 VARCHAR类型的行数据就不会
存放到BLOB页中去。经过多次试验测试,发现这个阈值的长度为8098。如用户建立
个列为 varchar(8098)的表,然后插入2条记录:
mysql> CREATE TABlE t
archar(8098)
)ENGINE=InnoDB:
Query oK,0y。 ws affected〔0.12sec}
mysql> INSErt into t SELECT REPEAT(a,8098
Query Okr l row affected (0.04 ec)
Records: 1 Duplicates: 0 warnings: 0
mysql> INSERT INto t SELECT REPEAT (a,:i
Query oK, 1 row affected (0. 03 sec)
Records: 1 Duplicates: 0 Warnings: 0
接着用 py innodb page info工具对表空间tbd进行查看,可以发现此时的行记
录都是存放在数据页中,而不是在BLOB页中了(熟悉 Microsoft SQL Server数据库的
DBA可能会感觉 InnoDB存储引擎对于 VARCHAR类型的管理和 SQL Server中的 varchar
(MAX)类似)。
[rootenineyou0-43 mytest]+ py innodb page info. py -v tibd
page offset 00000000, page type <File Space Header>
page offsct 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>, page level <0000>
page offset 00.000C00, page type <freshly Allocated Page>
page offset 00000C00, page type <Freshly Allocated Page>
Tota⊥ number of page:6
Freshly Allocated Page: 2
Insort Buffer Bitmap: 1
File space Header: 1
B-tree Node: 1
File segment inode: 1
另一个问题是,对于TEXT或BOB的数据类型,用户总是以为它们是存放在
Uncompressed BLOB Page中的,其实这也是不准确的,是放在数据页中还是BLOB页中,
和前面讨论的 VARCHAR一样,至少保证一个页能存放两条记录,如
mysql> CREATE TablE t
>a bloBhttp://blog.csdn.net/jiongyi1
5
116躬4亨表
>)ENGINE=InnoDB:
你
Query OK, D rows affected (0.12 see)
mysql> INSERT INTo t SELECT REPEAT(a, 8000):
Query oK
row affected (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTo t SELECT REPEAT(a,8000);
Query OK, l row affected (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTo t SELECT REPEAT(a8000)i
Query OK, 1 row affected (0.01 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTo t sELECT REPEAT(a,8000)i
Query OK, l row affected (0.06 sec)
Records: 1 Duplicates:0 Warnings: 0
上述例子建立含有BLOB类型列的表,然后插人4行数据长度为8000的记录。若
通过py_ innodb page info工具对表空间tbd进行查看,会发现其实数据并没有保存在
BLOB页中。
lrootenineyou0-43 mytest] py innodb page info, py -v t ibd
page offset 00000000, page type <File Space Header>
page offset 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offse: 00000003, page type <B-tree Node>r page level <0001>
page offset 00000004, page type <B-tree Node r page level <00002>
page offset 00000005, page type <B-tree Node>, page level<o000>
page offset 00000006, page type <B-tree Node>, page level <0000>
page offset 00000000, page type <Freshly Allocated Page>
Total number of page: 8:
Freshly Allocated l'age: 1
Insert Buffer Bitmap: 1
File Space Header: 1
B-tree node: 4
File segment inode: 1
当然既然用户使用了BLOB列类型,一般不可能存放长度这么小的数据。因此在大
多数的情况下BLOB的行数据还是会发生行溢出,实际数据保存在BLOB页中,数据页
只保存数据的前768字节。http://blog.csdn.net/jiongyi1
5I.
4.3oDB行记录括式17
434 Compressed和 Dynam行记录格式
你
InnoDB10.x版本开始引入了新的文件格式( file format,用户可以理解为新的页格式),
以前支持的 Compact和 Redundant格式称为 Antelope文件格式,新的文件格式称为 Barracuda
文件格式。 Barracuda文件格式下拥有两种新的行记录格式: Compressed和 Dynamic
新的两种记录格式对于存放在BLOB中的数据采用了完全的行溢出的方式,如
图4-5所示,在数据页中只存放20个字节的指针,实际的数据都存放在 Off Page中,
而之前的 Compact和 Redundant两种格式会存放768个前缀字节。
InnoDB行
20字节
Off Page
图4-5 Barracuda文件格式的溢出行
Compressed行记录格式的另一个功能就是,存储在其中的行数据会以zlib的算法进
行压缩,因此对于BLOB、TEXT、 VARCHAR这类大长度类型的数据能够进行非常有效
的存储
43.5CHAR的行结构存储
通常理解 ARCHAR是存储变长长度的字符类型,CHAR是存储固定长度的字符类
型。而在前面的小节中,用户巳经了解行结构的内部的存储,并可以发现每行的变长字
段长度的列表都没有存储CHAR类型的长度。
然而,值得注意的是之前给出的两个例子中的字符集都是单字节的 latinI格式。从
MySQL4.1版本开始,CHR(N)中的N指的是字符的长度,而不是之前版本的字节长度。
也就说在不同的字符集下,CHAR类型列内部存储的可能不是定长的数据。例如下面的
这个示例:
mysql> CREATE TABLE 3
- a CHAR(2)
->)CHARSET=GBK ENGINE=InnoDB:
Query OK, 0 rows affected (0.11 sec
mysql> INSERT INTO j sElECT lab'i
Query OK, 1 row affected (0.03 sec)http:/blog.csdnnet/jiongyi11
5I.A
184幸袤
Records: Duplicates: 0 Warnings: 0
督里令
mysql> SET NAMES GBK
Query OK, 0 rows affected (0.00 sec)
mysq1> INSERT INTO 1 SELECT'我们';
Query OK, 1 row affected [0.04 sec)
Records: Duplicates: 0 Warnings: 0
mysql> INSERT INTO 1 SELECT i
Query OK, 1 row affected (0.03 sec)
Records: Duplicates: 0 Warnings: 0
在上述例子中,表j的字符集是GBK。用户分别插入了两个字符的数据ab和我
们',然后査看所占字节,可得如下结果:
mysql> selEcT a ChAr LENGTH (a) LenGTh(a)
FROM 3G;
rOw★舟★★★*肯★;**★★★★★责次☆责责
a: aR
CHAR LENGTH(d: 2
LENGTH【a):2
★★★★★★★★★实★★大★★★向★★★★★★★女★2
a:我们
CHAR LENGTH【a):2
LENGTH【a):4
CHAR LENGTH【a):1
LeNGTH (a): 1
3 rows in set (0.co sec)
通过不同的 CHAR LENGTH和CHAR函数可以观察到:前两个记录'ab'和!我
们字符串的长度都是2。但是内部存储上'ab’占用2字节,而’我们'占用4字节。
如果通过HEX函数查看内部十六进制的存储,可以看到:
mysql> sElect a, HEX(at
FROM 3\G:
青★青★青古★t内★曾青青青安中青★胄害★1.row*★★★★★☆★黄★“★青★★黄★★★★★★女★
HEKa}:6162
AA人AAAA内去内南直内青南青血*h古2OW专★★★★★女青★★肯★★★★★实灾
a:我们
HEX(a): CED2C3C7
食实★史史史史★*安安安女女史实读3,owt★★★★★如央★★★舟★★★★★★赏★★★青http://blog.csdn.net/jiongyi1
6I
43mmDB行记格式199
HEX (a): 61
参
3 raws in set (0.00 sec)
可以看到对于字符串”ab",其内部存储为0x6162。而字符串,我们为0xCED2C3C7。
因此对于多字节的字符编码,CHAR类型不再代表固定长度的字符串了。例如,对于
UTF8下CHAR(10)类型的列,其最小可以存储10字节的字符,而最大可以存储
30字节的字符。因此,对于多字节字符编码的CHAR数据类型的存储, InnoDB存
储引擎在内部将其视为变长字符类型。这也就意味着在变长长度列表中会记录CHAR
数据类型的长度。下面通过 hexdump工具来查看表空间jibd文件:
0000c07073757072656d7560200000010001c00 I supremum。
0000c0800000b62b2b0000005152da800000002d|。。++.Q
0000c090011061620400000018ffd5000000b62b|。ab.,。,,,,,+
0000c0a02c00c0005152db800000002d0110ced2
QR
0000c0b0c3c70000000000000000000000000000
整理后可以得到如下结果:
是第一行记录
02
/*变长字段长度2,将CHAR视作变长类型*
00
/+NULL标志位*
000010001c
/ Recoder Header *
000000b62b2b
/★R。wID幽
0000005152da
/* Transaction★
800000002d0110
/* Roll point *i
/*字符!ab!*/
普第二行记录
04
/*变长字段长度4,将CHAR视作变长类型*/
00
★NULL标志位*/
000018ffd5
/* Recoder header★
000000b62b2c
ROWID貴
0000005152db
/ TransactionID *
80D0D0002d口110
/ Roll Point *f
c3 d2 c3 c7
/*字符'我们!*
普第三行记录
02
/*变长字段长度2,将CHAR视作变长类型*
00
/*NUL标志位*
000020ffb7
/ Recoder Header *
000c00b62b2d
/★ ROWID 3
000000515317
/* Transact主onID*
800000002d0110
/ Roll Point */
6120
/*字符a·*http:/blog.csdnnet/jiongyi11
1204幸表
上述例子清楚地显示了 InnoDB存储引擎内部对CHAR类型在多字节字符集类型的
存储。CHAR类型被明确视为了变长字符类型,对于未能占满长度的字符还是填充0x20。
InnoDB存储引擎内部对字符的存储和我们用HEX函数看到的也是一致的。因此可以认
为在多字节字符集的情况下,CHAR和 VARCHAR的实际行存储基本是没有区别的
44 InnoDE数据页结构
相信通过前面几个小节的介绍,读者已经知道页是 InnoDB存储引擎管理数据库的
最小磁盘单位。页类型为 B-tree node的页存放的即是表中行的实际数据了。在这一节
中,我们将从底层具体地介绍 InnoDB数据页的内部存储结构。
注意 InnoDB公司本身并没有详细介绍其页结构的实现, MySQL的官方手册
中也基本没有提及 InnoDB存儲引擎页的内部结构。本节通过阅读源代码来了
解 InnoDB的页结构,此外结合了 Peter对于 InnoDB页结构的分析。 Peter写
这部分内容的时间很久远了,在其之后 InnoDB引入了 Compact格式,页结构
已经有所改动,因此可能出现对页结构分析错误的情况,如有错误,希望可以
指出。
InnoDB数据页由以下7个部分组成,如图4-6所示。
口 File header(文件头)
了 Page Header(页头)
日 Infimum和 Supremum records
日 User records(用户记录,即行记录)
口 Free Space〔空闲空间)
口 Page Directory(页目录)
口 File trailer(文件结尾信息)
其中 File header、 Pagc Hcadcr、 File trailer的大小是固定的,分别为38、56、8字
节,这些空间用来标记该页的一些信息,如 Checksum,数据页所在B+树索引的层数
等。 User records、 Free Space、 Page Directory这些部分为实际的行记录存储空间,因此
大小是动态的。在接下来的各小节中将具体分析各组成部分。http://blog.csdn.net/jiongyi1
sI
4.4 InnoDB数据页點构21
File header
38字节
Page Header eH
56字书
Infimun Supremum Records
User Records
行记录
Page Size
Free ST
Page Directory
File trailer
8字节
图46 InnoDB存储引擎数据页结构
4.4.1 File Header
File header用来记录页的一些头信息,由表4-3中8个部分组成,共占用38字节。
表43 File Header组成部分
名称
大小(字节)
说明
FIL PAGE SPACE
当 MysQL为 MySQL4.0.14之前的版本时,该值为U,在之后的 MysQL
OR CHKSUM
版本中,该值代表页的 checksum值(一种新的 checksum值)
表空间中页的偏移值。如某独立表空间aid的大小为1GB,如果页的
FIL PAGE OFFSET
大小为16KB,那么总共有65536个页。 FIL PAGE OFFSET表示该页在
所有页中的位置。若此表空间的ID为10,那么搜索页〔10,1)就表示查
找表a中的第二个页
FIL PAGE PREV
当前页的上一个页,B+Tre特性决定了叶子节点必须是双向列表
FIL PAGE NEXT
当前页的下一个页,B+Tree特性决定了叶子节点必须是双向列表
FIL PAGE LSN
该值代表该页最后被修改的日志序列位置LSN( Log Sequence Number)
InnoDE存储引擎页的类型。常见的类型见表4-4。记住0x45BF,该值
FIL PAGE TYPE
44828
代表了存放的是数据页,即实际行记录的存储空间
FIL PAGE FILE
该值仅在系统表空间的一个页中定义,代表文件至少被更新到了该LSN
FLUSH LSN
值。对于独立表空间,该值都为0
FIL PAGE ARCH
LOG NO OR SPACE
从 MySQL41开始,该值代表页属于哪个表空间
IDhttp:/blog.csdnnet/jiongyi11
5I.6
122第4章表
表4-4 InnoDB存储引中页的类型
名称
十六进制
解释
FIL PAGE INDEX
0x45BF
B+树叶节点
FIL PAGE UNDO LOG
0x0002
Undo log页
FIL PAGE INODE
0x0003
索引节点
FIL PAGE IBUF FREE LIST
x004
Insert buffer空闲列表
FIL PAGE TYPE ALLOCATED
0x0000
该页为最新分配
FIL PAGE IBUF BITMAP
0x0005
Insert Buffer位图
FIL PAGE TYPE SYS
cx0006
系统页
FIL PAGE TYPE TRX SYS
0x0007
事务系统数据
FIL PAGE TYPE FSP HDR
0x0008
File space header
FIL PAGE TYPE XDES
0x0009
扩展描述页
FIL PAGE TYPE BLOB
0x000A
BLOB页
4.4.2 Page Header
接着 File header部分的是 Page Header,该部分用来记录数据页的状态信息,由
14个部分组成,共占用56字节,如表4-5所示。
表45 Page Header组成部分
名称
大小(字节
说明
在 Page Directory(页目录)中的Slot(槽)数,“44.5Page
PAGE N DIR SLOTS
2
Directory”小节中会介绍
PAGE HEAP TOP
堆中第一个记录的指针,记录在页中是根据堆的形式存放的
PAGE N HEAP
2222
堆中的记录数。一共占用2字节,但是第15位表示行记录格式
PAGE FREE
指向可重用空间的首指针
PAGE GARBAGE
已删除记录的字节数,即行记录结构中 delete flag为1的记录大小的总数
PAGE LAST INSERT
最后插入记录的位置
最后插入的方向。可能的取值为
口 PAGE LEFT(0x01)
口 PAGE RIGHT(0x02)
PAGE DIRECTION
日 PAGE SAME REC(0x03
口 PAGE SAME PAGE〔0x04
O PAGE NO DIRECTION (Ox05)
PAGE N DIRECTION
个方向连续插人记录的数量
PAGE RECS
该页中记录的数量
PAGE MAX TRX ID
修改当前页的最大事务m,注意该值仅在 Secondary Index中定义
PAGE LEVEL
22828
当前页在索引树中的位置,0X00代表叶节点,即叶节点总是在第0层
PAGE INDEX ID
索引ID,表示当前页属于哪个索引http://blog.csdn.net/jiongyi1
6I
44 InnoDB数据项构123争
续)鲁
名称
大小(字节
说明
B+树数据页非叶节点所在段的 segment header。注意该值仅在B+
PAGE ETR SEG LEAF
树的Root页中定义
PAGE BTR SEG TOP
B+树数据页所在段的 segment header。注意该值仅在B+树的Root
10
页中定义
4.4.3 Infimum A Supremum Record
在 InnoDB存储引擎中,每个数据页中有两个虚拟的行记录,用来限定记录的边
界。 Infimum记录是比该页中任何主键值都要小的值, Supremum指比任何可能大的值
还要大的值。这两个值在页创建时被建立,并且在任何悄况下不会被删除。在 Compact
行格式和 Redundant行格式下,两者占用的字节数各不相同。图47显示了 Infimum和
Supremum记录。
B+ Tree
行记录数
页
行记录数据
行记录数据
据
图47 Infimum和 Supremum Record
4. 4.4 User Record fA Free Space
User record就是之前讨论过的部分,即实际存储行记录的内容。再次强调, InnoDB
存储引擎表总是B+树索引组织的。
Free Space很明显指的就是空闲空间,同样也是个链表数据结构。在一条记录被删
除后,该空间会被加入到空闲链表中。http://blog.csdn.net/jiongyi1
5
124算4章夜
4.4.5 Page Directory
冷银
Page Directory(页目录)中存放了记录的相对位置(注意,这里存放的是页相对
位置,而不是偏移量),有些时候这些记录指针称为 Slots(槽)或目录槽( Directory
Slts)。与其他数据库系统不同的是,在 InnoDB中并不是每个记录拥有一个槽, InnoDB
存储引擎的槽是一个稀疏目录( sparse directory),即一个槽中可能包含多个记录。伪记
录 Infimum的 n owned值总是为1,记录 Supremum的 n owned的取值范围为[1,8]
其他用户记录 n owned的取值范围为[4,8]。当记录被插人或删除时需要对槽进行分裂
或平衡的维护操作。
在 Slots中记录按照索引键值顺序存放,这样可以利用二叉查找迅速找到记录的指
针。假设有(i','d",'c","b','e',"g','"l’,
f
,"k
同时假设一个槽中包含4条记录,则Slos中的记录可能是("a·,"e!,'i')
由于在 InnoDB存储引擎中 Page Direcotry是稀疏目录,二叉査找的结果只是一个粗
略的结果,因此 InnoDB存储引擎必须通过 recorder header中的 next record来继续查找
相关记录。同时, Page Directory很好地解释了 recorder header中的 n owned值的含义,
因为这些记录并不包括在 Page Directory中。
需要牛记的是,B+树索引本身并不能找到具体的一条记录,能找到只是该记录所
在的页。数据库把页载入到内存,然后通过 Page Directory再进行二叉查找。只不过二
叉查找的时间复杂度很低,同时在内存中的查找很快,因此通常忽略这部分查找所用的
时间。
4.4.6 File Trailer
为了检测页是否已经完整地写人磁盘(如可能发生的写入过程中磁盘损坏、机器关
机等), InnoDB存储引擎的页中设置了 File trailer部分。
File Trailer只有一个 FIL PAGE END LSN部分,占用8字节。前4字节代表该页
的 checksum值,最后4字节和 File header中的 FIL PAGE LSN相同。将这两个值与
File header中的 FIL PAGE SPACE OR CHKSUM和 FIL PAGE LSN值进行比较,看
是否一致( checksum的比较需要通过 InnoDB的 checksum函数来进行比较,不是简单
的等值比较),以此来保证页的完整性( not corrupted)。http:/blog.csdnnet/jiongyi11
5I
44 InnoDB数据页结构25
在默认配置下, InnoDB存储引擎每次从磁盘读取一个页就会检测该页的完整性
页是否发生 Corrupt,这就是通过 File trailer部分进行检测,而该部分的检测会有一定的
开销。用户可以通过参数 innodb checksums来开启或关闭对这个页完整性的检查。
MySQL5.66版本开始新增了参数 innodb checksum algorithm,该参数用来控制检
测 checksum函数的算法,默认值为crc32,可设置的值有: innodb、crc32、none、 strict
innodb、 strict crc32、 strict none。
innodb为兼容之前版本 InnoDB页的 checksum检测方式,crc32为 MySQL566版
木引进的新的 checksum算法,该算法较之前的 innodb有着较高的性能。但是若表中所
有页的 checksum值都以 strict算法保存,那么低版本的 MySQL数据库将不能读取这些
页。none表示不对页启用 checksum检查
strict*正如其名,表示严格地按照设置的 checksum算法进行页的检测。因此若低
版本 MySQL数据库升级到 MySQL566或之后的版本,启用 strict crc32将导致不能读
取表中的页。启用 strict crc32方式是最快的方式,因为其不再对inob和cre32算法
进行两次检测。故推荐使用该设置。若数据库从低版本升级而来,则需要进行
upgrade操作。
44.7noDB数据页结构示例分析
通过前面各小节的介绍,相信读者对 InnoDB存储引擎的数据页已经有了一个大致
的了解。本小节将通过一个具体的表,结合前面小节所介绍的内容来具体分析一个数据
页的内部存储结构。首先建立一张表t,并导入一定量的数据:
mysql> DROP TABLE IF EXISTS ti
Query OK, D rows affected (C,04 sec)
mysql> CREATE TABLe t
a INT UNSIGNED NOT NULL AUTO INCREMENT
-> b CHAR【10),
> PRIMARY KEY【a),
)ENGINE=InnoDB ChARSET=UTE8
Query OK,0 rows affected (0.00 sec)
mysql> DELIMITER $$
mysql> CREATE PROCEDURE load t (count INT UNSIGNED)
BEGINhttp:/blog.csdnnet/jiongyi11
51.6
26笫4幸表
> SET Ec =0:
WhILe C
count do
INSERT工N"ot
SELECT NUL- REPEAT (CHAR (97+RAnd()*26)10)i
SET@￠=@c+1;
END WHIL
END:
5与
Query OK, 0 rows affected (0.01 sec)
myse1> DELIM工TER
mysql> CALI load t (100)
Query OK, 0 rows affected (0.60 sec)
mysql> SELECTa, bfROM t LIMIT 10;
十
b
I 1 dddddddddd
I2 hhhhhhhhhh I
I 3 bbbbbbbbbb I
I 5 nnnnnrnnnn
I 61 4q9999q99
7|。。。。c。。。a
I8 yyyyyyyyyy I
yyyyyyYyyy
110 vVVVVVVVVV
10 rows in set (ooo sec)
接着用工具py_ innodb_page_inf来分析tibd,得到如下内容:
frootenineyou0-43 mytest]f py innodb page info. py -v t, ibd
page offset c0000000, page type <File space Header>
page offset co000001, page type <Insert Buffer Bitmap>
page offset C0000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>r page level <0000>
page offset 00000000, page type <Freshly Allocated Page>
page offset 00000000, page type <Freshly Allocated Page>
Total number of page: 6:
Freshly Allocated Page: 2
Insert Buffer Bitmap: 1
File Space header: 1
B-tree node: 1
File segment inode: 1http:/blog.csdnnet/jiongyi11
5I.
44mDB数据君构127争
可以发现第四个页( page offset3)是数据页,然后通过 hexdump来分析ihd文纯
打开整理得到的十六进制文件,数据页从ox000c0(16K*3=0xc000)处开始,得到以
下内容:
0000c000 52 1b 240000000003 Ef ff ff ff ff ffffff
R.宁
0000c0100000000a6ae0ac9345bf000000000000
0000c0200000000000dc001a0dc0806600000000
0000c0300da50002006300640000000000000060
0000c040000000000000000001ba000000dc0000
瞢善甲甲曹「鲁费鲁鲁鲁
0000c050000200f2000000dc00000002003201◆0
2
0000c06002001c696e66696d7560005000b0000
infimum。,。。。,
0000c07073757072656d76d0ao0000010002200 supremum..:·"l
0000c080000001000000516deb800000002d0110
0000e090646464646464646464640a0000001800| dddddddddd,,,,
0000c0a022000c0002000000516dec800000002d
0000e0b00110686868686868686868680a000000, hhhhhhhhhh
0000c0c020002200000003003000516ded8000001,
0000c0d0002d0110626262626262626262620a001.-.. bbbbbbbkk。.
0000c0e0040028002200000034000000516dee80
Q
0000e0f00000002d011069696969696969696969
1111111主ii
0000c1000a0000003000220000005000000516d
0000c110ef80000002d01106e6e6e6e6e6e6e6e|,,,,-。, nonnnnnn
0000c1206e6e0a0000003800220000006000000|nn....8.
0000c130516df0800000002d11077777171Qm…,-… q9g999
0000c140717171710a0000004000220000000700|gqqq..,
0000c1500000516df1800000202d01106f66E6f
Om
0000c1606f6f6f6f6f6f0a000400480022000000|oooo°o.。H
0000c1700800000516df2800000002d01107979|....Qm.,,,,-,,yy
0000c18079797979797979790a00000050002200 yyyyyyyy..,,P,",I
0000c190000009000000516df3800000002d0110
0000c1a0797979797979797979790a0000005800| yyyyyyyyyy....X
0000c1b0220003000a000000516df4800000002
Om
0000c1c00110767676767676767676760a000000
+-VVVvVUtTVV
0000c1d06000220000000b009000516df5800000
0000c1e0002d01106b6b6b6b6b6b6b6b6b6b0a00
kkkkkkkkkk. I
0000c1f004006900220n0000hc000000516df6A0
0000ffc000000000070d1de90c0d0b850afd
0000ffd00a7509ed096508dd985507cd074506bd
·“
0000ffe0063505ad0525049d0415038d0305027d1.5,.眚
0000fff001f5016d00e5006395ae5d396ae0a93
]9
先来分析前面 File header的38字节:http://blog.csdn.net/jiongyi1
5.
28笫4幸表
拼爱翻
口521b2400,数据页的 Checksum值。
你
口0000003,页的偏移量,从0开始。
口ffff,前一个页,因为只有当前一个数据页,所以这里为0xmrr
口ffff,下一个页,因为只有当前一个数据页,所以这里为0 xfffifffiff
口0000000a6ae0ac93,页的LSN。
口45bf,页类型,0x45bf代表数据页。
口00000000000000,这里暂时不管该值。
口000000dc,表空间的 SPACE ID。
不急着看下面的 Page Header部分,先来观察 File trailer部分。因为 File trailer通
过比较 Filc Header部分来保证页写入的完整性。 Filc Trailer的8字节为:
95 ae 5d39 6a e0 ac 93
口95ae5d39, Checksum值,该值通过 checksum函数与 File header部分的
checksum值进行比较。
口6ae0ac93,注意该值和 File header部分页的LSN后4个值相等。
接着分析56字节的 Page Header部分。对于数据页而言, Page Header部分保存了该
页中行记录的大量细节信息。分析后可得:
Page Header (56 bytes]:
PAGE N DIR SLOTS -0x0013
PAGE HEAP TOP=OxCdco
PAGE N HEAP=0X8O66
PAGE FREE=OX 0000
PAGE GARBAGE=0x0000
PAGE LAST INSERT=0xOda5
PAGE DIRECTION=0x0002
PAGE N DIRECTION=0x0063
PAGE N RECS=0x0064
PAGE MAX TRX ID=0x0000000000000000
PAGE LEVEL=00 00
PAGE INDEX ID=0x00000000000001ba
PAGE BTR SBG LEAE=0x0000oodc0000000200f2
PAGE BTR S3GTP=0x000000dc900000020032
PAGE N DIR SLOTS=0x00la,代表 Page Directory有26个槽,每个槽占用2字
节,我们可以从0x000014到0x0m中找到如下内容:http:/blog.csdnnet/jiongyi11
44mODB数据页构l29
0000ffc0000000000700d1dcc950e0d0b85)afd
召量擦
0000ffd00a750ged096508did085507cd074506bd
e..L
000ffe0063505ad0525049d0415038d030527d|.5.,,号
000fff001f5016d00e5006395ae5d396ae0ac93
C·]9
PAGE HEAP TOP=0xodc0代表空闲空间开始位置的偏移量,即0xc000+0x0dc00xcdc0
处开始,观察这个位置的情况,可以发现这的确是最后一行的结束,接下去的部分都是空
闲空间了。
0000cdb00000002d011070707070707070707070
PPPPPPPPPP
0000cdc000.00000000000000000000000002000
0000cdd00000000000000000000000000003000
0000cde00000000000000000000000000003000
PAGE N HEAP-0x8066,当行记录格式为 Compact时,初始值为0x0802;当行
格式为 Redundant时,初始值是2。其实这些值表示页初始时就已经有 Infinimun和
Supremum的伪记录行,0x8066-0x8002=0x64,代表该页中实际的记录有100条记录。
PAGE FREE=0X00代表可重用的空间首地址,因为这里没有进行过任何删除操
作,故这里的值为0
PAGE GARBAGE=0x0000代表删除的记录字节为0,同样因为我们没有进行过删除
操作,这里的值依然为0。
PAGE LAST INSERT=0x0da5,表示页最后插入的位置的偏移量,即最后的插人位
置应该在0xc0000+0x0da5=0Xcda5,查看该位置:
0000cda0000328f2cb00000064000000516e9e80|:,(..d...QnN.
0000cdb00000002a011070707070707070707070
. pppppppppp I
0000cdc00000000000000000c000000000000000
可以看到的确是最后插入a列值为100的行记录,但是这次直接指向了行记录的内
容,而不是指向行记录的变长字段长度的列表位置。
PAGE DIRECTION=0x0002,因为通过自增长的方式进行行记录的插人,所以
PAGE DIRECTION的方向是向右,为0x00002。
PAGE N DIRECTION=0x0063,表示一个方向连续插入记录的数量,因为我们是自
增长的方式插入了100条记录,因此该值为99
PAGE N RECS=0x0064,表示该页的行记录数为100,注意该值与PA( EN HEAP
的比较,PAGE_ N HEAP包含两个伪行记录,并且是通过有符号的方式记录的,因此值http:/blog.csdnnet/jiongyi11
5.e
130第4章表
拼号发
为0x8066
PAGE LEVEL=0x00,代表该页为叶子节点。因为数据量目前较少,因此当前B+
树索引只有一层。B+数叶子层总是为0x00。
PAGE INDEX ID=0x000000000ba,索引ID。
上面就是数据贞的 Page Header部分了,接下去就是存放的行记录了,前面提到过
InnoDB存储引擎有两个伪记录,用来限定行记录的边界,接着往下看:
0000c050000200f2000000dc0000000200320100|..
2..
0000c06002001c696e66696d756d0035000b0000| infimum。,,,:,
0000c07073757072656d756d0a00005010002200| supremum.,,.".l
观察0xc05E到0Xc077,这里存放的就是这两个伪行记录,在 InnodB存储引擎中
设置伪行只有一个列,且类型是Char(8)。伪行记录的读取方式和一般的行记录并无不
同,我们整理后可以得到如下结果
井 Infimum伪行记录
010002001c
/ recorder header
696e66696d756d00
★只有一个列的伪行记录,记录内容就是 Infimum(多了一个
*0x00字节)*
# Supremum伪行记录
050003000
/ recorder header
73757072556d756d
*只有一个列的伪行记录,记录内容就是 Supremum*
然后来分析 infimum行记录的 recorder header部分,最后两个字节位001c表示下
个记录的位置的偏移量,即当前行记录内容的位置0xc063+0x001c,即0xc07f。0xc07f
应该很熟悉了,之前分析的行记录结构都是从这个位置开始,如
0000c07073757072656d756d0a0000001)002200 supremum,,,,.l
0000c080000001000000516deb800000032d0110l
m
0000c090646464646464646464640a0003001800 I dddddddddo..,,·l
0000c0a02200000002000000516dec800300002d
可以看到这就是第一条实际行记录内容的位置了,整理后我们可以得到
/*第一条行记录★/
00000001
/*因为我们在建表时设定了主键,这里的RMD即为列a的值1+/
000000516deb
/ Transaction id +/
800000002d0110
★Rol1 Pointer★
64646464646464646464/*b列的值' aaaaaaaaaa*/
这和查表得到的数据是一致的:http:/blog.csdnnet/jiongyi11
51.6
4.4 InnoDB数据结构l3l
mysql> SELEcT a, b, hex(b) FROM t ORDER BY a lImit 1
I hex(b
=----+一--
1| dddddddddd|64646464646464646464
+
l row in set (0.00 sec)
通过 Recorder header的最后两个字节记录的下一行记录的偏移量就可以得到该页中
所有的行记录,通过 Page Header的 PAGE PREⅤ和 PAGE NEXT就可以知道上个页和
下个页的位置,这样 InnoDB存储引擎就能读到整张表所有的行记录数据。
最后分析 Page Directory。前面已经提到了从0x00o0f到0x0000m是当前页的
Page Directory,如下:
0000ffc00000000000700d1d0c950c0d0b850afd
0000ffd0Ca7509ed096508dd085507cd074506bd|.1.e..U.E.
0000ffe0063505ad052s049d0415038d0305027d.5。。.8..,,
b画
0000fff0c1f5016d00e5005395ae5d396ae0ae93
c.]95.
需要注意的是, Page Directory是逆序存放的,每个槽占2字节,因此可以看
到0063是最初行的相对位置,即0xc063;0070就是最后一行记录的相对位置,即
0xc070。我们发现这就是前面分析的 Infimum和 Supremum的伪行记录。 Page Directory
槽中的数据都是按照主键的顺序存放的,因此查询具体记录就需要通过部分进行。前面
已经提到 InnoDB存储引擎的槽是稀疏的,故还需通过 Recorder header的 n owned进
行进一步的判断,如 InnodB存储引擎需要找主键a为5的记录,通过二叉查找Page
Directory的槽,可以定位记录的相对位置在00e5处,找到行记录的实际位置0xc0e5。
0000c0e0040028002200000004000000516dee80|..《.",,,,,,,Qm.
n00cnf0000002d0110696969696969696969691..,一,,ii主 L1111
0000c1000a00000030002200000005000000516d
m
0000c110ef800000002d01106e6e6e6e6e6e6e6e|..,,,-., nnnnnnnr
0000c1206e6e0a0000038002200c00006000000|nn....8
0000c130516d重080000002d01107171717171711Qm.
0000c140717171710a00000040002200000007001qqqq..,
可以看到第一行的记录是4,不是我们要找的6,但是可以发现前面的5字节的
Record header为0400280022。找到4-8位表示 n owned值得部分,该值为4,表
示该记录有4个记录,因此还需要进一步查找,通过 recorder header最后两个字节的偏http://blog.csdn.net/jiongyi1
5.
132茅4章哀
移量0x0022找到下一条记录的位置0xc107,这才是最终要找的主键为5的记录
这节通过一个示例深入浅出地分析了数据页屮各信息的存储,相信这对于用户今后
更好地理解 InnoDB存储引擎和优化数据库带来益处。
4.5 Named File Formats机制
随着 InnoDB存储引擎的发展,新的页数据结构有吋用来支持新的功能特性。比如
前面提到的 InnoDB1.0x版本提供了新的页数据结构来支持表压缩功能,完全的溢出
( Off page)大变长字符类型字段的存储。这些新的页数据结构和之前版本的页并不兼
容,因此从 InnoDe1.0.x版本开始, InnoDb存储引通过 Named File formats机制来解决
不同版本下页结构兼容性的问题。
InnoDB存储引擎将1.0.x版本之前的文件格式( file format)定义为 Antelope,将这
个版本支持的文件格式定义为 Barracuda。新的文件格式总是包含于之前的版本的页格
式。图48显示了 Barracuda文件格式和 Antelope文件格式之间的关系, Antelope文件
格式有 Compact和 Redudant的行格式, Barracuda文件格式既包括了 Antelope所有的文
件格式,另外新加入了之前已经提到过的 Compressed和 Dynamic行格式。
Barracuda file format
Antelope File Format
Compressed
ynamic
Compact
Redundant
图48文件格式
InnoDB Plugin的官方手册中提到了,未来版本的 InnoDB存储引擎还将引入新的文
件格式,此文件格式的名称取自动物的名字(这个学 Apple的命名方式?),并按照字母
排序进行命名。我翻阅了源代码,发现目前已经定义好的文件格式有:
/* List of animal names representing file format.
static const char*file format name map[]=[
Antelope",
bArracudahttp://blog.csdn.net/jiongyi1
6I
4.5 Named file formats犰就133
Cheetah"
Dracon
Elk
FOx
gAzelle"
Hornet
Impala
Jaguar
Kangaroo"
Leopard
Moose
Nautilus
celor
Porpoise
uail
Rabbit
sHark
Tiger
Urch⊥
Viper,
Whale"
Xenaps"
Yak
Zebra
参数 innodb file format用来指定文件格式,可以通过下面的方式来查看当前所使用
的 InnoDB存储引擎的文件格式。
mmy sql> SELECT G @version\G:
★k★★★★★女★★★★★大青大青古+古古古★1,row★★**青宵t肯内t肯言宫言言方食宫害皆
eversion: 541.37
i row in set(0.00 sec)
mysql> SHOW VARIABLES LIKe 'innodb version '\G:
★有*南有内青*青内青青肯*肃★青實重★★贵1.rowx古★★★★★青★黄★★★女★实★★★★★★★★
Variable name: innodb version
Value: 1, 0.4
1r。 W In set(0.00sec)
mysql> SHOW VARIABLES LIKE 'innodb file format\G;
★文★★责*k★★★★★★计★★★★★★★1,row★古★★★★★★★★★★★★★★青★★★★★★★青
Variable name: innodb file format
Value: Barracuda
l row in set (0.00 sec)http:/blog.csdnnet/jiongyi11
134郭4章夜
挤者墨
参数 innodb file format check用来检测当前 InnoDB存储引擎文件格式的支持度,
该值默认为ON,如果出现不支持的文件格式,用户可能在错误日志文件中看到类似如
下的错误:
InncDB: Warning: the systen tablespace is in a
file format that this version doesn't support
46约束
46.1数据完整性
关系型数据库系统和文件系统的一个不同点是,关系数据库本身能保证存储数据的
完整性,不需要应用程序的控制,而文件系统一般需要在程序端进行控制。当前几乎所
有的关系型数据库都提供了约束( constraint)机制,该机制提供了一条强大而简易的途
径来保证数据库中数据的完整性。一般来说,数据完整性有以下三种形式:
实体完整性保证表中有一个主键。在 InnodB存储引擎表中,用户可以通过定义
Primary Key或 Unique Key约束来保证实体的完整性。用户还可以通过编写一个触发器
来保证数据完整性。
域完整性保证数据每列的值满足特定的条件。在 InnoDB存储引擎表中,域完整性
可以通过以下几种途径来保证
口选择合适的数据类型确保一个数据值满足特定条件。
口外键( Foreign Key)约束。
口编写触发器。
口还可以考虑用 DEFAULT约束作为强制域完整性的一个方面。
参照完整性保证两张表之间的关系。 InnoDB存储引擎支持外键,因此允许用户定义
外键以强制参照完整性,也可以通过编写触发器以强制执行。
对于 InnoDB存储引擎本身而言,提供了以下几种约束
口 Primary Key
口 Unique Key
Foreign Key
口 Defaulthttp:/blog.csdnnet/jiongyi11
4.6约束35
拼吾
口 NOT NULL
46.2约束的创建和查找
约束的创建可以采用以下两种方式
口表建立时就进行约束定义
口利用 ALTER TABLE命令来进行创建约束
对 Unique Key(唯一索引)的约束,用户还可以通过命令 CREATE UNIQUE INDEX
来建立。对于主键约束而言,其默认约束名为 PRIMARY。而对于 Unique Key约束而言,
默认约束名和列名一样,当然也可以人为指定 Unique Key约束的名字。 Foreign Key约束
似乎会有一个比较神秘的默认名称。下面是一个简单的创建表的语句,表上有一个主键
和一个唯一键:
Imly> CREATE TABLE u 4
一> id int
> name VARCHAR(20)
> id card ChAr(18),
PRIMARY KEY ld)
UNICUE KEY name ))i
Query OK, 0 rows affected (0,16 sec)
mysql> SELECT constraint name, constraint type
- FROM
information schema TABlE Constraints
WhERE table schema='mytest ANd table name='u:\G;
*点西南来青走内内古古青六青六青内★★青肯★1,。★肯★★匆**责宴宽害世幸诸查音t
constraint name: PRIMARY
constraint type: PRIMARY KEY
青青★**★实实*去去★齿走★★★女★★★2,rw★★★★★大*大★★古大贵★★★大青★古★★吉南
constraint name: name
constraint type: UNIQUE
2 rows in set (0.00 sec
可以看到,约束名就如之前所说的,主键的约束名为 PRIMARY,唯一索引的默认
约束名与列名相同。当然用户还可以通过 ALTER TABLE来创建约束,并且可以定义用
户所希望的约束名,如下面这个例子:
mysql> ALTER TABLE u
- ADD UNIQUE KEY uk id card (id card);http://blog.csdn.net/jiongyi1
5
136笫4章表
部拼没
Query Okr 0 rows affected (0.19 sec)
Records: 0 Duplicates: 0 Warnings: 0
你
mys I> SELECT constraint name r constraint type
FROM
information schema. TABLE CONSTRAINTS
Where table schema='my test. And table name=u'i\G:
古★女古★★肃汝古★;★片站齿去计*南1.工OW*★★★★★内★★★★★★宴古害实★计霄内★
constraint name: PRIMARY
constraint type: PRIMARY KEY
實害案實食實實實食★★★
★★★★★★★★2,EW★★★★★★
食★★实★T★实★★★★肯★★赏
constraint name: name
constraint type: UNIQUE
★★女典女★★★★★★女★★责★★*★*3.rw★★黄★★★
constraint name: uk id carc
constraint type: UNIQUE
3 rows in set (0.00 sec)
接着来看 Foreign Key的约東。为了创建 Foreign Key,用户必须创建另一张表,例
如在下面的示例中创建表p。
mysql> CREATE TABIE p
1C INT
u id Int
EK⊥ MARY KEY(id)
FOREIGN KEY (u id) REFERENCES p(id))
Query OK, 0 rows affected (0.13 sec)
mysql> SELECT constraint name, constraint. type
FROM
->information schema TABLE CONSTRAINTS
WHERE table schema=mytest and table name=p'Gi
★★★★贵★★★★★大★丈内★★内★★★★★★*大1.r。w★★★★南★★★★★“★★★★★青内k★
constraint name: PRImArY
constraint type: PRIMARY KEY
★★责夹★★k知*史来来夹审肉肉来青来来2.rw★★★★南光★★★肯★★★★★★青夹青青大k★女
constraint name: p ibk 1
constraint type: FOREIGN KEY
2 rows in set (0. 00 sec
在上面的例子中,通过 information schema架构下的表 TABLE CONSTRAINTS来
查看当前 MySQL库下所有的约束信息。对于 Foreign Key的约束的命名,用户还可以通
过查看表 REFERENTIAL CONSTRAINTS,并且可以详细地了解外键的属性,如:http:/blog.csdnnet/jiongyi11
4.6约束137
ysql> SELECT EROM
章尽
- information schema REFERENTIAL CONSTRAINT
>WHERE constraint schema=my tesL \G;
卖★;女走☆★支*★皆★青青★青青★★1,x★★青★★★★w南*★
CONSTRAINT CATAI OG: NOI,.
CONSTRAINT SCHEMA test2
CONSTRAINT NAME:p ibk l
UNIQUE CONSTRAINT CATALOG: NULL
UNIQUE CONSTRAINT SCHEMA: test2
UNIQUE CONSTRAINT NAME: PRIMARY
MATCH OPTION: NONE
UPDATE RULE: RESTR工cT
DELETE RULE: RESTRICT
TABLE NAME p
REFERENCED TABLE NAME: P
1 row in set (0. 00 sec)
463约束和索引的区别
在前面的小节中已经看到 Primary Key和 Unique Key的约束,有人不禁会问:这不
就是通常创建索引的方法吗?那约束和索引有什么区别呢?
的确,当用户创建了一个唯一索引就创建了一个唯一的约束。但是约束和索引的概
念还是有所不同的,约束更是一个逻辑的概念,用来保证数据的完整性,而索引是一个
数据结构,既有逻辑上的概念,在数据库中还代表着物理存储的方式。
464对错误数据的约束
在某些默认设置下, MySQL数据库允许非法的或不正确的数据的插入或更新,又或
者可以在数据库内部将其转化为一个合法的值,如向 NOT NULI的字段插入一个NULL
值, MySQL数据库会将其更改为0再进行插入,因此数据库本身没有对数据的正确性进
行约束。例如:
mysqL> CREATE TABLE a
> id Intⅳ OT NULL;
- date DATE NOT NULL)
Query CK, 0 rows affected (0.13 sec)
mysql> INSERT INTO ahttp://blog.csdn.net/jiongyi1
5
138第4亨哀
SELECT NULL, 2009-02-30'
Query OK, 1 row affected 2 warnings (0.04 sec)
Records: 1 Duplicates: 0 Warnings: 2
mysql> SHOW WARNINGS \G;
★★★责★青肯青专青★青安青责责★實★灾★★★食1
eM★**★★★女
★党囊女史责★建
Level; Warning
Code: 1048
Message: Column id cannot be null
★★世★★肯★★★★★实责★责青责★★★★此★★t2,。w★★*肯★★★*★★青★★★责★★★★均★内★★★★★
Level: Warning
Code: 1265
Message: Data truncated for column date at row 1
2 rows in set (0.oo secx
mysql> SELECT FROM a\G:
★★★★★★★★★★★★★★★★★★女★量
oT
★★★★丈貴★★★貴
id: o
date;0000-00-00
1 row in set【0.00se)
在上述例子中,首先向 NOT NULL的列插入了一个NULL值,同时向列date插入
了一个非法日期·200902-30。“奇怪”的是 MySQL数据库并没有报错,而是显示了
警告( warning)。如果用户想通过约束对于数据库非法数据的插入或更新,即 MYSQL
数据库提示报错而不是警告,那么用户必须设置参数 sql mode,用来严格审核输入的参
数,如:
mysql> SET sal mode
STRICT TRANS TABLES
Query ok, 0 rows affected (0.00 sec)
mysql> INSERT INTO a
SELECT NULL, 2009-02-301i
ERROR 1048 (23000):Column .id cannot be null
mysql> INSERT INTo a
> SELECT1,"2009-02-30";
ERECR 1292(22007):Incorrect date value: 2009-02-30 for column date t at row 1
通过设置参数 sql mode的值为 STRICT TRANS TABLES,这次 MySQL数据库对
于输入值的合法性进行了约束,而且针对不同的错误,提示的错误内容也都不同。参数
sql mode可设的值有很多,具体可参考 MySQL官方手册。http:/blog.csdnnet/jiongyi11
5I.6
46约束139
爸拼吾
4.6.5ENUM和SET约束
MySQL数据库不支持传统的 CHECK约束,但是通过ENUM和SET类型可以解决
部分这样的约束需求。例如表上有一个性别类型,规定域的范围只能是male或 female,
在这种情况下用户可以通过ENUM类型来进行约束
mysql> CREATE TABLE a
> id Int
sex ENUM('male,female))i
Query Ok, o rows affected (0.12 secy
mysqL> INSERT INTO a
->sELECT 1,female
Query OK, 1 row affected (C,03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTO a
ELECt 2,bit
Query OK, 1 row affected, 1 warning (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 1
可以看到,在上述例子中对第二条记录的插人依然是报了警告。因此如果想实现
CHECK约束,还需要配合设置参数 sql mode
mysql> SET sql mode = STRICT TRANS TABLESF
Query OK, 0 rows affect.ed (0.0o sec)
myscI> INSERT INTO a
- SELECt 2,bii
ERROR 1265(01000): Data truncated for column 'sex at row 1
这次对非法的输入值进行了约束,但是只限于对离散数值的约束,对于传统
CHECK约束支持的连续值的范围约束或更复杂的约束,ENUM和SET类型还是无能为
力,这时用户需要通过触发器来实现对于值域的约束。
4.6.6触发器与约束
通过前面小节的介绍,用户已经知道完整性约束通常也可以使用触发器来实现,因
此在了解数据完整性前先对触发器来做一个了解。
触发器的作用是在执行 INSERT、 DELETE和 UPDATE命令之前或之后自动调用http://blog.csdn.net/jiongyi1
6I
1404幸夜
SQL命令或存储过程。 MySQL50对触发器的实现还不是非常完善,限制比较多,而从
MySQL51开始触发器已经相对稳定,功能也较之前有了大幅的提高。
创建触发器的命令是 CREATE TRIGGER,只有具备 Super权限的 My SQL数据库用
户才可以执行这条命令:
CREATE
I DEFINER user CURRENT USER 1
TRIGGER trigger name BEFORE AFTER INSERTI UPDATE I DELETE
on tbl name FOR EACH RoW trigger stmt
最多可以为一个表建立6个触发器,即分别为 INSERT、 UPDATE、 DELETE的
BEFORE和 AFTER各定义一个。 BEFORE和 AFTER代表触发器发生的时间,表示是在
每行操作的之前发生还是之后发生。当前 MySQL数据库只攴持 FOR EACH ROW的触发
方式,即按每行记录进行触发,不支持像DB2的 FOR EACH STATEMENT的触发方式
通过触发器,用户可以实现 MySQL数据库本身并不支持的一些特性,如对于传统
CHECK约束的支持,物化视图、高级复制、审计等特性。这里先关注触发器对于约束
的支持
假设有张用户消费表,每次用户购买一样物品后其金额都是减的,若这时有“不怀
好意”的用户做了类似减去一个负值的操作,这样用户的钱没减少反而会不断增加,如:
mysql> CREATE TABLE usercash
>口 serid in NoT null
cash INT UNSIGNED NOT NULL);
Query oK, o rows affected (0.11 sec
mysql> INSERT INTo usercash
>SELECT 1:1000;
Query oK, 1 row affected (0.03 secl
Records: 1 Duplicates: 0 Warnings: 0
mysql> UPDATE usercash
> ser cash=cash-【-20》 WHERE userid=1;
Query OK I row affected (0.05 sec
Rows matched: 1 Changed: 1 Warnings: 0
上述运行的SQL语句对数据库来说没有任何问题,都可以正常的运行,不会报错。
但是从业务的逻辑上来说,这是绝对错误的。因为消费总是意味着减去一个正值,而不
是负值,所以这时要通过触发器来约束这个逻辑行为,可以进行如下设置:http:/blog.csdnnet/jiongyi11
5.6
46束l41
研翻
mysql> CREATE TABLE usercash err log
userid INt NoT NUlL,
>。1dc吕 sh INT UNS工 GNED NOT NULL
- new cash INT UNSIGNED NOT NULLI
user VARCHAR(30)
time DATETIME)i
Query oR,0r⊙ s affected(0·138ec}
mysq-> DELIMITER s$
Cuery OK, o rows affected (0.00 sec)
ysg_> CREATE TRIGGER tgr usercash update BEFORE UPDATE ON usercdsh
>FOR EACH ROA
一> BEGIN
>IF new. cash-old cash >0 THEN
>INSERT INTO usercash err log
>SELECT old userid, old. cash, new, cash, USER( NOW()
->SET new. cash s old. cash:
>END工F
ENDA
Query oK 0 rows affected (0.00 sec)
mysq1> DELIMITER今
Query OK, 0 rows affected (0,00 sec)
上述例子首先创建了一张表 usercash err log来记录错误数值更新的日志,然后创建
了进行约束操作的触发器 tgr usercash update,其类型为 BEFORE。触发器首先判断新、
旧值之间的差值,在正常情况下消费总是减的,新值应该总是小于原来的值,因此大于
原值的数据被判断为非法的输人,将cash值设定为原来的值,并将非法的数据更新插入
表 usercash err log。再次运行上述的SQL语句:
mysql> DELETE FROM usercash:
Query OK, I row affected (0.02 sec
mysql> INSERT INTo usercash
- SELECT 11000;
Query OK, 1 row affected (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> UPDATE usercash
SET cash cash -(-20)
WHERE userid=1http:/blog.csdnnet/jiongyi11
5
/42第4幸表
Query OK,0 rows affected (0.02 sec)
Rows matched: 1 Changed: o warnings: 0
mysql> SELECT FROM usercdsh\G:
★★★女★★★女tt甘tb山由甘世者面1.rW宽食書奥言★大t建害了宽★宽宵青
userid: 1
cash: 100
row in set (0.00 sec)
mysql> sEleCt FROM usercash err log\G;
★宵★青青★离专灾窝★实灾實★★實灾霄霄★1.r。w★★★★★★★★★青★文宽★宽案霄實★★
userid: 1
ld cash: 1000
new cash: 1020
user: roatelocalhost
time:2009-11-0611:49:49
Message: Calumn id cannot be null
l row in set (0.00 sec)
可以看到这次对于异常的数据更新通过触发器将其保存到了 uscrcash crT log。此外
该触发器还记录了操作该SQL语句的用户及时间。通过上述的例子可以发现,创建触发
器也是实现约束的一种手段和方法。
4.6.7外键约束
外键用来保证参照完整性, MySQL数据库的 MyISAM存储引擎本身并不支持外键,
对于外键的定义只是起到一个注释的作用。而 InnoDB存储引擎则完整支持外键约束。
外键的定义如下:
I CONSTRAINT [symbol]] FOREIGN KEY
[index name] (index col name,
REFERENCEs tbl name (index col name,.)
[ON DELETE reference option]
[ON UPDATE reference option]
reference option:
RESTRICT CASCADE SET NULL
NO ACTION
用户可以在执行 CREATE TABLE时就添加外键,也可以在表创建后通过 ALTER
TABLE命令来添加。一个简单的外键的创建示例如下
mysl> CREATE TABLE parent
- id INT NOT NULLEhttp:/blog.csdnnet/jiongyi11
5I
46●约束143
PRIMARY KEY (id)
) ENGINE=工oDB
Query OK, 0 rows affected (0.13 sec)
mysql> CREATE TABLE child
>d工N, parent id INT
- FOREIGN KEY (Parent id) REFERENCES Parent(id)
>) ENGINE=工 NNODB S
Query OK, 0 rows affected (0.15 sec)
般来说,称被引用的表为父表,引用的表称为子表。外键定义时的 ON DELETE
和 ON UPDATE表示在对父表进行 DELETE和 UPDATE操作时,对子表所做的操作,
叮定义的子表操作有:
口 CASCADE
口 SET NULL
日 NO ACTION
口 RESTRICT
CASCADE表示当父表发生 DELETE或 UPDATE操作时,对相应的子表中的数据
也进行 DELETE或 UPDATE操作。 SET NULL表示当父表发生 DELETE或 UPDATE
操作时,相应的子表中的数据被更新为NULL值,但是子表中相对应的列必须允许为
NULL值。 NO ACTION表示当父表发生 DELETE或 UPDATE操作时,抛出错误,不
允许这类操作发生。 RESTRICT表示当父表发生 DELETE或 UPDATE操作时,抛出
错误,不允许这类操作发生。如果定义外键时没有指定 ON DELETE或 ON UPDATE
RESTRICT就是默认的外键设置。
在其他数据库中,如 Oracle数据库,有一种称为延时检查( deferred check)的外
键约束,即检查在SQL语句运行完成后再进行。而目前 MySQL数据库的外键约束都
是即时检查( immediate check),因此从上面的定义可以看出,在 MySQL数据库中NO
ACTION和 RESTRICT的功能是相同的。
在 Oracle数据库中,对于建立外键的列,一定不要忘记给这个列加上一个索引。而
InnoDB存储引擎在外键建立时会自动地对该列加一个索引,这和 Microsoft SQL Server
数据库的做法一样。因此可以很好地避免外键列上无索引而导致的死锁问题的产生。例
如在上述的例子中,表 child创建时只定义了外键,并没有手动指定 parent id列为索引http://blog.csdn.net/jiongyi1
5
144弟4章夜
拼吾翻
但是通过命令 SHOW CREATE TABLE可以发现 InnODB存储引擎自动为外锁约束的列
parent id添加了索引:
mysql> SHOW CREATE TABLE child\G;
★★★★古★★古害青肯内青★古青实青青★青1.rw·★★*★如**★*头青k*k夹青k来南★★责★
Table: child
Create Table: CREATE TABLE child1
id int (I1) DEFAULT NULL,
parent id in=(11)NOT NULLr
KEY parent id(parent id)
conSTRAINT child ibfk 1 ForeIGN KeY (Parent id) references parent.('id')
ENGIND一工 nnoDB dE FAUlT ChArSet=1t8
1r。 w n set(0.00sec
对于参照完整性约束,外键能起到一个非常好的作用。但是对于数据的导入操作
时,外键往往导致在外键约束的检耷上花费大量时间。因为 MySQL数据库的外键是即
时检查的,所以对导入的每一行都会进行外键检查。但是用户可以在导入过程中忽视外
键的检耷,如:
mysql> sET foreign key checks =0;
mysq> LOAD DATA…
mysql> SeT foreign key checks = li
4.7视图
在 MySQL数据库中,视图(view)是一个命名的虚表,它由一个SQL查询来定
义,可以当做表使用。与持久表( permanent table)不同的是,视图中的数据没有实际的
物理存储。
4.7.1视图的作用
视图在数据库中发挥着重要的作用。视图的主要用途之一是被用做一个抽象装置,
特别是对于一些应用程序,程序本身不需要关心基表( base table)的结构,只需要按照
视图定义来取数据或更新数据,因此,视图同时在一定程度上起到一个安全层的作用。
MySQL数据库从50版本开始支持视图,创建视图的语法如下:
CREAThttp://blog.csdn.net/jiongyi1
5.
4.7视图145
拼爱
[OR REPLACE]
你
[ALGORI THM =I UNDEFINED I MERGE I TEMPTABLE1
I DEFINER user I CURRENT USER
[ SQL SECU:工T￥【 DEFINER! INVOKER}]
VIEWview nldmme [(column list)]
As select sta tement
IWITH ICASCADED I LOCAL) CHECK OPTION I
虽然视图是基于基表的一个虚拟表,但是用户可以对某些视图进行更新操作,其
本质就是通过视图的定义来更新基本表。一般称可以进行更新操作的视图为可更新视图
( updatable view)。视图定义中的 WITH CHECK OPTION就是针对于可更新的视图的,
即更新的值是否需要检查。先看下面的一个例子:
mysql> CREATE TABLE t( id INT )
Query oK,0 rows affected (0.13 sec)
my sql>CREATE VIEW Vt
SeleCt FROM t where id<10:
Query oK, 0 rows affected (0.00 sec)
mysql> INSERT INto v t SELECT 20;
Query OK 1 row affected (0.03 sec)
Records: 1 Duplicates: o arnings: 0
mysql SELECT* FROM v t:
Empty set (0.00 sec)
在上面的例子中,创建了一个id<10的视图vt。但之后向视图里插入了i为20的
值,插入操作并没有报错。但是用户查询视图还是没能查到数据。接着更改视图的定
义,加上 WITH CHECK OPTION选项:
mysql> ALTER VIEW v t
- AS
SeLECT FRom t WHERE id<lo
- WITH CHECK OPTION
Query OR, 0 rows affected (0.00 sec)
mysql> INSERT INTo v t SELECT 20:
ERROR 1369(HYOOO): CHECK OFTION failed mytestv t
这次 MySQL数据库会对更新视图插入的数据进行检查,对于不满足视图定义条件http:/blog.csdnnet/jiongyi11
5
46第4章表
部拼没要
的,将会抛出一个异常,不允许视图中数据更新。
MySQL数据库DBA的一个常用的命令是 SHOW TABLES,该命令会显示出当前数
据库下所有的表。但因为视图是虚表,同样被作为表显示出来,例如:
mysql> SHOW TABLES\G;
贵★★★了贵贵★食★食★★食★★★★度食★實青1rOw★★★★★★★★★★实★★青★★★★★
Tables in mytest:t
★★★★★★★★★★★★★★为★★★★★青2,row★★★★★★★★★★★★★★★★大古内吉丙AA
Tables in mytest:vt
2 rows in set (0.00 sec)
可见 SHOW TABLES命令把表t和视图yt都显示出来了。若用户只想查看当前架
构下的基表,可以通过 information schema架构下的 TABLE表来查询,并搜索表类型为
BASE TABLE的表,SQL语句如下:
mysql> SELECT FROM information schema.TABLE
WHEre table type= BASE TABLE
AND table schema=database(\g;
青w古★★去请古★★责古青★★古★★★★★★★★1.rOwx★★★责★★★★大肉★★青★古古★言★肃★*吉脔
TABLE CATALOG:NUL工
TABLE SCHEMA: mytest
TABLE NAME: t
TABLE TYPE: BASE TABLE
ENGINE:Tnn。DB
VERSICN: 10
ROW FORMAT: Compact
TABLE RCWS: 1
AVG ROW LENGTH: 16384
DATA LENGTH: 16384
MAX DATA LENGTH: 0
INDEX LENGTH+ O
DATA FREE: O
AUTO INCREMENT: NULL
CREATE TIME:200911-0916:27:52
UPDATE TIME: NULL
CHECK TIME: NULL
TABLE COLLATION: utf ceneral ci
CHECKSUM: NULL
CREATE OPTIONS
TABLE COMMENT
1 row in set【Q.00sec
要想查看视图的一些元数据( meta data),可以访问 information schema架构下的http://blog.csdn.net/jiongyi1
5
4.7视图147
研发
VEWs表,该表给出了视图的详细信息,包括视图定义者( definer.)定义内容是香
是可更新视图、字符集等。如耷询VEWS表可得:
mysql> SELECT EROM
- information schera VIEWS
Where table schera=database(\g
貴★如啬面面盲言古者古肯青大古;出宋
1,row實★大青★★★★青★下内南声青*内★六★青青古
TABLE CATALOG: NUNL
TABLE SCHEMA: mytest
TABLE NAME:V七
VIEW DEFINITION: select ' mytest.t.idid from mytest.t where
(mytest.t.id< 10
CHECK OPTION: CASCADED
IS UPDATABLE: YES
DEFINER: root@localhost
SECURITY TYPE: DEFINER
CHARACTER SET CLIENT: latin1
COLLATION CONNECTION: latin1 swedish ci
l row in set (0.00 seck
4.72物化视图
Oracle数据库支持物化视图—该视图不是基于基表的虚表,而是根据基表实际存
在的实表,即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算
并保存多表的链接(JON)或聚集( GROUP BY)等耗时较多的SQL操作结果。这样,
在执行复杂查询时,就可以避免进行这些耗时的操作,从而快速得到结果。物化视图的
好处是对于一些复杂的统计类查询能直接查出结果。在 Microsoft SQL Server数据库中,
称这种视图为索引视图
在 Oracle数据库中,物化视图的创建方式包括以下两种
Q BUILD IMMEDIATE
口 BUILD DEFERRED
BUILD IMMEDIATE是默认的创建方式,在创建物化视图的时候就生成数据,而
BUILD DEFERRED则在创建物化视图时不生成数据,以后根据需要再生成数据。
查询重写是指当对物化视图的基表进行查询时,数据库会自动判断能否通过查询物
化视图来直接得到最终的结果,如果可以,则避免了聚集或连接等这类较为复杂的SQLhttp://blog.csdn.net/jiongyi1
5.
148第4章
操作,直接从已经计算好的物化视图中得到所需的数据。
你
物化视图的刷新是指当基表发生了DML操作后,物化视图何时采用哪种方式和基
表进行同步。刷新的模式有两种:
口 ON DEMAND
口 ON COMMIT
ON DEMAND意味着物化视图在用户需要的时候进行刷新, ON COMMIT意味着物
化视图在对基表的DML操作提交的同时进行刷新。
而刷新的方法有四种
日FAST
口 COMPLETE
.口 FORCE
口 NEVER
FAST刷新采用增量刷新,只刷新自上次刷新以后进行的修改。 COMPLETE刷新是
对整个物化视图进行完全的刷新。如果选择 FORCE方式,则数据库在刷新时会去判断
是否可以进行快速刷新,如果可以,则采用FAST方式,否则采用 COMPLETE的方式。
NEVER是指物化视图不进行任何刷新。
MySQL数据库本身并不支持物化视图,换句话说, MySQL数据库中的视图总
是虚拟的。但是用户可以通过一些机制来实现物化视图的功能。例如要创建一个ON
DEMAND的物化视图还是比较简单的,用户只需定时把数据导人到另一张表。例如有
如下的订单表,记录了用户采购电脑设备的信息:
mysql> CREATE TABLE orders
->order id INT UNSIGNED NOT NULL AUTO INCREMENT
product name VARCHAR(30) NT NULL
- price DECIMAL(8, 2) NOT NULL
amount SMAlLINT
NOT NULLt
>PR工 MARY KEY【 order id
>)ENG工NE=Inn°DB
Query OK, o rows aftected (0.13 sec)
mysqL> INSERT INTO Orders VALUES
>( NULL"cPU",135.5,1)
->(NULLrMemory'482,3,http://blog.csdn.net/jiongyi1
5.
47·图149
留拼
NULL;"CPU,125·6,3),
>(NULL;'cPU',105·3,4)
你盛
Query OK, 4 rows affected (0.03 sec)
Records: 4 Duplicates: 0 Warnings: 0
mysql> SELECT FROM Orders\G;
青*★内青青方★青青青青古责青青责责青青青★青1。1W六青青六青★青青★害青實★肯次★★青肯
rcer id: 1
product name: CPU
price: 135.50
amount t I
★青青内南育青青宵害實肯青肯尹青肯★青货肯宽青★★2.ow★踺胄寓實
order id: 2
product name: MemOry
price: 48.20
amount: 3
★青k窗定★★★★★★★★★★女★★★3.。w★★★★青★★★★实实泱肉★★★★★★★青★
order id: 3
product name: CPU
price: 125.50
am。unt:3
★★囊南实★★★★丈贵★★★★★★★★★★★实★青★4,row★★★*★計★★★女★★★★☆★★★★★★★★★
order id: 4
product name: CPU
price: 105.30
amount: 4
4 rows in set〔0.00sec)
接着建立一张物化视图的基表,用来统计每件物品的信息,如
mysql> CREATE TABLE Orders Mv(
product name. VARCHAR (30] NOT NULL
rP上 ice sur
DECIMAL《8,2) NOT NULI
r anmount sum
工NT
NOT NULL
r prlce avg
ELOAT
NOT NULL
orders cnt
INT
NOT NULL
UNIQUE INDEX (product name)
Query OK, 0 rows affected (0. 13 sec)
mysq1>工 NSERT工 No Orders Mv
SELECT Product name
SUM(price) SUM(amount), AVG (price]
COUNT【*}http:/blog.csdnnet/jiongyi11
51.6
150第4幸表
研
FROM Orders
GROUP BY product namei
召盛
Query Ok, 2 rows affccted (0.02 sec)
Records: 2 Duplicates: o Warnings: 0
mysql>
mysql> SELECT FROM Orders MV\G;
肃★★青大★大言青★★大青古大青★大★★★★1,row大★★★害古*大片★古大为大内大★大★大肃★★
prcduct name: CPU
prce:366.40
amount sum: 8
price avg: 122.133
orders cnt: 3
贵★t★★青了青★★★★★青宵★★文★★★2.r。w宽宽★黑霄害實★肉灾★害x责★★肯
product name: Memory
Prce:48.20
amount sum: 3
price avg: 42.2
orders cnt:1
2 rows in set (0.00 sec)
在上面的例子中,把物化视图定义为一张表 Orders mv。表名以MV结尾,以便
能让DBA很好地理解这张表的作用。通过上面的方式,用户就拥有了一个统计信息的
物化视图。如果是要实现 ON DEMAND的物化视图,只需把表清空,重新导入数据即
可。当然,这是 COMPLETE的刷新方式,要实现FAST的方式,也是可以的,只不过
稍微复杂点,需要记录上次统计时 order id的位置
但是,如果要实现 ON COMMIT的物化视图,就不像上而这么简单了。在
Oracle数据库中是通过物化视图日志来实现的,很显然 MySQL数据库没有这个日
志,不过通过触发器同样可以达到这个目的,首先需要对表 Orders建立一个触发器,
代码如下:
DELIMITER S
CREATE TRIGGER tgr orders insert
AFTER INSERT oN Orders
FOR EACH ROW
BEGIN
SET old price sum =0
SEt Gold amount sum =0:
SET @old price avghttp://blog.csdn.net/jiongyi1
5
47祝图151
SEt Gold orders cnt =0;
SELECT IFNULL(price sum, 0), IENULL(amount sum, 0), IENULL (price avg, 0)
IFNULL (orders cntr 0)
FROM Orders Mv
WHERE product name NEW product name
INTo (old price sum, old amount sum, Bold price avg, Bold orders cnt:
SeT new price sum =old price sum NEW price:
set @ new amount sum =@old amount sum NEw amount;
SET @new orders cnt Cold orders cnt t l:
SET Qnew price avg 2new price sum / Enew arders cnt i
REPLACE INTO Orders MV
VALUES(NEW product name, @new price sum, @new amount sum, enew price avg,
new orders cnt】;
END:
DELIMITER
上述代码创建了一个 INSERT的触发器,每次 INSERT操作都会重新统计表 Orders
MV中的数据。接着运行以下插入操作,并观察之后物化视图表 Orders mv中的记录。
mysql> INSERT INTo orders VALUES (NULL, 'SSD,299,3);
Query OK, 1 row affected, 1 warning (0.03 sec)
mysql> INSERT INTO Orders VALUES (NULL,'Memory,47.9,5)
Query OK, 1 row affected (0.03 sec)
mysql> SELECT FROM Crders Mv\g;
★★★★★★★★★宵言★★★青青★青古★★★★★★★1.row*★★★★责t责★青★责★责曲☆★★☆☆★实★
product name: CPU
price: 366.40
amouint sum: B
price avg: 122.133
orders cnt: 3
肯★★肯★★青肯肯责肯肯青贵青责食*害实*审2.ow★★★實女★★★★★★★★★★t★★*★k★★★
product name Memory
price: 96.10
amount sum: 8
price avg: 48.05
orders cnt: 2http:/blog.csdnnet/jiongyi11
5L.
J52第4章表
★★★*如*★★女★★★★★女女青女女★火★3.r。w
★★言k言★k★大古★大大★★★★女★文★★
螺器
product name: SSD
pr±ce;299.00
amount sum: 3
price avg: 299
orders cnt: 1
3 rows in set (0.00 sec)
叮以发现在插入两条新的记录后,直接查询 Orders mv表就能得到统计信息。而不
像之前需要重新进行SQL语句的统计,这就实现了 ON COMMIT的物化视图功能。需
要注意的是, Orders表可能还会有 UPDATE和 DELET的操作,所以应该还需要实现
DELETE和 UPDATE的触发器,这就留给读者白己去实现了。
通过触发器,在 MySQL数据库中实现了类似物化视图的功能。但是 MySQL数据
库本身并不支持物化视图,因此对于物化视图支持的查询重写( Query Rewrite)功能就
显得无能为力,用户只能在应用程序端做一些控制。
48分区表
48.1分区概述
分区功能并不是在存储引擎层完成的,因此不是只有 InnoDB存储引擎支持分区,
常见的存储引擎 MyIsAM、NDB等都支持。但也并不是所有的存储引擎都支持,如
CSV、 FEDORATED、 MERGE等就不攴持。在使用分区功能前,应该对选择的存储引
擎对分区的支持有所了解。
MySQL数据库在51版本时添加了对分区的支持。分区的过程是将一个表或索引分
解为多个更小、更可管理的部分。就访问数据库的应用而言,从逻辑上讲,只有一个表
或一个索引,但是在物理上这个表或索引可能由数十个物理分区组成。每个分区都是独
立的对象,可以独自处理,也可以作为一个更大对象的一部分进行处理
MySQL数据库支持的分区类型为水平分区°,并不支持垂直分区°。此外, MySQL
数据库的分区是局部分区索引,一个分区中既存放了数据又存放了索引。而全局分区是
指,数据存放在各个分区中,但是所有数据的索引放在一个对象中。目前, MySQL数据
白水平分区,指将同一表中不同行的记录分配到不同的物理文件中
合垂直分区,指将同一表中不同列的记录分配到不同的物理文件中http://blog.csdn.net/jiongyi1
5.
48分表153争
研者安
库还不支持全局分区。
可以通过以下命令来查看当前数据库是否启用了分区功能:
mysql> SHOW VARIABLES LIKE 'Partition%'\Gi
★赏实大青★★★大★★★★青★★肉内★★★1.r。wA
▲▲▲赢k赢此矗★真熏
variable name: have partitioning
Value: YES
1 row in set (0.00 seck
也可以通过命令 SHOW PLUGINS来查看:
mysql> SHOW PLUGINS\G;
★★★★★食青肯★**齿*黄青★六肯★t★★★★★2,rOw★★★★★大专★★*x为*x片★青★★★肃★青古
Name: partition
status: ACTIVE
Type: STORAGE ENGINE
Library: NULL
License: GPL
9 rows in set (0, c1 sec)
大多数DBA会有这样一个误区:只要启用了分区,数据库就会运行得更快。这个
结论是存在很多问题的。就我的经验看来,分区可能会给某些SQL语句性能带来提高,
但是分区主要用于数据库高可用性的管理。在OLTP应用中,对于分区的使用应该非常
小心。总之,如果只是一味地使用分区,而不理解分区是如何工作的,也不清楚你的应
用如何使用分区,那么分区极有可能会对性能产生负面的影响。
f前 MySQL数据库支持以下几种类型的分区。
口 RANGE分区:行数据基于属于一个给定连续区间的列值被放入分区。 MySQL55
开始支持 RANGE COLUMNS的分区。
口LsT分区:和 RANGE分区类型,只是LST分区面向的是离散的值。 MySQL55
开始支持 LIST COLUMNS的分区
口HASH分区:根据用户自定义的表达式的返回值来进行分区,返回值不能为负数
口KEY分区:根据 MySQL数据库提供的哈希函数来进行分区。
不论创建何种类型的分区,如果表中存在主键或唯一索引时,分区列必须是唯一索
引的一个组成部分,因此下面创建分区的SQL语句会产生错误
mysql> CREATE TABlE t1http:/blog.csdnnet/jiongyi11
5I.A
154某4丧
拼吾费
>c。11 INT NOT NULL,
>c。12 DATE NOT NULL
Co13 INT NOT NULL,
col4 INT NOT NULLr
> UNIQUE KEY(c。11,c。12)
PARTTTTON BY HASH (co13)
PARTIT工oNs4
ERROR 1503 (HY00O): A PRIMARY KEY must include all columns in the tables
partitioning function
唯一索引可以是允许NULL值的,并且分区列只要是唯一索引的一个组成部分,不
需要整个唯一索引列都是分区列,如:
mysql> CREATE TABLE t1
3c。11 INT NOLL
->co12 DATE NULLr
-> CO13 INT NULL
r
col4 TNT NULLg
> NIQUE KEY C。11,c。12,co13,co14
>PART工T工 ON BY HASH(co3)
PARTITIONS 4
Query OK, 0 rows affected (0.53 sec)
如果建表时没有指定主键,唯一索引,可以指定任何一个列为分区列,因此下面两
句创建分区的SQL语句都是可以正确运行的。
CREATE TABLE tl
c。11 INT NULI
c。12 DATE NUI
COl3 INT NULL
co14工 NT NULL
)enginesinnodb
PAR工 TION BY HASH(c。13)
PARTITIONs 4
CREATE TABLE t1
COl1 INT NULL
CO12 DATE NULLI
col3 INT NULLe
c。4 INT NULL
key (col4)
cngine=innodbhttp://blog.csdn.net/jiongyi1
5.
48分区表155
PARTITION BY HASH(co13)
PARTITions 47
482分区类型
1. RANGE分区
我们介绍的第一种分区类型是 RANGE分区,也是最常用的一种分区类型。下面的
CREATE TABLE语句创建了一个id列的区间分区表。当i小于10时,数据插入p0分
区。当i大于等于10小于20时,数据插入p1分区。
CREATE TABL三t(
id INT
)ENGINE=INNDB
PARTITION BY RANGE (id)(
PARTITION PO VALUES LESS THAN (10)
PARTITION Pl VALUES LESS THAN (20))i
查看表在磁盘上的物理文件,启用分区之后,表不再由一个id文件组成了,而是
由建立分区时的各个分区id文件组成,如下面的饼P#p0bd,t#Plbd
mysql> system
/usr/local/mysql/data/test2/t
rw一rw
1 mysql mysql 84K 7 A 31 14: 11 /usr/local/mysql/data/test2/t frm
rw-rw----1 mysql mysql
28 7A 31 14: 11 /usr/local/mysql/data/test2/tpar
IN-EN-
1 mysql mysql 96K 7 H 31 14: 12 /usr/local/mysql/data/test2/t#P#po
ibd
1 mysql mysql 96K 7 A 31 14: 12 /usr/local/mysql/data/test2/t#P#pl
ibd
接着插入如下数据
mysq l> INSERT INto t SELECT 9:
Query oK, 1 row affected (0.03 scc)
Rec。rs:1 Duplicates;0刚 annas:0
mysql> INSERT INto select 10
Query OK, l row affected (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INto t SELECT 15:
Query OK, 1 row affected (0.03 sec)
Records: 1 Duplicates: o Warnings: 0http://blog.csdn.net/jiongyi1
BL
156莩4章夜
哥研者
因为表t根据列过进行分区,所以数据是根据列id的值的范围存放在不同的物理文
件中的,可以通过查询 information schema架构下的 PARTITIONS表来查看每个分区的
具体信息:
mysql> SELECT FROM information schema PARTITIONS
>Where table schema=database( and table name= t \ G:
★★★★★★★★★★★★★★走★★★货★黄请黄*1,工ow★变★费责费贵★★★安★安安啸安责贵★
TABLE CATALOG: NULL
TABLE SCHEMA: test?
TABLE NAME: t
PARTIT工 N NAME:p0
SUBPARTITION NAME: NULL
PARTITION ORDINAL POSITION: 1
SUBPARTITION ORDINAL POSITION: NULL
PARTITION METHOD: RANGE
SUBPARTITION METHOD: NULL
PARTITION EXPRESSION id
SUBPARTITION EXPRESSION: NULL
PARTITION DESCRIPTION: 10
TABLE ROWS: 1
AVG ROW LENGTH: 16384
DATA LENGTH: 16384
MAX DATA LENGTH: NULL
INDEX LENGTH: 0
DATA FREE: 0
CREATE TIME: NULL
UPDATE T工ME:NULL
CHECK TIME: NULL
CHECKSUM: NULL
A"⊥⊥ ON COMMENT
NODEGROUP: de fault
TABLESPACE NAME. NULL
害常青赏青食青贵常青★★☆☆☆★★食肯實食t2.roW*實言☆*☆★★★量★★★★★★★★★★女★女★★
TABLE CATALOG: NULL
TABLE SCHEMA:七est2
TABLE NAME: t
PARTITION NAME: p1
SUBPARTITION NAME: NULL
PARTITION ORDINAL POSITICN: 2
SUBPARTITION ORDINAI. POsTTICN: NULL
PARTITION ME THOD: RANGE
SUBPARTITION METHOD: NULL
PARTTTION EXPRESSION: id
SUBPARTITION EXPRESSION: NULL
PARTITION DESCRIPTION: 20http:/blog.csdnnet/jiongyi11
51.6
4.8分区表157
TABLE ROWS: 2
AVG RON LENGTH: 8192
DATA LENGTH: 16384
MAX DATA LENGTH: NULL
INDEX LENGTH: 0
DATA FREE: 0
CREATE TIME: NULL
UPDATE TIME. NULL
CHECK TIME: NULL
CHECKSUM: NUL,I
FARTITION COMMENT
NODEGR0UI: defau⊥t
TABLESPACE NAME NULL
2 rows in set【0.00sec
TABLE ROWS列反映了每个分区中记录的数量。由于之前向表中插入了9、10、
15三条记录,因此可以看到,当前分区p0中有1条记录,分区p中有2条记录
PARTITION METHOD表示分区的类型,这里显示的是 RANGE。
对于表t,由于我们定义了分区,因此对于插入的值应该严格遵守分区的定义,当插
入一个不在分区中定义的值时, MySQL数据库会抛出一个异常。如下所示,我们向表t
中插入30这个值。
mysql> INSERT INTo t SELECT 30
ERROR 1526(HYC00):Table has no partition for value 30
对于上述问题,我们可以对分区添加一个 MAXVALUE值的分区。 MAXVALUE可
以理解为正无穷,因此所有大于等于20且小于 MAXVALUE的值别放入p2分区。
mysqL> ALTER TABLE t
. ADD PARTITION
partition p2 values less than maxvalue
Query Ok, 0 rows affected (0. 45 sec)
Records: 0 Duplicates: o Warnings: 0
mysql> INSERT INTO L SELECT 30
Query OK, 1 row affected (0.03 sec)
Records: 1 Duplicates: 0 Warnings: 0
RANGE分区主要用于日期列的分区,例如对于销售类的表,可以根据年来分区存
放销售记录,如下面的分区表
saleshttp:/blog.csdnnet/jiongyi11
5I
158某4表
拼安
mysql> CREATE TABLE sales
- money INT LINS IGNE.D NOT NULT.
date datetIMe
->ENGINE=INNODB
PARTITIon by RANGE (YEAR (date))(
- PARTITION P2008 VALUE LESS TEEN (2009)
PARTTTTON P2009 VALUE LESS THEN (2010)
PARTITION P2010 VALUE LESS THEN (2011)
Query ok, rows affected 0.34 sec)
mysql> INSERT INTO sales SELECT 100,2008-01-C1
Query Ok, 1 row affected (0.03 sec
Records: 1 Duplicates: 0 Warrings: 0
mysql> INSERT INTO sales SELECT 100, 2008-02-01
Query OK, 1 row affected (0.03 secl
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTo sales SELECT 200, 2008-01-02'
Query Ok, 1 row aftected (0.04 secI
Records: 1 Duplicates: o Warnings: 0
mysql> INSERT INTO sales SELECT 100, 2009-03-01i
Query OK, l row affected (C. 03 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTO sales SELECT 200, 2010-03-01
Query oK, 1 row affected (0.03 scc)
Records: 1 Duplicates: o Warnings: 0
这样创建的好处是,便于对 sales这张表的管理。如果我们要删除2008年的数据,
不需要执行 dELetE FROM sales where date>=200801-0l' and date<"2009-01-01',
只需删除2008年数据所在的分区即可:
mysql> alter table sales drop partition p2008
Query OK, n rows affected (0.18 sec)
Records: Duplicates:0 Warnings: 0
这样创建的另一个好处是可以加快某些查询操作,如果我们只需要查询2008年整
年的销售额,可以这样:
mysql> EXPLAIN PARTITIONS
> SELECT★ FROM sa1eshttp://blog.csdn.net/jiongyi1
48分区59
> Where date>=2008-01-01 and date<=!2008-12-31"\G
贵★★★青大★★重★★★★背★★★★量★★★走★
2,row★★★★★★★★★南★★★★★★★★为★★片★
d:1
select type: SIMPLE
table: sales
partitions: p2008
type: ALL
possible keys: NULL
key: NULL
key len: NULL
ref: NULL
rOws: 5
Extra: Using where
1 row in set (0.00 sec)
通过 EXPLAIN PARTITION命令我们可以发现,在上述语句中,SQL优化器只需
要去搜索p2008这个分区,而不会去搜索所有的分区——称为 Partition pruning(分区修
剪),故查询的速度得到了大幅度的提升。需要注意的是,如果执行下列语句,结果是
样的,但是优化器的选择可能又会不同了:
mysql> EXPLAIN PARTITIOENS
> SELECT★ FROM sa1es
> Where date>=12008-01-01! and date<"2009-01-01"G
★青青声南青青奇音古当诗中卉钟钟1,rOw*肯青★★井★井★★★肯青南南南★★青★★★★★★
id: 1
select type: SIMPLE
table: sales
partitions: p2008, P2009
type: ALL
possible keys: NULL
key: NULL
key len: NULL
ref: null
rOws: 5
Extra: Using where
l row in set (0.00 sec)
这次条件改为date<"2009-01-01'而不是date<=2008-12-31'时,优化器会选择搜
索p2008和p2009两个分区,这是我们不希望看到的。因此对于启用分区,应该根据分
区的特性来编写最优的SQL语句。
对于 sales这张分区表,我曾看到过另一种分区函数,设计者的原意是按照每年每月http:/blog.csdnnet/jiongyi11
5.e
60第4莩衣
来进行分区,如
mysql> CREATE TABLE sales
- money INT UNSIGNED NOT NULLr
date daTetime
>)ENG工NE= INNODB
- PARTITION Dy RANGE (YEAR (da:e)*100+MONTH (date))(
PARTITION P201001 VALUES LESS THEN (201002)
PARTITION 0201002 VALUES LESS THEN (2010031
PARTITION p201003 VALVES LESS THEN (201004)
Query ok 0 rows affected (0.37 sec)
但是在执行SQL语句时开发人员发现,优化器不会根据分区进行选择,即使他们编
写的SQL语句已经符合了分区的要求,如:
mysql> EXPLAIN PARTITIONS
SELECT FROM sales
2 Where date>=2010-01-ol and date<=2010-01-31\G:
★★大古;★古h計★h★★食貴★★★實责實
1,r。w*大★黄★★★★★★★★★女★★为为★★*专
id: 1
select type: SIMPLE
table: sale
partitions:p201001,p201002P201003
type: AlL
possible keys: NULL
key: NULL
key len: NULl
ref: NULL
ruws: 4
Extra: Using where
1 row in set (0. oo sec)
可以看到优化对分区p201001,p201002,p201003都进行了搜索。产生这个问题
的主要原因是对于 RANGE分区的查询,优化器只能对 YEARO, TO DAYS0,TO
SECONDSO, UNIX_ TIMESTAMPO这类函数进行优化选择,因此对于上述的要求,需
要将分区函数改为 TO DAYS,如:
mysql> CREATE TABLE sales(
morey INT UNSIGNED NOT NULL,
s date dateTOe
->)ENGINE=INNODB
PARTITIoN by range (To Days date))(http://blog.csdn.net/jiongyi1
48分区表5l6D
PARTITTON P201001
VALUES LESS THEN (TO DAYS(2010-02-01)
PARTITION p201002
多盛
VALUES LESS THEN (TO DAYS(2010-03-01))
PARTITION p201003
VALUES LESS THEN (TO DAYS(2010-04-01)
Query oK, o rows affected(0.36 sec)
这时再进行相同类型的查询,优化器就可以对特定的分区进行查询了
mys
SCl> EXPLAIN PATITIONS
- SELECT from sales
> ahere date>=12010-01-01! and date<="2010-01-311G;
★囊★安★★★★卖实★实★★★★★★★*★*1,r。w★★★★★★*★★★★★货★★★★★★★★安★★
id: 1
select type: SIMPLE
table: sales
partitions: p201001
type: ALL
possible keys NULL
key: NULL
key len: NULL
ref: NULL
rows: 4
Extra: Using where
1r。 w in set(0.00sec
2.L|ST分区
LIST分区和 RANGE分区非常相似,只是分区列的值是离散的,而非连续的。如:
mysql> CREATE TABLE t
a INt,
b INT)ENGINE=INNODB
- PARTITION BY LIST (E)(
PARTITION PC VALUES IN (1,3,5,7,9)
PARTITION pl VALUES IN (0,2, 4,6,8)
Query oK,0 rows affected (0.26 sec)
不同于 RANGE分区中定义的 ALUES LESS THAN语句,LIST分区使用 ALUES
因为每个分区的值是离散的,因此只能定义值。例如向表t中插入一些数据:
mysql> INSERt INTo t sELECT 1, 1
Query OK, 1 row affected (0. 03 sec)http:/blog.csdnnet/jiongyi11
5,e
162第4幸表
Records: 1 Duplicates: o Warnings: O
mysql> INSERT INTo t SELECT 1, 2;
Query OK, 1 row affected (0.03 secl
Records: 1 Duplicates: o Warnings: 0
mysql> INSERT INto t SELECT 1, 3:
Query OK, l row affected (0.03 secl
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERt INTo t SELECT 1,4;
Query OK, 1 row affected (0.03 secl
Records: 1 Duplicates: 0 Warnings: 0
mysql> SElect table name, partition name, table rows
> from information schema. PArTITIONS
Where table name='t ANd table schema=DATABASE(\G:
★南★★★★★★南霄女★肯★★肃★肃丈★★★★★★
rOw*大*★大★★★★★★*★★★★★*★★★★
table name: t
partition name: PO
table rows: 2
★★*★★★★★★★★柬★★★青★★★★★★★贾2-。W★★★★★★卖南★★南★女★★女★★★女★★★如央央
table name:t
partition name: pl
table rows: 2
2 rows in set 0.0o sec)
如果插入的值不在分区的定义中, MySQL数据库同样会抛出异常:
mysql> INSERT INTo t SELECT 1,10;
ERROR 1526 (HY000): Table has no partition for value 10
另外,在用 INSERT插入多个行数据的过程中遇到分区未定义的值时, MyISAM和
InnoDB存储引擎的处理完全不同。 MyISAM引擎会将之前的行数据都插入,但之后的
数据不会被插人。而 InnoDB存储引擎将其视为一个事务,因此没有任何数据插入。先
对 MyIsAM存储引擎进行演示,如:
mysql> CRATE TABlE t
a INT,
- b INTIENGINE=MY ISAM
PARTITION BY LIST(b)(
PARTITION PO VALUES IN (1,3,5,7,9)
PARTITION Pl VALUES IN (0,2,4,6,8)http://blog.csdnnet/jiongyi1
BL
4.8分区表163
拼哪
Query oK, 0 rows affected (0.05 sec)
mysql> INSERT INTo t VALUES (1,2),(2, 4),(6,10),(5,3)
ERROR 1525 (HY000): Table has no partition for value 10
mysql> sElECT FROM ti
2 rows in set (0.00 sec)
可以看到(6,10)、(5,3)记录的插入没有成功,但是之前的(1,2),(2,4)
记录都已经插入成功了。而对于同一张表,存储引擎换成 InnoDB,则结果完全不同:
mysql> TRUNCATE TABLE t;
Query OK, 2 rows affected (0.00 sec)
mysql> ALTER TABle t ENGINE=InnoDB:
Query OK,c rows affected (0.25 sec)
Records: o Duplicates: o warnings: 0
mysql> INSERT INTo t VALUES (1,2),(2,4,(6,10),(5,3)i
ERROR 1526(HYO00): Table has no partition for value 10
mysql> SElECT FRoM t;
Empty set【0.00sec
可以看到同样在插入(6,10)记录时报错,但是没有任何一条记录被插入到表t中
因此在使用分区时,也需要对不同存储引擎支持的事务特性进行考虑
3.HASH分区
HASH分区的目的是将数据均匀地分布到预先定义的各个分区中,保证各分区的数
据数量大致都是一样的。在 RANGE和LIST分区中,必须明确指定一个给定的列值或
列值集合应该保存在哪个分区中;而在HASH分区中, MySQL自动完成这些工作,用
户所要做的只是基于将要进行哈希分区的列值指定一个列值或表达式,以及指定被分区
的表将要被分割成的分区数量。
要使用HASH分区来分割一个表,要在 CREATE TABLE语句上添加一个“ PARTITION
BY HASH(apr)”子句,其中“ayr”是一个返回一个整数的表达式。它可以仅仅是字段http:/blog.csdnnet/jiongyi11
EL
64第4章衣
类型为 MySQL整型的列名。此外,用户很可能需要在后面再添加一个“ PARTITIONS min
子句,其中mm是一个非负的整数,它表示表将要被分割成分区的数量。如果没有包括
个 PARTITIONS子句,那么分区的数量将默认为1。
下面的例子创建了一个HASH分区的表t,分区按日期列b进行:
CREATE TABLE t hash
a工NT
b DATETIME
)ENGINE=InnoDB
PARTITION BY HASH (YEAR (E))
PARTITIONS 4
如果插入一个列b为2010-04-01的记录到表 t hash中,那么保存该条记录的分区
如下:
MoD(YEAR/"2010-04-01"),4)
=MOD【2010r4)
因此记录会放入分区p2中,我们可以按如下方法来验证:
mysql> INSERT INTo t hash select 1,2010-04-01*
Query OKr 1 row affected (0.01 sec
Records: 1 Duplicates: o warnings: 0
mysql> SELEcT table name, partiion name table rcws
- FROM information schema. PARTITIONS
WhEre table schema=DATABASE() AND table name='t hash'\Gi
★★★文★★黄★★★k责★★★★丈★★责贵★★★★1。row★内*大★★★内★★肯★害大★★★内★
table name: t hash
partition name: pO
table rows: 0
★★★★★青★★★*★青★黄★★古★内★★2.￥。w★★地地★*★青内★肯★女★女青青★★责责
table name: t hash
partition narre: pl
table rows: 0
南古★★★★★★★内w★★★★★★★★★★★★3.rOw★青★内★★★害实“害★★★害货★★
table name
hash
partition name: p2
table rows: 1
实★审审★★*肯古★大古古青大★★kt4.y。W*t啬★*女女+女旮★★★★★★★★★★★★专
table name: t hash
partition name: p3http:/blog.csdnnet/jiongyi11
5.A
4.8分区夜165
able rows: 0
召盛
4 rows in set (0.00 sec)
可以看到p2分区有1条记录。当然这个例子中也许并不能把数据均匀地分布到各
个分区中去,因为分区是按照YEAR函数进行的,而这个值本身可是离散的。如果对于
连续的值进行HASH分区,如自增长的主键,则可以较好地将数据进行平均分布。
MYSQL数据库还支持一种称为LⅠ NEAR HASH的分区,它使用一个更加复杂的算
法来确定新行插入到已经分区的表中的位置。它的语法和HASH分区的语法相似,只是
将关键字HASH改为 LINEAR HASH。下面创建一个 LINEAR HASH的分区表 t linea
hash,它和之前的表 t hash相似,只是分区类型不同。
CREATE TABLE t linear ash
己INT
b DATETIME
ENGINE=Inn。DB
PARTITION BY LINEAR HASH (YEAR (b))
PARTITIONS 1A
同样插入'2010-0401’的记录,这次 MySQL数据库根据以下的方法来进行分区的
判断:
口取大于分区数量4的下一个2的幂值V,V= POWER(2, CEILING(LOG(2,
m))=4;
口所在分区N=YEAR(2010-0401)&(V1)=2。
虽然还是在分区P2,但是计算的方法和之前的HASH分区完全不同,接着进行插
入实际数据的验证:
mysqL> INSERT INTo t linear hash SELECT 1, 2010-04-01
Query OK, 1 row affected (0.02 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> SElECT table nanme, partition name, table rows
F'RoM information schema PArTITIoNs
WHERE table schema=DATAEASE
AND table name='t linear hash\G:
★★★★★★★★★审★灾★*★★★★★★★★★★1.rw★★★*★★为★★南★★★肃实★★★丈★★★★★女★女
table name: t linear hash
partition name: pO
table rows: o
★★★青古古青内出专古古青★女青★★#★★★★2,￥。w★为★古大★大★为肃★言★★★★★★亩★★http:/blog.csdnnet/jiongyi11
5.e
166茅4表
table name: t linear hash
盛
partition name: pl
★★内★青★★青★★★女女★*审★★青★★青★★★3.row★★★大为★★实★★★背★★★★黄★★★
table name: t linear hash
partition name: p2
table rows: 1
★女★★★★★★★★★实***如实实声肃★肖★肉4.r⊙w★*★★★★★餐★*★*t黄★表责来★★来
table name: t linear hash
Partition name: p3
table rows: 0
4r。 ws in set(0.01sec
LINEAR HASH分区的优点在于,增加、删除、合并和拆分分区将变得更加快捷,
这有利于处理含有大量数据的表。它的缺点在于,与使用HASH分区得到的数据分布相
比,各个分区间数据的分布可能不大均衡。
4.KEY分区
KEY分区和HASH分区相似,不同之处在于HASH分区使用用户定义的函数进
行分区,KEY分区使用 MySQL数据库提供的函数进行分区。对于 NDB Cluster引擎,
MySQL数据库使用MD5函数来分区;对于其他存储引擎, MySQL数据库使用其内部
的哈希函数,这些函数基于与 PASSWORDC一样的运算法则。如:
mysql> CREATE TABLe t key
>a int
> b DATET工ME} ENGINE=工 nodE
PARTITION BY KEY (b
>> PARTITIONs 4
Query Ok 0 rows affected (0.43 sec)
在KEY分区中使用关键字LⅠNEAR和在HASH分区中使用具有同样的效果,分区
的编号是通过2的幂( powers- of-two)算法得到的,而不是通过模数算法
5 COLUMNS分区
在前面介绍的 RANGE、LIST、HASH和KEY这四种分区中,分区的条件是:数
据必须是整型( Interger),如果不是整型,那应该需要通过函数将其转化为整型,如
YEAR, TO DAYSO, MONTHO等函数。 MySQL5.5版本开始支持 COLUMNS分
区,可视为 RANGE分区和LIST分区的一种进化。 COLUMNS分区可以直接使用非整
型的数据进行分区,分区根据类型直接比较而得,不需要转化为整型。此外, RANGEhttp://blog.csdn.net/jiongyi1
4.8分区夜167
COLUMNS分区可以对多个列的值进行分区。
COLUMNS分区支持以下的数据类型:
口所有的整型类型,如INT、 SMALLINT、 TINYINT、BIGⅠNT。 FLOAT和 DECIMAL
则不予支持。
口日期类型,如DATE和 DATETIME。其余的日期类型不予支持。
口字符串类型,如CHAR、 VARCHAR、 BINARY和 VARBINARY。BLOB和TEXT
类型不予支持。
对于日期类型的分区,我们不再需要 YEAR和 TO DAYSO函数了,而直接可以
使用 COLUMNS,如:
CREATE TABLE t columns range
a INT,
D DATETTMF
) ENGINE=工 NNODB
PARTITION BY RANGE COLUMNS (B)(
PARTITION PO VALUES LESS THAN (2009-01-01),
PARTITION P1 VALUES LESS THAN (2010-01-01)
)
同样可以直接使用字符串的分区:
CREATE TABLE customers 1
first name VARCHAR (25)
last name VARCHAR(25)
street 1 VARCHAR(30)
street 2 VARCHAR(30)
city VARCHAR(15)
renewal date
PARTITION BY LIST COLUMNS(city)
PARTI TION pRegion 1
VALUES IN(OSkarshamn', 'Hogsby', ' '),
PARTITION PRegion 2
VALUES IN(Vimmerby, 'Hultsfred,, 'vastervik)
PARTITIoN pRegion 3
VALUES IN(Nass]8,Fksjor'Vetlanda')
PART工T工 on PRegion4
ALUEs IN(Uppvidinge, 'Alvesta',lVaxjo')
对于 RANGE COLUMNS分区,可以使用多个列进行分区,如:http://blog.csdn.net/jiongyi1
5.
l68箬4表
CREATE TABLE rCx
a INte
b INTE
C CHAR【3)
d iNt
)Engine=InnoDB
PARTITION BY RANGE COLUMNS ar d, c)
PARTITION pO VALUES LESS THAN (5,10,ggg)
PARTITION p1 VALUES LESS THAN (10,20,mmmm)
PARTITION P2 VALUES LESS THAN (15,30,sss),
PARTITION p3 VALUES LESS THAN (MAXVALUE, MAXVALUE, MAXVALUE)
ySQL55开始支持 COLUMNS分区,对于之前的 RANGE和LST分区,用户可
以用 RANGE COLUMNS和 LIST COLUMNS分区进行很好的代替。
48.3子分区
子分区( cubpartitioning)是在分区的基础上再进行分区,有时也称这种分区为复合
分区( composite partitioning)。 MySQL数据库允许在 RANGE和LIST的分区上再进行
HASH或KEY的子分区,如:
mysql> CREATE TABLE ts (a INT, b dATE)engine=innodb
PARTITICN BY RANGE( YEAR(b))
. >SUBPARTITION BY HASH( TO DAYS(b))
SUBPARTITIONS 2
PARTI TICN PO VALUES LESS THAN (1990)
- PARTITICN Pl VALUES LESS THAN (2000)
PARTITICN P2 VALUES LESS THAN MAXVALUE
Query Ok 0 rows affected (0.01 sec)
mysql> system ls -lh /usr/local/mysql/data/test2/ts
rw-rw----l mysql mysql4K Aug
15: 50 /usr/local/mysql/data/test2/ts frm
rw-Iw
mysqlmysql 96 Aug 1 15: 50 /usr/local/mysql/data/test2/tspar
rw-rw----1 mysql mysql 96K Aug 1 15: 50 /usr/local/mysql/data/test2/
ts+P#p0#SPfpOspo ibd
rw"rw----1 mysql mysql
96K Aug
1 15: 50 /usr/local/mysql/data/test2/
ts#P#PO+SP#pOspliba
rw-rw----1 mysql mysql 96K Aug 1 15: 50 /usr/local/mysql/data/test2/
ts#Pfpl+SP#plsp0ibc
-rw-rw----l mysql mysql 96K Aug 1 15: 50 /usr/local/mysql/data/test2/http:/blog.csdnnet/jiongyi11
5.A
4.8分区表169
ts#P#plSPfPlspl ibd
1 mysql my q1 96K Aug 1 15: 50 /usr/local/mysql/data/tega
ts#P#F2#SP#p2spoibd
1 mysql mysql 96K Aug 1 15: 50 /usr/local/mysql/data/test2/
tsfPfp2 fSP#pspl ibd
表ts先根据b列进行了RANG分区,然后又进行了一次HASH分区,所以分风的
数量应该为(3×2=)6个,这通过查看物理磁盘上的文件也可以得到证实。我们也可以
通过使用 SUBPARTITION语法来显式地指出各个子分区的名字,例如对上述的ts表同
样可以这样
mysql> CREATE TABLE ts (a INT, b dATE
PARTITION BY RANGE YEAR(b)
SUBPARTITION BY HASH< TO DAYS( 5))(
>PART工T工oNp0 VALUES LESS THAN(1990)(
冫 SUBRARTITION S0
> SUBPART工 TION S1
PARTITION P1 VALUES LESS THAN (2000(
SUBPARTITION
SUBPARTITIoN S3
>PART工T工oNp2 VALUES LESS THAN MAXVALUE
SUBPARTITION S4r
SUBPARTITION S5
Query oK, rows attested (0.00 sec
子分Ⅸ的建立需要注意以下儿个问题
口每个子分区的数量必须相同。
口要在一个分区表的任何分区上使用 SUBPARTITION来明确定义任何子分区,就
必须定义所有的子分区。因此下面的创建语句是错误的:
mysql> CREATE table ts (a INt b DATE)
- PARTITION BY RANGE( YEAR(b))
-S SUBPARTITION BY HASH( TO DAYG(b)
PARTITION PO VALUES LESS THAN (1990)(
SUBPARTITION SO,
SUBPARTITION S1
PARTITION P1 VALUES LEES THAN 2000)http:/blog.csdnnet/jiongyi11
EL
170第4幸表
FARTITION P2 VALUES LESS THAN MAXVALUE
章器
-> SUBPAR2T工oNs2p
-X SUBPARTITION S3
P
ERROR1064(42000): Wrong nunber of subpartition8de￡in自d,皿主 match with
pevi。 ug setting near
PARTITION P2 VALUES LESS THAN MAXVALUE
SUBPARTIT工oNs2,
SUBPARTITION S3
i at line g
口每个 SUBPARTITION子句必须包括子分区的一个名字。
口子分区的名字必须是唯一的。因此下面的创建语句是错误的
mysql> CREATE TABLE ts (a InT, b DATE)
PARTITION BY RANGE( YEAR())
SUBPARTITION BY HASH( TO DAYS (b))(
PARTITION PO VALUES LESS THAN (1990)(
-> SU3PARTITION sO
SUBPARTITIoN S1
PARTITION pl VALUES LESS TIIAN (2010)(
- SUBPARTITION S0
r
SUBPARTITION S1
F
- PARTITION P2 VALUES LESS THAN MAXVALUE
SUBPARTITION S0
SUBPARTITTON S1
ERoR1517【HY000〕:Dp1 cate par
七 ation name g0
子分区可以用于特别大的表,在多个磁盘间分别分配数据和索引。假设有6个磁
盘,分别为/disk0、/disk1、 /disk2等。现在考虑下面的例子
mysql> CREATE TABLE ts (a INT, b DATE)ENGINE=MY. SAM
PARTITION BY RANGE( YEAR (5)
- SUBPARTITION BY HASH( TO DAYS(b))(
PARTITION PO VALUES LESS TIAN (2000)(
SUBPARTITION 50
-> DATA DIRECTORY =1/disko/data.
->INDEX DIRECTORY ='/disko/idx'rhttp://blog.csdn.net/jiongyi1
SI
48众区表17/
部拼吾
SUBFARTITION 51
DATA DIRECTORY
Adiskl/data
INDEX DIRECToRY =r/disk1/idx#
PARTITION p1 VALUES LESS THAN (2010)(
S SUBPARTITION s2
. DATA DIRECTORY
/disk/data'
INDEx DIRECTORY ='/disk/idx'
SUBPARTITION s3
DATA DIRECTORY =r/disk/data
INDEX DIRECTORY =' /disk3/idx
PARTITION P2 VALCES LESS THAN MAXVALUE 4
> SUBPART工T工QNs4
DATA DIRECTORY ='/disk/data
INDEX DIRECTORY=’/disk4/idκ"r
SUBPART工T工N85
DATA DIRECTORY =' /disks/detar
->INDEx DIRECTORY =t/disks/idx
Query OK, 0 rows affected (0.02 sec)
由于 InnoDB存储引擎使用表空间自动地进行数据和索引的管理,因此会忽略DATA
DIRECTORY和 INDEX DIRECTORY语法,因此上述的分区表的数据和索引文件分开放
置对其是无效的:
mysql> CREATE TABLE ts (a INT, b DATE]engine=innodb
- PARTITION BY RANGE( YEAR b)
SUBPARTITION BY HASH( TO DAYS(b))(
>PART工 TION F0 VALUES LESS THAN《2000)(
- SUBPARTITION sO
DATA DIRECTORY =1/disko/data'
>INdex dIRECtorY =i/disko/idx
> SUBPIRTIT工CN1
DATA DIRECTORY =/disk/data
>工 NDEX DIREC TORY
/disk1/idx
. PARTITION Pl VALUES LESS THAN (2010)(
X SUBBARTITION 32
DATA DIRECTORY =./disk2/data r
. INDEX DIRECTORY =/disk/idx
SUBPARTITION $3
>datA DIRECTORY =1/disk/data 1http://blog.csdn.net/jiongyi1
6I
172弟4亨衣
部拼
INDEX DIRECTORY
/disk/idx'
PARTITION P2 VALUES LESS THAN MAXVALUE i
> SUBPART工 TION S4
. DATA DIRECTORY =1/disk/data
INDEX DIRECTORY =A/disk/idx
SUBPARTITION 55
DATA DIRECTORY ='/disks/data
INDEX DIRECTORY s / disks/idx
Query OK, o rows affected (0.02 see
mysql> system Is -lh /usr/local/mysql/data/test2/ts
一TW一
1 mysql mysql 84K Aug 1 16: 24 /usr/lccal/mysql/data/test2/ts frm
rw-rw----1 mysqlmysql 80 Aug 1 16: 24 /usr/lccal/mysql/data/test2/tspar
1 mysql mysql 96K Aug 1 16: 25 /usr/local/mysql/data/test2/ts#?#p0#SP#sO
ibd
1 mysql mysql 96K Aug 1 16: 25 /usr/local/mysql/data/test2/ts#?#pO#SPisl
ibd
mysql mysql 96K Aug 1 16: 25 /usr/local/mysql/data/test2/ts#?#pl#SP#s2
rW=工W
1 mysql mysql 96K Aug 1 16: 25/ usr/local/mysql/data/test2/ts#?#pl#SP#s3
ibd
w一工v
1 mysql mysql 96K Aug 1 16: 25 /usr/local/mysql/data/test2/ts?#p2#SP+s4
w一W一一
1 mysql mysql 96K Aug 116: 25 /usr/local/mysql/data/test2/ts#P#p2#SP#s5
d
484分区中的NULL值
MYSQL数据库允许对NULL值做分区,但是处理的方法与其他数据库可能完全
不同。 MYSQL数据库的分区总是视NULL值视小于任何的一个非NULL值,这和
MySQL数据库中处理NULL值的 ORDER BY操作是一样的。因此对于不同的分区类
型, MySQL数据库对于NULL值的处理也是各不相同。
对于 RANGE分区,如果向分区列插入了NULL值,则 MySQL数据库会将该值放
入最左边的分区。例如:
mysql> CREATE TAELE t range
a Intr
> b INT)ENGINE=InnoDBhttp:/blog.csdnnet/jiongyi11
5I
48分区裒173
拼吾
PARTITION BY RANGE (b)(
PARTITION PO VALUES LESS THAN (10)
- PARTTTION P1 VALUES LESS THAN (20),
PARTITION P2 VALUES LESS THAN MAXVALUE
Query oK, 0 rows affected (0.01 sec)
接着向表中插人(1,1),(1,NULL)两条数据,并观察每个分区中记录的数量
mysql> INSERT INTo t range SELECT 1,li
query OK 1 row af=ected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> INSERT INTo t range sElECT 1 NULL
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 warnings: 0
mys 1> SELECT FROM t range\G:
★★★★★文★★★★实k★★★★实内★;1,rOw*古青*古古青古★★肯古青青古肯★青★
a!1
青w害实古青兴皆*古古青古古女+★青★2.roW*为★为为为★★十大太古古大言言★★★★★★
b;ⅳULL
2 rows in set (0.00 sec)
mysql> SELECT table name, partition name table rows
FROM in format ion schema PARTITIONS
WhERE table schema=DATABASE () AND table name='t range\G
青*青★古★肯★★实实实实★文害宵*害x⊥,row木六肖言言六青★★★★★★★★★★★★★★★★
table name: t range
partition name: pO
taple rcws: 2
才方大青★★*★★青肃**★青★★★2,xow*黄史★★女女文量★货★★诸★★★★★★★南★★
table name: t range
partition name: pl
table rows: 0
有十★有青大胄次南★★★★为大★★★食t3.r。w“古女★★★女★★★★★头为★而古青★★★
table name: t range
partition name p2
七ab1 e roWS:0
3 rows in set (0.00 scc)
可以看到两条数据都放入了p0分区,也就是说明了 RANGE分区下,NULL值会放
入最左边的分区中。另外需要注意的是,如果删除p0这个分区,删除的将是小于10的http:/blog.csdnnet/jiongyi11
EL
I744章夜
记录,并且还有NULL值的记录,这点非常重要:
章召器
mysql> ALTER TABLE t range DROP PARTITION po;
Query oK, 0 rows affected (0.01 sec)
Records: 0 Duplicates: 0 Warnings: 0
mysql> seleCt FRoM t range;
Empty set (0.00 sec)
在LST分区下要使用NULL值,则必须显式地指出哪个分区中放入NULL值,否
则会报错,如:
mysql> CREATE TABLE t list
->a工NT
>bINT〕 ENGINE= INNODE
> PARTITION BY L工sT(上}
PARTITION PO VALUES IN (1,3,5,7,9)
> PARTIT工ONP1 VALUES工N(0,24r6;B)
Query OK, 0 rows affected (0.00 sec)
mysql> INSERT INto t list select 1, NULL;
ERROR 1526 (HY000): Table has no partition for value NULL
若p0分区允许NULL值,则插入不会报错:
mysql> CREATE TABLE t list(
工NTr
INT ENGINE=INNODE
> PARTITION BY L工sT()
- PARTITION PO VALUES IN (1,3,5,7,9, NULL
->PARTITION P1 VALUES IN (0,2,4,6,8)
Query CK, 0 rows affected (0.00 sec)
mysql> INSERT INTo t list sElECT l,NUll;
Query CK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: Q
mysql> SELECT table name. partition name, table rows
FRoM information schema, PArtiTIons
WHERE table schema=DATABASE( AND table name='t list!\G
★實實賁寊實★★實★史★★★曾★寅★顰實寅實實實
1,row★★南★★肉★青六★★肯★t★青★t责内食责
table name t list
partition name: pOhttp://blog.csdn.net/jiongyi1
5
4.8分区表I75
table rows: 1
★★★★★★★★★头女★女*★★★文★★女貴訾2,r○w★★★★★是★★
賁肃富害古古★★背肯★★★
tab1en品me:t1ist
partition name: pl
table rows: 0
2 rows in set (0.00 sec)
HASH和KEY分区对于NUL的处理方式和 RANGE分区、LIST分区不一样。任
何分区函数都会将含有NULL值的记录返回为0。如:
mysql> CREATE TABLE t hash(
a INT,
>bINT) ENGINE=Inn。DB
PARtITION BY HASH (b)
PARTITIons 4i
Query OK, 0 rows affected (0.00 sec)
mysql> INSERT INto t hash sElect 1,0
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: o warnings: 0
mysql> INSERT INTo t hash SELECT l NULLi
Query OK, 1 row affected (0.01 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> SeLeCT table name, partition name, table rows
Froy information schema, PARTITIONS
->WhErE table schema=DATABASE( AND table name='t hash\G
★★★定★★大★古贵古t★大k太女女★★★1,rw★實古青★★青*★k青青女★害★责★食责★贵★责
table name t hash
partition name: pO
table￥ows:2
★★★责☆言★古★★大★★青★古古★古古青古古青★2.row★古*青古青言青内言青★★言青★t青古青★
table name: hash
artition name: pl
table rows: 0
南中喃;賣西内内中賣当舌省
中古审中中中啬审内青南中中曹★升青青声★青青
table name: t hash
partition name: p2
table rows: 0
★★黑*★密青★青青★★★★责曹责★★★旾★.工W**胄★★訾★★★實貴★★★★★★★★★★★★★★
table name: t hash
partition name: p3
table rows: 0http://blog.csdn.net/jiongyi1
6I
176第4表
拼没
4 raws in set (0.00 sec)
48.5分区和性能
我常听到开发人员说“对表做个分区”,然后数据库的查询就会快了。这是真的
吗?实际上可能根本感觉不到查询速度的提升,甚至会发现查询速度急剧下降。因此
在合理使用分区之前,必须了解分区的使用环境。
数据库的应用分为两类:一类是OLTP(在线事务处理),如Blog、电子商务、网络
游戏等;另一类是OLAP(在线分析处理),如数据仓库、数据集市。在一个实际的应用
环境中,可能既有OLTP的应用,也有OLAP的应用。如网络游戏中,玩家操作的游戏
数据库应用就是OLTP的,但是游戏厂商可能需要对游戏产生的日志进行分析,通过分
析得到的结果来更好地服务于游戏,预测玩家的行为等,而这却是OLAP的应用。
对于OLAP的应用,分区的确是可以很好地提高查询的性能,因为OLAP应用大多
数查询需要频繁地扫描一张很大的表。假设有一张1亿行的表,其中有一个时间戳属性
列。用户的查询需要从这张表中获取一年的数据。如果按时间戳进行分区,则只需要扫
描相应的分区即可。这就是前面介绍的 Partition Pruning技术
然而对于OLTP的应用,分区应该非常小心。在这种应用下,通常不可能会获取
张大表中10%的数据,大部分都是通过索引返回几条记录即可。而根据B+树索引的原
理可知,对于一张大表,一般的B+树需要2~3次的磁盘⑩O。因此B+树可以很好地
完成操作,不需要分区的帮助,并且设计不好的分区会带来严重的性能问题。
我发现很多开发团队会认为含有1000W行的表是一张非常巨大的表,所以他们往
往会选择采用分区,如对主键做10个HASH的分区,这样每个分区就只有100W的数
据了,因此查询应该变得更快了,如 SELECT* FROM TABLE WHERE PK=@pk但
是有没有考虑过这样一种情况:100W和1000行的数据本身构成的B+树的层次都是
样的,可能都是2层。那么上述走主键分区的索引并不会带来性能的提高。好的,如
果1000的B+树的高度是3,100W的B+树的高度是2,那么上述按主键分区的索引
可以避免1次IO,从而提高查询的效率。这没问题,但是这张表只有主键索引,没有
任何其他的列需要查询的。如果还有类似如下的SQL语句: SELECT* FROM TABLE
WHERE KEY=@key,这时对于KEY的查询需要扫描所有的10个分区,即使每个分区http://blog.csdn.net/jiongyi1
5.
48分区表177
的查询开销为2次O,则一共需要20次0。而对于原来单表的设计,对于KEY的查
询只需要2~3次IO。
接着来看如下的表 Profile,根据主键ID进行了HASH分区,HASH分区的数量为
0,表 Profile有接近1000W的数据:
mysql>CREATE TABLE Profile(
id int(11) NOT NULL AUTO INCREMENT,
nickname varchar(20) NOT NULL DEFAULt 1
password varchar (32) NOT NULL DEFAULT 1+
4 sex char(1)NCT NULL DEFAULT
F rdate date NCT NULL DEFAULt 0000-00-00+
PRIMARY KEY (id)
KEY 'nickname('nickname
->)ENGINE=InnoDB
> PARTITION BY HASH【id
PARTITIoNs 10
Query oK, 0 rows affected (1.29 sec)
mysql> SELECT COUNT(nickname)E'ROM profile;
★★南★★★★肯实★★青责南★青★★★★★1。rOw★★★★内青*青★★声古★青责★★★★★古太★责
c。unt【1):9999248
1 rcw in set (1 min 24.62 sec)
因为是根据HASH分区的,所以每个区分的记录数大致是相同的,即数据分布比较
均匀:
mysql> sElECT table name, partition name, table rows
FRom information schema. partitions
- WhERE table schema=DATABASE() anD table name=' '\G:
★★★大★★古太青言言★★★言害★★★★1.rw★k★★建★史★★★黄央★女★大女女★女女女★★★★
table name: profile
partition name: P0
table rows: 990703
★★★★灾灾安★★丈★★★★★k★★★古★★2.row★★★内★★★*★内柬★★★★言★古★★★★★
table name: profile
partition name: Fl
table rows: 1086519
★★★★*★*★★★★★★★★青★青青★常★★3.工ow*青六责青青六青六★六★去古太古古肃古★黄★★★
table name: Profile
partition name: p2
table rows: 976474
★★★大★★★★青南★肉★责★★青★青★★★4,row实实★安*★**★卖★★★读★★★★央★★★★★
table name: Profile
partition rame p3http:/blog.csdnnet/jiongyi11
51.6
178第4幸表
table rows: 986937
★★南古*卉青内★青六古古★★为★★★*★★★5,工Ow★★★当*★★青青★古★走大★大★★
table rame: Profile
partition name: p4
table rows: 993667
★★★责责青责责★★齿★贵责吉★★向★6,yOw★★青★★向★★★★★★★★★★★★责★读★走★★
table rame: Profile
partition name: p5
table rows: 978046
實★青南青青南六青★青大青★言肯片青★肯青★7,工Qw为青★★为大★★★★★言青★★★★★★肯★★★大
table name: Profile
partition name: p6
table rows: 990703
曾★女安★★曹内责出责女★★音盘责数8.1oW责★责青★青★★★t★食食t★责
table name: Profile
partition name: P7
table rows: 978639
宴t★★★★青丸★★★★★★责★★★★★★★★*9.row块青★★青内★为★★★凼★★★★★肯★★★★★为★
table name: Profile
partition name: P8
table rows: 1085334
宴青言世言青言南青言青言言食者★★言青★★10,r。W青★★青内青责责责言贵言言言★★★★★★
table name: profile
partition name: pg
table rows: 982788
t0 rows in set (0.80 sec
注意即使是根据自增长主键进行的HASH分区也不能保证分区数据的均匀。
因为插入的自增长D并非总是连续的,如果该主键值因为某种原因被回滚了,
则该值将不会再次被自动使用。
如果进行主键的查询,可以发现分区的确是有意义的:
mysqL> EXPLAIN PARTITIONS SELECT
FRoM Profile Where id=1\Gi
★青责青青言责言古责责★责青★言☆言★宴★害贵1,y。W實☆☆★☆★★音★★★★★七★★★实★★★★
select type: SIMPLE
table: Profile
partitions: pl
type: const
possible keys: PRIMARY
key: PRIMARY
key len:http://blog.csdn.net/jiongyi1
5.
4.8分区表l79
ef: const
rows: 1
Extr
1 row in set (0.oo sec)
可以发现只寻找了p1分区,但是对于表Pofl中 nickname列索引的查询, EXPLAIN
PARTITIONS则会得到如下的结果:
mysql> EXPLAIN PARTITIONS
->SELECT FROM Profile WHERE nickname='david!\G
★食★★雪★★★實貴★貴★★貴食★★★官★★★
1.row★★★实☆★★★★食★★★★★★★★★★安史★
id: 1
select type: SIMPLE
table: profile
partitions: pO, pl, p2, p3, p4,p5, p6, p7, p8,p9
type: ref
possible keys: nickname
key: nickname
key len: 62
ref: const
rows: 10
Extra: Using where
1Y。 w in set(0.00sec
可以看到, MySQL数据库会搜索所有分区,因此查询速度上会慢很多,比较上述
的语句:
mysql> SELECT FROM Profile WHERE nickname=david\G:
★★★☆女☆★★背食貴女食★★食★★★食★★★★
1,r。w★安★★★安★丧安★安安**★青★★★★青
ia:5566
nickname: david
password: 3e35d1025659d07ae2e0069ec5lab92
sex: M
rdate:2003-09-20
1r。 u in set(1.05sec
上述简单的索引查找语句竞然需要105秒,这显然是因为查询需要遍历所有分区的
关系,实际的IO执行了约20~30次。而在未分区的同样结构和大小的表上,执行上
述同样的SQL语句只需要026秒
因此对于使用 InnoDB存储引擎作为OLTP应用的表在使用分区时应该十分小心,
设计时确认数据的访问模式,否则在OTP应用下分区可能不仅不会带来查询速度的提
高,反而可能会使你的应用执行得更慢。http:/blog.csdnnet/jiongyi11
80第4章表
研者
486在表和分区间交换数据
MySQL56开始支持 ALTER TABLE… EXCHANGE PARTITION语法。该语句允许
分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区表中的数据
为空,那么相当于将分区中的数据移动到非分区表中。若分区表中的数据为空,则相当
于将外部表中的数据导入到分区中。
要使用 ALTER TABLE… EXCHANGE PARTITION语句,必须满足下面的条件
口要交换的表需和分区表有着相同的表结构,但是表不能含有分区
口在非分区表中的数据必须在交换的分区定义内
口被交换的表中不能含有外键,或者其他的表含有对该表的外键引用
口用户除了需要 ALTER、 INSERT和 CREATE权限外,还需要DROP的权限
此外,有两个小的细节需要注意
口使用该语句时,不会触发交换表和被交换表上的触发器
口 AUTO INCREMENT列将被重置
接着来看一个例子,首先创建含有 RANGE分区的表e,并填充相应的数据
CREATE TABLE e
id INT NOT NULL,
fname VARCHAR (30)
lname VARCHAR (30
PARTITION BY RANGE (id)(
PARTITION PO VALUES LESS THAN (50)
PARTITION Pl VALUES LESS THAN (100
PARTITION P2 VALUES LESS THAN (150
PARTITION P3 VALUES LESS THAN (MAXVALUE)
INSERT工 no e VALEs
(1659,Jim"r"Smith")r
(337,"Mary","Jones")
(16,Frank, White
(2005,Linda""Black")
然后创建交换表e2。表ε2的结构和表e一样,但需要注意的是表e2不能含有分区:
mysq> CREATE TABLE e2 LIKe e
Query oK, o rows affected (1.34 sec)http:/blog.csdnnet/jiongyi11
5.6
48分区表I87
mysel> ALTER TABLE C2 REMOVE PART工T工 ONING
Query OR,o rows affected (0.90 sec)
Records: 0 Duplicates: o warnings: 0
通过下列语句观察分区表中的数据:
mysqL> SELECT FARTITION NAME r TABLE ROWS
FROM INECRMATION SCHEMA PARTITIONS
WHERE TABLE NAME=·e'
I PARTITION NAME
TABLE ROAS
+
I pO
I pl
I p2
4 rows in set (0.00 sec
因为表c2中的没有数据,使用如下语句将表e的分区p0中的数据移动到表e2中:
mysql> ALTER TABLE e EXCHANGE PARTITION PO WITH TABLE e2
Query oK, o rows affected (0.28 sec)
这时再观察表c中分区的数据,可以发现p0中的数据已经没有了。
mysqL> SELECT PARTITION NAME, TABLE ROWS
- FROM INFORMATION SCHEMA PARTITIONS
WHFRE TABLE NAME aei
PARTITION NAME I TABLE ROWS
pO
I pl
0
I p2
4 rows in set (0. 00 sec)
而这时可以在表e2中观察到被移动的数据
mysql> SELECT FROM 82
十
l id fname lname
116|Franκ| White
I row in se: (0.00 sec)http:/blog.csdnnet/jiongyi11
5
182某4李表
4.9小结
读完这一章后,希望用户对 InnoDE存储引擎表有一个更深刻的理解。在这一章
中首先介绍了 InnoDB存储引擎表总是按照主键索引顺序进行存放的。然后深入介绍了
表的物理实现(如行结构和页结构),这一部分有助于用户更进一步了解表物理存储的
底层。接着介绍了和表有关的约束问题, MySQL数据库通过约束来保证表中数据的各
种完整性,其中也提到了有关 InnoDB存储引擎支持的外键特性。之后介绍了视图,在
MySQL数据库中视图总是虚拟的表,本身不支持物化视图。但是通过一些其他的技巧
(如触发器)同样也可以实现一些简单的物化视图的功能。
最后部分介绍了分区, MySQL数据库支持 RANGE、LIST、HASH、KEY、 COLUMNS
分区,并且可以使用HASH或KEY来进行子分区。需要注意的是,分区并不总是适合于
OLTP应用,用户应该根据自己的应用好好来规划自己的分区设计。http://blog.csdn.net/jiongyi1
5
部拼没
第5章索引与算法
索引是应用程序设计和开发的一个重要方面。若索引太多,应用程序的性能可能会
受到影响。而索引太少,对查询性能又会产生影响。要找到一个合适的平衡点,这对应
用程序的性能至关重要。
一些开发人员总是在事后才想起添加索引——我一直认为,这源于一种错误的开发
模式。如果知道数据的使用,从一开始就应该在需要处添加索引。开发人员往往对于数
据库的使用停留在应用的层面,比如编写SQL语句、存储过程之类,他们甚至可能不知
道索引的存在,或者认为事后让相关DBA加上即可。DBA往往不够了解业务的数据流,
而添加索引需要通过监控大量的SQL语句进而从中找到问题,这个步骤所需的时间肯定
是远大于初始添加索引所需要的时间,并且可能会遗漏一部分的索引。当然索引也并不
是越多越好,我曾经遇到这样一个问题:某台 MySQL服务器 lestat显示磁盘使用率一直
处于100%,经过分析后发现是由于开发人员添加了太多的索引,在删除一些不必要的
索引之后,磁盘使用率马上下降为20%。可见索引的添加也是非常有技术含量的。
这一章的主旨是对 InnoDB存储引擎支持的索引做一个概述,并对索引内部的机制
做一个深入的解析,通过了解索引内部构造来了解哪里可以使用索引。本章的风格和别
的有关 MySQL的书有所不同,更偏重于索引内部的实现和算法问题的讨论。
5.1 InnoDB存储引擎索引概述
InnoDB存储引擎支持以下几种常见的索引:
口B+树索引
口仝文索引
口哈希索引
前面已经提到过, InnoDB存储引擎支持的哈希索引是自适应的, InnoDB存储引擎会
根据表的使用情况自动为表生成哈希索引,不能人为干预是否在一张表中生成哈希索引。http:/blog.csdnnet/jiongyi11
184茅5东引与算法
研者墨
B+树索引就是传统意义上的索引,这是目前关系型数据库系统中查找最为常用和最
为有效的索引。B+树索引的构造类似于二又树,根据键值( Key value)快速找到数据
注意B-树中的B不是代表二叉( binary),而是代表平衡( balance),因为
B+树是从最早的平衡二叉树演化而来,但是B+树不是一个二又树。
另一个常常被DBA忽视的问题是:B+树索引并不能找到一个给定键值的具体行。
B+树索引能找到的只是被查找数据行所在的页。然后数据库通过把页读人到内存,再在
内存中进行查找,最后得到要查找的数据。
52数据结构与算法
B+树索引是最为常见,也是在数据库中使用最为频繁的一种索引。在介绍该索引之
前先介绍与之密切相关的一些算法与数据结构,这有助于读者更好的理解B+树索引的
工作方式。
521二分查找法
二分查找法( binary search)也称为折半查找法,用来合找一组序的记录数组中的某
一记录,其基本思想是:将记录按有序化(递增或递减)排列,在查找过程中采用跳跃式
方式査找,即先以有序数列的中点位置为比较对象,如果要找的元素值小于该中点元素
则将待查序列缩小为左半部分,否则为右半部分。通过一次比较,将查找区间缩小一半
如有5、10、19、21、31、37、42、48、50、52这10个数,现要从这10个数中查
找48这条记录,其查找过程如图5-1所示。
5l01921313742485055
5101921313742485055
5I019213l3742485055
图5-1二分查找法http://blog.csdn.net/jiongyi1
6I.
5,2数据结构与薯法185
从图5-1可以看出,用了3次就找到了48这个数。如果是顺序查找,则需要8次
因此二分查找法的效率比顺序查找法要好(平均地来说)。但如果说查5这条记录,顺序
查找只需1次,而二分查找法需要4次。我们来看,对于上面10个数来说,平均查找次
数为(1+2+3+4+5+6+7+8+9+10)/10=55次。而二分查找法为(4+3+2+4+3+1+4+3+2+3)
/10=29次。在最坏的情况下,顺疗查找的次数为10,而二分查找的次数为4。
二分查找法的应用极其广泛,而且它的思想易于理解。第一个二分查找法在1946
年就出现了,但是第一个完全正确的二分查找法直到1962年才出现。在前面的章节中
相信读者已经知道了,每页 Page Directory中的槽是按照主键的顺序存放的,对于某
条具体记录的查询是通过对 Page Directory进行二分查找得到的
522二叉查找树和平衡二叉树
在介绍B+树前,需要先了解一下二叉查找树。B+树是通过二叉查找树,再由平衡
二叉树,B树演化而来。相信在任何一本有关数据结构的书中
都可以找到二叉查找树的章节,二叉找树是一种经典的数据
结构。图5-2显示了一棵二又查找树。
图5-2中的数字代表每个节点的键值,在二义查找树中,
左子树的键值总是小于根的键值,右子树的键值总是大于根的
键值。因此可以通过中序遍历得到键值的排序输出,图5-2的图52二又查找树
二叉查找树经过中序遍历后输出:2、3、5、6、7、8。
对图5-2的这棵二叉树进行查找,如查键值为5的记录,先找到根,其键值是
6,6大于5,因此查找6的左子树,找到3;而5大于3,再找其右子树;一共找了
3次。如果按2、3、5、6、7、8的顺序来找同样需要3次。用同样的方法再查找键
值为8的这个记录,这次用了3次查找,而顺序查找需要6次。计算平均查找次数
可得:顺序查找的平均查找次数为(1+2+3+4+5+6)/6=3.3次,二叉查找树的平均
查找次数为(3+3+3+2+2+1)/6=23次。二又查找树的平均查找速度比顺序查找来
得更快。
二叉查找树可以任意地构造,同样是2、3、5、6、7、8这五个数字,也可以按照图5-3
的方式建立二叉查找树。http:/blog.csdnnet/jiongyi11
5L.
186芗5章索引与算法
图5-3的平均查找次数为(1+2+3+4+5+5)/6=3.16次,和顺序查找差多,显然这
棵二叉査找树的查询效率就低了。因此若想最大性能地构造
棵二叉查找树,需要这棵二叉查找树是平衡的,从而引出
3
了新的定义——平衡二叉树,或称为AVL树。
平衡二叉树的定义如下:首先符合二叉查找树的定义,
5
其次必须满足任何节点的两个子树的高度最大差为1。显然,
图5-3不满足平衡二叉树的定义,而图5-2是一棵平衡二叉
树。平衡二叉树的查找性能是比较高的,但不是最高的,只
6
是接近最高性能。最好的性能需要建立一棵最优二叉树,但53效率较低的一棵
是最优二叉树的建立和维护需要大量的操作,因此,用户
二叉査找树
般只需建立一棵平衡二叉树即可。
平衡二叉树的查询速度的确很快,但是维护一棵平衡二叉树的代价是非常大的。通
常来说,需要1次或多次左旋和右旋来得到插入或更新后树的平衡性。对于图52所示
的平衡树,当用户需要插入一个新的键值为9的节点时,需做如图5-4所示的变动。
这里通过一次左旋操作就将插入后的树重新变为平衡的了。但是有的情况可能需要
多次,如图5-5所示。
2
8
插入新值9
平衡二叉树
插入新健值3
4
5
3
5。7
9
左旋以保证平衡
9
右旋一次
再左旋一次
图5-4插人键值9,平衡二叉树的变化
图55需多次旋转的平衡二叉树http://blog.csdn.net/jiongyi1
5
53助树187
部拼没
图54和图5-5中列举了向一棵平衡二又树插入一个新的节点后,平衡叉树需萼
做的旋转操作。除了插入操作,还有更新和删除操作,不过这和插入没有本质的区别,
都是通过左旋或者右旋来完成的。因此对一棵平衡树的维护是有一定开销的,不过平衡
叉树多用于内存结构对象中,因此维护的开销相对较小。
53B+树
B+树和二叉树、平衡二又树一样,都是经典的数据结构。B+树由B树和索引顺序访问方
法(ISAM,是不是很熟悉?对,这也是MyAM引擎最初参考的数据结构)演化而来,但是
在现实使用过程屮几乎已经没有使用B树的情况了。
B+树的定义在任何一本数据结构书中都能找到,其定义十分复杂,在这里列出来
只会让读者感到更加困惑。这里,我来精简地对B树做个介绍:B+树是为磁盘或其他
直接存取辅助设备设计的一种平衡查找树。在B+树中,所有记录节点都是按键值的大
小顺序存放在同一层的叶子节点上,由各叶子节点指针进行连接。先来看一个B+树
其高度为2,每页可存放4条记录,扇出( fan out)为5,如图5-6所示。
从图5-6可以看出,所有记录都在叶子节点上,并且是顺序存放的,如果用户从最
左边的叶子节点开始顺序遍历,可以得到所有键值的顺序排序:5、10、15、20、25、
30、50、55、60、65、75、80、85、90。
5101520
2530
-os566++n1os5
图5-6一棵高度为2的B+树
53.1B+树的插入操作
B+树的插入必须保证插入后叶子节点中的记录依然排序,同时需要考虑插入到B+
树的三种情况,每种情况都可能会导致不同的插入算法。如表5-1所示。http:/blog.csdnnet/jiongyi11
5.6
88第5幸索引与算法
部拼吾
表5-1B+树插入的3种情况
Leaf Page满
ndex Page满
操作
No
N
直接将记录插入到叶子节点
1)拆分 Leaf Page
2)将中间的节点放入到 Index Page中
3)小于中间节点的记录放左边
4)大于或等于中间节点的记录放石边
1)拆分 Leaf Page
2)小于中间节点的记录放左边
3)大于或等于中间节点的记录放右边
Ye
4)拆分 Index Page
5)小于中间节点的记录放左边
6)大于中间节点的记录放右边
7)中间节点放入上一层 Index Page
这里用一个例子来分析B+树的插人。例如,对于图56中的这棵B+树,若用户插入
28这个键值,发现当前 Leaf Page和 Index Page都没有满,直接进行插人即可,之后得图57。
25
50
75
5101520+252830
50556065+75808590
图5-7插人键值28
接着再插入70这个键值,这时原先的 Leaf Page已经满了,但是 Index Page还没有
满,符合表5-1的第二种情况,这时插入 Leaf Page后的情况为55、55、60、65、70,
并根据中间的值60来拆分叶子节点,可得图5-8。
1015
20
5055
75808590
252830
606570
图5-8插入键值70http://blog.csdnnet/jiongyi1
5
5.3B树189
部拼吾
因为图片显示的关系,这次没有能在各叶子节点加上双向链表指针。不过和图5
图5-7一样,它还是存在的
最后插入键值95,这时符合表5-1中讨论的第三种情况,即 Leaf page和 Index Page
都满了,这时需要做两次拆分,如图59所示。
25
50
75
85
101520
2[∞|s
606570
252830
7580
859095
图5-9插入键值95
可以看到,不管怎么变化,B+树总是会保持平衡。但是为了保持平衡对于新插入的
键值可能需要做大量的拆分页( split)操作。因为B+树结构主要用于磁盘,页的拆分意
味着磁盘的操作,所以应该在可能的情况下尽量减少页的拆分操作。因此,B+树同样提
供了类似于平衡二叉树的旋转( Rotation)功能。
旋转发生在 Leaf Page已经满,但是其的左右兄弟节点没有满的情况下。这时B+树
并不会急于去做拆分页的操作,而是将记录移到所在页的兄弟节点上。在通常情况下,
左兄弟会被首先检查用来做旋转操作,因此再来看图5-7的情况,若插入键值70,其实
B+树并不会急于去拆分叶子节点,而是去做旋转操作,得到如图5-10所示的操作。
25
55
75
5
10
15|20
25283050
5606570
75808590
图5-10B+树的旋转操作http:/blog.csdnnet/jiongyi11
EL
190第5幸索引与算法
部拼吾没要
从图5-10可以看到,采用旋转操作使B+树减少了一次页的拆分操作←同时这棵
B+树的高度依然还是2。
532B+树的删除操作
B+树使用填充因子( fill factor)来控制树的删除变化,50%是填充因子可设的最
小值。B+树的删除操作同样必须保证删除后叶子节点中的记录依然排序,同插入一样,
B+树的删除操作同样霱要考虑以下表5-2中的三种情况,与插入不同的是,删除根据填
允因子的变化来衡量。
表5-2B+树删除操作的三种情况
叶子节点小于填充因子中间节点小于填充因子
操作
直接将记录从叶子节点删除,如果该节点还是 Index
Page的节点,用该节点的右节点代替
Ye
es
No
合并叶子节点和它的兄弟节点,同时更新 Index Page
1)合并叶子节点和它的兄弟节点
Y
Ye
2)更新 Index Page
3)合并 Index Page和它的兄弟节点
根据图5-9的B+树来进行删除操作。首先删除键值为70的这条记录,该记录符合
表5-2讨论的第一种情况,删除后可得到图5-11。
75
85
101520
5055
6065
25|2830
7580
859095
图5-11删除键值70
接着删除键值为25的记录,这也是表52讨论的第一种情况,但是该值还是 Indexhttp://blog.csdn.net/jiongyi1
6I
54B+树引191
器拼吾
Page中的值,因此在删除 Leaf Page中的25后,还应将25的右兄弟节点的28更新
Page Index中,最后可得图5-12
∞∏
2s∏[工
1015:20
50
55
6065
2830
7580
859095
图5-12删除键值25
最后看删除键值为60的情况。删除 Leaf Page中键值为60的记录后, Fill Factor小
于50%,这时需要做合并操作,同样,在删除 Index Page中相关记录后需要做 Index
Page的合并操作,最后得到图5-13。
75
80
5
1015|20
505565
85
95
2830
7580
图5-13删除键值60
54B+树索引
前面讨论的都是H+树的数据结构及其一般操作,B+树索引的本质就是B+树在数
据库中的实现。但是B+索引在数据库中有一个特点是高扇出性,因此在数据库中,B+http://blog.csdn.net/jiongyi1
BI
/92茅5幸余引与算法
部拼没
树的高度一般都在2~4层,这也就是说查找某一键值的行记录时最多只需要2到4次
IO,这倒不错。因为当前一般的机械磁盘每秒至少可以做100次1O,2~4次的IO意
味着查询时间只需0.02~0.04秒。
数据库中的B+树索引可以分为聚集索引( clustered inex)和辅助索引( secondary
index),但是不管是聚集还是辅助的索引,其内部都是B+树的,即高度平衡的,叶子
节点存放着所有的数据。聚集索引与辅助索引不同的是,叶子节点存放的是否是一整行
的信息。
541聚集索引
之前已经介绍过了, InnoDB存储引擎表是索引组织表,即表中数据按照主键顺序存
放。而聚集索引( clustered index〉就是按照每张表的主键构造一棵B+树,同时叶子节
点中存放的即为整张表的行记录数据,也将聚集索引的叶子节点称为数据页。聚集索引
的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样,每个
数据页都通过一个双向链表来进行链接。
由于实际的数据页只能按照一棵B+树进行排序,因此每张表只能拥有一个聚集索
引。在多数情况下,查询优化器倾向于采用聚集索引。因为聚集索引能够在B+树索引
的叶子节点上直接找到数据。此外,由于定义了数据的逻辑顺序,聚集索引能够特别快
地访问针对范围值的査询。查询优化器能够快速发现某一段范围的数据页需要扫描
接着来看一张表,这里以人为的方式让其每个页只能存放两个行记录,如:
CREATE TABLE t
a INT NOT nilt
b VARCHAR (8000)
C INT NOT NULLi
PRIMARY KEY (a
kEY idx c (c)
ENGTNF-TNNODB
INSERT INTo t seLECT 1, REPEAT(a,7000,-1
INSERT INTo t SElECT 2, REPEAT('a,7000),-2
INSERT INTo t SELECT 3, REPEAT('a',7000)r-3
INSFRT tNT t sElECt 4, rEPEAT('a7000)F-4F
分辅助索引有时也称非聚集索引(non- clustered index)。http:/blog.csdnnet/jiongyi11
5I.
54B+树紧引193
在上述例子中,插入的列b长度为7000因此可以以人为的方式使目前每全页尽能
存放两个行记录。接着用py_ innodb page int工具来分析表空间,可得:
rootenineyouc-43 data]# py innodb page info.py -v mytest/t ibd
page offset oC000000, page type <File Space Header>
page offset 0c000001, page type <Insert Buffer Bitmap>
page offset oC000002, page type <File Segment inode>
page offset oC000003, page type <B-tree Node>, page level <0001>
page offset oC000004, page type <B-tree Node>, page level <0000>
page offset 00000005, page type <B-tree Node>, page level <0000>
page offset oC000006, page type <B-tree Node>, page level <0000>
page offset 00000000, page type <Freshly Allocated Page>
Total number of page: 8
Freshly Allocated Page: 1
Insert Buffer Bitmap: 1
ile Space Header: 1
B-tree node: 4
Segment inode: 1
page level为0000的即是数据页,而前面的章节也对数据页进行了分析,所以这不
是当前所需要关注的部分。要分析的是 page level为0001的页,当前聚集索引的B+树
高度为2,故该页是B+树的根。通过 hexdump工具来观察索引的根页中所存放的数据
000Oc000 c233629500000c 03 ffffffffffff ff ff I.3b.
0000c01000C0000ab68cce5745bf000000000000|.....WE..,,,,,
0000c02000c0000000f9009200a2800500000000|.
0000c030009a0002000200030000000000000000|,
0000c04000C100000000000001e2000000f90000
0000e05000C200f2000000f90000000200320100|......,.2,
0000c06002c01b696e66695d756d0004000b0000|... infimum.
0000c07073757072656d755d00100011000e8000| supremum
0000e08000C10000000400000019000e80000002
0000c09000c0000500000021fd6800000040000|.
0000c0a000c60000000000000000000000000000
0000e0b000c00000000000000000000000000000
0000c:0c000c0000000000000000000c000000000
00o0fff0000000000070006373d8523ab68cce57|.-..p.csR:W
这里可以直接通过页尾的 Pagc Directory来分析此页。从0063可以知道该页中行
开始的位置,接着通过 Recorder header来分析,0xc063开始的值为696e66696d75
6d00,就代表 infimum为行记录,之前的5字节010002001b就是 Recorder header,http://blog.csdn.net/jiongyi1
6I
l94茅5幸索引与算法
部拼雳
分析第4位到第8位的值代表该行记录中只有一个记录(需要记住的是,和 nodE的
Page Directory是稀疏的),即 infimum记录本身。通过 Recorder header中最后的两个字
节001b来判断下一条记录的位置,即c063+1b=c07e,读取键值可得800001,这就
是主键为1的键值(表定义时INT是无符号的,因此二进制是0x80000001,而不是
0x0001),80000001后的值00000004代表指向数据页的页号。同样的方式可以找到
80000002和80000004这两个键值以及它们指向的数据页。
通过以上对非数据贞节点的分析,可以发现数据贞上存放的是完整的每行的记录,
而在非数据页的索引页中,存放的仅仅是键值及指向数据页的偏移量,而不是一个完整
的行记录。因此这棵聚集索引树的构造大致如图5-14所示。
Page Offse:0003(根节点
Kcy:80000001
K
80000002
Kcy:80000004
Painter: o0 04
Pointer: 00 05
Pointer: 00 06
Page Offset: 00 04
Page Offset: 00 05
Page Offset: 00 06
l, repeat('a’,7000)
2, repeat (a, 7000)
4, repeat(a’,7000
3, repeat (a.7000)
图5-14B+树索引
许多数据库的文档会这样告诉读者:聚集索引按照顺序物理地存储数据。如果看
图5-14,可能也会有这样的感觉。但是试想一下,如果聚集索引必须按照特定顺序存放
物理记录,则维护成本显得非常之高。所以,聚集索引的存储并不是物理上连续的,而
是逻辑上连续的。这其中有两点:一是前面说过的页通过双向链表链接,页按照主键的
顺序排序;另一点是每个页中的记录也是通过双向链表进行维护的,物理存储上可以同
样不按照主键存储。
聚集索引的另一个好处是,它对于主键的排序查找和范围查找速度非常快。叶子节
点的数据就是用户所要查询的数据。如用户需要查询一张注册用户的表,查询最后注册
的10位用户,由于B+树索引是双向链表的,用户可以快速找到最后一个数据页,并取http://blog.csdn.net/jiongyi1
5
54B树引195
拼要
出10条记录。若用命令 EXPLAIN进行分析,可得:
你
mysg1>EPLA工N
SELECT FROM Profile oRDER BY id LIMIT 10\G
大★责女★★女★责★★★安安读安★专★费ψ脚1,工。w声申责南由由由★咖南审南中由中由古南
ic: 1
select type: SIMPLE
table: Profile
type: index
possible keys: NULL
key: PRIMARY
key len: 4
ref: NULL
rCws: 10
Extrat
1 row in set〔0.00se≈)
可以看到虽然使用 ORDER BY对记录进行排序,但是在实际过程中并没有进行所
谓的 filesort操作,而这就是因为聚集索引的特点。
另一个是范围查询( range query),即如果要查找主键某一范围内的数据,通过叶子
节点的上层中间节点就可以得到页的范围,之后直接读取数据页即可,又如:
mysqL> EXPLAIN
一> SELECT W FROM Profile
WHERE id>10 AND id<10000\Gi
贵★★请青内青青古专★内南内青*青實密青*★1.r。w☆*☆訕*☆★★★★★★★女★★大★★★内★★★
id: 1
se1 ect type:S工MPLE
table: Profile
type:rdng日
possible keys: PRIMARY
key: PRIMARY
key len: 4
ref: NUlL
rows:14868
Extra: Using where
1 row in set (0.01 sec)
执行 EXPLAIN得到了 MySQL数据库的执行计划( execute plan),并且在rows列
中给出了一个查询结果的预佔返回行数。要注意的是,rows代表的是一个预估值,不是
确切的值,如果实际执行这句SQL的查询,可以看到实际上只有9946行记录:http://blog.csdn.net/jiongyi1
5
196茅5章索引与算法
部拼吾
mysql> SELECT COCNT(*] from Profile
WhEre id>10 ANd id<10000:
声★实突实安安★丈实女★★★★★★★★文★南★★★1。rcw
言★置青★★實声★★肯言古言言古言★
COUNT(1):9946
l row in set (0.00 sec)
542辅助索引
对于辅助索引( Secondary Index,也称非聚集索引),叶子节点并不包含行记录的
全部数据。叶子节点除了包含键值以外,每个叶子节点中的索引行中还包含了一个书签
( bookmark)。该书签用来告诉 InnodB存储引擎哪里可以找到与索引相对应的行数据。由
于 InnoDB存储引擎表是索引组织表,因此 InnoDB存储引擎的辅助索引的书签就是相应
行数据的聚集索引键。图5-15显示了 InnoDe存储引擎中辅助索引与聚集索引的关系。
Secondary Index
Secondary Index
Clustered Index
■■
图5-15辅助索引与聚集索引的关系
辅助索引的存在并不影响数据在聚集索引中的组织,因此每张表上可以有多个辅助索
引。当通过辅助索引来寻找数据时, InnoDe存储引擎会遍历辅助索引并通过叶级别的指针http:/blog.csdnnet/jiongyi11
54B+树索引197
获得指向主键索引的主键,然后再通过主键索引来找到一个完整的行记录。举例来说,如果
在一棵高度为3的辅助索引树中査找数据,那需要对这棵辅助索引树遍历3次找到指定主
键,如果聚集索引树的高度同样为3,那么还需要对聚集索引树进行3次查找,最终找到一
个完整的行数据所在的页,因此一共需要6次逻辑IO访问以得到最终的一个数据页。
对于其他的一些数据库,如 Microsoft SQL Server数据库,其有一种称为堆表的表类
型,即行数据的存储按照插入的顺序存放。这与 MySQL数据库的 MyISAM存储引擎有
些类似。堆表的特性决定了堆表上的索引都是非聚集的,主键与非主键的区别只是是否
唯一且非空( NOT NULL)。因此这时书签是一个行标识符( Row Identified,RID),可
以用如“文件号:页号:槽号”的格式来定位实际的行数据。
有的 Microsoft SQL Server数据库DBA问过我这样的问题,为什么在 Microsoft SQL
Server数据库上还要使用索引组织表?堆表的书签使非聚集查找可以比主键书签方式更
快,并且非聚集可能在一张表中存在多个,我们需要对多个非聚集索引进行查找。而且
对于非聚集索引的离散读取,索引组织表上的非聚集索引会比堆表上的聚集索引慢一些
当然,在一些情况下,使用堆表的确会比索引组织表更快,但是我觉得大部分原因
是由于存在OLAP(On- Line Analytical Processing,在线分析处理)的应用。其次就是前
面提到的,表中数据是否需要更新,并且更新是否影响到物理地址的变更。此外另一个
不能忽视的是对于排序和范围查找,索引组织表通过B+树的中间节点就可以找到要查
找的所有页,然后进行读取,而堆表的特性决定了这对其是不能实现的。最后,非聚集
索引的离散读,的确存在上述的情况,但是一般的数据库都通过实现预读( read ahead)
技术来避免多次的离散读操作。因此,具体是建堆表还是索引组织表,这取决于应用,
不存在哪个更优的问题。这和 InnoDB存储引擎好还是 MyISAM存储引擎好这个问题的
答案是一样的, t all depends
接着通过阅读表空间文件来分析 InnoDB存储引擎的非聚集索引的实际存储。还是分
析上一小节所用的表t。不同的是,在表t上再建立一个列c,并对列c创建非聚集索引:
mysqL> ALTER TABLE t
> ADD C INT N。 T NCLI
Query oK, rows affected (0.24 sec)
Records: 4 Duplicates: 0 Warnings: 0
mysql> UPDATE t SET C=0-a
Query ok, 4 rows affected (0.04 sec)http://blog.csdn.net/jiongyi1
51.
198茅5幸索引与算法
部拼吾
Rows matched: 4 changed: 4 Warnings: 0
你盛
mysql> ALTER TALBE t ADDKEY idx c (c)i
Query OK, 4 rows affected (0, 28 sec)
Records: 4 Duplicates: 0 Warnings: 0
mysql> SHOW INDEX FROM t\Gi
了。☆☆☆货★★食专★走★★★★责责青★★★★
Table:t
Non unique: 0
Key name: PRIMARY
seg in index: 1
Column name: a
Collation:A
Cardinality: 2
Sub part: NULL
Packed: NULL
Null
Index type: BTREE
Comment
★★★★宵方害★★★★青★背青内★青肃★★★责t2。◎W★★由知★★★安★★★★★★食向★★★★
Table:t
Non unique: 1
Key name: idx c
Seg in index: 1
Column name:c
Collation: A
Cardinality: 2
art NULL
Packed: NULl
Null
工 ndex type: BTREE
Comment:
2 rows in set (0.00 sec)
mysc> select a,c from ti
4
3
2|-2
11
1
4 rows in set (0. 00 sec)http:/blog.csdnnet/jiongyi11
54B树索引199
然后用 py innodb page info工具来分析表空间,可得:
章尽
[rootgnineyou0-43 mytest]# py innodb page info. py -v tibd
page offset 00000000, page type <file Space Header>
page offset 00000001, page type <Insert Buffer Bitmap>
page offset 00000002, page type <File segment inode>
page offset 00000003, page type <B-tree Node>, page level <0001>
page offset 00000004 page type <B-tree Node>, page level <0000>
page offset 00000005, page type <B-tree Ncde>, page level <0000>
page offset 00000006, page type <B-tree Node>, page level <0000>
page offset 00000007, page type <B-tree Node>, page level <0000>
page offsct 00000000, page type <Freshly Allocated page>
Total number of page: 9:
Freshly Allocated Page: 1
Insert Buffer Bitmap: 1
File Space Header: 1
B-tree node: 5
File segment inode: 1
对比前一次分析,我们可以看到这次多了一个页。分析 page offset为4的页,该页
即为非聚集索引所在页,通过工具 hexdump分析可得:
00010000 b9 aa 8e do 00 0000 04 ffffffffffffffff I
000100100000000 a ec ea4e2745bf000000000000|...M"E...。
00010020000000000102000200ae800600000000|
0001003000a4000100030004000000000052d48b|,,,,,
00010040000000000000000001f20000010200001。,,,,,,l
0001005000020272000001020000000201b20100|...x,,,,
00010060020041696e66696756d0005000b0000|,, Infimum,,,,
0001007073757072656d756d000010ff37 f ff ff I supremum..-,
00010080f80000001000018fff37 f =f ff fe8000
00010390000200002)EfE37 f ffff fo8000000300
4福“画
000100a00028fff37 E ff ff fc8000000400000000.(
00013￡f00000000000700063E346772ecea4e27|.,p,c.Fw……·N
由于只有4行数据,并且列c只有4字节,因此在一个非聚集索引页中即可完成
整理分析可得如图5-16所示的关系。
图5-16显示了表t中辅助索引idxc和聚集索引的关系。可以看到辅助索引的叶子
节点中包含了列c的值和主键的值。因为这里我特意将键值设为负值,所以会发现-1以
7 f ffff ff的方式进行内部存储。7(0111)最高位为0,代表负值,实际的值应该取反后
加1,即得-1。http:/blog.csdnnet/jiongyi11
5
200荜5章索引与算法
辅助索引idxc
Page Offset: O0 04
Key: fff ff ft
Key: 7f ff ff fe
Key: 7fff'fffd
Key: 7f ff ff fc
Pointer:80000001 Pointer: 80 0000 02 Pointer: 80 00 00 03 Pointer: 80 0000 04
聚集索引 Page Offset0003
Key80000001
Key:80000002
Key:0000004
Pointer: 00 05
Pointer: 00 06
Pointer: 00 07
Page Offset: 00 05
Pagc Offset: 00 06
Pagc Offsct: 00 07
1, repeat(a, 7000)
2, repeat(a,17000), -2
4, repeat(a, 7000)4
3 repeat(a,7000),-3
图5-16辅助索引分析
543B+树索引的分裂
在53节中介绍B+树的分裂是最为简单的一种情况,这和数据库中B+树索引的情况
可能略有不同。此外53节页没有涉及并发,而这才是B+树索引实现最为困难的部分。
B+树索引页的分裂并不总是从页的中间记录开始,这样可能会导致页空间的浪费。
例如下面的记录:
1、2、3、4、5、6、7、8、9
插入是根据自增顺序进行的,若这时插人10这条记录后需要进行页的分裂操作,
那么根据531节介绍的分裂方法,会将记录5作为分裂点记录( split record),分裂后
得到下面两个页;
P1:1、2、3、4
2:5、6、7、8、9、1
然而由于插入是顺序的,P1这个页中将不会再有记录被插入,从而导致空间的浪费
而P2又会再次进行分裂。
InnoDB存储引擎的 Page Header中有以下几个部分用来保存插入的顺序信息:http://blog.csdn.net/jiongyi1
6I
54B+树引201
PAGE LAST INSERT
督函令
凵 PAGE DIRECTION
口 PAGE N DIRECTION
通过这些信息, InnoDB存储引擎可以决定是向左还是向右进行分裂,同时决定将分
裂点记录为哪一个。若插入是随机的,则取页的中间记录作为分裂点的记录,这和之前
介绍的相同。若往同一方向进行插入的记录数量为5,并且目前已经定位( cursor)到的
记录( InnoDB存储引擎插入时,首先需要进行定位,定位到的记录为待插人记录的前一
条记录)之后还有3条记录,则分裂点的记录为定位到的记录后的第三条记录,否则分
裂点记录就是待插入的记录。
来看一个向右分裂的例子,并且定位到的记录之后还有3条记录,则分裂点记录如
图5-17所示。
cursor record
split record
-非]
record to be insert
图5-17向右分裂的一种情况
图5-17向右分裂且定位到的记录之后还有3条记录, split record为分裂点记录最终
向右分裂得到如图5-18所示的情况。
Page
Right Page
cursor record
Mit record
IHHH-T
record to be insert
图5-18向右分裂后页中记录的情况
对于图5-19的情况,分裂点就为插入记录本身,向右分裂后仅插入记录本身,这在
自增插入时是普遍存在的一种情况。http:/blog.csdnnet/jiongyi11
5.6
202躬5幸索引与算法
cursor record
split record
record to be insert
After Split
Right Page
cursor record
·-七H
lit record
record to be inser
图5-19向右分裂的另一种情况
544B+树索引的管理
1.索引管理
索引的创建和删除可以通过两种方法,一种是 ALTER TABLE,另一种是 CREATE/
DROP INDEX。通过 ALTER TABLE创建索引的语法为:
ALTER TABLE tbl name
ADD (INDEX! KEY] [index name)
[index type] (index col name,.][index option]
ALT三 R TABLE th1name
DROP PRIMARY KEY
DROP I INDEXI KEY index name
CREATE/DROP INDEX的语法同样很简单
CREATE [UNIQUE INDEX index name
[index type]
on thl name (index col name,..
DRoP工NDEX± ndex name on tb1name
用户可以设置对整个列的数据进行索引,也可以只索引一个列的开头部分数据,如http://blog.csdn.net/jiongyi1
6
54B+树余引203
前面创建的表t列b为 varchar(8000,但是用户可以只索引前100个字段舞如
mysqL>ALTER TABLE t
- ADD KEY icx b (b(100))
Query OK, 4 rows affected (0.32 sec)
Records: 4 Duplicates: 0 warnings: 0
若用户想要查看表中索引的信息,可以使用命令 SHOW INDEX。下面的例子使用
之前的表t,并加一个对于列(a,c)的联合索引 idx a c,可得:
mysql> ALTER TABLE t
ADD KEY idκac(arc)
Query OK, 4 rows affected (0.31 sec)
Records: 4 Duplicates: o warnings: 0
mysql>SHOW INDEX FROM t\G;
★★大内大内宵内育★★大★大青宽青宽裹1r。w訾安安青安皆貴貴★★女★★女女★★安女责
Table: t
Non unique: 0
key name: PRIMARY
Sec in index: 1
Column name: a
Collation: a
Cardinality: 2
Sub part: NULL
Packed: NULL
Nul.
Index type: BTREE
Comment
★★★★★★★★★★★★内宫★★食★★★★肯★肯
言實胄實實青背★食★★★實丈★會會貴貴★最
Tabl
t
Non unique: 1
key name: idx b
Seg in index: I
Column name b
Collation: A
cardinality: 2
Sub part: 100
Packed: NULl,
NuLl: YES
Index type: BTREE
Comment
★★★量青★★★女青★大★★★★★肯★★肯★青★*3.x。H實★★★★★实*★安★★★★★★血★★★★★★★★
Table: thttp:/blog.csdnnet/jiongyi11
5I
204第5章凉引与算法
Non unig
Key name: idx a c
Seg in index: 1
Column name
Collation: A
Cardinality: 2
Suh part: NULL
Packed: NULL
Null
Index type: BTREE
Comment
古古古古西古古此☆身★★出★★置★★★★
4,rw太真去身青当青六★★★t六大x宽★宽女蜜:去去
Tabl
七
Non unique: 1
key name: idx ac
seg in index: 2
Column name: c
Collation: A
Cardinality: 2
Sub part: NULl
Packed: NULl
Nu11:
Index type: BTREE
Comment:
女★★★★★★★★★*害*齿内青青六青青内★*5。oW★★*大★肯大★★青肃言★★*★★★★★女★★實嗽
Table: t
Non unique: 1
Key name:idκc
Seq in index: 1
Column name: c
collation: A
Cardinality: 2
Sub part: NULL
Packed: NULL
Nu11:
Index type: BTREE
Comment
5 rows in set (o.00 sec)
通过命令 SHOW INDEX FROM可以观察到表t上有4个索引,分别为主键索引、c
列上的辅助索引、b列的前100字节构成的辅助索引,以及(a、c)的联合辅助索引。
接着具体阐述命令 SHOW INDEX展现结果中每列的含义。
口 Table:索引所在的表名。http://blog.csdn.net/jiongyi1
5I
5.4B+树潆引205
口 Non unique:非唯一的索引,可以看到 primary key是0,因为必须是唯的
口 Key name:索引的名字,用户可以通过这个名字来执行 DROP INDEX。
口seq_ in index:索引中该列的位置,如果看联合索引idx_a_c就比较直观了。
口 Column name:索引列的名称
口 Collation:列以什么方式存储在索引中。可以是A或 NULLy B+树索引总是A,
即排序的。如果使用了Heap存储引擎,并且建立了Hash索引,这里就会显示
NULL了。因为Hash根据Hash桶存放索引数据,而不是对数据进行排序。
口 Cardinality:非常关键的值,表示索引中唯一值的数目的估计值。 Cardinality表的
行数应尽可能接近1,如果非常小,那么用户需要考虑是否可以删除此索引。
口Sub_part:是否是列的部分被索引。如果看dxb这个索引,这里显示100,表示
只对b列的前100字符进行索引。如果索引整个列,则该字段为NULL。
口 Packed:关键字如何被压缩。如果没有被压缩,则为NLL
口Nul是否索引的列含有NULL值。可以看到idxb这里为Yes,因为定义的列b
允许NULL值。
口 Index type:索引的类型。 InnoDB存储引擎只支持B+树索引,所以这里显示的
都是 BTREE。
口 Comment:注释。
Cardinality值非常关键,优化器会根据这个值来判断是否使用这个索引。但是这个
值并不是实时更新的,即并非每次索引的更新都会更新该值,因为这样代价太大了。因
此这个值是不太准确的,只是一个大概的值。上面显示的结果主键的 Cardinality为2,
但是很显然我们的表中有4条记录,这个值应该是4。如果需要更新索引 Cardinality的
信息,可以使用 ANALYZE TABLE命令,如:
mysql> analyze table t\G
★★★★★★实★★★★★★肯★青★★*★贵1rW★★★★★★史★女变文★女★女女安女★安卖★★
Table: mytest.t
op:ana⊥yze
Msg type: status
Msg text: OK
1孟。 w n set(0.01sec
mysql> show index from t\G:
言实实密南聚专★音★安★★★食★★★★女★1,row★★★★★*★★★★★★★★女★★★★★旾★☆★齒http://blog.csdn.net/jiongyi1
FI
206第5索引与算法
Table: t
Non unique: 0
Key name: PRIMARY
Seg in index: 1
column name a
Collation: A
Cardinality: 4
Sub part: NULL
Packed: Null
Null
Index type: BTREE
Comment
这时的 Cardinality值就对了。不过,在每个系统上可能得到的结果不一样,因为
ANALYZE TABLE现在还存在一些问题,可能会影响最后得到的结果。另一个问题是
MySQL数据库对于 Cardinality计数的问题,在运行一段时间后,可能会看到下面的结果:
mysql> show index from Profile\G
★★定★史★★★★★贸★史实灾★实来★★★1,r⊙★★*★★★★★★南央★南★★★★★★★共★★★★★
Table: Profile
Non unique: 0
Key name: UserName
Sec in index: 1
Column name: username
Collation: a
Cardinality: NULL
Sub part: NULL
Packed: NULL
Nu11:
Index type: BTREE
Comment
Cardinality为NULL,在某些情况下可能会发生索引建立了却没有用到的情况。或
者对两条基本一样的语句执行 EXPLAIN,但是最终出来的结果不一样:一个使用索引,
另外一个使用全表扫描。这时最好的解决办法就是做次 ANALYZE TABLE的操作。因
此我建议在一个非高峰时间,对应用程序下的几张核心表做 ANALYZE TABLE操作,这
能使优化器和索引更好地为你工作。
2. Fast Index Creation
MySQL55版本之前(不包括55)存在的一个普遍被人诟病的问题是 MySQL数据http:/blog.csdnnet/jiongyi11
54B+索引207争
研
库对于索引的添加或者删除的这类DDL操作, MySQL数据库的操作过程为麒器
口首先创建一张新的临时表,表结构为通过命令 ALTER TABLE新定义的结构。
口然后把原表中数据导入到临时表。
口接着删除原表。
口最后把临时表重名为原来的表名。
可以发现,若用户对于一张大表进行索引的添加和删除操作,那么这会需要很长的
时间。更关键的是,若有大量事务需要访间正在被修改的表,这意味着数据库服务不可
用。而这对于 Microsoft SQL Server或 Oracle数据库的DBA来说, MySQL数据库的索
引维护始终让他们感觉非常痛苦。
InnoDB存储引擎从 InnoDB1.0x版本开始支持一种称为 Fast Index creation(快速
索引创建)的索引创建方式——简称FIC
对于辅助索引的创建, InnoDB存储引擎会对创建索引的表加上一个S锁。在创建
的过程中,不需要重建表,因此速度较之前提高很多,并且数据库的可用性也得到了提
高。删除辅助索引操作就更简单了, InnoDB存储引擎只需更新内部视图,并将辅助索引
的空间标记为可用,同时删除 MySQL数据库内部视图上对该表的索引定义即可。
这里需要特别注意的是,临时表的创建路径是通过参数tmpd进行设置的。用户必
须保证tmpd有足够的空间可以存放临时表,否则会导致创建索引失败
由于FIC在索引的创建的过程中对表加上了S锁,因此在创建的过程中只能对该
表进行读操作,若有大量的事务需要对目标表进行写操作,那么数据库的服务同样不可
用。此外,FIC方式只限定于辅助索引,对于主键的创建和删除同样需要重建一张表
3. Online Schema Change
Online Schema Change(在线架构改变,简称OSC)最早是由 Facebook实现的一种
在线执行DDL的方式,并广泛地应用于 Facebook的 MySQL数据库。所谓“在线”是
指在事务的创建过程中,可以有读写事务对表进行操作,这提高了原有 MySQL数据库
在DDL操作时的并发性。
Facebook采用PHP脚本来现实OSC,而并不是通过修改 InnoDB存储引擎源码的方
式。OSC最初由 Facebook的员工 Vamsi ponnekanti开发。此外,OSC借鉴了开源社区
之前的工具 The openarkkit toolkit oak-online- alter-table。实现OSC步骤如下:
口init,即初始化阶段,会对创建的表做一些验证工作,如检查表是否有主键,是否http:/blog.csdnnet/jiongyi11
5L
208第5章索引与草法
研考
存在触发器或者外键等。
口 create CopyTable,创建和原始表结构一样的新表
口 alter Copy Table:对创建的新表进行 ALTER TABLE操作,如添加索引或列等。
口 create Deltas Table,创建 deltas表,该表的作用是为下一步创建的触发器所使用
之后对原表的所有DML操作会被记录到 createDeltas Table中
口 crcatcTriggers,对原表创建 INSERT、 UPDATE、 DELETE操作的触发器。触发
操作产生的记录被写入到dlta表。
口 startSnpshotXact,开始OSC操作的事务。
口 selectTablelnto Outfile,将原表中的数据写入到新表。为了减少对原表的锁定时
间,这里通过分片( chunked)将数据输出到多个外部文件,然后将外部文件的
数据导入到copy表中。分片的大小可以指定,默认值是50000
口 dropNCIndexs,在导人到新表前,删除新表中所有的辅助索引。
口 load Copy Table,将导出的分片文件导入到新表。
口 replay Changes,将OSC过程中原表DML操作的记录应用到新表中,这些记录被
保存在 deltas表中。
口 recreateNCIndexes,重新创建辅助索引。
口 replay Changes,再次进行DML日志的回放操作,这些日志是在上述创建辅助索
引中过程中新产生的日志。
口 swapTables,将原表和新表交换名字,整个操作需要锁定2张表,不允许新的数
据产生。由于改名是一个很快的操作,因此阻塞的时间非常短。
上述只是简单介绍了OSC的实现过程,实际脚本非常复杂,仅OSC的PHP核心代
码就有2200多行,用到的 MySQL InnoDB的知识点非常多,建议DBA和数据库开发人
员尝试进行阅读,这有助于更好地理解 InnoDB存储引擎的使用。
由于OSC只是一个PHP脚本,因此其有一定的局限性。例如其要求进行修改的表
定要有主键,且表本身不能存在外键和触发器。此外,在进行OSC过程中,允许SET
qI bin_log=0,因此所做的操作不会同步 slave服务器,可能导致主从不一致的情况。
4. Online DDL
虽然FIC可以让 InnoDB存储引擎避免创建临时表,从而提高索引创建的效率。但
正如前面小节所说的,索引创建时会阻塞表上的DML操作。OSC虽然解决了上述的部
分问题,但是还是有很大的局限性。 MySQL56版本开始支持 Online ddl(在线数据定http://blog.csdn.net/jiongyi1
5
54+辫素引209
义)操作,其允许辅助索引创建的同时,还允许其他诸如 INSERT、 UPDATE DELETE
这类DML操作,这极大地提高了 MySQL数据库在生产环境中的可用性。
此外,不仅是辅助索引,以下这几类DDL操作都可以通过“在线”的方式进行操作:
口辅助索引的创建与删除
口改变自增长值
口添加或删除外键约東
口列的重命名
通过新的 ALTER TABLE语法,用户可以选择索引的创建方式
AlTER TABLE tbl name
I ADD i INDEX I KEY [index name]
[index type] (index col name,.) [index option]
ALGORITHM (=][DEFAULT I INPLACE I COPYK
LOCK [=](DEFAULT I NONE I SIIARED I EXCLUSIVE]
ALGORITHM指定了创建或删除索引的算法,COPY表示按照 My SQL51版本之前
的工作模式,即创建临时表的方式。 INPLACE表示索引创建或删除操作不需要创建临时
表。 DEFAULT表示根据参数 old alter table来判断是通过 INPLACE还是COPY的算法,
该参数的默认值为OFF,表示采用Ⅰ NPLACE的方式,如:
mysql> seleCt @eversion\G
★黄坡★★★★大★★*★★大大★★内黄★*★*1.row*效★★史★★女★女★*★★★责★黄★★南★★★★
aversion: 5,6,6-Im9
1 row in set (0.00 seck
mysql> SHOW VARIABLES LIKE old alter table'\G:
青旗青内青责责言害★★★量★★货★贵★★t★★★★1,rw;★★★★★★★★责★★☆当卖★★★★★★★★★★
Variable name: old altcr table
Value: OFF
I rcw in set (0.00 sec)
LOCK部分为索引创建或删除时对表添加锁的情况,可有的选择为:
(1) NONE
执行索引创建或者删除操作时,对目标表不添加任何的锁,即事务仍然可以进行读
写操作,不会收到阻塞。因此这种模式可以获得最大的并发度。
(2) SHARE
这和之前的FIC类似,执行索引创建或删除操作时,对目标表加上一个S锁。对于http://blog.csdn.net/jiongyi1
5
210茅5李索引与算法
研
并发地读事务,依然可以执行,但是遇到写事务,就会发生等待操作。如果存储引擎矿
支持 SHARE模式,会返回一个错误信息。
(3) EXCLUSIVE
在 EXCLUSIVE模式下,执行索引创建或删除操作时,对目标表加上一个锁。读
写事务都不能进行,因此会阻塞所有的线程,这和COPY方式运行得到的状态类似,但
是不需要像COPY方式那样创建一张临时表。
4) DEFAULT
DEFAULT模式首先会判断当前操作是否可以使用NONE模式,若不能,则判
断是否可以使用 SHARE模式,最后判断是否可以使用 EXCLUSIVE模式。也就是说
DEFAULT会通过判断事务的最大并发性来判断执行DDL的模式。
InnoDB存储引擎实现 Online dDl的原理是在执行创建或者删除操作的同时,将
INSERT、 UPDATE、 DELETE这类DML操作日志写入到一个缓存中。待完成索引创
建后再将重做应用到表上,以此达到数据的一致性。这个缓存的大小由参数 innodb
online alter log_max_size控制,默认的大小为128MB。若用户更新的表比较大,并且
在创建过程中伴有大量的写事务,如遇到 innodb online alter log max size的空间不能
存放日志时,会抛出类似如下的错误:
Error: 1799SQLSTATE: HYODO(ER INNODB ONLINE LOG TOO BIG)
Message: Creating index idx aaa required more than 'innodb online alter log
max size bytes of modification log. Please try again
对于这个错误,用户可以调大参数 innodb online altcr log max size,以此获得更
大的日志缓存空间。此外,还可以设置 ALTER TABLE的模式为 SHARE,这样在执行
过程中不会有写事务发生,因此不需要进行DML日志的记录。
需要特别注意的是,由于 Online ddl在创建索引完成后再通过重做日志达到数据
库的最终一致性,这意味着在索引创建过程中,SQL优化器不会选择正在创建中的索引。
5.5 Cardinality值
551什么是 Cardinality
并不是在所有的查询条件中出现的列都需要添加索引。对于什么时候添加B+树索http:/blog.csdnnet/jiongyi11
5I.
55 Cardinal值21争
留研
引,一般的经验是,在访问表中很少一部分时使用B+树索引才有意义。对手性别字殿
地区字段、类型字段,它们可取值的范围很小,称为低选择性。如:
SELECT from student Where sex=M
按性别进行查询时,可取值的范围一般只有M、F。因此上述SQL语句得到的
结果可能是该表50%的数据(假设男女比例1:1),这时添加B+树索引是完全没有
必要的。相反,如果某个字段的取值范围很广,几乎没有重复,即属于高选择性,则
此时使用B+树索引是最适合的。例如,对于姓名字段,基本上在一个应用中不允许重
名的出现。
怎样查看索引是否是高选择性的呢?可以通过 SHOW INDEX结果中的列 Cardinality
来观察。 Cardinality值非常关键,表示索引中不重复记录数量的预估值。同时需要注意的
是, Cardinality是一个预估值,而不是一个准确值,基本上用户也不可能得到一个准确的
值。在实际应用中, Cardinality/n rows in table应尽可能地接近1。如果非常小,那么用
户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很
少一部分数据时,对这个字段添加B+树索引是非常有必要的。如:
SELECT FROM member Where usernick David.
表 member大约有500万行数据。 usenick字段上有一个唯一的索引。这时如果查找
用户名为Davd的用户,将会得到如下的执行计划:
mysql>EXPLAIN SELECT FROM member
>WHERE usernick= David\G:
建★★★夹★★★南★★肉★★★★为*★肯青t★青★★1.rOw肯★蠹★☆*★;★*★★★卖★★★★★大★★★★★★
id+ 1
select type: SIMPLE
table member
type: const
possible keys: usernick
kev: usernick
key len: 62
ref: const
Extra
1 row in set (0.00 secl
可以看到使用了 wernick这个索引,这也符合之前提到的高选择性,即SQL语句选
取表中较少行的原则http:/blog.csdnnet/jiongyi11
51.6
212笫5幸引匀算法
5.52 InnoDB存储引擎的 Cardinality统计
上一小节介绍了 Cardinality的重要性,并且告诉读者 Cardinality表示选择性。建立
索引的前提是列中的数据是高选择性的,这对数据库来说才具有实际意义。然而数据库
是怎样来统计 Cardinality信息的呢?因为 MySQL数据库中有各种不同的存储引擎,而
每种存储引擎对于B+树索引的实现又各不相同,所以对 Cardinality的统计是放在存储
引擎层进行的。
此外需要考虑到的是,在生产环境中,索引的更新操作可能是非常频繁的。如果每
次索引在发生操作时就对其进行 Cardinality的统计,那么将会给数据库带来很大的负
担。另外需要考虑的是,如果一张表的数据非常大,如一张表有50G的数据,那么统计
次 Cardinality信息所需要的时间可能非常长。这在生产环境下,也是不能接受的。因
此,数据库对于 Cardinality的统计都是通过采样( Sample)的方法来完成的。
在 InnoDB存储引擎中, Cardinality统计信息的更新发生在两个操作中: INSERT
和 UPDATE。根据前面的叙述,不可能在每次发生 INSERT和 UPDATE时就去更新
Cardinality信息,这样会增加数据库系统的负荷,同时对于大表的统计,时间上也不允
许数据库这样去操作。因此, InnoDB存储引擎内部对更新 Cardinality信息的策略为:
口表中116的数据已发生过变化
口 stat modified counter>2000000000。
第一种策略为自从上次统计 Cardinality信息后,表中1/16的数据已经发生过变化,
这时需要更新 Cardinality信息。第二种情况考虑的是,如果对表中某一行数据频繁地
进行更新操作,这时表中的数据实际并没有增加,实际发生变化的还是这一行数据,则
第一种更新策略就无法适用这这种情况。故在 InnoDB存储引擎内部有一个计数器stat
modified counter,用来表示发生变化的次数,当 stat modified counter大于2000000
000时,则同样需要更新 Cardinality信息。
接着考虑 InnoDB存储引擎内部是怎样来进行 Cardinality信息的统计和更新操作的
呢?同样是通过采样的方法。默认 InnoDB存储引擎对8个叶子节点( Leaf Page)进
行采用。釆样的过程如下:
口取得B+树索引中叶子节点的数量,记为A
口随机取得B+树索引中的8个叶子节点。统计每个页不同记录的个数,即为P1,http://blog.csdn.net/jiongyi1
BI
55 Cardinality213争
拼没
P2,…,P8。
口根据釆样信息给出 Cardinality的预估值: Cardinality-=(P1+P2+…+P8)*A8
通过上述的说明可以发现,在 InnoDB存储引擎中, Cardinality值是通过对8个叶
子节点预估而得的,不是一个实际精确的值。再者,每次对 Cardinality值的统计,都是
通过随机取8个叶子节点得到的,这同时又暗示了另一个 Cardinality现象,即每次得到
的 Cardinality值可能是不同的。如
SHOW INDEX FROM OrderDetails
上述这句SOL语句会触发 MySQL数据库对于 Cardinality值的统计,第一次运行得
到的结果如图5-20所示
Cam
ordered 0
FRILARY
BTREE
BTREE
orded- 1
Order
BTREE
OaD
BTREE
4
BTREE
P
ATAFF
图5-20第一次运行 SHOW INDEX FROM OrderDetails的结果
在上述测试过程中,并没有通过 INSERT、 UPDATE这类操作来改变表 OrderDetails
中的内容,但是当第二次再运行 SHOW INDEX FROM语句时, Cardinality值还是会发
生变化,如图5-21所示。
Calm rave
Paled
N dex N
Orders
9.….m、m
产Rr
BTREE
Creeper Deal t
BTREE
acTuAls
Pa或H|D
ProductD
BTREE
cHaeta 1
P-dhoder Detah 1
Freddi
16
BTREE
图5-21第二次运行 SHOW INDEX FROM OrderDetail的结果
可以看到,第二次运行 SHOW INDEX FROM语句时,表 OrderDetails中索引的
Cardinality值都发生了变化,虽然表 OrderDetails本身并没有发生任何的变化,但是,
由于 Cardinality是对随机取8个叶子节点进行分析,所以即使表没有发生变化,用户观
察到的索引 Cardinali值还是会发生变化,这本身并不是 InnoDB存储引擎的Bug,只
是随机采样而导致的结果。
当然,有一种情况可能使得用户每次观察到的索引 Cardinality值都是一样的,那就http://blog.csdn.net/jiongyi1
5
214第5章索引与算法
部拼没
是表足够小,表的叶子节点数小于或者等于8个。这时即使随机采样,也总是会采取到
这些页,因此每次得到的 Cardinality值是相同的。
在 InnodB12版本之前,可以通过参数 innodb stats sample pages用来设置统计
Cardinality时每次采样页的数量,默认值为8。同时,参数 innodb stats method用来判
断如何对待索引中出现的NUL值记录。该参数默认值为 nulls equal,表示将NULL值
记录视为相等的记录。其有效值还有 nulls unequal, nulls ignored,分别表示将NULL
值记录视为不同的记录和忽略NULL值记录。例如某页中索引记录为NULL、NULL、1、
2、2、3、3、3,在参数 innodb stats method的默认设置下,该页的 Cardinality为4;若
参数 innodb stats method为 nulls unequal,则该页的 Cardinality为5;若参数 innodb
stats mcthod为 nulls ignored,则 Cardinality为3。
当执行SQL语句 ANALYZE TABLE、 SHOW TABLE STATUS、 SHOW INDEX
以及访问 INFORMATION SCHEMA架构下的表 TABLES和 STATISTICS时会导致
InnoDB存储引擎去重新计算索引的 Cardinality值。若表中的数据量非常大,并且表中
存在多个辅助索引时,执行上述这些操作可能会非常慢。虽然用户可能并不希望去更新
Cardinality值
InnoDB2版本提供了更多的参数对 Cardinality统计进行设置,这些参数如表53所示。
表5-3 InnoDB12新增参数
參数
说明
是否将命令 ANALYZE TABLE计算得到的 Cardinality值存放到磁盘
上。若是,则这样做的好处是可以减少重新计算每个索引的 Cardinality
值,例如当 MySQL数据库重启时,此外,用户也可以通过命令 CREATE
innodb stats persistent
TABLE和 ALTER TABLE的选项 STATS PERSISTENT来对每张表进行
控制。
默认值:OFF
当通过命令 SHOW TABLE STATUS、 SHOW INDEX及访问
INFORMATION SCHEMA架构下的表 TABLES和 STATISTICS时,是
innodb stats on metadata
否需要重新计算索引的 Cardinality值。
默认值:OFF
若参数 innodb stats persistent设置为ON,该参数表示 ANALYZE
innodb_stats_persistent_sample_pages TABLE更新 Cardinality值时每次采样页的数量。
默认值:20
该参数用来取代之前版本的参数 innodb stats sample pages,表示每次
innodb stats transient sample pages釆样页的数量。
默认值为:8http:/blog.csdnnet/jiongyi11
51.6
56B+树索引的用215
研
56B+树索引的使用
561不同应用中B+树索引的使用
在了解了B+树索引的本质和实现后,下一个需要考虑的问题是怎样正确地使用B+
树索引,这不是一个简单的问题。这里所总结的可能并不适用于所有的应用场合。我所
能做的只是概括一个大概的方向。在实际的生产环境使用中,每个DBA和开发人员,
还是需要根据自己的具体生产环境来使用索引,并观察索引使用的情况,判断是否需要
添加索引。不要盲从任何人给你的经验意见, Think different
根据第1章的介绍,用户已经知道数据库中存在两种类型的应用,OLTP和OLAP
应用。在OLTP应用中,查询操作只从数据库中取得一小部分数据,一般可能都在10条
记录以下,甚至在很多时候只取1条记录,如根据主键值来取得用户信息,根据订单号
取得订单的详细信息,这都是典型OLTP应用的查询语句。在这种情况下,B+树索引建
立后,对该索引的使用应该只是通过该索引取得表中少部分的数据。这时建立B+树索
引才是有意义的,否则即使建立了,优化器也可能选择不使用索引。
对于OLAP应用,情况可能就稍显复杂了。不过概括来说,在OLAP应用中,都需
要访问表中大量的数据,根据这些数据来产生查询的结果,这些查询多是面向分析的查
询,目的是为决策者提供支持。如这个月每个用户的消费情况,销售额同比、环比增长
的情况。因此在OLAP中索引的添加根据的应该是宏观的信息,而不是微观,因为最终
要得到的结果是提供给决策者的。例如不需要在OLAP中对姓名字段进行索引,因为很
少需要对单个用户进行查询。但是对于OLAP中的复杂查询,要涉及多张表之间的联接
操作,因此索引的添加依然是有意义的。但是,如果联接操作使用的是 Hash join,那么
索引可能又变得不是非常重要了,所以这需要DBA或开发人员认真并仔细地研究自己
的应用。不过在OLAP应用中,通常会需要对时间字段进行索引,这是因为大多数统计
需要根据时间维度来进行数据的筛选
562联合索引
联合索引是指对表上的多个列进行索引。前面讨论的情况都是只对表上的一个列进行
索引。联合索引的创建方法与单个索引创建的方法一样,不同之处仅在于有多个索引列http://blog.csdn.net/jiongyi1
5
216某5章索引与算法
例如,以下代码创建了一张t表,并且索引 idx a b是联合索引,联合的列为(验
CREATE TABLE t
a工NT
b INT,
PRIMARY KEY (a)r
KEY idx a b( arb)
ENGINE=工 SINODE
那么何时需要使用联合索引呢?在讨论这个问题之前,先来看一下联合索引内部的
结果。从本质上来说,联合索引也是一棵
(2,4)
B+树,不同的是联合索引的键值的数量不
是1,而是大于等于2。接着来讨论两个整
型列组成的联合索引,假定两个键值的名
(1,1)(1,2)(2,1)
(2,4)(3,1)(3,2)
称分别为a、b,如图522所示
图5-22多个键值的B+树
从图5-22可以观察到多个键值的B+树情况。其实和之前讨论的单个键值的B+树
并没有什么不同,键值都是排序的,通过叶子节点可以逻辑上顺序地读出所有数据,就
上面的例子来说,即(1,1)、(1,2)、(2,1)、(2,4)、(3,1)、(3,2)。数据按〔a,
b)的顺序进行了存放。
因此,对于查询 SELECT* FROM TABLE WHERE a xxx and b=xxx,显然是可以
使用(a,b)这个联合索引的。对于单个的a列查询 SELECT* FROM TABLE WHERE
a=xx,也可以使用这个(a,b)索引。但对于b列的查询 SELECT幸 FROM TABLE
WhERE b=xx,则不可以使用这棵B+树索引。可以发现叶子节点上的b值为1、2、1、
4、1、2,显然不是排序的,因此对于b列的查询使用不到(a,b)的索引。
联合索引的第二个好处是已经对第二个键值进行了排序处理。例如,在很多情况下
应用程序都需要查询某个用户的购物情况,并按照时间进行排序,最后取出最近三次的
购买记录,这时使用联合索引可以避免多一次的排序操作,因为索引本身在叶子节点已
经排序了。来看一个例子,首先根据如下代码来创建测试表buy_log:
CREATE TABLE buy log
userid INT UNSIGNED NOT NULL
buy date DATE
)ENGINE-=InnoDB
INSERT INTo buy log VALUES 1,'2009-01-01)
INSERT INTO buy log VALUES (2, 2009-01-01)http:/blog.csdnnet/jiongyi11
5I.A
56B+树索引的使用217
INSeRt INTo buy log VAlUes 3,2009-01-01'Ii
INSERT INTO buy log VALUES 1,2009-02-01I5
INSERT INTO buy log VALUES (3,'2009-02-01 )i
INSERT INTo buy log VALUES 1,2009-03-01]
INSERT INTo buy log VALUES (1,2009-04-01I
ALTER TABLE buy log ADD KEY userid )i
ALTER TABLE buy log ADd KEY userid, buy date )i
以上代码建立了两个索引来进行比较。两个索引都包含了 userid字段。如果只对于
userid进行查询,如:
sEleCt FROM buy log WhEre userid=2:
则优化器的选择为如图5-23所示。
seed ype
、kk旧n
SIMPLE
图5-23查询条件仅为 userid的执行计划
从图5-23中可以发现, possible kcys在这里有两个索引可供使用,分别是单个的
userid索引和( userid, buy date)的联合索引。但是优化器最终的选择是索引 userid,
因为该索引的叶子节点包含单个键值,所以理论上一个页能存放的记录应该更多。
接着假定要取出 userid为1的最近3次的购买记录,其SQL语句如下,执行计划
如图5-24所示。
SELECT* FROM buy1。g
WHERE userid=l ORDER BY buy date DESC LIMIT 3
aa2a-------
d
HFLE
cond 3 Uing where Ung indec
图5-24SQL语句的执行计划
同样的,对于上述的S①L语句既可以使用 userid索引,也可以使用( userid,buy
date)索引。但是这次优化器使用了( userid, buy date)的联合索引 userid2,因为在
这个联合索引中 buy date已经排序好了。根据该联合索引取出数据,无须再对 buy date
做一次额外的排序操作。若强制使用 userid索引,则执行计划如图5-25所示。
e ks key_t
飞L2
pe pose ke
1hh加aau1hh5a
m加电我飞飞么儿4
图5-25强制使用 userid索引的执行计划http://blog.csdn.net/jiongyi1
5
218邦5孝索引与算法
部拼吾
在Bxma选项中可以看到 Using f角eon,即需要额外的一次排序操作才谁完成查海
而这次显然需要对列 buy date排序,因为索引 userid中的 buy date是未排序的。
正如前面所介绍的那样,联合素引(a,b)其实是根据列a、b进行排序,因此下列
语句可以直接使用联合索引得到结果
SELECT.. FROM TABLE WHERE a=xxX ORDER BY b
然而对于联合索引(a,b,c)来说,下列语句同样可以直接通过联合索引得到结果:
select. FROM TABLE WHERE a=xxx oRdER By b
sEleCt.. FRoM TABLE WHERE axxX AND b=XXX ORDER BY c
但是对于下面的语句,联合索引不能直接得到结果,其还需要执行一次 filesort排序
操作,因为索引(a,c)并未排序:
sElECT.. FROM TABLE WHERE a=xXx ORDER BY C
563盖索引
InnoDB存储引擎支持覆盖索引( covering index,或称索引覆盖),即从辅助索引中
就可以得到査询的记录,而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是
辅助索引不包含整行记录的所有信息,故其大小要远小于聚集索引,因此可以减少大量
的IO操作
注意覆盖索引技术最早是在 InnoDB Plugin中完成并实现。这意味着对于
InnoDB版本小于1.0的,或者 MySQL数据库版本为50或以下的, InnoDB存
储引擎不攴持覆盖索引特性。
对于 InnoDB存储引擎的辅助索引而言,由于其包含了主键信息,因此其叶子节点
存放的数据为( primary keyl, primary key2,…,keyl,key2,…)。例如,下列语句都
可仅使用一次辅助联合索引来完成查询:
SelECT key2 FROM table WhERE keyl=xXX:
SELECT primary key2, key2 FROM table WhERe keyl=xxx:
SELECT primary keyl, key2 FRoM table Where keyl=xxX:
SELECT primary keylr primary key2 key2 FROM table WhERe key1=XXX:
覆盖索引的另一个好处是对某些统计问题而言的。还是对于上一小节创建的表buyhttp:/blog.csdnnet/jiongyi11
5I.
56B+树索引的使用219争
log,要进行如下的查询
SELECT COUNT(*)FRoM buy log i
InnoDB存储引擎并不会选择通过查询聚集索引来进行统计。由于 buy log表上还有
辅助索引,而辅助索引远小于聚集索引,选择辅助索引可以减少⑩O操作,故优化器的
选择为如图526所示
sclect_ type
possble keys
key_jon
Etre
SIMPLE
buy- Jog ndex
Lgend
Uaing index
图5-26 COUNT(*)操作的执行计划
通过图5-26可以看到, possible keys列为NULL,但是实际执行时优化器却选择了
userid索引,而列 Extra列的 Using index就是代表了优化器进行了覆盖索引操作。
此外,在通常情况下,诸如(a,b)的联合索引,一般是不可以选择列b中所谓的查
询条件。但是如果是统计操作,并且是覆盖索引的,则优化器会进行选择,如下述语句
SELECT COUNT(*) FROM buy log
WHErE buy date>=2011-01-01: ANd buy date< 2011-02-011
表 buy log有( userid, buy date)的联合索引,这里只根据列b进行条件查询,
般情况下是不能进行该联合索引的,但是这句SQL查询是统计操作,并且可以利用到覆
盖索引的信总,因此优化器会选择该联合索引,其执行计划如图527所示。
ndens
Leing where: using index
图5-27利用覆盖索引执行统计操作
从图5-27中可以发现列 possible keys依然为NULL,但是列key为 userid2,即表
示( userid, buy date)的联合索引。在列 Extra同样可以发现 Using index提示,表示为
覆盖索引。
564优化器选择不使用索引的情况
在某些情况下,当执行 EXPLA命令进行SQL话句的分析时,会发现优化器并没
有选择索引去查找数据,而是通过扫描聚集索引,也就是直接进行全表的扫描来得到数
据。这种情况多发生于范围查找、JOIN链接操作等情况下。例如:http://blog.csdn.net/jiongyi1
6I
2205享索引与算法
部拼吾
seleCt FRoM orderdetail
WHErE orderidxl0000 and orderid<102000:
你
上述这句SQL语句查找订单号大于10000的订单详情,通过命令 SHOW INDEX
FROM orderdetails,可观察到的索引如图5-28所示。
T如Nm、Km、、 aq in ndx Columm_name
Collation
t加生他智
Sb part Facked
hdet tpe
Commat
b odetta C
PRAR丫
z311
euta制0
ProducD
orderdetada 1
iorderdeta 1
desorder Detsl I
ardec
AAAAA
BTREE
1
BTHEE
BTAEE
ordedataik 1
ProductOrde Das T
PioevallD
BTREE
图5-28表 orderdetails的索引详情
可以看到表 orderdetails有( OrderID, ProductID)的联合主键,此外还有对于列
OrderID的单个索引。上述这句SQL显然是可以通过扫描 OrderID上的索引进行数据的
查找。然而通过 EXPLAIN命令,用户会发现优化器并没有按照 Orderly上的索引来查
找数据,如图5-29所示。
呦
poss 0e kes
y n
SIMPLE
orderdetals range PRIMARY, Onder D Orden Oder Detal PRIMARY 4
t55
ara when
图5-29上述范围查询的SQL执行计划
在 possible keys一列可以看到查询可以使用 PRIMARY、 OrderID、 OrdersOrder
Details三个索引,但是在最后的索引使用中,优化器选择了 PRIMARY聚集索引,也就
是表扫描( table scan),而非 OrderID辅助索引扫描( index scan)。
这是为什么呢?原因在用户要选取的数据是整行信息,而 OrderID索引不能覆盖
到我们要查询的信息,因此在对 Orderl索引查询到指定数据后,还需要一次书签访问
来査找整行数据的信息。虽然 OrderID索引中数据是顺序存放的,但是再一次进行书签
查找的数据则是无序的,因此变为了磁盘上的离散读操作。如果要求访问的数据量很
小,则优化器还是会选择辅助索引,但是当访问的数据占整个表中数据的蛮大一部分时
(一般是20%左右),优化器会选择通过聚集索引来查找数据。因为之前已经提到过,顺
序读要远远快于离散读。
因此对于不能进行索引覆盖的情况,优化器选择辅助索引的情况是,通过辅助索引
查找的数据是少量的。这是由当前传统机械硬盘的特性所决定的,即利用顺序读来替换
随机读的查找。若用户使用的磁盘是固态硬盘,随机读操作非常快,同时有足够的自信http:/blog.csdnnet/jiongyi11
5I.
56B+树索引的用221
来确认使用辅助索引可以带来更好的性能,那么可以使用关键字 FORCEⅠNDEX来强制
使用某个索引,如:
SELECT EROM orderdetails force index (orderId)
Where orderid>10000 and ordcrid<102000 i
这时的执行计划如图5-30所示。
d
ect_type
ys
Ed
SIMPLE
OrdereD
OerD
抛943
USing where
图5-30强制使用辅助索引
565索引提示
MySQL数据库支持索引提示( INDEX HINT),显式地告诉优化器使用哪个索引。
个人总结以下两种情况可能需要用到 INDEX HINT:
口 MySQL数据库的优化器错误地选择了某个索引,导致SQL语句运行的很慢。这
种情况在最新的 MySQL数据库版本中非常非常的少见。优化器在绝大部分情况
下工作得都非常有效和正确。这时有经验的DBA或开发人员可以强制优化器使
用某个索引,以此来提高SQL运行的速度。
口某SQL语句可以选择的索引非常多,这时优化器选择执行计划时间的开销可能
会大于SQL话句本身。例如,优化器分析 Range查询本身就是比较耗时的操作。
这时DBA或开发人员分析最优的索引选择,通过 Index hint来强制使优化器不
进行各个执行路径的成本分析,直接选择指定的索引来完成查询。
在 My SQL数据库中 Index hint的语法如下
t1name〔[AS]a1ias][ index hint1⊥st]
index hint list
index hint index hint
index hint
USE (INDEX IKEY
[ I FOR JOIN I ORDER BY I GROUP BY1 ([index list])
工 GNORE【 INDEX|KEY}
[!FOR I JOIN I ORDER BY I GROUP BY)] (index list)
FORCE(工NDEX|KEY}
[ FOR ( I ORDER BY I GROUP BY1](index list)
index list:
index name [r index name]http:/blog.csdnnet/jiongyi11
5
222第5幸索引与算法
接着来看一个例子,首先根据如下代码创建测试表t,并填充相应数据。
CREATE TABLE t
a INT
D INTE
KEY (a)
KEY (b)
》 ENGINE= INNODB;
INSERT INTo t SelECt 1,1
INSERT INTo t sElECT 1,27
INSERT INTO t SELECT 2,3
insERT INto t selECt 2,4;
INSERT INTo t sElECT 1,2
然后执行如下的SQL语句:
sELECt FRom t WHeRe a=1 And b=2
通过 EXPLAIN命令得到如图5-31所示的执行计划。
d
select tpe
sbe k
Erra
SIMPLE
ndex eoe ah
sing rtersectb a. tang whare: Using ndex
图5-31SQL语句的执行计划
图5-31中的列 possible keys显示了上述SQL语句可使用的索引为a,b,而实际使
用的索引为列key所示,同样为a,b。也就是 My SQL数据库使用a,b两个索引来完成
这一个查询。列 Extra提示的 Using intersect(b,a)表示根据两个索引得到的结果进行
求交的数学运算,最后得到结果。
如果我们使用 USE INDEX的索引提示来使用a这个索引,如:
SELECT fRoM t use INDEX(a) WhEre al AND b =2
那么得到的结果如图5-32所示。
select_type
tahe
pe
possible_ keys
key_ len
SINPLE
ALL
MEKL nULL
Using where
图5-32使用 USE INDEX后的执行计划
可以看到,虽然我们指定使用a索引,但是优化器实际选择的是通过表扫描的方式。
因此, USE INDEX只是告诉优化器可以选择该索引,实际上优化器还是会再根据自己的
判断进行选择。而如果使用 FORCE INDEX的索引提示,如:http:/blog.csdnnet/jiongyi11
56B+树索引的使用223
拼号
SELeCt FRoM t FORce INDEX (a] WHERe a=l AND b = 2:
召擦器
则这时的执行计划如图5-33所示。
elect type
type
possble keys key key len
LOws
SIMPLE
g
图5-33使用 FORCE INDEX后的执行计划
叮以看到,这时优化器的最终选择和用户指定的索引是一致的。因此,如果用户
确定指定某个索引来完成查询,那么最可靠的是使用 FORCE INDEX,而不是USE
INDEX。
566 Multi-Range Read优化
MySQL5.6版本开始支持 Multi- Range Read(MRR)优化。 Multi-Range Read优化的
目的就是为了减少磁盘的随机访问,并且将随机访问转化为较为顺序的数据访问,这对
于IO- bound类型的SQL查询语句可带来性能极大的提升。 Multi-Range read优化可适
用于 range,ref, eq ref类型的查洵。
MRR优化有以下几个好处
口MRR使数据访问变得较为顺序。在查询辅助索引时,首先根据得到的查询结果,
按照主键进行排序,并按照主键排序的顺序进行书签查找。
口减少缓冲池中页被替换的次数。
口批量处理对键值的查询操作。
对于 InnoDB和 MyISAM存储引擎的范围查询和JoN查询操作,MRR的工作方式
如下:
口将查询得到的辅助索引键值存放于一个缓存中,这时缓存中的数据是根据辅助索
引键值排序的。
口将缓存中的键值根据 ROWID进行排序。
口根据 ROWID的排序顺序来访问实际的数据文件。
此外,若 Inno DB存储引擎或者 MyISAM存储引擎的缓冲池不是足够大,即不能
存放下一张表中的所有数据,此时频繁的离散读操作还会导致缓存中的页被替换出缓冲
池,然后又不断地被读入缓冲池。若是按照主键顺序进行访问,则可以将此重复行为降http:/blog.csdnnet/jiongyi11
5I
224第5幸索引与算法
为最低。如下面这句SQL语句:
SELECT fRCM salaries Where salary>10000 ANd salary<4000c;
salary上有一个辅助索引idκ_s,因此除了通过辅助索引查找键值外,还需要通过书
签查找来进行对整行数据的查询。当不启用 Multi-Range Read特性时,看到的执行计划
如图5-34所示。
select type
SIMPLE
table. type possble_keo wo如
Edra
valais range ix s
23378 Using index condo
图5-34不启用 Multi-Range Read的执行计划
若启用 Mulit- Range Read特性,则除了会在列Exta看到 Using index condition外,
还会看见 Using Mrr选项,如图5-35所示。
ln:nf
SIMPLE
四2378" Uang index cond tion1inMR
图5-35启用Mut- Range Read的执行计划
而在实际的执行中会体会到两个的执行时间差别非常巨大,如表5-4所示。
表54是否启用 Multi-Range Read的执行时间对比
执行时间(秒)
不使用 Multi-Range Read
43213
使用 Multi- Range Read
4.212
在我的笔记本电脑上,上述两句语句的执行时间相差10倍之多。可见 Multi-Range
Rcad将访问数据转化为顺序后查询性能得到提高。
注意上述测试都是在 My SQL数据库启动后直接执行SoL查询语句,此时需
确保缓冲池中没有被预热,以及需要查询的数据并不包仑在缓冲池中。
此外, Multi- Range Read还可以将某些范围查询,拆分为键值对,以此来进行批量
的数据查询。这样做的好处是可以在拆分过程中,直接过滤一些不符合查询条件的数
据,例如:
SELECT
FROM t
WheRE key partl >=1000 AND key partl <2000
And key part2=10000;http:/blog.csdnnet/jiongyi11
56B+树索引的使用225
表t有( key partI, key part2)的联合索引,因此索引根据 key parti, key_ part2的
位置关系进行排序。若没有 Multi-Read Range,此时查询类型为 Range,sQL优化器会先
将 key partI大于1000且小于2000的数据都取出,即使 key_part2不等于1000待取出
行数据后再根据 key_ part.2的条件进行过滤。这会导致无用数据被取出。如果有大量的数
据且其 key part不等于1000,则启用 Mulit-Range Read优化会使性能有巨大的提升。
倘若启用了 Multi-Range Read优化,优化器会先将查询条件进行拆分,然后再进行
数据查询。就上述查询语句而言,优化器会将查询条件拆分为(1000,1000),(1001,
1000),(1002,1000),…,(1999,1000),最后再根据这些拆分出的条件进行数据的查询。
可以来看一个实际的例子,查询如下:
SELECT★ FROM salaries
WHErE (from date between '1986-01-01 AND 1995-02-01'
ANd Salary between 38000 and 40000)a
若启用了Mult- Range Read优化,则执行计划如图5-36所示。
“3…t0,八Akk、y如 re.Mows Ban. w i inmo mrr
MPLE
EE
图5-36启用 Multi-Range Read的执行计划
表 salaries上有对于 salary的索引idxs,在执行上述SQL语句时,因为启用了
Multi-Range Read优化,所以会对查询条件进行拆分,这样在列 Extra中可以看到 Using
MRR选项
是否启用 Multi-Range Read优化可以通过参数 optimizer_ switch中的标记(fag)来
控制。当mr为on时,表示启用 Multi- Range read优化。 mrr cost based标记表示是否
通过 cost based的方式来选择是否启用mr若将mm设为on, mrr cost based设为of
则总是启用 Multi-Range Read优化。例如,下述语句可以将Muti- Range read优化总是
设为开启状态:
mYS I> SET @optimizer switch='mrr=on, mrr cost based=offr
Query Ok, 0 rows affected (0.00 sec)
参数 read nd buffer size用来控制键值的缓冲区大小,当大于该值时,则执行器
对已经缓存的数据根据 RowID进行排序,并通过 ROWD来取得行数据。该值默认为
256Khttp:/blog.csdnnet/jiongyi11
5I
226第5章索引与算法
考翻
mysql> SELECT e@read_nd buffer size\G:
督你器
★★★★★★肃★卤古肃★青大言★★★★1.xOw青青古大★责★★★★★★★音★吉
GGread rnd buffer size: 262144
1 rcw in set (0.00 sec)
5.6.7 Index condition Pushdown(CP)优化
和 Multi-Range Read一样, Index Condition pushdown同样是 MySQL5.6开始支持的
一种根据索引进行查询的优化方式。之前的 MySQL数据库版本不支持 Index condition
Pushdown,当进行索引查询时,首先根据索引来查找记录,然后再根据 WHERE条件来
过滤记录。在支持 Index condition pushdown后, MySQL数据库会在取出索引的同时,
判断是否可以进行 WHERE条件的过滤,也就是将 WHERE的部分过滤操作放在了存储
引擎层。在某些查询下,可以大大减少上层SQL层对记录的索取( fetch),从而提高数
据库的整体性能
Index condition pushdown优化支持 range、ref、 eq ref、 ref or null类型的查询,当
前支持 MyISAM和 InnoDB存储引擎。当优化器选择 ndex Condition pushdown优化时,
可在执行计划的列 Extra看到 Using index condition提示。
注意 NDB Cluster存储引擎支持 Engine condition pushdown优化。不仅可以进
行“ Index”的 Condition pushdown,也可以支持非索引的 Condition pushdown,
不过这是由其引擎本身的特性所决定的。另外在 MySQL51版本中 NDB Cluster
存储引擎就开始支持 Engine Condition Pushdow优化
假设某张表有联合索引( zip code, last name, first name),并且查询语句如下
SELECT FROM People
WHERE Zipcode=95054
AND⊥ astname lire'告 etruria为
and address lIre"是 Main street暑"
对于上述语句, MySQL数据库可以通过索引来定位 zipcode等于95054的记录,但
是索引对 WHERE条件的 lastname liKe!% etruria%! And address liKe'%Main
Street%没有任何帮助。若不支持 Index Condition Pushdown优化,则数据库需要先通
过索引取出所有 zipcode等于95054的记录,然后再过滤 WHERE之后的两个条件。http:/blog.csdnnet/jiongyi11
5I
57哈算法227
若支持 Index Condition Pushdown优化,则在索引取出时,就会进行 WHERE条侍
的过滤,然后再去获取记录。这将极大地提高查询的效率。当然, WHERE可以过滤的
条件是要该索引可以覆盖到的范围。来看下面的SQL语句:
SELECT★ FROM salaries
WHERE (from date between 1986-01-01 ANn 1995-01-01)
And (salary between 38000 and 40000);
若不启用 Multi- Range Read优化,则其执行计划如图5-37所示
id
table
able ke
key len
ref ows
Erra
5IMPLE
setnes ange
210740 Uaing index condt
图5-37不进行Mu- Range Read优化的执行计划
可以看到列Etra有 Using index condition的提示。但是为什么这里的idxs索引会
使用 Index condition pushdown优化呢?因为这张表的主键是 emp no, from date)的联
合索引,所以idxs索引中包含了 from date的数据,故可使用此优化方式
表5-5对比了在 MySQL5.5和 My SQL56中上述SQL语句的执行时间,并且同时
比较开启MRR后的执行时间。
表55 My SQL5.5和 MySQL5.6中是否启用 ndex Condition Pushdown的执行时间对比
执行时间(秒)
MySQL 5.5
46.738
MySQL 5.6 with ICP
37924
MySQL 5. 6 with ICP &e Mrr
7816
上述的执行时间的比较同样是不对缓冲池做任何的预热操作。可见 Index Condition
Pushdown优化可以将查询效率在原有 MySQL55版本的技术上提高23%而再同时启
用 Mulit-Range Read优化后,性能还能有400%的提升!
57哈希算法
哈希算法是一种常见算法,时间复杂度为O(1),且不只存在于索引中,每个数据库
应用中都存在该数据库结构。设想一个问题,当前服务器的内存为128GB时,用户怎么从
内存中得到某一个被缓存的页呢?虽然内存中查询速度很快,但是也不可能每次都要遍历
所有内存来进行查找,这时对于字典操作只需O(1)的哈希算法就有了很好的用武之地。http://blog.csdn.net/jiongyi1
5
228弟5幸引与算法
留研考
571哈希表
哈希表( Hash table)也称散列表,由直接寻址表改进而来。我们先来看直接寻址
表。当关键字的全域U比较小时,直接寻址是一种简单而有效的技术。假设某应用要用
到一个动态集合,其中每个元素都有一个取自全域U={0,1,…,m-1}的关键字。同
时假设没有两个元素具有相同的关键字。
用一个数组(即直接寻址表)T[0.m-1]表示动态集合,其中每个位置(或称槽或
桶)对应全域U中的一个关键字。图5-38说明了这个方法,槽k指向集合中一个关键
字为k的元素。如果该集合中没有关键字为k的元素,则T[k]=NULL。
U
(关健字全域
89
4
7
K(实际的关键字
图5-38直接寻址表
直接寻址技术存在一个很明显的问题,如果域U很大,在一台典型计算机的可用容量
的限制下,要在机器中存储大小为U的一张表T就有点不实际,甚至是不可能的。如果实
际要存储的关键字集合K相对于U来说很小,那么分配给T的大部分空间都要浪费掉。
因此,哈希表出现了。在哈希方式下,该元素处于h(k)中,即利用哈希函数h,
根据关键字k计算出槽的位置。函数h将关键字域U映射到哈希表T[0.m-1]的槽位
上,如图5-39所示。
哈希表技术很好地解决了直接寻址遇到的问题,但是这样做有一个小问题,如
图539所示的两个关键字可能映射到同一个槽上。一般将这种情况称之为发生了碰
撞( collision)。在数据库中一般采用最简单的碰撞解决技术,这种技术被称为链接法
( chaining)。
宁此处的m不是一个很大的数。http:/blog.csdnnet/jiongyi11
5I
57哈希法29令
召擦器
U(关健字域)
h(K1)
h(K)
Ki
K(实际
h(K2)=h(K3)
的关健字
图5-39哈希表
在链接法中,把散列到同一槽中的所有元素都放在一个链表中,如图5-40所示。槽
j中有一个指针,它指向由所有散列到j的元素构成的链表的头:如果不存在这样的元素,
则j中为NULL。
U(关健字域)
h(K
h(K4)
K
K(实际
K
h(K
的关键字)K
h(ks
图5-40通过链表法解决碰撞的哈希表
最后要考虑的是哈希函数。哈希函数h必须可以很好地进行散列。最好的情况是能
避免碰撞的发生。即使不能避免,也应该使碰撞在最小程度下产生。一般来说,都将关
键字转换成自然数,然后通过除法散列、乘法散列或全域散列来实现。数据库中一般采
用除法散列的方法。
在哈希函数的除法散列法中,通过取k除以m的余数,将关键字k映射到m个槽
的某一个去,即哈希函数为
h(k)= k mod m
57.2 nodE存储引鼙中的哈希算法
InnoDB存储引擎使用哈希算法来对字典进行查找,其冲突机制采用链表方式,哈http:/blog.csdnnet/jiongyi11
230荜5幸索引与算法
希函数釆用除法散列方式。对于缓冲池页的哈希表来说,在缓冲池中的Pag都有今个
chain指针,它指向相同哈希函数值的页。而对于除法散列,m的取值为略大于2倍的
缓冲池页数量的质数。例如:当前参数 innodb buffer pool size的大小为10M,则共有
640个16KB的页。对于缓冲池页内存的哈希表来说,需要分配640×2=1280个槽,但
是由于1280不是质数,需要取比1280略大的一个质数,应该是1399,所以在启动时会
分配1399个槽的哈希表,用来哈希查询所在缓冲池中的页。
那么 InnoDB存储引擎的缓冲池对于其中的页是怎么进行查找的呢?上面只是给出
了一般的算法,怎么将要查找的页转换成自然数呢?
其实也很简单, InnoDB存储引擎的表空间都有一个 space id,用户所要查询的应该
是某个表空间的某个连续16KB的页,即偏移量 offset. InnoDB存储引擎将 space id左
移20位,然后加上这个 space id和of8et;,即关键字K= space id<<20+ space id+offset;
然后通过除法散列到各个槽中去。
573自适应哈希案引
自适应哈希索引采用之前讨论的哈希表的方式实现。不同的是,这仅是数据库自
身创建并使用的,DBA本身并不能对其进行干预。自适应哈希索引经哈希函数映射
到一个哈希表中,因此对于字典类型的查找非常快速,如 SELECT* FROM TABLE
WHERE index col='xxx'。但是对于范围查找就无能为力了。通过命令 SHOW ENGINE
INNODB STATUS可以看到当前自适应哈希索引的使用状况,如:
mysql>SHOW ENGINE INNODB STATUS \G:
★青赏食青★贵★食★★害实灾审★★★1.r。w★★★★★★★★★★★如★★★实★★★★*k★害
Status:
二一一如一=而西一西甚名一==
090922 11:52:51 INNODB MONITOR OUTPUT
〓〓〓〓〓〓〓〓〓〓〓〓纽出出〓〓三
Per second averages calculated from the last 15 seconds
一一世世出出 HI
INSERT BUFFER AND ADAPTIVE HASH INDEX
Ibuf: size 2249, free list len 3346, seg size 5596
374650 inserts, 51897 merged recs, 14300 merges
Hash table size 4980499, node heap has 1246 buffer(s)
1640.60 hash searches/s, 3709.46 non-hash searches/s
物自物自物http:/blog.csdnnet/jiongyi11
5I
58全文检索231
现在可以看到自适应哈希索引的使用信息了,包括自适应哈希索引的大术e使用情
况、每秒使用自适应哈希索引搜索的情况。需要注意的是,哈希索引只能用来搜索等值的
查询,如:
SELECT FRoM table where index col='xxx
而对于其他查找类型,如范围查找,是不能使用哈希索引的。因此,这里出现了
non- hash searches/s的情况。通过 hash searches:non- hash searches可以大概了解使用哈希
索引后的效率。
由于自适应哈希索引是由 InnoDB存储引擎自己控制的,因此这里的这些信息只供参
考。不过可以通过参数 innodb adaptive hash index来禁用或启动此特性,默认为开启。
58全文检索
58.1概述
通过前面章节的介绍,已经知道B+树索引的特点,可以通过索引字段的前缀
( prefix)进行查找。例如,对于下面的查询B+树索引是支持的
SELECT FROM blog WHERE conten like 1xxx%
上述SQL语句可以查询博客内容以xxx开头的文章,并且只要 content添加了B+
树索引,就能利用索引进行快速查询。然而实际这种查询不符合用户的要求,因为在更
多的情况下,用户需要查询的是博客内容包含单词xxx的文章,即:
SElECT* FROM h1。 C WHERE content1ike"xxx暑
根据B+树索引的特性,上述SQL语句即便添加了B+树索引也是需要进行索引的
扫描来得到结果。类似这样的需求在互联网应用中还有很多。例如,搜索引擎需要根据
用户输入的关键字进行全文查找,电子商务网站需要根据用户的查询条件,在可能需要
在商品的详细介绍中进行查找,这些都不是B+树索引所能很好地完成的工作。
全文检索(Fu- ext Search)是将存储于数据库中的整本书或整篇文章中的任意内
容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息,
也可以进行各种统计和分析。
在之前的 MySQL数据库中, InnoDB存储引擎并不支持全文检索技术。大多数的用http://blog.csdn.net/jiongyi1
I
232第5幸索引与草法
户转向 MyISAM存储引擎,这可能需要进行表的拆分,并将需要进行全文检索的数据存
储为 MyISAM表。这样的确能够解决逻辑业务的需求,但是却丧失了 InnoDB存储引擎
的事务性,而这在生产环境应用中同样是非常关键的。
从 InnoDB1.,2.x版本开始, InnoDB存储引擎开始支持全文检索,其支持 MyISAM
存储引擎的全部功能,并且还支持其他的一些特性,这些将在后面的小节中进行介绍
582倒排索引
全文检索通常使用倒排索引( inverted index)来实现。倒排索引同B+树索引一样,
也是一种索引结构。它在辅助表( auxiliary table)中存储了单词与单词自身在一个或多
个文档中所在位置之间的映射。这通常利用关联数组实现,其拥有两种表现形式:
口 inverted file index,其表现形式为{单词,单词所在文档的ID}
口 full inverted index,其表现形式为{单词,(单词所在文档的,在具体文档中的位置)
例如,对于下面这个例子,表t存储的内容如表5-6所示。
表5-6全文检索表t
DocumentId
Text
Documented
Text
Pease porridge hot, pease porridge cold
Some like it hot, some like it cold
2
Pease porridge in the pot
Some like it in the pot
3
Nine days old
6
Nine days old
DocumentId表示进行全文检索文档的Id,Text表示存储的内容,用户需要对存储的
这些文档内容进行全文检索。例如,查找出现过Some单词的文档ld,又或者查找单个
文档中出现过两个Some单词的文档Id,等等。
对于 inverted file index的关联数组,其存储的内容如表5-7所示。
表5-7 inverted file index的关联数组
Number
Text
Documents
Number
Text
Documents
coe
old
3,6
2
3,6
pease
l、2
3
hot
1. 4
porridge
1,2
4
2.5
pot
2.5
5
4.5
12
4,5
like
13
the
25
nlte
3.6http:/blog.csdnnet/jiongyi11
5I
58全文捡索
233
可以看到单词c存在于文档!1和4中,单词如存在与文档3和6点
要进行全文查询就简单了,可以直接根据 Documents得到包含查询关键字的文档。对
于 inverted file index,其仅存取文档ld,而 full inverted index存储的是对(pair),即
( DocumentId, Position),因此其存储的倒排索引如表5-8所示。
表5-8 full inverted index的关联数组
Number
Text
Documents
Number
Text
Documents
code
(1:6),(4:8
old
(3:3〕,(6:3)
2
days
3:2),(6:2)
pease
(I:l4),(2:l)
hot
〔I:3),(4:4)
10
porridge
(1:2,5),(22)
In
2:3),(5:4)
ot
(2:5〕,(5:6)
5
(4:3,7),(5:3)
12
Soime
(4:15),(5:1)
6
like
4:26),〔5:2)
13
the
2:4〕,(5:5
7
nine
〔3:1),(6:1)
full inverted index还存储了单词所在的位置信息,如code这个单词出现在(1:6),
即文档1的第6个单词为code。相比之下, full inverted index占用更多的空间,但是能
更好地定位数据,并扩充一些其他的搜索特性。
5.8.3noDB全文检索
InnoDB存储引擎从1.2.x版本开始支持全文检索的技术,其采用 full inverted index
的方式。在 InnoDB存储引擎中,将( DocumentId, Position)视为一个“ ilist”。因此在全
文检索的表中,有两个列,一个是word字段,另一个是 ilist字段,并且在word字段上
有设有索引。此外,由于 InnoDB存储引擎在iist字段中存放了 Position信息,故可以
进行 Proximity Search,而 MyIsAM存储引擎不支持该特性
正如之前所说的那样,倒排索引需要将word存放到一张表中,这个表称为
Auxiliary Table(辅助表)。在 InnoDB存储引擎中,为了提高全文检索的并行性能,共
有6张 Auxiliary Table,目前每张表根据word的 Latin编码进行分区
Auxiliary Table是持久的表,存放于磁盘上。然而在 InnoDB存储引擎的全文索引
中,还有另外一个重要的概念 FTS Index cache(全文检索索引缓存),其用来提高全文
检索的性能。
FTS Index cache是一个红黑树结构,其根据(word,iist)进行排序。这意味着插http:/blog.csdnnet/jiongyi11
51.6
234第5亨索引与算法
部拼吾
入的数据已经更新了对应的表,但是对全文索引的更新可能在分词操作后还在 FTS Index
Cache中, Auxiliary Table可能还没有更新。 InnoDB存储引擎会批量对 AuxiliaryTable
进行更新,而不是每次插入后更新一次 Auxiliary Table。当对全文检索进行查询时,
Auxiliary Table首先会将在 FTS Index Cache中对应的word字段合并到 Auxiliary Table
中,然后再进行查询。这种 merge操作非常类似之前介绍的 Insert Buffer的功能,不同
的是 Insert Buffer是一个持久的对象,并且其是B树的结构。然而 FTS Index cache的
作用又和 Insert Buffer是类似的,它提高了 InnoDB存储引擎的性能,并且由于其根据红
黑树排序后进行批量插人,其产生的 Auxiliary Table相对较小
InnoDB存储引擎允许用户查看指定倒排索引的 auxiliary table中分词的信息,可以
通过设置参数 innodb ft aux table来观察倒排索引的 Auxiliary Table。下面的SQL语句
设置查看test架构下表ftsa的 Auxiliary Table:
mysql>SET GLOBAL innodb ft aux table='test/fts a'i
Query OK, 0 rows affected (0.00 secl
在上述设置完成后,就可以通过查询 information schema架构下的表 INNODB FT
INDEX TABLE得到表ftsa中的分词信息。
对于其他数据库,如 Oracle11g,用户可以选择手工在事务提交时,或者固定间隔
时间时将倒排索引的更新刷新到磁盘。对于 InnoDB存储引擎而言,其总是在事务提交
时将分词写人到 FTS Index Cache,然后再通过批量更新写人到磁盘。虽然 InnoDB存储
引擎通过一种延时的、批量的写入方式来提高数据库的性能,但是上述操作仅在事务提
交时发生。
当数据库关闭时,在 FTS Index Cache中的数据库会同步到磁盘上的 Auxiliary Table
中。然而,如果当数据库发生岩机时,一些 FTS Index Cache中的数据库可能未被同步到
磁盘上。那么下次重启数据库时,当用户对表进行全文检索(查询或者插入操作)时,
InnoDB存储引擎会自动读取未完成的文档,然后进行分词操作,再将分词的结果放入到
FTS Index cach中
参数 innodb ft cache size用来控制 FTS Index Cache的大小,默认值为32M。当该
缓存满时,会将其中的(word,ilit分词信息同步到磁盘的 Auxiliary Table中。增大该
参数可以提高全文检索的性能,但是在宕机时,未同步到磁盘中的索引信息可能需要更
长的时间进行恢复http:/blog.csdnnet/jiongyi11
51.6
58全文检柔235令
FTS Document ID是另外一个重要的概念。在 InnoDB存储引擎中,为子支持全文
检索,必须有一个列与word进行映射,在 InnoDB中这个列被命名为 FTS DOC ID,其
类型必须是 BIGINT UNSIGNED NOT NULL,并且 InnoDB存储引擎自动会在该列上加
入一个名为 FTS DOC ID INDEX的 Unique Index。上述这些操作都由 InnoDB存储引
擎自己完成,用户也可以在建表时自动添加 FTS DOC ID,以及相应的 Unique Index
由于列名为 FTS DOC IL的列具有特殊意义,因此创建时必须注意相应的类型,否则
MySQL数据库会抛出错误,如:
mysql> CREATE TABLE fts a
- FTS DOC ID INT UNS I GNED ATO INCREMENT NOT NULL
>body TEXT
PRIMARY KEY(FTS DOC ID)
ERROR 1166(42000): Incorrect column name ETS DOC ID
可以看到,由于用户手动定义的列 FTS DOC ID的类型是INT,而非 BIG INT,因
此在创建的时候抛出了 Incorrect column name FTS DOC iD,因此需将该列修改为对应
的数据类型,如
mysql> CREATE TABLE fts a(
FTS DOC ID BIGINT UNSIGNED AUTO INCREMENT NOT NULL,
a> body TEXT,
> PRIMARY KE￥ ETS DOC ID
Query oK, 0 rows affected (0.02 sec)
文档中分词的插入操作是在事务提交时完成,然而对于删除操作,其在事务提交
时,不删除磁盘 Auxiliary Table中的记录,而只是删除 FTS Cache index中的记录。对
于Auκ ciliary Table中被删除的记录, InnoDB存储引擎会记录其 FTS Document id,并
将其保存在 DELETED auxiliary table中。在设置参数 innodb ft aux table后,用户同
样可以访问 information schema架构下的表 INNODB FT DELETED来观察删除的FTS
Document D。
由于文档的DML操作实际并不删除索引中的数据,相反还会在对应的 DELETED
表中插人记录,因此随着应用程序的允许,索引会变得非常大,即使索引中的有些数据
已经被删除,查询也不会选择这类记录。为此, InnoDB存储引擎提供了一种方式,允许
用户手工地将已经删除的记录从索引中彻底删除,该命令就是 OPTIMIZE TABLE。因为http://blog.csdn.net/jiongyi1
5.
2365章涂引与算法
部拼没
OPTIMIZE TABLE还会进行一些其他的操作,如 Cardinality的重新统计,若用户希望仅
对倒排萦引进行操作,那么可以通过参数 innodb optimize fulltext only进行设置,如
mysql>SET GLOBAL innoch optimize fulltext only=l;
mysl>oPTIMIZE TABLEEts a:
若被删除的文档非常多,那么 OPTIMIZE TABLE操作可能需要占用非常多的时间,
这会影响应用程序的并发性,并极大地降低用户的响应时间。用户可以通过参数 innodb
ft num word optimize来限制每次实际删除的分词数量。该参数的默认值为200
下面来看一个具体的例子,首先通过如下代码创建表ftsa:
CREATE TABLE fts a(
FTS DOC ID BIGINT UNSIGNED AUTO INCREMENT NOT NULLr
body TEXT,
PRIMARY KEY (ETS DOC IDX
INSERT INTo fts a
SELECT NULL,'Pease porridge in the pot
INSERT INTo fts a
SELECT NULL,Pcasc porridge hot, pease porridge cold
INSERT INTO￡tsa
SELECT NULL, 'Nine days old'i
INSERT INTo fts a
SELECT NULL, Some like it hot, some like it cold;
INSERT工 NTo Ets且
SELECT NULL,Some like it in the pot;
INSERT INTo fts a
SElECT NULL, Nine days old
INSERT INTO￡tsa
SELECT NULL, I like code days
CREATE FULLTEXT INDEX idx fts on fts a(body)i
上述代码创建了表fsa,由于body字段是进行全文检索的字段,因此创建一个类
型为 FULLTEXT的索引。这里首先导入数据,然后再进行倒排索引的创建,这也是比较
推荐的一种方式。创建完成后观察到表ftsa中的数据:
mysql> SELECT FROM fts ai
十
十
I FTS DOC ID I body
〓〓〓十〓http://blog.csdn.net/jiongyi1
5
58全检索23
1 I Pease porridge in the pot
2 I Pease porridge hot, pease porridge cold I
3 Nine days ola
4 Some like it hot some like it cold
5 I Some like it in the pot
6 Nine days old
7I I like code days
一-十
7 rows in set【0.00sec
通过设置参数 innodb ft aux table来查看分词对应的信息:
mysql> SET GLOBAL innodb ft aux table='test/fts a';
luery OK, 0 rows affected (0.00 sec)
mysql> SELECT FROM information schema INNODB FT INDEX TABLE
=====+====-=+-=-=--+
I WORD
1 FIRST DOC_工D| LAST DOC ID I DOC COUNT!DoC工DPs工TrON
code
cold
722
cold
I days
744777447
223
35|
31
3
days
avS
I hot
33224
322
12
hct
Iike
like
4
18
lik
3
I like
2436724445736
7
I nine
443333
01
nlhe
6666222
32222222
0
i old
10
old
10
pcasc
0
i pease
i pease
i porridge I
I porridge i
21
122122
0
20
6
6
I porridge I
20
ipot
1
22
I pot
201
I some
5
i some
18http://blog.csdn.net/jiongyi1
5
238躬5幸索引与草法
部拼吾
I some
5
一-----==---
27 rows in set (0.00 sec)
可以看到每个word都对应了一个 DOC ID和 POSITION。此外,还记录了 FIRST
DOCI、 LAST DOC D以及 DOC COUNT,分别代表了该word第一次出现的文档
ID,最后一次出现的文档ID,以及该word在多少个文档中存在
若这时执行下面的SQL语句,会删除 FTS DOC ID为7的文档:
mysql> DELETE FRCM test fts a WHERE FTS DOC ID=7
Query OK 1 row affected (0.00 sec?
由于之前的介绍, InnoDB存储引擎并不会直接删除索引中对应的记录,而是将删除
的文档I插人到 DELETED表,因此用户可以进行如下的查询:
mysq-> SELECT FROM INNODB FT DELETED
I DOC ID
7
1 row in set (0.00 sec)
可以看到删除的文档ID插人到了表 INNODB FT DELETED中,若用户想要彻底
删除倒排索引中该文档的分词信息,那么可以运行如下的SQL语句:
mysql> SET GLOBAL innodb optimize fulltext only=l;
Query OK, C rows affected (0.00 sec)
mysql>OPTIMIZE TABLE test fts a;
=一---+一一一
I Table
I Msg type I Msg text
一→一一一十
一一一一一
I test fts a optimize I status OK
一一中一一一一
row in set (0.01 sec)
mysql> SELECT FROM INNODB FT DELETED
十
I DOC ID I
中====m=-http:/blog.csdnnet/jiongyi11
5I
58全文太29
1 row in set (0.00 sec)
6盛
mysql> SELECT
FROM INNODB FT BEING DELETED:
DOC ID I
1 row in set (0.00 sec)
通过上面的例子可以看到,运行命令 OPTIMIZE TABLE可将记录进行彻底的删
除,并且彻底删除的文档ⅠD会记录到表 INNODB FT BEING DELETED中。此外,
由于7这个文档I已经被删除,因此不允许再次插入这个文档ID,否则数据库会抛
出如下异常
mysqL> INSERT INTo test fts a SELECT 7,i like this days i
ERROR 182 (HYO0O) Invalid InnoDB FTS DOc Id
stopword列表( stopword list)是本小节最后阐述的一个概念,其表示该列表中
的word不需要对其进行索引分词操作。例如,对于the这个单词,由于其不具有具体
的意义,因此将其视为 stopword。 InnoDB存储引擎有一张默认的 stopword列表,其
在 information schema架构下,表名为 INNODB FT DEFAULT STOPWORD,默认共
有36个 stopword。此外用户也可以通过参数 innodb_ft_ server_ stopword table来自定义
stopword列表。如:
mysql> CREATE TABlE user stopword(
value VARCHAr(30)
>) ENGINE=工 NNODE
Query oKr 0 rows affected (0.03 sec)
mysqL> SET GLOBAL
innodb ft server stopword table s "test/user stopword"
Query OK, o rows affected (0. 00 sec)
当前 InnoDB存储引擎的全文检索还存在以下的限制
口每张表只能有一个全文检索的索引。
口由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则。
口不支持没有单词界定符( delimiter)的语言,如中文、日语、韩语等.http://blog.csdn.net/jiongyi1
6I
240茅5聿余引与算法
部拼吾
584全文检索
你
MYSQL数据库支持全文检索( Full-Text Search)的查询,其语法为
MATCI(coll, col2,.) AGAINST (expr search modifier])
search modifier:
IN NATURAL LANGUAGE MCDE
工 N NATURAL LANGUAGE MODE w工 TH QUERY EXPANSION
工 N BOOLEAN MODE
WITE QUERY EXPANSION
MySQL数据库通过 MATCH(O… AGAINSTO语法支持全文检索的查询, MATCH指
定了需要被查询的列, AGAINST指定了使用何种方法去进行查询。下面将对各种查询
模式进行详细的介绍。
1. Natural Language
全文检索通过 MATCH函数进行查询,默认采用 Natural Language模式,其表示查
询带有指定word的文档。对于58.3小节中创建的表ftsa,查询body字段中带有 Pease
的文档,若不使用全文索引技术,则允许使用下述SQL语句
mysq-> SELECT FROM fts a wheRE body LIKe 'sFeases'i
显然上述SQL语句不能使用B+树索引。若采用全文检索技术,可以用下面的SQL
语句进行查询:
mysqL> SELECT FROM fts a
WHERE MATCH (body)
->AGAINST ('Porridge1 IN NATURAL LANGUAGE MODE)i
I FTS DOC ID I Eody
一一一一一一一一一一一一一一一一三一一一一一一一一一一
2 I Pease porridge hot, pease porridge cold I
1 I Pease porridge in the pot
2r。 Hs in set(0.00sec}
由于 NATURAL LANGUAGE MODE是默认的全文检索查询模式,因此用户可以省
略查询修饰符,即上述SQL语句可以写为:
SELECT* EROM fts a hErE MATCH (body) AGaInst ('Porridge')i
观察上述SQL语句的查询计划,可得:http:/blog.csdnnet/jiongyi11
5.6
58全文检索241
mysql> EXPLAIN SELECT FROM ftsa
盛
WHERE MATCH(body ) AGAINST ('2orridge')\G;
★★★青古t+★★★为★★★★★卖
1.。w
★ψ★★★★★★卖★卖★虫卖★★★★
id: I
select type:S工MPLE
table: fts a
type: fulltext
possible keys: idx fts
key: idx fts
key lcn: 0
ref: NULL
rows: 1
Extra: Using where
1r。 w in set(0.00sec)
可以看到,在vpe这列显示了fute,即表示使用全文检索的倒排索引,而key这
列显示了 idx fts,表示索引的名字。可见上述查询使用了全文检索技术。同时,若表没
有创建倒排索引,则执行 MATCH函数会抛出类似如下错误:
mysql> SELeCt FROM fts b
where MATCH (body aGainst ( porridge '
ERROR 1191 (HY000): Can't find FULLTEXT index matching the column list
在 WHERE条件中使用MATH函数,查询返回的结果是根据相关性( Relevance)进
行降序排序的,即相关性最高的结果放在第一位。相关性的值是一个非负的浮点数字,0表
示没有任何的相关性。根据 MySQL官方的文档可知,其相关性的计算依据以下四个条件:
凵word是否在文档中出现
口word在文档中出现的次数。
口word在索引列中的数量。
口多少个文档包含该word
对于上述查询,由于 Porridge在文档2中出现了两次,因而具有更高的相关性,故
第一个显示。
为了统计 MATCH函数得到的结果数量,可以使用下列SQL语句:
mysql> SELECT count(*)
from Ets a where
>MATCH (body) AGAINST ('PorridgeIN NATURAL LANGUAGE MODE)
i count (FTS DOC ID) Ihttp://blog.csdn.net/jiongyi1
5
242第5幸索引与算法
抗者墨
2
1 row in set (0.00 sec)
上述SQL语句也可以重写为:
mysql> SELECt
>coUNT(IF(MaTCH (body)
AGAINsT ( Porridge IN NATURAL LANGUAGE MODE) 1, NOLL))
> As count
FR○ M fts a;
十
I count
一一----
1 row in set (0.00 sec)
上述两句SQL语句虽然得到的逻辑结果是相同的,但是从内部运行来看,第二句
SQL的执行速度可能更快些。这是因为第一句SQL语句还需要进行相关性的排序统计,
而在第二句SQL中是不需要的。
此外,用户可以通过SQL语句查看相关性:
mysql> SELECT fts doc id, body,
MATCH (body) AGAINST ( Porridge IN NATURAL LANGUAGE MODEl
As Relevance
FRoM fts ai
fts doc id I body
i Relevance
1 Pease porridge in the pot
0.2963100471973419
2 Pease porridge hot, pease porridge cold 0.5920200943946838
3 Nine days old
0
4 Some like it hot, some l=ke it cold
5 some like it in the pot
0
6I Nine days old
7I like hot and code days
0
7 rows in set(C,01 sec)
对于 InnoDB存储引擎的全文检索,还需要考虑以下的因素
口查询的word在 stopword列中,忽略该字符串的查询http:/blog.csdnnet/jiongyi11
58仝文裣索243
口查询的word的字符长度是否在区间[ innodb ft min token size, innodbrft- max
token size]内。
如果词在 stopword中,则不对该词进行查询,如对the这个词进行查询,结果如下
所示:
mysql> SElECT fts doc id as idr body
MATCH (body AGaInsT ('the IN NATURAL LANGUAGE MODE
- As rl
froM Its ai
十
id i body
I 1 I Pease porridge in the pot
2 Pease porridge hot, pease porridge cold
3 I Nine days old
4|sonc1 ike it hot;s。me1 ike it c。id
5 I Some like it in the pot
6 Nine days old
0000b0
7工2 ke hot and code days
7 raws in set (0.co sec)
可以看到,the虽然在文档1、5中出现,但由于其是 stopword,故其相关性为0。
参数 innodb ft min token size和 innodb ft max token size控制 InnoDB存储引擎
查询字符的长度,当长度小于 innodb ft min token size,或者长度大于 innodb ft ma
token size时,会忽略该词的搜索。在 InNoDB存储引擎中,参数 innodb ft min token
size的默认值为3,参数 innodb ft max token size的默认值为84。
2 Boolean
My SQL数据库允许使用 IN BOOLEAN MODE修饰符来进行全文检索。当使用该
修饰符时,查询字符丰的前后字符会有特殊的含义,例如下面的语句要求查询有字符串
Pease但没有hot的文档,其中+和-分别表示这个单词必须出现,或者一定不存在
mysql> sEleCt FROM fts a
->WHERE MATCH (body AGAINST ('+Pease -hot IN BOOLEAN MODE)\G:
★★★★★★★★★★★★★★★★青★★请★1.roW★★★★肯★★★★为★出★★★★★★吉古女★★食★
FTS DOC ID: 1
body Pease porridge in the pot
Boolean全文检索支持以下几种操作符http://blog.csdn.net/jiongyi1
5
244茅5幸索引勻草法
口+表示该word必须存在。
口表示该word必须被排除。
口( no operator)表示该wor是可选的,但是如果出现,其相关性会更高
口@ distance表示查询的多个单词之间的距离是否在 distance之内, distance的单
位是字节。这种全文检索的查询也称为 Proximity Search。如 MATCH(body)
AGAINST(" Pease pot"@30 IN BOOLEAN MODE)表示字符串 Pease和pot之
间的距离需在30字节内。
口>表示出现该单词时增加相关性。
口<表示出现该单词时降低相关性。
口~表示允许出现该单词,但是出现时相关性为负(全文检索查询允许负相关性)。
口*表示以该单词开头的单词,如lk*,表示可以是lk、like,又或者 likes。
口"表示短语。
接着将根据上述的操作符及之前创建的表sa来进行具体的介绍。下面的SQL语
句返回有peae又有hot的文档:
mysql> SElECt FROM fts a
>wHERE MATCH (body AGAINST ('+Pease thot' IN BOOLEAN MODE)\G;
t青古★★★★★奇青南审申审向南内申由1.1oW青青青南青青青★t世害青责贵★青★青青青青★古★青
FTsD。cIP:2
body: Pease p。 rridge hat; pease p。 rridge cold
r。 w in set(0.00sec)
下面的SQ语句返回有 pease但没有hot的文档:
scl> SELECT FROM fts a
WhERe MATCH (body AGAINST ('+Pease -hot IN BOOLEAN MODE)\G
啸安啸★向★向★实实肉青★★肯★★青★★1.y。M★★★★★★★★★★★★★★★量★★★★青★★★
FTs DOC工D:1
body: Pease porridge in the pot
1 row in set (0.00 sec)
下面的SQL语句返回有peae或有hot的文档:
mysql> SELECT
FROM fts a
s WHERE MATCH(body AGAINst ( Pease hot IN BOOLEAN MODE)
I FTs DOC ID I body
2 I Pease porridge hot, pease porridge cold
1 I Pease porridge in the pot
4 Some like it hot, some like it coldhttp://blog.csdn.net/jiongyi1
FI
58全文索245
7 I like hot and code days
〈冷
4 rows in set (0.00 sec)
下面的SQL语句进行 Proximity Search:
mysql> SELECT fts doc id, body FROM fts_a
WHERE MATCH (Rody)
>AGAINST (pEase pot "230 IN BOOLEAN MODE)\
★★女★安★★女★★★★女★★★女★★女史★★★★★1.Yow★★责★★★★责★责★★★实建青安责★青曲青★
fts doc id: 1
body Pease porridge in the pot
1 row in set (0.01 sec)
mysq-> SELECT fts doc id, body FROM ftsa
WHERE MATCH (body)
> AGAINST(" Pease pot"囟10′ IN BOOLEAN MODE);
Empty set (0.01 sec)
可以看到文档1屮单词 Pease和pot的距离为22字节,因此第一条@30的查询可
以返回结果,而之后@10的条件不能返回任何结果。如:
mysc_> SeLECT fts doc ia, body
- MATCH (body AGAINST (like >pot IN BOOLEAN MODE
As Relevance fron￡tsa
I fts doc id i body
I Relevance
+
1 Pease porridge in the pot
1.2960100173950195
2 Pease porridge hotr pease porridge ' cold I
3 I Nine days old
01
4 I Some like it hot some like it cold
0.270813822746276日6
5 Some like it in the pot
1.4314169883728027
6 I Nine days old
0
7 I like hot ard code days
10.13540691137313843
一--+一--------
7 rows in set (0.00 sec)
上述SQL语句查询根据是否有单词lke或pot进行相关性统计,并且出现单词pot
后相关性需要增加。文档4虽然出现两个lke单词,但是没有pot,因此相关性没有文
档1和5高
下面的查询增加了“<some”的条件,最后得到的结果:
mysql> SELECT fts doc id, body
MATCH(body] Against (like >hot <some IN BOOLEAN MODE)
As Relevance
FROM fts athttp:/blog.csdnnet/jiongyi11
5I
246第5章索引与算法
￡ ts doc id|body
I Relevance
-----
1 I Pease porridge in the pot
0
21 Pease porridge hot, pease porridge cold I 1.2960100173950195
3| Nine days o⊥d
4I Some like it hot, some like it cold
1.158843994140525
5 I Some like it in the pot
-0.5685830116271973
6 I Nine days old
0
工1 ike hot and code days
0.13540691137313843
r。 ws in set(0.00sec)
可以发现文档5的相关性变为了负,这是因为虽然其中存在like单词,但是也存在
some单词,所以根据查询条件,其相关性变为了负相关
接着来看下面的SQL语句:
mysql> SELECT FROM fts a
WhERE MATCH (body AGAINST ('po*.IN BOOLEAN MODE)
ETS DOC ID
I body
2 I Pease porridge hot, pease porridge cold I
1 I Pease porridge in the pot
5 Some like it in the pot
ows in set (0.00 sec)
可以看到最后结果中的文档包含以po开头的单词,如 porridge,poto
最后是关于短语的SQL查询,如:
mysql> SELECT FROM Ets a
WHERE MATCH (body AGAINst ('like hot IN BOOLEAN MODE):
ETs DOC Id I body
===
4|S
like it hot, some like it cold
7 I like hot and code day
2 I Pease porridge hot, pease porridge cold I
Some like it in the pot
一一
4 rows in set (0.00 sec)
mys I> SELECT FROM fts a
WHERE MATCH (body AGAINST (."like hot"1 IN BOOLEAN MODE);
十=
FTs_DoC_IDlb。dyhttp:/blog.csdnnet/jiongyi11
5.6
58全文检农247
7I like hot and code days
1 row in get【0.00sec
可以看到第一条SQL语句没有使用"将lke和hot视为一个短语,而只是将其视
为两个单词,因此结果共返回4个文档。而第二条SQL语句使用" like hot",因此查询
的是短语,故仅文档4符合查询条件。
3. Query Expansion
MySQL数据库还支持全文检索的扩展查询。这种查询通常在查询的关键词太短,用户
需要 implied knowledge(隐含知识)时进行。例如,对于单词 database的查询,用户可能希
望查询的不仅仅是包含 database的文档,可能还指那些包含 MySQL、 Oracle、DB2、 RDBMS
的单词。而这时可以使用 Query Expansion模式来开启全文检索的 implied knowledge
通过在查询短语中添加 WITH QUERY EXPANSION或 IN NATURAL LANGUAGE
MODE WITH QUERY EXPANSION可以开启 blind query expansion(又称为 automatic
relevance feedback)。该查询分为两个阶段。
口第一阶段:根据搜索的单词进行全文索引查询。
口第二阶段:根据第一阶段产生的分词再进行一次仝文检索的查询。
接着来看一个具体的例子,首先根据如下代码创建测试表 articles:
CREATE TABLE articles c
id INt UNSIGNED AUTO INCrEMENT NOT NULL PRIMARY KEY,
title VARCHAR(200)
body TExT,
FuLLTEXT Litle r bodv
ENG工NE=工 nnODB i
INSERT INTC articles (title, body VALUES
('MySQI Tutorial, 'DBMs stands for DataBase ..')
('How To Use MysqL Well,'After you went through a ..'
【' OptimizingⅣySQL·," In this tutorial we wi11show,,")
(1001 My SCL Tricks, 1. Never run mysqld as root. 2
MYSQL vs. Your,In the following database comparison
(MYSQI Security hen configured properly, MysQL ..)s
Tuning DB2 ,For IBM database ..')
( IBM History,'DB2 hitory for IBM
在这个例子中,并没有显示创建 FTS DOC ID列,因此 InnoDB存储引擎会自动建
立该列,并添加唯一索引。此外,表 articles的全文检索索引是根据列tle和body的联
合索引。接着根据 database关键字进行的全文检索查询。http://blog.csdn.net/jiongyi1
5
248第5章索引与算法
Er-2
mysql> SELECT FROM articles
- WHERE MATCH (title, body
AGAINsT(database IN NATURal LANGUAge Mode);
ia|tit⊥e
body
一一
III MySQL Tutorial
DBMs stands for dataBase
5 I MySQL vS, YoursqL I In the following database comparison
I 7 I Tuning DB2
I For IBM database
3 rows in set (0.00 sec
可以看到,查询返回了3条记录,body字段包含 database关键字。接着开启 Query
Expansion,观察最后得到的结果如下所示
mysql> SELECT FROM articles
WHERE MATCH(title, body
AGAINsT( database WITH QUERY EXPANSION);
I id i title
i body
一---4-4叫口口mm十一一-----------
5 MYSQL VS. YourSQL
In the following database comparison .. I
1|硎 YSQL Tutorial
DBMs stands for database ,t
7 I Tuning DB2
I For IBM database
B|工 BM History
DB2 hitory for工BM
3I Optimizing MySQL
In this tutorial we will show
i 6 I MYSQL Security
When configured properly, MySQL
2 I How To Use My sQL Well I After you went through a
i 4 1 1001 MysQL Tricks
1. Never run mysgld as root. 2.
8r。 ws in set(0.00sec)
可以看到最后得到8条结果,除了之前包含 database的记录,也有包含 title或bod
字段中包含 MySQL、DB2的文档。这就是 Qucry Expansion。
由于 Query Expansion的全文检索可能带来许多非相关性的查询,因此在使用时,用
户可能需要非常谨慎。
59小结
本章介绍了一些常用的数据结构,如二分查找树、平衡树、B+树、直接寻址表和哈
希表,以及 InnoDB12版本开始支持的全文索引。从数据结构的角度切入数据库中常见的
B+树索引和哈希索引的使用,并从内部机制上讨论了使用上述索引的环境和优化方法http://blog.csdn.net/jiongyi1
5
部拼
第6章锁
开发多用户、数据库驱动的应用时,最大的一个难点是:一方面要最大程度地利用
数据库的并发访问,另外一方面还要确保每个用广能以一致的方式读取和修改数据。为
此就有了锁( locking)的机制,同时这也是数据库系统区别于文件系统的一个关键特
性。 InnoDB存储引擎较之 MySQL数据库的其他存储引擎在这方面技高一筹,其实现方
式非常类似于 Oracle数据库。而只有正确了解这些锁的内部机制才能充分发挥 InnoDB
存储引擎在锁方面的优势。
这一章将详细介绍 InnoDE存储引擎对表中数据的锁定,同时分析 InnoDe存储引擎
会以怎样的粒度锁定数据。本章还对 MyISAM、 Oracle、 SQL Server之间的锁进行了比较,
主要是为了消除关于行级锁的一个“神话”:人们认为行级锁总会增加开销。实际上,只
有当实现木身会增加开销时,行级锁才会增加开销。 InnoDB存储引擎不需要锁升级,因
为一个锁和多个锁的开销是相同的。
61什么是锁
锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并
发访问°。 InnoDB存储引擎会在行级别上对表数据上锁,这固然不错。不过 InnoDB存
储引擎也会在数据库内部其他多个地方使用锁,从而允许对多种不同资源提供并发访
问。例如,操作缓冲池中的LRU列表,删除、添加、移动LRU列表中的元素,为了保
证一致性,必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问,
提供数据的完整性和一致性
另一点需要理解的是,虽然现在数据库系统做得越来越类似,但是有多少种数据
库,就可能有多少种锁的实现方法。在SQL语法层面,因为SQL标准的存在,要熟悉
多个关系数据库系统并不是一件难事。而对于锁,用户可能对某个特定的关系数据库
注意:这里说的是“共享资源”而不仅仅是“行记录http:/blog.csdnnet/jiongyi11
250郭6李锁
拼吾
系统的锁定模型有一定的经验,但这并不意味着知道其他数据库。在使用0DB
引擎之前,我还使用过 MySQL数据库的 MyISAM和 NDB Cluster存储引擎。在使用
MySQL数据库之前,我还曾经使用过 Microsoft SQL Server、 Oracle等数据库,但它们
各自对于锁的实现完全不同。
对于 MyISAM引擎,其锁是表锁设计。并发情况下的读没有问题,但是并发插入时
的性能就要差一些了,若插入是在“底部”, MyISAM存储引擎还是可以有一定的并发
写人操作。对于 Microsoft SQL Server数据库,在 Microsoft SQL Server2005版本之前其
都是页锁的,相对表锁的 MyISAM引擎来说,并发性能有所提高。页锁容易实现,然而
对于热点数据页的并发问题依然无能为力。到2005版本, Microsoft SQL Server开始支
持乐观并发和悲观并发,在乐观并发下开始支持行级锁,但是其实现方式与 InnodB存
储引擎的实现方式完全不同。用户会发现在 Microsoft SQL Server下,锁是一种稀有的资
源,锁越多开销就越大,因此它会有锁升级。在这种情况下,行锁会升级到表锁,这时
并发的性能又回到了以前。
InnoDB存储引擎锁的实现和 Oracle数据库非常类似,提供一致性的非锁定读、行
级锁支持。行级锁没有相关额外的开销,并可以同时得到并发性和一致性。
62lock与 latch
这里还要区分锁中容易令人混淆的概念1ock与1atch。在数据库中,lock与 latch都
可以被称为“锁”。但是两者有着截然不同的含义,本章主要关注的是lock
latch一般称为闩锁(轻量级的锁),因为其要求锁定的时间必须非常短。若持续的
时间长,则应用的性能会非常差。在 InnoDB存储引擎中, latch又可以分为 mutex(互
斥量)和 relock(读写锁>。其目的是用来保证并发线程操作临界资源的正确性,并且
通常没有死锁检测的机制。
lock的对象是事务,用来锁定的是数据库中的对象,如表、页、行。并且一般lock
的对象仅在事务 commit或 rollback后进行释放(不同事务隔离级别释放的时间可能不
同)。此外,lock,正如在大多数数据库中一样,是有死锁机制的。表6-1显示了lock与
latch的不同。http://blog.csdn.net/jiongyi1
5
6.2lock与 catch251
部拼吾
表6-1lock与 latch的比较
lock
latch
对象
事务
线程
保护
数据库内容
内存数据结构
持续时间整个事务过程
临界资源
模式
行锁、表锁、意向锁
读写锁、互斥量
通过 waits-for graph, lIme out等机制进行无死锁检测与处理机制。仅通过应用程序加锁
死锁
死锁检测与处理
的顺序( lock leveling)保证无死锁的悄况发生
存在于 Lock Manager的哈希表中
每个数据结构的对象中
对于 InnoDe存储引擎中的 latch,可以通过 mysq l= sHOW aGINE INNoDB MUTEx;
命令 SHOW ENGⅠ NE INNODB MUTEX来进行」 Type I Name
status
查看,如图6-1所示。
InnoDB I srvasrv. c: 1028 I os_waits=5 E
I InnoDB 1 loglog. C: 833 I os_waits=3 I
在 Debug版本下,通过命令 SHOW ENGINE
2 rows in set (0.03 sec)
INNODB MUTEX可以看到 latch的更多信息,如
图61通过命令 SHOW ENGINE INNODE
图6-2所示。
MUTEX查看 latch
mysqL> SHOW ENGINE INNODB MUTEX;
I Type I Name
t Statu
InnoDB &kernetmutex:srvBsrvc count=54, spin_walts=6, spin_rounds=60, os_waits=3, os yields=3, os_wait times=d
InnoDB loglOg C: 833
os waits=2
nneD|rlak那 mutexes
I counte, spin, waits=e, spin_ rounds=a, os_waits=e, os yields=e, os_wait times=0
3 rows in set (e.G sec)
图62在 Debug版本下查看到的 latch
通过上述的例子可以看出,列Type显示的总是 InnoDB,列Name显示的是 latch的信
息以及所在源码的位置(行数)。列 Status比较复杂,在 Debug模式下,除了显示owas
还会显示 count、 spin waits, spin_ rounds、 os yields、 as wait times等信息。其具体含义见表62。
表6-2命令 SHOW ENG| NE INNODB MUTEX输出结果说明
名称
说明
count
mutex被请求的次数
spin lock〔自旋锁)的次数, InnoDB存储引擎 latch在不能获得锁时首先进行自旋,若自旋后
spin waits
还不能获得锁,则进入等待状态
自旋内部循环的总次数,每次自旋的内部循环是一个随机数。 spin rounds/spain waits表示平
spin rounds均每次自旋所需的内部循环次数
表示操作系统等待的次数。当 spin lock通过自旋还不能获得 latch时,则会进入操作系统等待
os waits
状态,等待被唤醒
os yields
进行 us thread yield唤醒操作的次数
os_wait_times操作系统等待的时间,单位是mshttp://blog.csdn.net/jiongyi1
6I
252第6苹锁
部拼没
上述所有的这些信息都是比较底层的,一般仅供开发人员参考。但是用户还是可以
多盛
通过这些参数进行调优。
相对于 latch的查看,lock信息就显得直观多了。用户可以通过命令 SHOW ENGⅠNE
Ⅰ NNODB STATUS及 information schema架构下的表 INNODB TRX、 INNODB LOCKS、
INNODB LOCK WAITS来观察锁的信息。这将在下节中进行详细的介绍。
63 InnodB存储引擎中的锁
631锁的类型
InnoDB存储引擎实现了如下两种标准的行级锁:
口共享锁( S Lock),允许事务读一行数据。
口排他锁( X Lock),允许事务删除或更新一行数据
如果一个事务T1已经获得了行r的共享锁,那么另外的事务T2可以立即获得行r
的共享锁,因为读取并没有改变行r的数据,称这种情况为锁兼容( Lock Compatible)
但若有其他的事务T3想获得行r的排他锁,则其必须等待事务T1、T2释放行r上的共
享锁——这种情况称为锁不兼容。表6-3显示了共享锁和排他锁的兼容性。
表6-3排他锁和共享锁的兼容性
不兼容
不兼容
不兼容
兼容
从表6-3可以发现X锁与任何的锁都不兼容,而S锁仅和S锁兼容。需要特别注意
的是,S和X锁都是行锁,兼容是指对同一记录(row)锁的兼容性情况。
此外, InnoDB存储引擎支持多粒度( granular)锁定,这种锁定允许事务在行级上的
锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作, InnodB存储引擎支持
一种额外的锁方式,称之为意向锁( Intention Lock)。意向锁是将锁定的对象分为多个层
次,意向锁意味着事务希望在更细粒度(血 ne granularity)上进行加锁,如图6-3所示。
若将上锁的对象看成一棵树,那么对最下层的对象上锁,也就是对最细粒度的对象
进行上锁,那么首先需要对粗粒度的对象上锁。例如图6-3,如果需要对页上的记录r进
行上X锁,那么分别需要对数据库A、表、页上意向锁IX,最后对记录r上X锁。若http:/blog.csdnnet/jiongyi11
5I
63 InnoDB存儲储引擎中的253
爸拼吾没
数据库A
表1
表2
表3
表4
4,4
页
页
页
页
记录
记录
记录
记录
图6-3层次结构
其中任何一个部分导致等待,那么该操作需要等待粗粒度锁的完成。举例来说,在对记
录r加Ⅹ锁之前,已经有事务对表1进行了S表锁,那么表1上已存在S锁,之后事务
需要对记录r在表1上加上ⅸX,由于不兼容,所以该事务需要等待表锁操作的完成。
InnoDB存储引擎支持意向锁设计比较简练,其意向锁即为表级别的锁。设计目的主
要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁
1)意向共享锁( IS Lock),事务想要获得一张表中某几行的共享锁
2)意向排他锁( X Lock),事务想要获得一张表中某几行的排他锁
由于 InnODB存储引擎支持的是行级别的锁,因此意向锁其实不会阻塞除全表扫以
外的任何请求。故表级意向锁与行级锁的兼容性如表6-4所示
表6-4 InnoDB存储引擎中锁的兼容性
X
Is
兼容
兼容
兼容
不兼容
IX
兼容
兼容
不兼容
不兼容
兼容
不兼容
兼容
不兼容
不兼容
不兼容
不兼容
不兼容http:/blog.csdnnet/jiongyi11
EL
254第6幸
拼吾
用户可以通过命令 SHOW ENGINE INNODB STATUS命令来查看当前锁请求的信息e
mysql> SHOW ENGINE INNODB STATUS\G;
TRANSACTIONS
Tex id counter 48B89BE
Purge done for trx's n:o< 48B89BA undo n:o 0
History list length 0
LIST OE TRANSACIIONS FOR EACH SESSION
-TRANSACTION 0, not started, process no 13757, os thread id 1255176512
My SQL thread id 42, query id 80424887 localhost root
show engine innodb status
TRANSACTIoN 48B89BE, ACTIVE 193 sec, process no 13757, os thread id
1254910272 starting index read
mysql tables in use l, locked 1
LOCK WAIT 2 lock struct(s), heap size 368, 1 row lock(s)
MySQL thread id 1, query id 80424886 localhost root sending data
select from t where a< 4 lock in share mode
一型: HAS BEEN TATING2sER咡邛 LOCK NO 33 GRN:
RECORd LOCKs sPace id 30 page no 3 n bita 72 index PRIMARY of table
test.'t trx id 48BB9BE lock mode s waiting
TABLE LOCK table itest 'ti trx id 48bb9be lock mode is
RECORD LOCKs space id 30 page no 3 n bits 72 index FRIMaRy of table
i test.'t trx id 48B89BE lock mode s waiting
TRANSACTIoN 48B89BD, ACTIvE 205 sec, process no 13757, os thread id
1257838912
2 lock struct(s),heap size 368, 1 row lock(s)
MysQL thread id 40, query id 80424881 localhost root
TABLE LOCK table i testi. t trx id 48B89BD lock mode Ix
RECORd LOCKs space id 30 page no 3 n bits 72 index 1 FRIMARY of table
'test.t trx id 48B89BD lock mode x locks rec but not gap
ENd OF INNODB MONITOR OUTPUT
l row in set (0.0l sec)
叮以看到SQL语句 select* from t where a<4 lock in share mode在等待, RECORD
LOCKS space id 30 page no 3 n bits 72 index"' PRIMARY ' of table' test. ' 'trx id 48B89BD
lock mode X locks rec but not gφp表示锁住的资源。 locks rec but not gap代表锁住的是一
个索引,不是一个范围。http://blog.csdn.net/jiongyi1
5.
63ODB存儲引擎中锁255
部拼没
在 InnoDB1.0版本之前,用户只能通过命令 SHOW FULL PROCESSLIST,SHQW
ENGINE INNODB STATUS等来查看当前数据库屮锁的请求,然后再判断事务锁的情
况。从 InnoDB1.0开始,在 INFORMATION SCHEMA架构下添加了表 INNODB TRX
INNODB LOCKS、 INNODB LOCK WAITS。通过这三张表,用户可以更简单地监控当
前事务并分析可能存在的锁问题。我们将通过具体的示例来分析这三张表,在之前,首
先了来看表6-5中表 INNODB TRX的定义,其由8个字段组成。
表6-5表| NNODB TRX的结构说明
字名
说明
trX
InnoDB存储引擎内部唯一的事务ID
trx state
当前事务的状态
trx started
事务的开始时间
等待事务的锁ID。如 trx state的状态为 LOCK WAIT,那么该值代表当前的事务等待
trx requested lock id
之前事务占用锁资源的D,若 try state不是 LOCK WAIT,则该值为NUL
trx wait started
事务等待开始的时间
事务的权重,反映了一个事务修改和锁住的行数。在 InnoDE存储引擎巾,当发生死
trx weight
锁需要回滚时, InnoDB存储引擎会选择该值最小的进行回滚
trx mysql thread id
MySQL中的线程ID, SHOW PROCESSLIST显示的结果
trx query
事务运行的SQL语句
接着来看一个具体的例子
mysql> seLect FROM information schema. INNOD3 TRX \Gi
★★★★★古言★青内青★青★青青内t青吉离古吉★★1。y。w★★青古青肯南南内内★★青吉肯责内★责肯★
trx id: 7311F4
七 x state: LOCK WA工T
trx started:2010-01-0410:49:33
trx requested lock id:7311E4: 96:3: 2
trx wait started: 2010-01-04 10: 49: 33
trx weight: 2
trx mysql thread id: 471719
七上 x query; select· trom parent1 ock in share mode
贵★★★★★★★★世★★肯青黄背★★★★肯★★★★2。xew★訾★★★★★肯★★肯★★★★★★★黄★★★★★
trx id: 73ofee
trx state: RUNNING
try started:2010-01-0410:18:37
trx requested lock ic: NULL.
trx wait started: NULL
trx weight: 2
trx mysql thread id: 471718
trx query: NULL
2 rows in set (0.00 sec)http://blog.csdn.net/jiongyi1
256笫6幸
通过列sate可以观察到mxi为730FE的事务当前正在运行,而mx73l4
的事务目前处于“ LOCK WAIT”状态,且运行的SQL语句是 sclcct*from parent lock in
share mode该表只是显示了当前运行的 InnoDB事务,并不能直接判断锁的一些情况
如果需要查看锁,则还需要访问表 INNODB LOCKS,该表的字段组成如表6-6所示。
表6-6表| NNODB LOCKS的结构
字段名
说明
lock id
锁的ID
lock trx id
事务ID
lock mode
锁的模式
lock type
锁的类型,表锁还是行锁
lock table
要加锁的表
lock index
锁住的索弓
lock space
锁对象的 space id
lock page
事务锁定页的数量。若是表锁,则该值为NULL
lock rec
事务锁定行的数量,若是表锁,则该值为NULL
lock data
事务锁定记录的主键值,若是表锁,则该值为NULL
接着上面的例子,继续查看表 INNODB LOCKS:
mysql SELECT FROM information schema, INNODB LOCKS\G
★★★★★★★★★★★青★南★南★★★★★★★★1.y。w★★★★★★★★★内★★★★★实★★★★★★六★六★
lock id:7311F4:96:3:2
lock trx id: 7311F4
lock mode: s
lock type: RECORD
lock table: mytest. parent
lock index: PRIMARY
lock space: 96
lock page: 3
lock rec: 2
lock data: 1
★★实害害*★青宵k比;★肃2,rgw片★青大言肯内青古t吉害言责六★★★★
1 ock id;730EEE;96;3:2
lock trx id: 730FEE
1。 ck mode:X
lock type: RECCRD
lock table: ' mytest.parent
1 ock index:· PRIMARY
lock space: 96
lock page: 3
lock rec: 2
lock data: 1
2 rows in set (0.00 sec)http://blog.csdn.net/jiongyi1
5
63mnDB存储引学的2579
这次用户可以清晰地看到当前锁的信息。 trx id为730FEE的事务向表 parent加
一个X的行锁,ID为7311F4的事务向表 parent申请了一个S的行锁。 lock data都是
,申请相同的资源,因此会有等待。这也可以解释 INNODB TRX中为什么一个事务的
trx state是“ RUNNING”,另一个是“ LOCK WAIT”了。
另外需要特别注意的是,我发现 lock data这个值并非是“可信”的值。例如当用户
运行一个范围査找时, lock data可能只返回第一行的主键值。与此同时,如果当前资源
被锁住了,若锁住的页因为 InnoDB存储引擎缓冲池的容量,导致该页从缓冲池中被刷
出,则查看 INNODB LOCKS表时,该值同样会显示为NULL,即 InnoDB存储引擎不
会从磁盘进行再一次的查找。
在通过表 INNODB LOCKS查看了每张表上锁的情况后,用户就可以来判断由此
引发的等待情况了。当事务较小时,用户就可以人为地、直观地进行判断了。但是当
事务量非常大,其中锁和等待也时常发生,这个时候就不这么容易判断。但是通过表
INNODB LOCK WAITS,可以很直观地反映当前事务的等待。表 INNODB LOCK
WAITS由4个字段组成,如表67所示。
表67表 NNODB LOCK WAITS的结构
字段
说明
字段
说明
requesting trx id
申请锁资源的事务ID
blocking trx id
阻塞的事务ID
requesting lock id
申请的锁的ID
blocking_ trx id
阻塞的锁的ID
接着上面的例子,运行如下查询
mysql> SELECT* FROM information schema INNODB LOCK WAITS\G;
宵★青★害有青宵青★★黄實肯肯青青肯★*實1,rH★t食宽食意t女蜜吉宝安女皆安害古查
requesting trx id: 7311F4
requested lock id: 7311F4: 96: 3: 2
blocking trx id: 730FEE
blocking lock id: 730FEE: 96: 3: 2
l row in set (0.00 sec)
通过上述的SQL语句,用户可以清楚直观地看到哪个事务阻塞了另一个事务
当然,这里只给出了事务和锁的I。如果需要,用户可以根据表Ⅰ NNODB TRX、
INNODB LOCKS、 INNODB LOCK WAITS得到更为直观的详细信息。例如,用户可
以执行如下联合查询http:/blog.csdnnet/jiongyi11
SL
258箬6幸銨
研
mysql> SELEC
trx id waiting trx id
r trx mysql thread id waiting thread,
r trx query waiting query
b trx id blocking trx id,
b, trx mysql thread id blocking thread,
b trx query blocking query
FRoM information schema innodb lock waits w
INNER JOIN information schema innodb trx b
oN b trx id= w blocking trx id
INNER JOIn information schema. inncdb trx r
ON r trx id=w requesting trx id\G;
★为★★★女★女★实★女★☆★走皮★★★1.工ow*實**★常計责曹内为★为★青★★
waiting trx id: 73122F
waiting thread: 471719
waiting query: NOLL
blocking trx id: 7311FC
blocking thread: 471713
blocking query: NULL
row in set (0.00 sec)
6.32一致性非锁定读
致性的非锁定读( consistent nonlocking read)是指 InnoDB存储引擎通过行多版
本控制( multi versioning)的方
式来读取当前执行时间数据库中
SOL
行的数据。如果读取的行正在执
行 DELETE或 UPDATE操作,这
时读取操作不会因此去等待行上
锁的释放。相反地, InnoDB存储
引擎会去读取行的一个快照数据
LOcked
如图6-4所示。
Snapshot Data
Snapshot Data 2
图6-4直观地展现了 InnoDB
存储引擎一致性的非锁定读。之
所以称其为非锁定读,因为不需
要等待访问的行上X锁的释放。
图6-4 InnoDB存储引擎非锁定的一致性读http:/blog.csdnnet/jiongyi11
51.6
6.3nODB存储引乎中的259
快照数据是指该行的之前版本的数据,该实现是通过undo段来完成。而undo用来在事
务中回滚数据,因此快照数据本身是没有额外的开销。此外,读取快照数据是不需要上
锁的,因为没有事务需要对历史的数据进行修改操作
可以看到,非锁定读机制极大地提髙了数据库的并发性。在 InnodB存储引擎的默
认设置下,这是默认的读取方式,即读取不会占用和等待表上的锁。但是在不同事务隔
离级别下,读取的方式不同,并不是在每个事务隔离级别下都是采用非锁定的一致性
读。此外,即使都是使用非锁定的一致性读,但是对于快照数据的定义也各不相同。
通过图64可以知道,快照数据其实就是当前行数据之前的历史版本,每行记录
可能有多个版本。就图6-4所显示的,一个行记录可能有不止一个快照数据,一般称这
种技术为行多版本技术。由此带来的并发控制,称之为多版本并发控制( Multi version
Concurrency Control, MVCC)
在事务隔离级别 READ COMMITTED和 REPEATABLE READ( InnoDe存储引擎
的默认事务隔离级别)下, InnoDB存储引擎使用非锁定的一致性读。然而,对于快照数
据的定义却不相同。在 READ COMMITTED事务隔离级别下,对于快照数据,非一致
性读总是读取被锁定行的最新一份快照数据。而在 REPEATABLE READ事务隔离级别
下,对于快照数据,非一致性读总是读取事务开始时的行数据版本。来看下面的一个例
子,首先在当前 MySQL数据库的连接会话A中执行如下SQL语句:
i session a
mysl> BEGINi
Query OK, 0 rows affected (0.00 sec)
mysql> SELECT* EROM parent WHERE id =1;
1 row in set (0.00 sec)
会话A中已通过显式地执行命令BEGⅠN开启了一个事务,并读取了表 parent中id
为1的数据,但是事务并没有结束。与此同时,用户再开启另一个会话B,这样可以模
拟并发的情况,然后对会话B做如下的操作:http:/blog.csdnnet/jiongyi11
260葬6章频
mysql> BEGINi
盛
Query ok, 0 rows affected (0.00 sec)
mysql> UPDATE parent sET id=3 WherE id=l;
Query Ok, 1 row affected (0.00 sec)
Rows matched: 1 Changed: 1 Warnings: C
在会话B中将事务表 parent中id为1的记录修改为id=3,但是事务同样没有提交,
这样id=1的行其实加了一个X锁。这时如果在会话A中再次读取id为1的记录,根
据 InnoDB存储引擎的特性,即在 READ COMMITTED和 REPEATETABLE READ的
事务隔离级别下会使用非锁定的一致性读。回到之前的会话A,接着上次未提交的事
务,执行SQL语句 SELECT* FROM parent WhERE ic=1的操作,这时不管使用READ
COMMITTED还是 REPEATABLE READ的事务隔离级别,显示的数据应该都是:
mysl> SELECT FROM parent WHERE id -li
id
1
1r。 w in set(0.00sec)
由于当前id=1的数据被修改了1次,因此只有一个行版本的记录。接着,在会话B
中提交上次的事务:
f Session H
mysql> commit;
Query Ok, 0 rows affected (o,01 sec)
在会话B提交事务后,这时在会话A中再运行 SELECT* FROM parent WHERE
id=1的SQL语句,在 READ COMMITTED和 REPEATABLE事务隔离级别下得到结果
就不一样了。对于 READ COMMITTED的事务隔离级别,它总是读取行的最新版本,
如果行被锁定了,则读取该行版本的最新一个快照( fresh snapshot)。在上述例子中,因
为会话B已经提交了事务,所以 READ COMMITTED事务隔离级别下会得到如下结果
mysql> SELECT etx isolation\G;
★飞青青害宙南古音害★肯★★★★★★★★★★★1.row*k★旋★★读★★★★★★★★★内★★*★青★★
eetx isolation: READ-COMMITTED
1 row in set (0.00 sec)
mysql> SELECT FROM Parent WHERE id =1
Empty set (0.00 sec)http:/blog.csdnnet/jiongyi11
51.A
63 nnoDE存储引擎中收261
部拼吾患
而对于 REPEATABLE READ的事务隔离级别,总是读取事务开始时的行数据。因●
召器
此对于 REPEATABLE READ事务隔离级别,其得到的结果如下:
mysql> SELECT @etx isolation\Gi
★肃古贡肯★青古★★★大★★★★★★责★★★★貴1
QW青★卉青★★青★为★★★★★★★★★舜★向★★
eatx isolation: REPEATABLE-READ
1 row in get《0,00sec)
mysql> SELECT FROM parent WHERE id
I id
1 row in set (0.00 sec)
下面将从时间的角度展现上述演示的示例过程,如表6-8所示。需要特别注意的是,
对于 READ COMMITTED的事务隔离级别而言,从数据库理论的角度来看,其违反了
事务ACID中的I的特性,即隔离性。这会在第7章进行详细的介绍。
表68示例执行的过程
时间
会话A
会话B
BEGIN
SELECT FROM parent
234
WhERE id=1
BEGIN
uPDATE parent SET id=3
WheRE id= 1:
SELECT* FROM parent
WheRE id=1:
5678
COMMIT
SELECT FROM parent
whErE id=l:
COMMIT
633一致性锁定读
在前一小节中讲到,在默认配置下,即事务的隔离级别为 REPEATABLE READ模
式下, InnoDB存储引擎的 SELECT操作使用致性非锁定读。但是在某些情况下,用
户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支http:/blog.csdnnet/jiongyi11
51.6
262第6莩
部拼吾
持加锁语句,即使是对于 SELECT的只读操作。IoDB存储引擎对于 SELECT语句支
召擦器
持两种一致性的锁定读( locking read)操作:
口 SELECT… FOR UPDATE
口 SELECT… LOCK IN SHARE MODE
SELECT… FOR UPDATE对读取的行记录加一个ⅹ锁,其他事务不能对已锁定的行
加上任何锁。 SELECT… LOCK IN SHARE MODE对读取的行记录加一个S锁,其他事
务可以向被锁定的行加S锁,但是如果加X锁,则会被阻塞。
对于一致性非锁定读,即使读取的行已被执行了 SELECT… FOR UPDATE,也是可
以进行读取的,这和之前讨论的情况一样。此外, SELECT… FOR UPDATE, SELECT…
LOCK IN SHARE MODE必须在一个事务中,当事务提交了,锁也就释放了。因此在使
用上述两句 SELECT锁定语句时,务必加上 BEGIN, START TRANSACTION或者SET
AUTOCOMMIT=0。
634自增长与锁
自增长在数据库中是非常常见的一种属性,也是很多DBA或开发人员首选的主键
方式。在 InnoDB存储引擎的内存结构中,对每个含有自增长值的表都有一个自增长计
数器(auto- -increment counter)。当对含有自增长的计数器的表进行插入操作时,这个计
数器会被初始化,执行如下的语句来得到计数器的值:
SELECt MAX (auto inc col) FROM t FOR UPDATE:
插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做
AUTO- NC Locking。这种锁其实是采用一种特殊的表锁机制,为了提高插入的性能,锁
不是在一个事务完成后才释放,而是在完成对自增长值插入的SQL语句后立即释放。
虽然AUTO- INC Locking从一定程度上提高了并发插入的效率,但还是存在一些性
能上的问题。首先,对于有自增长值的列的并发插入性能较差,事务必须等待前一个插
入的完成(虽然不用等待事务的完成)。其次,对于 INSERT… SELECT的大数据量的插
人会影响插人的性能,因为另一个事务中的插入会被阻塞
从 MySQL5.1.22版本开始, InnoDE存储引擎中提供了一种轻量级互斥量的自增长
实现机制,这种机制大大提高了自增长值插入的性能。并且从该版本开始, InnoDB存储
引擎提供了一个参数 innodb autoinc lock mode来控制自增长的模式,该参数的默认值为http://blog.csdn.net/jiongyi1
6I
63 InnoDB存儲引擎中的锁263
部拼没
l。在继续讨论新的自增长实现方式之前,需要对自增长的插入进行分类,如表69所示
表6-9插入类型
插入类型
说明
insert-ike
insert-Iike指所有的插人语句,如 INSERT、 REPLACe、 INSERT.SELECT,
EPLACE… SEECT、 LOAD DATA等
simple inserts指能在插入前就确定插入行数的语句。这些语句包括 INSERT、
simple inserts
REPLACE等。需要注意的是; simple inserts不包含 INSERT… ON DUPLICATE KEY
UPDATE这类SQL语句
bulk inserts指在插人前不能确定得到插入行数的语句,如 INSERT… SELECT
bulk inserts
REPLACE SELECT, LOAD DATA
miκ ed-mode inserts指插人中有一部分的值是自增长的,有一部分是确定的。如
mixed-mode inserts| INSERT INTO tl (cl,2) VALUES(,4,NULb),,),(NULL;);也可以是指
INSERT… ON DUPLICATE KEY UPDATL这类SQL语句
接着来分析参数 innodb autoinc lock mode以及各个设置下对自增的影响,其总共
有三个有效值可供设定,即0、1、2,具体说明如表6-10所示。
表610参数 innodb autoinc lock mode的说明
nnodb autoinc lock mode
说明
这是 MySQL5122版本之前自增长的实现方式,即通过表锁的 AUTO-INC
0
ocking方式。因为有了新的自增长实现方式,0这个选项不应该是新版用户的首
选项
这是该参数的默认值。对于“ simple inserts",该值会用互斥量( mutex)去对内
存中的计数器进行累加的操作。对于“ bulk inserts”,还是使用传统表锁的 AUTO
INC Locking方式。在这种配置下,如果不考虑回滚操作,对于自增值列的增长还
是连续的。并且在这种方式下, statement- based方式的 replication还是能很好地工
作。需要注意的是,如果已经使用AUTO- NC Losing方式去产生自增长的值,而
这时需要再进行“ simple inserts”的操作时,还是需要等待 AUTO-INC Locking的
释放
在这个模式下,对于所有“ INSERT-ike”自增长值的产生都是通过互斥量,而
不是AUTO- INC Locking的方式。显然,这是性能最高的方式。然而,这会带来
定的问题。因为并发插人的存在,在每次插入时,自增长的值可能不是连续的。
此外,最重要的是,基于 Statement-Base Replication会出现问题。因此,使用这个
模式,任何时候都应该使用 rnw-hase replication,这样才能保证最大的并发性能及
replication主从数据的一致
此外,还需要特别注意的是 InnoDB存储引擎中自增长的实现和 MyISAM不同,
MyIsAM存储引擎是表锁设计,自增长不用考虑并发插入的问题。因此在 master上用
InnoDB存储引擎,在 slave上用 MyISAM存储引擎的 replication架构下,用户必须考虑
这种情况。http://blog.csdn.net/jiongyi1
5
264郭6频
部拼吾
另外,在 InnoDB存储引擎中,自增长值的列必须是索引,同时必须是索引的第命
个列。如果不是第一个列,则 My SQL数据库会抛出异常,而 MyISAM存储引擎没有这
个问题,下面的测试反映了这两个存储引擎的不同
mysql> CREATE TABLE t t
工 NT AUTO INCREMENT
B工N
KEY(b, a)
-2)ENGINE=InnoDB i
ERROR 1075(42000): Incorrect table definition, there can be only one auto
column and it must be defined as a key
mysql> CREATE TABLE t
a INT AUTO INCREMENT,
B INT,
>KEY(上,a)
)ENGINE=MY I SAMF
Query OK, 0 rows affected (0.01 sec)
635外键和锁
前面已经介绍了外键,外键主要用于引用完整性的约束检查。在 InnoDB存储引擎
中,对于一个外键列,如果没有显式地对这个列加索引, InnoDB存储引擎自动对其加
个索引,因为这样可以避免表锁——这比 Oracle数据库做得好, Oracle数据库不会自动
添加索引,用户必须自己手动添加,这也导致了 Oracle数据库中可能产生死锁。
对于外键值的插入或更新,首先需要查询父表中的记录,即 SELECT父表。但是对
于父表的 SELECT操作,不是使用一致性非锁定读的方式,因为这样会发生数据不一致
的问题,因此这时使用的是 SELECT… LOCK IN SHARE MODE方式,即主动对父表加
一个S锁。如果这时父表上已经这样加x锁,子表上的操作会被阻塞,如表6-11所示
表6-11外键测试用例
时间
会话A
会话B
BEGIN
DELETE FROM parent WHERE id=3
BEGIN
INSERT INTO child SELECT 2.3
#第二列是外键,执行该句时被阻塞
aitinghttp:/blog.csdnnet/jiongyi11
5
64锁的算法265
在上述的例子中,两个会话中的事务都没有进行COMM或 ROLLA《K操作,
而会话B的操作会被阻塞。这是因为id为3的父表在会话A中已经加了一个X锁,而
此时在会话B中用户又需要对父表中id为3的行加一个S锁,这时 INSERT的操作会被
阻塞。设想如果访问父表时,使用的是一致性的非锁定读,这时 Session b会读到父表
有id=3的记录,可以进行插人操作。但是如果会话A对事务提交了,则父表中就不存
在id为3的记录。数据在父、子表就会存在不一致的情况。若这时用户查询 INNODB
LOCKS表,会看到如下结果
mysql> SELECT* FROM information schema, INNODB LOCKS\G:
肯青责青古肯古青青青西由西西而
1.xoW★★★★★★★★★★大★★★★★★★★湾六★南★走
1。cki6:7573B8:96:3:4
lock trx id: 7573B8
lock mode: s
lock type: RECORD
lock table: mytest,parent
lock index: PRIMARy
ck space: 96
1。 ck page:3
lock rec: 4
lock data: 3
害古晋★古青★★★★★★责青★★★★★★★t★★★★
2,r。w内青青t★卖责★★★★责★★★★★食★★★★★★实★
ock id:?573B3:96:3:4
lock trx id: 7573B3
lock mode: x
1。 ck type: RECORD
lock table: "mytest. 'parent
lock index: F PRIMARY I
lock space: 96
1。 ck page:3
lock
lock data: 3
2r。 ws in set〔0.00sec)
64锁的算法
641行锁的3种算法
InnoDB存储引擎有3种行锁的算法,其分别是:
日 Record lock:单个行记录上的锁http:/blog.csdnnet/jiongyi11
266第6章锁
口 Gap Lock:间隙锁,锁定一个范围,但不包含记录本身
Next-Key Lock: Gap Lock+ Record lock,锁定一个范围,并且锁定记录本身
Record lock总是会去锁住索引记录,如果 InnoDB存储引擎表在建立的时候没有设
置任何一个索引,那么这时 InnoDB存储引擎会使用隐式的主键来进行锁定。
Next-Key Lock是结合了 Gap Lock和 Record Lock的一种锁定算法,在 Next-Key
Lock算法下, InnoDB对于行的查询都是采用这种锁定算法。例如一个索引有10,1l
13和20这四个值,那么该索引可能被 Next-Key Locking的区间为
10]
【10,11]
11,13]
13,20
20+∞)
采用 Next-Key Lock的锁定技术称为 Next-Key Locking。其设计的目的是为了解
决 Phantom Problem,这将在下一小节中介绍。而利用这种锁定技术,锁定的不是单个
值,而是一个范围,是谓词锁( predict lock)的一种改进。除了next- key locking,还
有 previous- key locking技术。同样上述的索引10、11、13和20,若采用 previous-key
locking技术,那么可锁定的区间为:
10)
[10,11
[11,13
13,20
[20+∞)
若事务T1已经通过next- key locking锁定了如下范围:
10,11]、(11,13
当插入新的记录12时,则锁定的范围会变成:
10,11]、(11,12]、(12,13]
然而,当查询的索引含有唯一属性时, InnoDB存储引擎会对Next- Key lock进行优
化,将其降级为 Record lock,即仅锁住索引本身,而不是范围。看下面的例子,首先根
据如下代码创建测试表t
DROP TABLE IF EXISTS t:http://blog.csdn.net/jiongyi1
51.
64的算法207
CREATE TABLE t( a INT PRIMARY KEY )i
INSERT INTO t SELECT 1;
INSERT INTC t SELECt 2
INSERT INTo t SElECT 5:
接着来执行表6-12中的SQL语句。
表6-12唯一索引的锁定示例
时间
会话A
会话B
BEGIN:
SELECT FROM t
WHERE a=s FOR UPdate
2345
BEGIN:
INSERT INTO t SeleCT 4
COMMIT
#成功,不需要等待
COMMIT
表t共有1、2、5三个值。在上面的例子中,在会话A中首先对a=5进行ⅹ锁定。
而由于a是主键且唯一,因此锁定的仅是5这个值,而不是(2,5)这个范围,这样在会
话B中插入值4而不会阻塞,可以立即插入并返回。即锁定由Next- Key Lock算法降级
为了 Record Lock,从而提高应用的并发性。
正如前面所介绍的, Next-Key Lock降级为 Record Lock仅在查询的列是唯一索引的
情况下。若是辅助索引,则情况会完全不同。同样,首先根据如下代码创建测试表z
CREATE TABLE z( a INT, b INT, PRIMARY KEY(a) key (b))
INSERT INTC z sElECT 11:
INSERT INTO Z SELECT 3, 1
INSERT INTO Z SELECT 5,3F
INSERT INT Z SELECT 7, 6:
INSERT INTC Z SELECT 10,8;
表z的列b是辅助索引,若在会话A中执行下面的SQL语句:
SELECT FROM Z WHERE D=3 FOR UPDATE
很明显,这时SoL语句通过索引列b进行查询,因此其使用传统的 Next-Key
Locking技术加锁,并且由于有两个索引,其需要分别进行锁定。对于聚集索引,其仅
对列a等于5的索引加上 Record lock。而对于辅助索引,其加上的是 Next-Key Lock,
锁定的范围是(1,3),特别需要注意的是, InnoDB存储引擎还会对辅助索引下一个键值http://blog.csdn.net/jiongyi1
I
268第6幸颔
加上 gap lock,即还有一个辅助索引范围为(3,6)的锁。因此,若在新会话史运行
面的SQL语句,都会被阻塞
SELECT★ FROM Z WHERE a=5LoCK工 N SHARE MODE
INSERT INT。 Z SELECT42
INSERT INTO Z SELECT 65;
第一个SQL语句不能执行,因为在会话A中执行的SQL语句已经对聚集索引中列a
5的值加上ⅹ锁,因此执行会被阻塞。第二个SQL语句,主键插人4,没有问题,但是
插入的辅助索引值2在锁定的范围(1,3)中,因此执行同样会被阻塞。第三个SQL语句,
插人的主键6没有被锁定,5也不在范围(1,3)之间。但插入的值5在另一个锁定的范围
(3,6)中,故同样需要等待。而下面的SQL语句,不会被阻塞,可以立即执行:
INSERT工 NTO Z SELEO8;6
INSERT INTO Z SELECT 20:
INSERT INTO Z SELECT 6.7
从上面的例子中可以看到, Gap Lock的作用是为了阻止多个事务将记录插人到同
范围内,而这会导致 Phantom roblem问题的产生。例如在上面的例子中,会话A中用
户已经锁定了b=3的记录。若此时没有 Gap Lock锁定(3,6),那么用户可以插人索
引b列为3的记录,这会导致会话A中的用户再次执行同样查询时会返回不同的记录,
即导致 Phantom problen问题的产生。
用户可以通过以下两种方式来显式地关闭 Gap Lock
口将事务的隔离级别设置为 READ COMMITTED
口将参数 innodb locks unsafe for binlog设置为1
在上述的配置下,除了外键约束和唯性检查依然需要的 Gap Lock,其余情况仅使
用 Record lock进行锁定。但需要牢记的是,上述设置破坏了事务的隔离性,并且对于
replication,可能会导致主从数据的不一致。此外,从性能上来看, READ COMMITTED
也不会优于默认的事务隔离级别 READ REPEATABLE。
在 InnoDB存储引擎中,对于Ⅰ NSERT的操作,其会检查插入记录的下一条记录是
否被锁定,若已经被锁定,则不允许查询。刈于上面的例子,会话A已经锁定了表z中
b=3的记录,即已经锁定了(1,3)的范围,这时若在其他会话中进行如下的插入同样
会导致阻塞:
INSERT INTO Z SELECT 2 2http:/blog.csdnnet/jiongyi11
51.6
64贫的算法269
因为在辅助索引列b上插入值为2的记录时,会监测到下一个记录3已经被索引
而将插入修改为如下的值,可以立即执行:
INSERT INTO Z SELECT 20:
最后需再次提醒的是,对于唯一键值的锁定, Next-Key Lock降级为 Record Lock
仅存在于查询所有的唯一索引列。若唯一索引由多个列组成,而查询仅是查找多个唯
一索引列中的其中一个,那么查询其实是 range类型查询,而不是 point类型查询,故
InnoDB存储引擎依然使用Next- Key Lock进行锁定。
642解决 Phantom prob|em
在默认的事务隔离级别下,即 REPEATABLE READ下, InMoDE存储引擎采用
Next-Key Locking机制来避免 Phantom problem(幻像问题)。这点可能不同于与其他的
数据库,如 Oracle数据库,因为其可能需要在 SERIALIZABLE的事务隔离级别下才能
解决 Phantom Problem。
Phantom problen是指在同一事务下,连续执行两次同样的SQL语句可能导致不同
的结果,第二次的SQL语句可能会返回之前不存在的行。下面将演示这个例子,使用前
小节所创建的表t。表t由1、2、5这三个值组成,若这时事务Tl执行如下的SQL语句:
SELECT FRoM t WhERE a>2 FOR UPDATE
注意这时事务T1并没有进行提交操作,上述应该返回5这个结果。若与此同时,
另一个事务T2插入了4这个值,并且数据库允许该操作,那么事务T1再次执行上述
S。L语句会得到结果4和5。这与第一次得到的结果不同,违反了事务的隔离性,即当
前事务能够看到其他事务的结果。其过程如表6-13所示。
表613 Phantom Problem的演示
时间
会话A
会话B
SET SESSION
tx isolation=READ-OMMITTED
2
BEGIN
SELECT· FROM t
WHERE a>2 FOR UPDAtE:
率丰率幸中*1.【0W中中中中中中事事http:/blog.csdnnet/jiongyi11
270菜6幸锁
酱时考翻
续)委
时间
会话A
会话B
4
BEGIN
InSerT INTO t seleCt 4
6
COMMIT
SELECT率 FROM t
WHERE a>2 FOR UPDATE
中中中中率率中率2,了Ow中中率申亭中中
InnoDB存储引擎采用 Next-Key Locking的算法避免 Phantom Problem。对于上述的
SQL语句 SELECT* FROM t Where a>2 FOR UPDATE,其锁住的不是5这单个值,而
是对(2,+∞)这个范围加了X锁。因此任何对于这个范围的插人都是不被允许的,从
而避免 Phantom Problem
InnoDB存储引擎默认的事务隔离级别是 REPEATABLE READ,在该隔离级别下,
其采用 Next-Key Locking的方式来加锁。而在事务隔离级别 READ COMMITTED下,
其仅采用 Record lock,因此在上述的示例中,会话A需要将事务的隔离级别设置为
READ COMMITTED。
此外,用户可以通过 InnoDB存储引擎的 Next-Key Locking机制在应用层面实现唯
一性的检查。例如
SELECT * FRom table WHERE COl=xxX LOCK IN SHARE MODE
If not found any row:
H unique for insert value
INSERT INTo table values (.x
如果用户通过索引查询一个值,并对该行加上一个 SLock,那么即使查询的值不在,
其锁定的也是一个范围,因此若没有返回任何行,那么新插入的值一定是唯一的。也许
有读者会有疑问,如果在进行第一步 SELECT… LOCK IN SHARE MODE操作时,有多
个事务并发操作,那么这种唯一性检查机制是否存在问题。其实并不会,因为这时会导
致死锁,只有一个事务的插人操作会成功,而其余的事务会抛出死锁的错误,如表6-14
所示http://blog.csdn.net/jiongyi1
5
65问题2n
表6-14通过Next- Key Locking实现应用程序的唯一性检查
时间
会话A
会话B
BEGIN
mysql>sEleCt* From z
WherE b=4
LOCK IN SHARE MODE
mysqIsELECT FrOM z
WHERE b=4
LOCK IN SHARE MODE
mysql>INSERT INTO Z SELECT 4, 4
#阻塞
mySql>INSERT INTO z
SELECT4 4
5
ERROR 1213(40001): Dcadlock found when
trying to get lock; try restarting transaction
#抛出死锁异常
6
# INSERT插入成功
65锁问题
通过锁定机制可以实现事务的隔离性要求,使得事务可以并发地工作。锁提高了
并发,但是却会带来潜在的问题。不过好在因为事务隔离性的要求,锁只会带来三种问
题,如果可以防止这三种情况的发生,那将不会产生并发异常。
651脏读
在理解脏读( Dirty Read)之前,需要理解脏数据的概念。但是脏数据和之前所介绍
的脏页完全是两种不同的概念。脏页指的是在缓冲池中已经被修改的页,但是还没有刷
新到磁盘中,即数据库实例内存中的页和磁盘中的页的数据是不一致的,当然在刷新到
磁盘之前,日志都已经被写入到了重做日志文件中。而所谓脏数据是指事务对缓冲池中
行记录的修改,并且还没有被提交( commit)。
对于脏页的读取,是非常正常的。脏页是因为数据库实侧内存和磁盘的异步造成的,
这并不影响数据的一致性(或者说两者最终会达到一致性,即当脏页都刷回到磁盘)。并
且因为脏页的刷新是异步的,不影响数据库的可用性,因此可以带来性能的提高。
脏数据却截然不同,脏数据是指未提交的数据,如果读到了脏数据,即一个事务可http:/blog.csdnnet/jiongyi11
51.6
272笫6章繽
时实要
以读到另外一个事务中未提交的数据,则显然违反了数据库的隔离性。
脏读指的就是在不同的事务下,当前事务可以读到另外事务未提交的数据,简单来
说就是可以读到脏数据。表6-15的例子显示了一个脏读的例子。
表6-15脏读的示例
Time
会话A
会话B
SET
@@tx isolation=read-ncommitted'
SET
@atx isolation='read-ncommitted
3
BEGIN
mysql> SELECT FROM t\G
率***靠率1,row本本本事昨事本事本卓事事
I row in set(0.00 sec
5
INSERT INTO t SELECT 2:
mysql> SELECT+ FROM tG
中中中申中中中申申1,『ow申市审康表市幸
中中章率*2.row靠春本串本本本毒本丰
2
2 row in sct (0.00 sec)
表t为我们之前在641中创建的表,不同的是在上述例子中,事务的隔离级别进行
了更换,由默认的 REPEATABLE READ换成了 READ UNCOMMITTED。因此在会话A
中,在事务并没有提交的前提下,会话B中的两次 SELECT操作取得了不同的结果,并
且2这条记录是在会话A中并未提交的数据,即产生了脏读,违反了事务的隔离性。
脏读现象在生产环境中并不常发生,从上面的例子中就可以发现,脏读发生的
条件是需要事务的隔离级别为 READ UNCOMMITTED,而目前绝大部分的数据库都
至少设置成 READ COMMITTED。 InnoDB存储引擎默认的事务隔离级别为READ
REPEATABLE, Microsoft sQL Server数据库为 READ COMMITTED, Oracle数据库同
样也是 READ COMMITTED。
脏读隔离看似毫无用处,但在一些比较特殊的情况下还是可以将事务的隔离级别设
置为 READ UNCOMMITTED。例如 replication环境中的 slave节点,并且在该save上
的查询并不需要特别精确的返回值。http:/blog.csdnnet/jiongyi11
5I.A
65縝题27
6.52不可重复读
不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时
另外一个事务也访问该同一数据集合,并做了一些DML操作。因此,在第一个事务中
的两次读数据之间,由于第二个事务的修改,那么第一个事务两次读到的数据可能是不
样的。这样就发生了在一个事务内两次读到的数据是不一样的情况,这种情况称为不
可重复读。
不可重复读和脏读的区别是:脏读是读到未提交的数据,而不可重复读读到的却是
已经提交的数据,但是其违反了数据库事务一致性的要求。可以通过下面一个例子来观
察不可重复读的情况,如表6-16所示。
表6-16不可重复读的示例
Time
会话A
会话B
SET@Ctx isolation-read-committed,
SeT @@tx isolation=read-committed
BEGIN
BEGIN
mysq> SELECT平 FROM t;
申中申申中1.roW
I row in set(.00 sec)
5
INSERT INTO t SELECT 2
6
COMMIT
mysqlSELECT"FROM t
本率·1,rOw*毒事率*率浓
7
本本本本事事事1,row*丰本事事本本事布率
2 row in set(0.00 sec)
在会话A中开始一个事务,第一次读取到的记录是1,在另一个会话B中开始了
另一个事务,插入一条为2的记录,在没有提交之前,对会话A中的事务进行再次读
取时,读到的记录还是1,没有发生脏读的现象。但会话B中的事务提交后,在对会话
A中的事务进行读取时,这时读到是1和2两条记录。这个例子的前提是,在事务开始
前,会话A和会话B的事务隔离级别都调整为 READ COMMITTED。
一般来说,不可重复读的问题是可以接受的,因为其读到的是已经提交的数据,本
身并不会带来很大的问题。因此,很多数据库厂商(如 Oracle、 Microsoft SQL Server)http:/blog.csdnnet/jiongyi11
51.6
274茅6字绞
将其数据库事务的默认隔离级别设置为 READ COMMITTEI,在这种隔离级别下允许矿
盛
可重复读的现象。
在 InnoDB存储引擎中,通过使用 Next-Key Lock算法来避免不可重复读的问题。在
MySQL官方文档中将不可重复读的问题定义为 Phantom problem,即幻像问题。在Next
Key lock算法下,对于索引的扫描,不仅是锁住扫描到的索引,而且还锁住这些索引覆
盖的范围(gap)。因此在这个范围内的插入都是不允许的。这样就避免了另外的事务在
这个范围内插入数据导致的不可重复读的问题。因此, InnoDB存储引擎的默认事务隔离
级别是 READ REPEATABLE,采用Next- Key lock算法,避免了不可重复读的现象。
653丢失更新
丢失更新是另一个锁导致的问题,简单来说其就是一个事务的更新操作会被另一个
事务的更新操作所覆盖,从而导致数据的不一致。例如:
1)事务T1将行记录r更新为vl,但是事务T1并未提交。
2)与此同时,事务T2将行记录r更新为v2,事务T2未提交。
3)事务T1提交。
4)事务T2提交。
但是,在当前数据库的任何隔离级别下,都不会导致数据库理论意义上的丢失更新
问题。这是因为,即使是 READ UNCOMMITTED的事务隔离级别,对于行的DML操
作,需要对行或其他粗粒度级别的对象加锁。因此在上述步骤2)中,事务T2并不能对
行记录r进行更新操作,其会被阻塞,直到事务T1提交。
虽然数据库能阻止丢失更新问题的产生,但是在生产应用中还有另一个逻辑意义的
丢失更新问题,而导致该问题的并不是因为数据库本身的问题。实际上,在所有多用户
计算机系统环境下都有可能产生这个问题。简单地说来,出现下面的情况时,就会发生
丢失更新
1)事务T1查询一行数据,放人本地内存,并显示给一个终端用户 User1。
2)事务T2也查询该行数据,并将取得的数据显示给终端用户User2。
3) User修改这行记录,更新数据库并提交。
4)User2修改这行记录,更新数据库并提交。http://blog.csdn.net/jiongyi1
65锁问题275
显然,这个过程中用户Uerl的修改更新操作“丢失”了,而这可能会导致一
,
“恐怖”的结果。设想银行发生丢失更新现象,例如一个用户账号中有10000元人民币
他用两个网上银行的客户端分别进行转账操作。第一次转账9000人民币,因为网络和
数据的关系,这时需要等待。但是这时用户操作另一个网上银行客户端,转账1元,如
果最终两笔操作都成功了,用户的账号余款是999民币,第一次转的9000人民币并
没有得到更新,但是在转账的另一个账号却会收到这9000元,这导致的结果就是钱变
多,而账不平。也许有读者会说,不对,我的网银是绑定 USB Key的,不会发生这种情
况。是的,通过 USB Key登录也许可以解决这个问题,但是更重要的是在数据库层解决
这个问题,避免任何可能发生丢失更新的情况。
要避免丢失更新发生,需要让事务在这种情况下的操作变成串行化,而不是并行的
操作。即在上述四个步骤的1)中,对用户读取的记录加上一个排他X锁。同样,在步
骤2)的操作过程中,用户同样也需要加一个排他Ⅹ锁。通过这种方式,步骤2)就必
须等待一步骤1)和步骤3)完成,最后完成步骤4)。表6-17所示的过程演示了如何避
免这种逻辑上丢失更新问题的产生。
表6-17丢失更新问题的处理方法
Time
会话A
会话B
BEGIN
SELECT cash into @cash
FROM account
WhERE user= USer FOR UPDATE;
SELECT cash into(gcash
FROM account
WHERE user=pUser FOR UPDATE:
等待
鲁!曾
UPDATE account
SET cash=tacash-9000
WhERE userpUser
m+1
COMMIT
UPDATE account set cash=@cash-I
WHERE userpUser,
0+3
COMMIT
有读者可能会问,在上述的例子中为什么不直接允许 UPDATE语句,而首先要进行
SELECT… FOR UPDATE的操作。的确,直接使用 UPDATE可以避免丢失更新问题的产http:/blog.csdnnet/jiongyi11
5
27第6幸锁
生。然而在实际应用中,应用程序可能需要首先检测用户的余额信息,查看是否可以进
行转账操作,然后再进行最后的 UPDATE操作,因此在 SELECT与 UPDATE操作之间
可能还存在一些其他的SoL操作。
我发现,程序员可能在了解如何使用 SELECT、 INSERT、 UPDATE、 DELETE语
句后就开始编写应用程序。因此,丢失更新是程序员最容易犯的错误,也是最不易发
现的一个错误,因为这种现象只是随机的、零星出现的,不过其可能造成的后果却十
分严重。
66阻塞
因为不同锁之间的兼容性关系,在有些时刻一个事务中的锁需要等待另一个事务中
的锁释放它所占用的资源,这就是阻塞。阻塞并不是一件坏事,其是为了确保事务可以
并发且正常地运行。
在 InnoDB存储引擎中,参数 innodb lock wait timeout用来控制等待的时间(默认
是50秒), innodb rollback on timeout用来设定是否在等待超时时对进行中的事务进行
回滚操作(默认是OFF,代表不回滚)。参数 innodb lock wait timeout是动态的,可以
在 MySQL数据库运行时进行调整:
mysql> set @@innodb lock wait timeout=60;
Query Ok, 0 rows affected (0.00 sec)
而 innodb rollback on timeout是静态的,不可在启动时进行修改,如:
mysql> seT e@innodb rollback on timeout=on;
ERROR 1238 (HY000):Variable 'innodb rollback on timeout is a read only
variable
当发生超时, MySQL数据库会抛出一个1205的错误,如
mySql> BEGIN;
Query OK, o rows affecTed (0.00 sec)
mysql> sElect FROM t WhERE a =1 FORUPDATE
ERROR 1205 (HY000]: Lcck wait timeout exceeded: try restarting transaction
需要牢记的是,在默认情况下 InnoDB存储引擎不会回滚超时引发的错误异常。其
实 InnoDB存储引擎在大部分情况下都不会对异常进行回滚。如在一个会话中执行了如http:/blog.csdnnet/jiongyi11
5I.
66哂寨277
挤吾
下语句:
暑会话A
mysql> SELECT * FROM ti
124
3 rows in set (0.oo sec)
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)
mysql> sELEcT FRoM t WHERE a 4 FOR UPDATE:
2 rows in set 0.00 sec)
在会话A中开启了一个事务,在 Next-Key Lock算法下锁定了小于4的所有记录
(其实也锁定了4这个记录本身)。在另一个会话B中执行如下语句:
暑会话B
mysqL> BEGIN:
Query OK, 0 rows affected (0.00 secy
mysql> INSERT INTo t SELECT 5:
Query Ok l row affected 10.00 sec)
Records
Duplicates: 0 Warnings: 0
mysql> INSERTINTO t SELECT 3;
ERROR 1205 (HY000]: Lock wait timeout exceeded; try restarting transaction
可以看到,在会话B中插入记录5是可以的,但是在插入记录3时,因为会话A中
Next-Key Lock算法的关系,需要等待会话A中事务释放这个资源,所以等待后产生了
超时。但是在超时后用户再进行 SELECT操作时会发现,5这个记录依然存在:
mysql>SELECT FROM tihttp:/blog.csdnnet/jiongyi11
5
278韩6章锁
12458
5 rows in set (0.00 sec
这是因为这时会话B中的事务虽然抛出了异常,但是既没有进行 COMMIT操
作,也没有进行 ROLLBACK。而这是十分危险的状态,因此用户必须判断是否需要
COMM还是 ROLLBACK,之后再进行下一步的操作
67死锁
671死锁的概念
死锁是指两个或两个以上的事务在执行过程中,因争夺锁资源而造成的一种互相等待
的现象。若无外力作用,事务都将无法推进下去。解决死锁问题最简单的方式是不要有等
待,将任何的等待都转化为回滚,并且事务重新开始。毫无疑问,这的确可以避免死锁问
题的产生。然而在线上环境中,这可能导致并发性能的下降,甚至任何一个事务都不能进
行。而这所带来的问题远比死锁问题更为严重,因为这很难被发现并且浪费资源
解决死锁问题最简单的一种方法是超吋,即当两个事务互相等待时,当一个等待时
间超过设置的某一阈值时,其中一个事务进行回滚,另一个等待的事务就能继续进行。
在 InnoDB存储引擎中,参数 innodb lock wait timeout用来设置超时的时间。
超时机制虽然简单,但是其仅通过超时后对事务进行回滚的方式来处理,或者说其
是根据FIFO的顺序选择回滚对象。但若超时的事务所占权重比较大,如事务操作更新
了很多行,占用了较多的 undo log,这时采用FIFO的方式,就显得不合适了,因为回滚
这个事务的时间相对另一个事务所占用的时间可能会很多。
因此,除了超时机制,当前数据库还都普遍采用 wait-for graph(等待图)的方式来
进行死锁检测。较之超时的解决方案,这是一种更为主动的死锁检测方式。 InnoDB存储
引擎也采用的这种方式。 wait-for graph要求数据库保存以下炳种信息http://blog.csdn.net/jiongyi1
5
67死锁279
部拼
口锁的信息链表
你
口事务等待链表
通过上述链表可以构造出一张图,而在这个图中若存在回路,就代表存在死锁,因
此资源间相互发生等待。在 wait-for graph中,事务为图中的节点。而在图中,事务Tl
指向T2边的定义为:
口事务T1等待事务T2所占用的资源
口事务T1最终等待T2所占用的资源,也就是事务之间在等待相同的资源,而事务
Tl发生在事务T2的后面
下面来看一个例子,当前事务和锁的状态如图6-5所示
Transaction
Lock lists
wait Lists
Tow
t2. x
row 2
tl: s
tI:s
t4: s
12:x
t
t3: x
图6-5示例事务状态和锁的信息
在 Transaction wait lists中可以看到共有4个事务t1、t2、t3、t4,故在wait-for
graph中应有4个节点。而事务t2对row占用x锁,事务t对row2占用s锁。事务tl
需要等待事务t中row1的资源,因此在wait- for graph中有条边从节点t1指向节点t2。
事务12需要等待事务t、1所占用的row2对象,故而存在节点t到节点t、t4的边。
同样,存在节点t3到节点t、t、4的边,因此最终的 wait-for graph如图6-6所示
通过图6-6叮以发现存在回路(tl,t),因此存在死锁。通过上述的介绍,可以发现
wait-for graph是一种较为主动的死锁检测机制,在每个事务请
求锁并发生等待时都会判断是否存在回路,若存在则有死锁,(t
通常来说 InnoDB存储引擎选择回滚udo量最小的事务。
wait-for graph的死锁检测通常采用深度优先的算法实现,
在 InnoDB12版本之前,都是采用递归方式实现。而从12版
本开始,对wait- or graph的死锁检测进行了优化,将递归用图66 wait-for graphhttp:/blog.csdnnet/jiongyi11
EI
280第6幸锁
拼吾
非递归的方式实现,从而进一步提高了 InnoDB存储引擎的性能。
672死锁概率
死锁应该非常少发生,若经常发生,则系统是不可用的。此外,死锁的次数应该还
要少于等待,因为至少需要2次等待才会产生一次死锁。本节将从纯数学的概率角度来
分析,死锁发生的概率是非常小的。
假设当前数据库中共有n+1个线程执行,即当前总共有n+1个事务。并假设每个事
务所做的操作相同。若每个事务由r1个操作组成,每个操作为从R行数据中随机地操
作一行数据,并占用对象的锁。每个事务在执行完最后一个步骤释放所占用的所有锁资
源。最后,假设n<R,即线程操作的数据只占所有数据的一小部分。
在上述的模型下,事务获得一个锁需要等待的概率是多少呢?当事务获得一个锁,
其他任何一个事务获得锁的情况为:
(1+2+3+…+r)1(r+1)≈P/2
由于每个操作为从R行数据中取一条数据,每行数据被取到的概率为1/R,因此
事务中每个操作需要等待的概率PW为;
PW=nr/2R
事务是由r个操作所组成,因此事务发生等待的概率PW()为:
P()=1-(-PM=P=2R
死锁是由于产生回路,也就是事务互相等待而发生的,若死锁的长度为2,即两个
等待节点间发生死锁,那么其概率为:
个事务发生死锁的概率≈P"()≈n
4R
由于大部分死锁发生的长度为2,因此上述公式基本代表了一个事务发生死锁的概
率。从整个系统来看,任何一个事务发生死锁的概率为:
系统中任何一个事务发生死锁的概率≈m
4R
从上述的公式中可以发现,由于mr<R,因此事务发生死锁的概率是非常低的。同
时,事务发生死锁的概率与以下几点因素有关:
口系统中事务的数量(n),数量越多发生死锁的概率越大。http:/blog.csdnnet/jiongyi11
51.6
67死鎖281
口每个事务操作的数量(r),每个事务操作的数量越多,发生死锁的概率越大
口操作数据的集合(R),越小则发生死锁的概率越大。
673死锁的示例
如果程序是串行的,那么不可能发生死锁。死锁只存在于并发的情况,而数据库本
身就是一个并发运行的程序,因此可能会发生死锁。表6-18的操作演示了死锁的一种经
典的情况,即A等待B,B在等待A,这种死锁问题被称为AB-BA死锁
表6-18死锁用例1
时间
会话A
会话B
BEGIN
mysqL>* FRoM t
WHERE a=I FOR UPDatE.
拿寒京L,row事章事拿事事事率辜
BEGIN
1 row in set(0.00 sec)
mysqlSELECT* FROM t
WHERE a=2 FOR UPDATE
童邀靠章章1,了ow章享拿章事章中
a:2
I row in set(0.00 sec)
mysql>select* from t WherE a=2
FOR UPDATE.
#等待
mysqL>seleCt* from t Where a 1
FOR UPDATE
ERROR 1213 (40001): Deadlock found when
trying to get lock; try restarting transaction
在上述操作中,会话B中的事务抛出了1213这个错误提示,即表示事务发生了死
锁。死锁的原因是会话A和B的资源在互相等待。大多数的死锁 InnoDB存储引擎本身
可以侦测到,不需要人为进行干预。但是在上面的例子中,在会话B中的事务抛出死锁
异常后,会话A中马上得到了记录为2的这个资源,这其实是因为会话B中的事务发生
了回滚,否则会话A中的事务是不可能得到该资源的。还记得66节中所说的内容吗?
InnoDB存储引擎并不会回滚大部分的错误异常,但是死锁除外。发现死锁后, InnoDB
存储引擎会马上回滚一个事务,这点是需要注意的。因此如果在应用程序中捕获了1213
这个错误,其实并不需要对其进行回滚。http:/blog.csdnnet/jiongyi11
5l-
282菜6幸續
拼号
Oalf数据库中产生死锁的常见原因是没有对外键添加索引,而 InnoDB存储擎
会自动对其进行添加,因而能够很好地避免了这种情况的发生。而人为删除外键上的索
引, MySQL数据库会抛出一个异常:
mysql> CREATE TABLE p
- aINT
- PRIMARY KEY(a)
>) ENGINE=工 noDB
Query OK, 0 rows affected (0.00 sec
my3q1> CREATE TABLE C(
->b工NTr
- ECREIGH KEY (b)REFERENCES p(a)
-2)ENGINE=InnoDE
Query OK,0 rows affected (0. 00 sec)
mysql> SHOW INDEX. FROM c\G:
大★★★★★★★★★★★★大★★★★★肃大★★大★★1,。w★★★k青齿走出女如世女t
Table: c
Non unique: 1
Key name: b
seq in indt
Column name: b
Collation: a
Cardinality: 0
Sub part: NULL
Packed: NULL
Null: YES
Index type: BTREE
Comment
1 row in set (0.c0 sec
mysql> dROP INDEX b oN C;
ERROR 1553 (HY000>: Cannot drop index 'b': needed in a foreign key constraint
通过上述例子可以看到,虽然在建立子表时指定了外键,但是IoDB存储引擎会
自动在外键列上建立了一个索引b。并且,人为地删除这个列是不被允许的。
此外还存在另一种死锁,即当前事务持有了待插入记录的下一个记录的X锁,但是
在等待队列中存在一个S锁的请求,则可能会发生死锁。来看一个例子,首先根据如下
代码创建测试表t,并导入一些数据:
CREATE TABLE t〔http://blog.csdn.net/jiongyi1
68汁级283
部拼爱
INT PRIMARY KEY
ENGINE=工 nodE
INSERT INTo t VALUEs(1)(2),(4),(5
表t仅有一个列a,并插入4条记录。接着运行表6-19所示的查询。
表6-19死锁用例2
时间
会话A
会话B
BEGIN
2
BEGIN
SELECT* FROM t
WhERE a=4 FOR UPDATE
SELECT+ FROM t
WhERE a < 4 LOCK IN SHARE MODE
等待
INSERT INTO t VALUES(3);
ERROR 1213(40001): Deadlock found when
trying to get lock; try restarting transaction
6
事务获得锁,正常运行
可以看到,会话A中已经对记录4持有了X锁,但是会话A中插入记录3时会导
致死锁发生。这个问题的产生是由于会话B中请求记录4的S锁而发生等待,但之前
请求的锁对于主键值记录1、2都已经成功,若在事件点5能插入记录,那么会话B在
获得记录4持有的S锁后,还需要向后获得记录3的记录,这样就显得有点不合理。因
此 InnoDB存储引擎在这里主动选择了死锁,而回滚的是 undo log记录大的事务,这与
AB-BA死锁的处理方式又有所不同
68锁升级
锁升级( Lock escalation)是指将当前锁的粒度降低。举例来说,数据库可以把
个表的1000个行锁升级为个页锁,或者将页锁升级为表锁。如果在数据库的设计中
认为锁是一种稀有资源,而且想避免锁的开销,那数据库中会频繁出现锁升级现象。
Microsoft SQL Server数据库的设计认为锁是一种稀有的资源,在适合的时候会自动
地将行、键或分页锁升级为更粗粒度的表级锁。这种升级保护了系统资源,防止系统使
用太多的内存来维护锁,在一定程度上提高了效率http:/blog.csdnnet/jiongyi11
51.6
284第6章绂
即使在 Microsoft SQL Server2005版本之后, SQL Server数据库支持了行锁,但是
其设计和 InnoDB存储引擎完全不同,在以下情况下依然可能发生锁升级:
口由一句单独的S语句在一个对象上持有的锁的数量超过了阈值,默认这个阈
值为5000。值得注意的是,如果是不同对象,则不会发生锁升级
口锁资源占用的内存超过了激活内存的40%时就会发生锁升级
在 Microsoft SQL Server数据库中,由于锁一种稀有的资源,因此锁升级会带来一定
的效率提高。但是锁升级带来的一个问题却是因为锁粒度的降低而导致并发性能的降低
InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的,相
反,其根据每个事务访问的每个页对锁进行管理的,采用的是位图的方式。因此不管
个事务锁住页中一个记录还是多个记录,其开销通常都是一致的
假设一张表有300000个数据页,每个页大约有100条记录,那么总共有30000000
条记录。若有一个事务执行全表更新的SQL语句,则需要对所有记录加X锁。若根据
每行记录产生锁对象进行加锁,并且每个锁占用10字节,则仅对锁管理就需要差不多
需要3GB的内存。而 InnoDB存储引擎根据页进行加锁,并采用位图方式,假设每个页
存储的锁信息占用30个字节,则锁对象仅需90MB的内存。由此可见两者对于锁资源
开销的差距之大。
69小结
这一章介绍的内容非常多,可能会让读者觉得很难,甚至会不时地抓耳挠腮。尽管锁
本身相当直接,但是它的一些副作用却不是这样。关键是用户需要理解锁带来的问题,
如丢失更新、脏读、不可重复读等。如果不知道这一点,那么开发的应用程序性能就会
很差。如果不学会怎样通过一些命令和数据字典来查看事务锁住了哪些资源,你可能永
远不知道到底发生了什么事情,可能只是认为 MySQL数据库有时会阻塞而已。
本章在介绍锁的同时,还比较了MyQL数据库 InnoDB存储引擎、 MyISAM存储
引擎、 Microsoft SQL Server数据库、 Oracle数据库锁的特性。通过这些比较了解到,虽
然每个数据库在SQL语句层面上的差别可能不是很大,在内部底层的实现却各有不同。
通过理解 InnoDB存储引擎锁的特性,对于开发一个高性能、高并发的数据库应用显得
十分重要和有帮助http://blog.csdn.net/jiongyi1
5
部拼吾费
第7章事务
事务( Transaction)是数据库区别于文件系统的重要特性之一。在文件系统中,如
果正在写文件,但是操作系统突然崩溃了,这个文件就很有可能被破坏。当然,有一些
机制可以把文件恢复到某个时间点。不过,如果需要保证两个文件同步,这些文件系统
可能就显得无能为力了。例如,在需要更新两个文件时,更新完一个文件后,在更新完
第二个文件之前系统重启了,就会有两个不同步的文件。
这正是数据库系统引入事务的主要目的:事务会把数据库从一种一致状态转换为另
种一致状态。在数据库提交工作时,可以确保要么所有修改都已经保存了,要么所有
修改都不保存
InnoDB存储引擎中的事务完全符合ACID的特性。ACID是以下4个词的缩写:
口原子性( atomicity)
口一致性( consistency)
口隔离性( isolation)
口持久性( durability)
第6章介绍了锁,讨论 InnoDB是如何实现事务的隔离性的。本章主要关注事务的
原子性这一概念,并说明怎样正确使用事务及编写正确的事务应用程序,避免在事务方
面养成一些不好的习惯。
7.1认识事务
7.1.1概述
事务可由一条非常简单的SQL语句组成,也可以由一组复杂的SQL话句组成。
事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的操作,要么
都做修改,要么都不做,这就是事务的目的,也是事务模型区别与文件系统的重要特
征之http:/blog.csdnnet/jiongyi11
5
286第7幸事务
理论上说,事务有着极共严格的定义,它必须同时满足四个特性,逦常所被
的事务的ACID特性。值得注意的是,虽然理论上定义了严格的事务要求,但是数据
库厂商出于各种目的,并没有严格去满足事务的ACID标准。例如,对于 MySQL的
NDB Cluster引擎来说,虽然其支持事务,但是不满足D的要求,即持久性的要求,对
于 Oracle数据库来说,其默认的事务隔离级别为 READ COMMITTED,不满足I的要
求,即隔离性的要求。虽然在大多数的情况下,这并不会导致严重的结果,甚至可能还
会带来性能的提升,但是用户首先需要知道严谨的事务标准,并在实际的生产应用中避
免可能存在的潜在问题。对于 InnoDB存储引擎而言,其默认的事务隔离级别为READ
REPEATABLE,完全遵循和满足事务的ACI特性。这里,具体介纲事务的ACID特
性,并给出相关概念。
A( Atomicity),原子性。在计算机系统中,每个人都将原子性视为理所当然。例
如在C语言中调用SQRT函数,其要么返回正确的平方根值,要么返回错误的代码,而
不会在不可预知的情况下改变任何的数据结构和参数。如果SQRT函数被许多个程序调
用,一个程序的返回值也不会是其他程序要计算的平方根
然而在数据的事务中实现调用操作的原子性,就不是那么理所当然了。例如一个用
户在ATM机前取款,假设取款的流程为:
1)登录ATM机平台,验证密码。
2)从远程银行的数据库中,取得账户的信息。
3)用户在ATM机上输入欲提取的金额。
4)从远程银行的数据库中,更新账户信息。
5)ATM机出款
6)用户取钱。
整个取款的操作过程应该视为原子操作,即要么都做,要么都不做。不能用户钱未
从ATM机上取得,但是银行卡上的钱已经被扣除了,相信这是任何人都不能接受的
种情况。而通过事物模型,可以保证该操作的原子性
原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作
都执行成功,才算整个事务成功。事务中任何一个SQL语句执行失败,已经执行成功的
SQL语句也必须撤销,数据库状态应该退回到执行事务前的状态。
如果事务中的操作都是只读的,要保持原了性是很简单的。一旦发生任何错误,要http://blog.csdn.net/jiongyi1
51.
7认事287
么重试,要么返回错误代码。因为只读操作不会改变系统中的任何相关部分。但是,当
事务中的操作需要改变系统中的状态时,例如插入记录或更新记录,那么情况可能就不
像只读操作那么简单了。如果操作失败,很有可能引起状态的变化,因此必须要保护系
统中并发用户访问受影响的部分数据。
C( consistency),一致性。一致性指事务将数据库从一种状态转变为下一种一致
的状态。在事务开始之前和事务结東以后,数据库的完整性约束没有被破坏。例如,在
表中有一个字段为姓名,为唯一约束,即在表中姓名不能重复。如果一个事务对姓名字
段进行了修改,但是在事务提交或事务操作发生回滚后,表中的姓名变得非唯一了,这
就破坏了事务的一致性要求,即事务将数据库从一种状态变为了一种不一致的状态。因
此,事务是一致性的单位,如果事务中某个动作失败了,系统可以自动撤销事务—返
回初始化的状态。
( isolation),隔离性。隔离性还有其他的称呼,如并发控制( concurrency control)、
可串行化( serializability)、锁( locking)等。事务的隔离性要求每个读写事务的对象对
其他事务的操作对象能相互分离,即该事务提交前对其他事务都不可见,通常这使用锁
来实现。当前数据库系统中都提供了一种粒度锁( granular lock)的策略,允许事务仅锁
住一个实体对象的子集,以此来提高事务之间的并发度。
D( durability),持久性。事务一且提交,其结果就是永久性的。即使发生岩机等故
障,数据库也能将数据恢复。需要注意的是,只能从事务本身的角度来保证结果的永久
性。例如,在事务提交后,所有的变化都是永久的。即使当数据库因为崩溃而需要恢复
时,也能保证恢复后提交的数据都不会丢失。但若不是数据库本身发生故障,而是一些
外部的原因,如RAID卡损坏、自然灾害等原因导致数据库发生问题,那么所有提交的
数据可能都会丢失。因此持久性保证事务系统的高可靠性( High Reliability),而不是高
可用性( High Availability)。对于高可用性的实现,事务本身并不能保证,需要一些系统
共同配合来完成。
7.1.2分类
从事务理论的角度来说,可以把事务分为以下几种类型:
口扁平事务( Flat Transactions)http://blog.csdn.net/jiongyi1
6I
288第7幸事齐
口带有保存点的扁平事务( Flat Transactions with Savepoints
你
口链事务( Chained transactions)
口嵌套事务( Nested Transactions)
口分布式事务( Distributed transactions)
扁平事务( Flat Transaction)是事务类型中最简单的一种,但在实际生产环境中,
这可能是使用最为频繁的事务。在扁平事务中,所有操作都处于同一层次,其由 BEGIN
WORK开始,由 COMMIT WORK或 ROLLBACK WORK结束,其间的操作是原子的,
要么都执行,要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块
图7-1显示了扁平事务的三种不同结果
BEGIN WORK
BEGIN WORK
BEGIN WORK
peration
Operation I
Operation 1
Operation 2
Operation 2
Operation 2
Operation K
Error!!!
COMMIT WORK
ROLLBACK WORK
由于外界原因要回滚,
如超时等
成功完成,约占所有
应用程序要求停止事务,
事务的96%
约占所有事务的3%
强制终止事务,约占所有
事务的1%
图7-1扁平事务的三种情况
图7-1给出了扁平事务的三种情况,同时也给出了在一个典型的事务处理应用中,
每个结果大概占用的百分比。再次提醒,扁平事务虽然简单,但在实际生产环境中使
用最为频繁。正因为其简单,使用频繁,故每个数据库系统都实现了对扁平事务的支
持
扁平事务的主要限制是不能提交或者回滚事务的某一部分,或分几个步骤提交。下
面给出一个扁平事务不足以支持的例子。例如用户在旅行网站上进行自己的旅行度假计
划。用户设想从杭州到意大利的佛罗伦萨,这两个城市之间没有直达的班机,需要用户
预订并转乘航班,或者需要搭火车等待。用户预订旅行度假的事务为:
BEGIN WORK
Sl:预订杭州到上海的高铁
S2:上海浦东国际机场坐飞机,预订去米兰的航班http://blog.csdn.net/jiongyi1
6I
7.!认识挛务289
部拼吾
S3:在米兰转火车前往佛罗伦萨,预订去佛罗伦萨的火车
但是当用户执行到S3时,发现由于飞机到达米兰的时间太晚,已经没有当天的火
车。这时用户希望在米兰当地住一晚,第二天出发去佛罗伦萨。这时如果事务为扁平事
务,则需要回滚之前Sl、S2、S3的三个操作,这个代价就显得有点大。因为当再次进
行该事务时,S1、S2的执行计划是不变的。也就是说,如果支持有计划的回滚操作,那
么就不需要终止整个事务。因此就出现了带有保存点的扁平事务。
带有保存点的扁平事务( Flat Transactions with Savepoint),除∫支持扁平事务支
持的操作外,允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些
事务可能在执行过程中出现的错误并不会导致所有的操作都无效,放弃整个事务不合乎
要求,开销也太大。保存点( Savepoint)用来通知系统应该记住事务当前的状态,以便
当之后发生错误时,事务能回到保存点当时的状态。
对于扁平的事务来说,其隐式地设置了一个保存点。然而在整个事务中,只有这
个保存点,因此,回滚只能回滚到事务开始时的状态。保存点用 SAVE WORK函数来建
立,通知系统记录当前的处理状态。当出现问题时,保存点能用作内部的重启动点,根
据应用逻辑,决定是回到最近一个保存点还是其他更早的保存点。图7-2显示了在事务
中使用保存点。
图7-2显示了如何在事务中使用保存点。灰色背景部分的操作表示由 ROLLBACK
WORK而导致部分回滚,实际并没有执行的操作。当用 BEGIN WORK开启一个事务
时,隐式地包含了一个保存点,当事务通过 ROLLBACK WORK:2发出部分回滚命令
时,事务回滚到保存点2,接着依次执行,并再次执行到 ROLLBACK WORK:7,直
到最后的 COMMIT WORK操作,这时表示事务结束,除灰色阴影部分的操作外,其余
操作都已经执行,并且提交。
另一点需要注意的是,保存点在事务内部是递增的,这从图7-2中也能看出。有人
可能会想,返回保存点2以后,下一个保存点可以为3,因为之前的工作都终止了。然
而新的保存点编号为5,这意味着 ROLLBACK不影响保存点的计数,并且单调递增的
编号能保持事务执行的整个历史过程,包括在执行过程中想法的改变。
此外,当事务通过 ROLLBACK WORK:2命令发出部分回滚命令时,要记住事务
并没有完全被回滚,只是回滚到了保存点2而已。这代表当前事务还是活跃的,如果想
要完全回滚事务,还需要再执行命令 ROLLBACK WORKhttp:/blog.csdnnet/jiongyi11
2907幸事务
爸拼吾
BEGIN WORK
召擦
隐含 SAVE WORK
保存点2覆盖的操作
Action
SAVE WORK: 2
Action
Action
保存点5覆盖的操作
SAVE WORK: 3
action
Action
SAVE WORK: 5
e Action
Action
Action
SAVE WORK: 6
SAVE wORK: 4
Action
Acti
Action
ROLLBACK WORK: 2
SAVE WORK: 7
CHon
action
ROLLBACK WORK: 7
Action
Action
SAVE WORK: 8
CTIOn
COMMIT WORK
图7-2在事务中使用保存点
链事务( Chained transaction)可视为保存点模式的一种变种。带有保存点的扁平
事务,当发生系统崩溃时,所有的保存点都将消失,因为其保存点是易失的( volatile),
而非持久的( persistent)。这意味着当进行恢复时,事务需要从开始处重新执行,而不能
从最近的一个保存点继续执行
链事务的思想是:在提交一个事务时,释放不需要的数据对象,将必要的处理上下
文隐式地传给下一个要开始的事务。注意,提交事务操作和开始下一个事务操作将合并
为一个原子操作。这意味着下一个事务将看到上一个事务的结果,就好像在一个事务中http://blog.csdn.net/jiongyi1
15l.
71认识旷务291
部拼没
进行的一样。图7-3显示了链事务的工作方式:
T3
A
C
触发器
触发器
图7-3链事务的开始,第一个事务提交触发第二个事务的开始
链事务与带有保存点的扁平事务不同的是,带有保存点的扁平事务能回滚到任意正
确的保存点。而链事务中的回滚仅限于当前事务,即只能恢复到最近一个的保存点。对
于锁的处理,两者也不相同。链事务在执行 COMMIT后即释放了当前事务所持有的锁,
而带有保存点的扁平事务不影响迄今为止所持有的锁
嵌套事务( Nested Transaction)是一个层次结构框架。由一个顶层事务(top
level transaction)控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务
( subtransaction),其控制每一个局部的变换。嵌套事务的层次结构如图74所示。
顶层事务
子事务
子事务
子事务
BEGIN WORK
BEGIN WORK
BEGIN WORK
调用子事务
COMMIT WORK
调用子事务
调用子事务
COMMIT WORK
BEGIN WORK
BEGIN WORK
BEGIN WORK
COM MIT WORK
COMMIT WORK
调用子事务
I COMMIT WORK
BEGIN WORK
调用子事务
调用子事务
BEGIN WORK
调用子事务
COMMIT WORK
COMMIT WORK
COMMIT WORK
图74嵌套事务的层次结构
下面给出Mos对嵌套事务的定义:
1)嵌套事务是由若干事务组成的一棵树,子树既可以是嵌套事务,也可以是扁平http:/blog.csdnnet/jiongyi11
5I
292第7章事务
事务。
你器
2)处在叶节点的事务是扁平事务。但是每个子事务从根到叶节点的距离可以是不
同的。
3)位于根节点的事务称为顶层事务,其他事务称为子事务。事务的前驱称
( predecessor)为父事务( parent),事务的下一层称为儿了事务(chid)
4)子事务既可以提交也可以回滚。但是它的提交操作并不马上生效,除非其父事
务已经提交。因此可以推论出,任何子事物都在顶层事务提交后才真正的提交。
5)树中的任意一个事务的回滚会引起它的所有子事务一同回滚,故子事务仅保留
A、C、I特性,不貝有D的特性
在Moss的理论中,实际的工作是交由叶子节点来完成的,即只有叶子节点的事务
才能访问数据库、发送消息、获取其他类型的资源。而高层的事务仅负责逻辑控制,决
定何时调用相关的子事务。即使一个系统不支持嵌套事务,用户也可以通过保存点技术
来模拟嵌套事务,如图7-5所示。
Tk1L
SI
Tk1
SIl
Tk121
s12
s121
Tka
Tk2
$2
Tk31
S3
Tk3
s31
time
图7-5用保存点技术来模拟嵌套事务
从图7-5中也可以发现,在恢复时采用保存点技术比嵌套查询有更大的灵活性。例
如在完成Tk3这事务时,可以回滚到保存点S2的状态。而在嵌套查询的层次结构中,http:/blog.csdnnet/jiongyi11
5I
7.1认祺事务293
这是不被允许的。
督你器
但是用保存点技术来模拟嵌套事务在锁的持有方面还是与嵌套查询有些区别。当
通过保存点技术来模拟嵌套事务时,用户无法选择哪些锁需要被子事务继承,哪些需要
被父事务保留。这就是说,无论有多少个保存点,所有被锁住的对象都可以被得到和访
问。而在嵌套查询中,不同的子事务在数据库对象上持有的锁是不同的。例如有一个父
事务P1,其持有对象X和Y的排他锁,现在要开始一个调用子事务P1,那么父事务P1
可以不传递锁,也可以传递所有的锁,也可以只传递一个排他锁。如果子事务P1中还
要持有对象Z的排他锁,那么通过反向继承( counter-inherited),父事务P1将持有3个
对象ⅹ、Y、Z的排他锁。如果这时又再次调用了一个子事务P12,那么它可以选择传递
那里已经持有的锁。
然而,如果系统支持在嵌套事务中并行地执行各个子事务,在这种情况下,采用保
存点的扁平事务来模拟嵌套事务就不切实际了。这从另一个方面反映出,想要实现事务
间的并行性,需要真正支持的嵌套事务。
分布式事务( Distributed transactions)通常是一个在分布式环境下运行的扁平事
务,因此需要根据数据所在位置访问网络中的不同节点
假设一个用户在ATM机进行银行的转账操作,例如持卡人从招商银行的储蓄卡转
账10000元到工商银行的储蓄卡。在这种情况下,可以将ATM机视为节点A,招商银
行的后台数据库视为节点B,工商银行的后台数据库视为C,这个转账的操作可分解为
以下的步骤:
1)节点A发出转账命令,
2)节点B执行储蓄卡中的余额值减去10000。
3)节点C执行储蓄卡中的余额值加上10000
4)节点A通知用户操作完成或者节点A通知用户操作失败。
这里需要使用分布式事务,因为节点A不能通过调用一台数据库就完成任务。其
需要访问网络中两个节点的数据库,而在每个节点的数据库执行的事务操作又都是扁平
的。对于分布式事务,其同样需要满足ACID特性,要么都发生,要么都失效。对于上
述的例子,如果2)、3)步中任何一个操作失败,都会导致整个分布式事务回滚。若非
这样,结果会非常可怕。
对于 InnoDB存储引擎来说,其支持扁平事务、带有保存点的事务、链事务、分http:/blog.csdnnet/jiongyi11
5
294够7幸事齐
布式事务。对于嵌套事务,其并不原生支持,因此,对有并行事务需求的用户来说
MySQL数据库或 InnoDB存储引擎就显得无能为力了。然而用户仍可以通过带有保存点
的事务来模拟串行的嵌套事务。
7.2事务的实现
事务隔离性由第6章讲述的锁来实现。原子性、一致性、持久性通过数据库的redo
log和 undo log来完成 redo log称为重做日志,用来保证事务的原子性和持久性。undo
log用来保证事务的一致性。
有的DBA或许会认为undo是redo的逆过程,其实不然。redo和undo的作用都可
以视为是一种恢复操作,redo恢复提交事务修改的页操作,而undo冋滚行记录到某个
特定版本。因此两者记录的内容不同,redo通常是物理日志,记录的是页的物埋修改操
作。undo是逻辑日志,根据每行记录进行记录
7. 2. 1 redo
1.基本概念
重做日志用来实现事务的持久性,即事务ACID中的D。其由两部分组成:一是内
存中的重做日志缓冲( redo log bulTer),其是易失的;二是重做日志文件( redo log file),
其是持久的。
InnodB是事务的存储引擎,其通过 Force Log at Commit机制实现事务的持久
性,即当事务提交( COMMIT)时,必须先将该事务的所有日志写入到重做日志文件
进行持久化,待事务的 COMMIT操作完成才算完成。这里的H志是指重做日志,在
InnoDB存储引擎中,由两部分组成,即 redo log和 undo log. redo log用来保证事务的
持久性, undo log用来帮助事务回滚及MVCC的功能。 redo log基本上都是顺序写的,
在数据库运行时不需要对 redo log的文件进行读取操作。而 undo log是需要进行随机读
写的。
为∫确保每次日志都写入重做日志文件,在每次将重做日志缓冲写入重做日志文件
后, InnoDB存储引擎都需要调用一次 fsync操作。由于重做日志文件打开并没有使用
O DIRECT选项,因此重做日志缓冲先写人文件系统缓存。为了确保重做日志写人磁http://blog.csdn.net/jiongyi1
BI
7.2事务的实现295
盘,必须进行一次fync操作。由于 fsync的效率取决于磁盘的性能,因此磁盘的性能决
定了事务提交的性能,也就是数据库的性能
InnoDe存储引擎允许用户手工设置非持久性的情况发生,以此提高数据库的性能。
即当事务提交时,日志不写入重做日志文件,而是等待一个时间周期后再执行 fsync操
作。由于并非强制在事务提交时进行一次 fsync操作,显然这可以显著提高数据库的性
能。但是当数据库发生宕机时,由于部分日志未刷新到磁盘,因此会丢失最后一段时间
的事务。
参数 innodb flush log at trx commit用来控制重做日志刷新到磁盘的策略。该参数
的默认值为1,表示事务提交时必须调用一次fync操作。还可以设置该参数的值为0和
2。0表示事务提交时不进行写人重做日志操作,这个操作仅在 master thread中完成,而
在 master thread中每1秒会进行一次重做日志文件的 fsync操作。2表示事务提交时将
重做日志写入重做日志文件,但仅写入文件系统的缓存中,不进行fsyn操作。在这个
设置下,当 MySQL数据库发生宕机而操作系统不发生宕机时,并不会导致事务的丢失
而当操作系统宕机时,重启数据库后会丢失未从文件系统缓存刷新到重做日志文件那部
分事务。
下面看一个例子,比较 innodb flush log at trx commit对事务的影响。首先根据如
下代码创建表t1和存储过程 p load:
CREATE TABLE test load
a INT
b CHAR(80)
ENGINE=INNODB
DELIMITER J
CREATE PROCEDURE P load(count INT UNSIGNED)
BEGIN
DECLARE S INT UNS IGNED DEFAULT 1
DECLARE C CHAE【8) DEEAULT REPEAT("a’,80);
WHILE S<=count Do
INSERT INTo test load SELECT NULL Ci
COMMIT
SET S=S+li
END WH工LE
END;
DELIMITERhttp:/blog.csdnnet/jiongyi11
5
296第7孝事务
存储过程p1ad的作用是将数据不断地插入表 test load中,并且每插入+条就进行
次显式的 COMMIT操作。在默认的设置下,即参数 innodb flush log at trx commit
为1的情况下, InnoDB存储引擎会将重做日志缓沖中的日志写入文件,并调用一次
fsync操作。如果执行命令 CALL p load(500000,则会向表中插入50万行的记录,
并执行50万次的fync操作。先看在默认情况插人50万条记录所需的时间下
mysql>CAlL p load (500000)
Qucry OK, 0 rows affected (1 min 53.11 sec)
可以看到插入50万条记录差不多需要2分钟的时间。对于生产环境的用户来说
这个时间显然是不能接受的。而造成时间比较长的原因就在于 fsync操作所需的时间。
接着来看将参数 innodb fush log at trx commit设置为0的情况
mysq 1> SHOW VARIABLES LIKE 'innodb flush log at trx comit '\G
古古害窗肃肯肯★肯古青★★★古古大十
工Ow★★★★大★★★★肉★★★★★如★★★★
Variable name: innodb flush log at trx commit
Value: 0
1rew⊥nset(0.00sec
mysql> CALL p load(500000)i
Query oK, o rows affected 13.90 sec)
可以看到将参数 innodb flush log at trx commit设置为0后,插人50万行记录的时
间缩短为了1390秒,差不多是之前的12%而形成这个现象的主要原因是:后者大大
减少了 fsync的次数,从而提高了数据库执行的性能。表7-1显示了在参数 innodb flush
log_at trx commit的不同设下,调用存储过程p_load插入50万行记录所需的时间。
表7-1不同 innodb flush| og at trx commit设置对于插入的速度影响
innodb flush log_ at trx commit
执行所用时间
0
1390秒
1分53.11秒
2
23.37秒
虽然用户可以通过设置参数 innodb flush log at trx commit为0或2来提高事务
提交的性能,但是需要牢记的是,这种设置方法丧失了事务的ACID特性。而针对上
述存储过程,为了提高事务的提交性能,应该在将50万行记录插入表后进行一次的
COMMIT操作,而不是在每插入一条记录后进行一次 COMMIT操作。这样做的好处是
还可以使事务方法在回滚时回滚到事务最开始的确定状态。http://blog.csdn.net/jiongyi1
5L.
72事务的现297
部拼没
在 MySQL数据库中还有一种二进制日志( binlog),其用来进行 POINT-IN-TIM
(PT)的恢复及主从复制( Replication)环境的建立。从表面上看其和重做日志菲常相
似,都是汜录了对于数据库操作的日志。然而,从本质上来看,两者有着非常大的不同。
首先,重做日志是在noDB存储引擎层产生,而二进制日志是在 MySQL数据库
的上层产生的,并且二进制H志不仅仅针对于 InnoDE存储引擎, MySQL数据库中的任
何存储引擎对于数据库的更改都会产生二进制日志。
其次,两种日志记录的内容形式不同。 MySQL数据库上层的二进制日志是一种逻
辑日志,其记录的是对应的SQL语句。而 InnoDB存储引擎层面的重做日志是物理格式
日志,其记录的是对于每个页的修改
此外,两种日志记录写入磁盘的时间点不同,如图76所示。二进制目志只在事务
提交完成后进行一次写入。而 InnoDB存储引擎的重做日志在事务进行中不断地被写入,
这表现为日志并不是随事务提交的顺序进行写入的。
binlog
T4
T3
T8
To
T7
T5
rod log
TI
T2
2
TI
*T3
TI
图7-6二进制日志与重做日志的写入的时间点不同
从图7-6中可以看到,二进制日志仅在事务提交时记录,并且对于每一个事务,仅
包含对应事务的一个日志。而对于 InnoDB存储引擎的重做日志,由于其记录的是物理
操作日志,因此每个事务对应多个日志条目,并且事务的重做日志写入是并发的,并非
在事务提交时写人,故其在文件中记录的顺序并非是事务开始的顺序。*T1、*T2、*T3
表示的是事务提交时的日志
2. log block
在 InnoDB存储引擎中,重做日志都是以512字节进行存储的。这意味着重做日志
缓存、重做日志文件都是以块( block)的方式进行保存的,称之为重做日志块(redo
log block),每块的大小为512字节。
若一个页中产生的重做日志数量大于512字节,那么需要分割为多个重做日志块进
行存储。此外,由于重做日志块的大小和磁盘扇区大小一样,都是512字节,因此重做http:/blog.csdnnet/jiongyi11
5
298躬7章事务
日志的写入可以保证原子性,不需要 doublewrite技术。
你器
重做日志块除了日志本身之外,还由日志块头( log block header)及日志块尾(log
block tailer)两部分组成。重做日志头一共占用12字节,重做日志尾占用8字节。故每
个重做日志块实际可以存储的大小为492字节(512-12-8)。图7-7显示了重做日志块缓
存的结构。
Redo log buffer
log
lot
log
log
og
og
og
log
lo
block blockblock block block blockblock block
block block block
log block header
LOG BLOCK HDR NO
LOG BLOCK HDR DATA LEN
Log block
LOG BLOCK FIRST REC GROUP
512 Bytes
OG BLOCK CHECKPOINT NO
log block tailer
LOG BLOCK TRL NO
图7-7重做日志块缓存的结构
图7-7显示了重做日志缓存的结构,可以发现重做日志缓存由每个为512宁节大小
的日志块所组成。日志块由三部分组成,依次为日志块头( log block header)、目志内容
( log body)、日志块尾( log block tailer)。
log block header由4部分组成,如表7-2所示。
表7-2 log block header
名称
占用字节
LOG BLOCK HDR NO
LOG BLOCK HDR DATA LEN
LOG BLOCK FIRST REC GROUP
4224
LOG BLOCK CHECKPOINT NO
log buffer是由 log block组成,在内部 log buffer就好似一个数组,因此LoG
BLOCK HDR NO用来标记这个数组中的位置。其是递增并且循环使用的,占用4个字
节,但是由丁第一位用来判断是否是 lush bit,所以最大的值为2G。http://blog.csdn.net/jiongyi1
72事多的现299
部拼吾哪
LOG BLOCK HDR DATA LEN占用2字节,表示bok所占用的小。当1命
block被写满时,该值为0x200,表示使用全部 log block空间,即占用512字节。
LOG BLOCK FIRST REC GROUP占用2个字节,表示 log block中第一个日志所
在的偏移量。如果该值的大小和 LOG BLOCK HDR DATA LEN相同,则表示当前log
block不包含新的日志。如事务Tl的重做日志1占用762字节,事务T2的重做日志占
用100字节。由于每个 log block实际只能保存492个字节,因此其在 log buffer中的情
况应如图7-8所示。
log block header
log block header
TI270 bytes
T2 100 bytes
LOG BLOCK FIRST__ REC GROUR
T1 492 bytes
log block tailer
log block tailer
图7-8 LOG BLOCK F| RST REC GROUP的例子
从图7-8中可以观察到,由于事务T1的重做日志占用792字节,因此需要占用两个
log block。左侧的 log block中 LOG BLOCK FIRST REC GROUP为12,即 log block
中第一个日志的开始位置。在第二个 log block中,由于包含了之前事务T1的重做日志,
事务T2的日志才是 log block中第一个日志,因此该 log block的 LOG BLOCK FIRST
REC GROUP为282(270+12)。
LOG BLOCK CHECKPOINT NC占用4字节,表示该 log block最后被写入时的检
查点第4字节的值。
log block tailer只由1个部分组成(如表7-3所示),且其值和 LOG BLOCK HDR
NO相同,并在函数 log block init中被初始化
表7-3| og block tailer部分
名称
大小(字节)
LOG BLOCK TRL NOhttp://blog.csdnnet/jiongyi1
BI
300箬7章事务
部拼没
3. log group
log group为重做日志组,其中有多个重做日志文件。虽然源码中已支持 log group
的镜像功能,但是在 ha innobase cc文件中禁止了该功能。因此 InnoDB存储引擎实际只
有一个 log group
log group是一个逻辑上的概念,并没有一个实际存储的物理文件来表示 log group
信息。 log group由多个重做日志文件组成,每个 log group中的日志文件大小是相同
的,且在 InnoDB12版本之前,重做日志文件的总大小要小于4GB(不能等于4GB)。
从 InnoDB12版本开始重做日志文件总大小的限制提高为了512 GBa InnoSQL版本的
InnoDB存储引擎在11版本就支持大于4GB的重做日志
重做日志文件中存储的就是之前在 log buffer中保存的 log block,因此其也是根据
块的方式进行物理存储的管理,每个块的大小与 log block一样,同样为512字节。在
InnoDB存储引擎运行过程中, log buffer根据一定的规则将内存中的 log block刷新到磁
盘。这个规则具体是:
口事务提交时
口当 log buffer中有一半的内存空间已经被使用时
口 log checkpoint时
今对于 log block的写人追加( append)在 redo log file的最后部分,当一个 redo log
fle被写满时,会接着写入下一个 redo log file,其使用方式为 round-robin
虽然 log block总是在 redo log file的最后部分进行写人,有的读者可能以为对redo
log file的写人都是顺序的。其实不然,因为 redo log file除了保存 log buffer刷新到磁盘
的 log block,还保存了一些其他的信息,这些信息一共占用2KB大小,即每个 redo log
fle的前2KB的部分不保存 log block的信息。对于 log group中的第一个 redo log file,
其前2KB的部分保存4个512字节大小的块,其中存放的内容如表7-4所示。
表7-4 redo log file前2KB部分的内容
名称
大小〔字节
log file header
512
checkpoint
512
512
checkpoint
512
需要特别注意的是,上述信息仅在每个 log group的第一个 redo log file中进行存储。http://blog.csdn.net/jiongyi1
72亨务
51
续现301
部拼没
lgop的其余mg仅保留这些空间,但不保存上述信息。正因为保了
些信息,就意味着对 redo log file的写入并不是完全顺序的。因为其除了 log block的写
入操作,还需要更新前2KB部分的信息,这些信息对于 InnoDB存储引擎的恢复操作来
说非常关键和重要。故 log group与 redo log file之间的关系如图7-9所示。
g Group
Redo Log File
Log File
Header/CPl
CP2
Lag
Log
g
Log
Log
g
L。
Block Block Block Block Block Block
Block
Redo Log File2
La
LO
g
Log
Log
g
Log
Block Block BlockBlock BlockBlock.Block
g Group
Redo log filel
Log Filc cPl
Log
p只
Los
Loy
CP2
pg
Header
Block Block Block Block BlockBlock
音十tt日t
Block
Redo log file2
Log
QE
g
L
. og
Log
Block Block Block Block Block Block
Block
图7-9 log group与 redo log file之间的关系
在 log filer header后面的部分为 InnoDB存储引擎保存的 checkpoint(检查点)值,
其设计是交替写入,这样的设计避免了因介质失败而导致无法找到可用的 checkpoint的
情况
4.重做日志格式
不同的数据库操作会有对应的重做日志格式。此外,由于 InnoDB存储引擎的存储
管理是基于页的,故其重做日志格式也是基于页的。虽然有着不同的重做日志格式,但
是它们有着通用的头部格式,如图7-10所示。
redolog type spacc page_no redo log body
图7-10重做日志格式http:/blog.csdnnet/jiongyi11
51.6
3027幸事务
通用的头部格式由以下3部分组成:
口redo_ log type:重做日志的类型。
口 space:表空间的ID
口 page no:页的偏移量
之后 redo log body的部分,根据重做日志类型的不同,会有不同的存储内容,例
如,对于页上记录的插人和删除操作,分别对应如图7-11所小的格式
MLOG REC INSERT
pageno cur rec
len
ype space
offset extra_ into
into bits
origin_ i mis_matc
fIset
h index
ec bod
MLOG REC DELETE
type space I page_no offset
图7-11插人和删除的重做日志格式
到 InnoDB12版本时,一共有51种重做日志类型。随着功能不断地增加,相信会
加入越来越多的重做日志类型。
5. LSN
LSN是 Log Sequence Number的缩写,其代表的是日志序列号。在 InnoDB存储引
擎中,LSN占用8字节,并且单调递增。LSN表示的含义有:
口重做日志写入的总量
口 checkpoint的位置
口页的版木
LSN表示事务写入重做日志的字节的总量。例如当前重做日志的LSN为1000,有
个事务T1写入了100字节的重做日志,那么LSN就变为了1100,若又有事务T2写
入了200字节的重做日志,那么LSN就变为了1300。可见LSN记录的是重做日志的总
量,其单位为字节。
LSN不仅记录在重做日志中,还存在于每个页中。在每个页的头部,有一个值FIL
PAGE LSN,记录了该页的LSN。在页中,LSN表示该页最后刷新时LSN的大小。因
为重做日志记录的是每个页的H志,因此贞中的LSN用来判断页是否需要进行恢复操
作。例如,页P1的LSN为10000,而数据库启动时, InnoDB检测到写入重做日志中的
LSN为l3000,并且该事务已经提交,那么数据库需要进行恢复操作,将重做日志应用http://blog.csdn.net/jiongyi1
6I
z2事务的实观039
到Pl页中。同样的,对于重做日志中LSN小于P页的LSN,不需要进行重做:图为
P1页中的LSN表示页已经被刷新到该位置。
用户可以通过命令 SHOW ENGINE INNODB STATUS查看LSN的情况:
mysq-> SHOW ENGINE INNODB STATUS\G
LOG
log sequence number 11 3047174608
Log flushed up to 11 3047174608
Last checkpoint at 11 3047174603
0 pending log writes, o pending chkp writes
42 log i/c's done, 0.00 log i/o's/second
1 row in set (0.00 sec)
Log sequence number表示当前的LSN, Log flushed up to表示刷新到重做日志文件
的LSN, Last checkpoint at表示刷新到磁盘的LSN。
虽然在上面的例子中, Log sequence number和 Log hushed up to的值是相同的,但
是在实际生产环境中,该值有可能是不同的。因为在一个事务中从日志缓冲刷新到重做
日志文件并不只是在事务提交时发生,每秒都会有从日志缓冲刷新到重做日志文件的动
作。下面是在生产环境下重做日志的信息的示例。
mysql> show engine innodb status\G
LOG
log sequence number 203318213447
og flushed up tc 203318213326
Last checkpoint at 203252831194
1 pending log writes, 0 pending chkp writes
103447 log i/os done, 7.00 log i/o's/second
1 row in set (0.00 secl
可以看到,在生产环境下 Log sec
quence number, Log flushed up to, Last checkpoint
at三个值可能是不同的。
6.恢复
InnoDB存储引擎在启动时不管上次数据库运行时是否正常关闭,都会尝试进行恢复http:/blog.csdnnet/jiongyi11
5.6
304第7章事务
拼吾
操作。因为重做日志记录的是物理日志,因此恢复的速度比逻辑日志,如兰进制
要快很多。与此同时, InnodB存储引擎自身也对恢复进行了一定程度的优化,如顺序读
取及并行应用重做日志,这样可以进一步地提高数据库恢复的速度。
出于 checkpoint表示已经刷新到磁盘页上的LSN,因此在恢复过程中仅需恢复
checkpoint开始的日志部分。对于图7-12中的例子,当数据库在 checkpoint的LSN为
10000时发生宕机,恢复操作仅恢复LSN10000~13000范围内的日志。
redo lag
LSN:10000
LSN;13000
Bufter pool
flush
checkpoint LSN: 10 000
Disk
Disk
图7-12恢复的例子
InnoDB存储引擎的重做日志是物理日志,因此其恢复速度较之二进制日志恢复快得
多。例如对于 INSERT操作,其记录的是每个页上的变化。对于下面的表:
CREATE TABLE t( a INT, b INT PRIMARY KEY (a], KEY(b))i
若执行SQL语句:
INSERT INTo t SELECT 1,2:
由于需要对聚集索引页和辅助索引页进行操作,其记录的重做日志大致为:
paqe(2,3), of=set32, value1;2#聚集索引
page(2,4}, of=set64,va1ue2#辅助索引
可以看到记录的是页的物理修改操作,若插入涉及B+树的 split,可能会有更多的
页需要记录日志。此外,由于重做日志是物理日志,因此其是幂等的。幂等的概念如下
∫((x)=f(x)
有的DBA或开发人员错误地认为只要将二进制日志的格式设置为ROW,那么二进制
日志也是幂等的。这显然是错误的,举个简单的例子, INSERT操作在二进制日志中就不是http:/blog.csdnnet/jiongyi11
72事务的实现305
幂等的,重复执行可能会插入多条重复的记录。而上述 INSERT操作的重做日志是幂等的
7.2.2 undo
1.基本概念
重做日志记录了事务的行为,可以很好地通过其对页进行“重做”操作。但是事务
有时还需要进行回滚操作,这时就需要undo。因此在对数据库进行修改时, InnoDB存
储引擎不但会产生redo,还会产生一定量的undo。这样如果用户执行的事务或语句由于
某种原因失败∫,又或者用户用一条 ROLLBACK语句清求回滚,就可以利用这些undo
信息将数据回滚到修改之前的样子。
red存放在重做日志文件中,与redo不同,undo存放在数据库内部的一个特殊段
( segment)中,这个段称为undo段( undo segment)。undo段位于共享表空间内。可以
通过 py_ innodb_ page info.py工具来查看当前共享表空间中undo的数量。如下代码显示
当前的共享表空间 datal内有2222个undo页。
Irootexer-server -If python py innodb page info. py /usr/local/mysql/data/
batal
Total number of page: 46208;
Insert Buffer Free List: 13093
Insert Aulffer Bitmap: 3
System Page: 5
Transaction system Page: 1
Freshly Allocated page: 4579
undo Log Page: 2222
File Segment inode: 6
B一 tree node;26296
File Space Header: 1
扩展描述页:2
用户通常对undo有这样的误解:undo用于将数据库物理地恢复到执行语句或事务
之前的样子—但事实并非如此。undo是逻辑日志,因此只是将数据库逻辑地恢复到原
来的样子。所有修改都被逻辑地取消了,但是数据结构和页本身在回滚之后可能大不相
同。这是因为在多用户并发系统中,可能会有数十、数百甚至数千个并发事务。数据库
的主要任务就是协调对数据记录的并发访问。比如,一个事务在修改当前一个页中某几
条记录,同时还有别的事务在对同一个页中另几条记录进行修改。因此,不能将一个页
回滚到事务开始的样子,因为这样会影响其他事务正在进行的工作http:/blog.csdnnet/jiongyi11
5.6
306笫7幸事务
例如,用户执行了一个 INSERT I0W条记录的事务,这个事务会导致分配矿个新的
段,即表空间会增大。在用户执行 ROLLBACK时,会将插入的事务进行回滚,但是表
空间的大小并不会因此而收缩。因此,当 InnoDB存储引擎回滚时,它实际上做的是与
先前相反的工作。对于每个 INSERT, InnoDB存储引擎会完成一个 DELETE;对于每个
DELETE, InnodB存储引擎会执行一个 INSERT;对于每个 UPDATE, InnoDB存储引
擎会执行一个相反的 UPDATE,将修改前的行放回去
除了回滚操作,undo的另一个作用是MVCC,即在noDB存储引擎中MVCC的
实现是通过undo来完成。当用户读取一行记录时,若该记录已经被其他事务占用,当
前事务可以通过undo读取之前的行版本信息,以此实现非锁定读取
最后也是最为重要的一点是, undo log会产生 redo log,也就是 undo log的产生会伴
随着 redo log的产生,这是因为 undo log也需要持久性的保护。
2.undo存储管理
InDB存储引擎对undo的管理同样采用段的方式。但是这个段和之前介绍的段有
所不同。首先 InnoDB存储引擎有 rollback segment,每个回滚段种记录了1024个undo
log segment,而在每个 undo log segment段中进行undo页的申请。共享表空间偏移量
为5的页(0,5)记录了所有 rollback segment header所在的页,这个页的类型为FL
PAGE TYPE SYS。
在 InnoDB11版本之前(不包括1.1版本),只有一个 rollback segment,因此支持同
时在线的事务限制为1024。虽然对绝大名数的应用来说都已经够用,但不管怎么说这是
个瓶颈。从1.版本开始 InnoDB支持最大128个 rollback segment,故其支持同时在
线的事务限制提高到了128*1024。
虽然 Innodb版本支持了128个 rollback segment,但是这些 rollback segment都
存储于共享表空间中。从 InnoDB12版本开始,可通过参数对 rollback segment做进一步
的设置。这些参数包括:
O innodb undo directory
口 innodb undo logs
U innodb undo tablespaces
参数 innodb_undo directory用于设置 rollback segment文件所在的路径。这意味着
rollback segment可以存放在共享表空间以外的位置,即可以设置为独立表空间。该参数http:/blog.csdnnet/jiongyi11
5I.
72亨务的现307
的默认值为“.”,表示当前 InnoDB存储引擎的目录。
参数 innodb undo logs用来设置 rollback segment的个数,默认值为128。在 Innodb2
版本中,该参数用来替换之前版本的参数 innodb rollback segments
参数 innodb undo tablespaces用来设置构成 rollback segment文件的数量,这样 rollback
segment可以较为平均地分布在多个文件中。设置该参数后,会在路径 innodb undo
directory看到undo为前缀的文件,该文件就代表 rollback segment文件。图7-13的示例
示了由3个文件组成的 rollback segment
myspl> SHOW VARIABLES LIKE innodb undoi
I Variable name
i Value
I innodb undo directory I
I innodb undo locs
128
I innodb undo tablespaces I 3
3 rows in set ( 0.00 sec)
mysql> SHOW VARiABlES lIke datadir
十
I Variable name I Value
I datadir
I /Users/david/mysql data/data/
1r° w ln set(0.00sec)
mysql> system ls -lh/users/david/mysql data/data/undo*
I david staff 10M 11 22 16: 55/Users/david/mysql data/data/undo0c1
EW-W一
I davia staff
10M 11 22 16: 51/Users/david/mysql data/data/undoDC 2
rW-Iw-
1 david staff
10M 11 22 16: 51/Users/david/mysql data/data/undo0C3
图7-13由3个文件组成的 rollback segment
需要特别注意的是,事务在 undo log segment分配页并写人 undo log的这个过程同
样需要写入重做日志。当事务提交时, InnodB存储引擎会做以下两件事情:
口将 undo log放入列表中,以供之后的 purge操作
口判断 undo log所在的页是否可以重用,若可以分配给下个事务使用
事务提交后并不能马上删除 undo log及 undo log所在的页。这是因为可能还有其他
事务需要通过 undo log来得到行记录之前的版本。故事务提交时将 undo log放入一个链
表中,是否可以最终删除 undo log及 undo log所在吹由 purge线程来判断。http://blog.csdn.net/jiongyi1
5
308笫7幸事齐
部吾爱
此外,若为每一个事务分配个单独的u会非常浪费存储空间,特别是对于。l郡
的应用类型。因为在事务提交时,可能并不能马上释放页。假设某应用的删除和更新操作
的TPs( transaction per second)为100,为每个事务分配一个undo页,那么一分钟就需要
100060个页,大约需要的存储空间为1GB。若每秒的 purge页的数量为20,这样的设计对
磁盘空间有着相当高的要求。因此,在 InnoDB存储引擎的设计中对umdo页可以进行重用
具体来说,当事务提交时,首先将 undo log放入链表中,然后判断undo页的使用空间是否小
于3/4,若是则表示该undo页可以被重用,之后新的 undo log记录在当前 undo log的后面。
由于存放 undo log的列表是以记录进行组织的,而uno页可能存放着不同事务的 undo log,
因此 purge操作需要涉及磁盘的离散读取操作,是一个比较缓慢的过程。
可以通过命令 SHOW ENGINE INNODB STATUS来查看链表中 undo log的数量,如:
mysql> SHOW ENGINE INNODB STATUS\G;
★古古背★★★青大★★古*肖内*青害*1。。W★青有★古青古言x古青青青青责古★青青内青青古离
TRANSACTIONS
中 tx i counter3000
Purge done for trx's n: o< 2C03 undo n:c<0
H主stXy1iBt1 ength12
LIST OF TRANSACTIONS FOR EACH SESSION
---TRANSACTION 0, not started
MysQL thread id 1, os thread handle 0x1500fl000, query id 4 localhost root
show engine innodb status
History list length就代表了 undo log的数量,这里为12。 purge操作会减少该值。然
而由于 undo log所在的页可以被重用,因此即使操作发生, History list length的值也可
以不为0。
3, undo log
格式
在 InnoDB存储引擎中, undo log分为
J insert undo log
口 update undo log
insert undo log是指在 insert操作中产生的 undo log。因为 Insert操作的记录,只对
事务木身可见,对其他事务不可见(这是事务隔离性的要求),故该 undo log可以在事
务提交后直接删除。不需要进行 purge操作, insert undo log的格式如图7-14所示。http:/blog.csdnnet/jiongyi11
5.6
72事务的实现309
图7-14显示了 insert undo log I的格式,其中大表示对存储的字段进行了压缩, insert
undo log开始的前两个字节next记录的是下一个 undo log的位置,通过该next的字节可
以知道一个 undo log所占的空间字节数。类似地,尾部的两个字节记录的是 undo log的
开始位置。 type cmpl占用一个字节,记录的是undo的类型,对于 insert undo log,该
值总是为1l。 undo no记录事务的ID, table ic记录 undo log所对应的表对象。这两个
值都是在压缩后保存的。接着的部分记录了所有主键的列和值。在进行 rollback操作时,
根据这些值可以定位到具体的记录,然后进行删除即可。
update undo log记录的是对 delete8 update操作产生的 undo log。该 undo log可能
需要提供MVC机制,因此不能在事务提交时就进行删除。提交时放人 undo log链表,
等待puge线程进行最后的删除。 update undo log的结构如图7-15所示。
update undo log record
next
type_cmpl
undo no
table id
info bits
DATA TRX ID
FDATA ROLL PTR
Lens
i coll
dey
en
insert undo log reeord
next
lenN
n_update_ficld
type_cmpl
update vector
1*lend iu old coli
*undo no
i FIcn2 i u_old_co12
哪 table id
i posn lenn i u_old_coIN
colI
n_bytes_ below
lent
col2
n unique index
pos
posi *len
coli
coIN
pos
en
CoIN
start
start
图7-14 insert undo log的格式
图7-15 update undo log格式http:/blog.csdnnet/jiongyi11
310第7幸亨齐
研翻
update undo lo相对于之前介编的 insert undo log,录的内容更多,所需占用的空
间也更大。next、 start、 undo no、 table id与之前介绍的 insert undo log部分相同。这里
的 type_ cmpl,由于 update undo log本身还有分类,故其可能的值如下:
口12 TRX UNDO UPD EXIST REC更新non- delete-mark的记录
口13 TRX UNDO UPD DEL REC将 delete的记录标记为 not delete
口14 TRX UNDO DEL MARK REC将记录标记为 delete
接着的部分记录 update vector信息, update vector表示 update操作导致发生改变的
列。每个修改的列信息都要记录的 undo log中。对于不同的 undo log类型,可能还需要
记录对索引列所做的修改。
4.查看undo倌息
Oracle和 Microsoft SQL Server数据库都由内部的数据字典来观察当前undo的信息,
InnoDB存储引擎在这方面做得还不够,DBA只能通过原理和经验来进行判断。 InnoSQL
对 information schema进行了扩展,添加了两张数据字典表,这样用户可以非常方便和
快捷地查看undo的信息。
首先增加的数据字典表为 INNODB TRX ROLLBACK SEGMENT。顾名思义,这
个数据字典表用来查看 rollback segment,其表结构如图7-16所示。
mysql> DESC INNODB TRX ROLLBACK SEGMENT:
I Field
I Type
I Null I Key I Default Extra I
=--=+===---十===-+==
Segment id
I bigint (21) unsigned o
I space
I bigint(21)unsigned I No
10
page no
i bigint(21)unsigned I NO
last fage no
i bigint(21)unsigned I YES
I NULL
last offset
I bigint (21)unsigned I NO
I last trx no
ⅴ archar(18
I NO
I update undo list I bigint(21)unsigned I NO
I update undo cached I bigint(21) unsigned I no
I insert undo list bigint (21)unsigned NO
I insert undo cached I bigint(21)unsigned I No
10 rows in set (0.00 sec)
图7-16 INNODB TRX ROLLBACK SEGMENT的结构
例如,可以通过如下的命令来查看 rollback segment所在的页:http://blog.csdn.net/jiongyi1
5
72事务实现311
mysql> SELECT segment id, space, page no
->FROM INNODB TRX ROLLBACK SEGMENT
十
segment id I space I page no I
0
46
128 rows in set (0.00 sec)
另一张数据字典表为 INNODB TRX UNDO,用来记录事务对应的 undo log,方
便DBA和开发人员详细了解每个事务产生的undo量。下面将演示如何使用 INNODB
TRX UNDO表,首先根据如下代码创建测试表t
CREATE TABLE t
a工NT
b VARCHAR(32)
PRIMARY KEY (a)
KEY(b)
)ENGINE=InnoDB
接着插入一条记录,并尝试通过 INNODB TRX UNDO观察该事务的 undo log的
情况
mysql> TBEGIN;
Query OK,a rows affected (0. c0 sec)
mysql> INSERT INTO t SELECT 1,i1
Query oK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> SElECT FROM information schema INNODB RX UNDO\G
★★★★★★★★★青★★★★★★内★青南★1.xOw☆★幽★★★★★★宵★★★古★青大头★古
trx id: 3001
rseg id: 2
und。 rec no:0
undo rec type: TRX UNDO INSERTREC
size: 12
space: 0
page n。:334
offset: 272
1r。 w in set(0.00sechttp:/blog.csdnnet/jiongyi11
5I
312第7幸事务
通过数据字典表可以看到,事务D为3001, rollback segment的ID为2因为是该
条事务的第一个操作,故 undo rec no为0。之后可以看到插入的类型为 TRX UNDO
INSERT REC,表示是 insert undo log。size表示 undo log的大小,占用12字节。最后
的 space、 page no、 offset表示 undo log开始的位置。打开文件 ibdata l,定位到页(34,
272),并读取12字节,可得到如下内容:
011c0b001504800000010110
上述就是 undo log实际的内容,根据上一小节对 undo log格式的介绍,可以理得到:
011c
下一个 undo log的位置272+12=0x01lc
井urdo1ag的类型, TRX UND0_ INSERT REC为11
00
靜 urdo log的记录,等同于undo_rec_no
表的ID
04
徘主键的长度
80000001
主键的内容
0110
#u: do log开始的偏移量,272=0x0110
此外,由于知道该 undo log所在的 rollback segment的ID为2,用户还可以通过
数据字典表 INNODB TRX ROLLBACK SEGMENT来查看当前 rollback segment的信
息,如:
mysql> SELECT segment id, insert undo list,insert undo cached
fRom information schema. INNCDB TRX ROLLBACK SEGMENT
->WHERE segment id=2\G:
★实★卖女女女★女安女女女★女音女变文★★文1,yow★★實烹*實*★太责★言★大古**
segment id: 2
insert undo lis=: 1
insert undo cached: 0
l row in set (0.00 sec)
可以看到 insert undo list为1。若这时进行事务的 COMMIT操作,再查看该数据字
典表
mysql> COMMIT:
Query OK, 0 rows affected (0. oC sec)
mysql> SELECT segment id, insert undo list, insert undo cached
fROM information schema INNCDB TRX ROLlBACK SeGMeNT
WHERE segment id=2\G;
★★片★★★★大★大大为大★为★*大★**1,工°w大★有★★青★t大★大大★大古古大大青青素
segment id: 2http:/blog.csdnnet/jiongyi11
51.6
72事务的实现313
insert undφ1ist:0
insert undo cached: 1
1 row in set (0.00 sec
可以发现, insert undo list变为0,而 insert undo cached增加为1。这就是前面所介绍
的undo页重用。下次再有事务需要向该 rollback segment申请undo页时,可以直接使用
该页。
接着再来观察dlet操作产生的 undo log。进行如下操作:
mysq-> BEGIN:
Cuery OK, 0 rows affected (0.00 secy
mysql> dElETE FROM t WHERE a=l
cuery ok 1 row af-ected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0
my sql> SeleCt FRoM in formation schema INNODB TRX UNDO\G
南★★责★★★★★t变★安审读w★*1,row★★★★★★★★★★★★★古★责★★六六女★
trx id: 3201
rsec id: 2
undo rec no: 0
undo rec type: TRX UNDO DEL MARK REC
size: 37
space: 0
page no: 326
offset: 620
1 row in set (0.00 sech
用上述同样的方法定位到页326,偏移量为620的位置,得到如下结果:
051826000000000000000000000000002910e00
051827016000000003001e082000014e011004
0s182308000000100000048000000103013102
05182906c000000000000000000000000000000
接着开始整理:
C291
#下一个 undo log开始位置的偏移量
Ce
# undo log类型, TRX UNDO DEL MARK REC为14
00
f undo no
15
t table id
00
t info bits
0000003001e0
#xec事务id
820000014e0110
#:ec回滾针http:/blog.csdnnet/jiongyi11
314第7章事齐
挤者
04
#主键子度
80000001
#主键值
000b
#之后部分的长度
00
列的位置
04
#列的长度
80000001
列的值
03
#列的位置,前00~02为系统列
01
#列的长度
31
#列b,插入的字符串·1·的十六进制
026e
#开始位置的偏移量
观察 rollback segment僧息,可以看到
Imysy 1> SELECT segment id, update undo list, update undo cached
FRoM information schema, INNODB TRX ROLLBACK SEGMENT
WIIERE segment id-2\G;
★kk青古肃责青去★★☆★虎★★青害★定*1。。w
青★★;青青肯青青★實青;灾责
segment id: 2
update undo list: 1
update undo cached: 0
1 row in set (0.00 sec)
同样的,在事务提交后,undo页会放入 cache列表以供下次重用:
mysql> COMMIT
Query OK, o rows affected (0.00 sec)
myscl> SELECT segment id, update undo list, update undo cached
>From in formation schema. INNODB TRX ROLLBACK SEGMENT
->WHERE segment id=2\G;
★★會言北言古古★古★食★會★出肯★會;害
上Ow★忠吉吉古古古★吉★★古★宙宙★古去
segment id: 2
update undo list: 0
update undo cached: 1
1 row in set (0.co sec)
通过上面的例子可以看到, delete操作并不直接删除记录,而只是将记录标记为
已删除,也就是将记录的 delete flag设置为L。而记录最终的删除是在 purge操作中
完成的。
最后来看 update操作产生的 undo log情况。首先再次插入记录(l,1),然后进
行 update操作,同时通过数据字典表 INNODB TRX UNDO观察 undo log的情况:
ysql>INSERT INTo t SELECT 1, 1:http://blog.csdn.net/jiongyi1
6I
72事务的实现315
mysql> BEGIN;
督份图函令
Query oK, 0 rows affected (0.00 sec)
mysql> update t set b=2 WhERE a=l
Query OK, l row affected (0.00 sec)
Rows matched: 1 Changed:
Warnings: 0
mysql> SElECT FROM information schema INNODB TRX UNDO\G:
建实灾灾来★史k★k大★量★青太★★大1.ro★★★★★★★★★★★★★★内为内★为★★古古★古十
trx d: 5205
rseg id: 5
uncc Fec I。:0
undo rec type: TRX UNDO UPD EXIST REC
size: 41
space: 0
Page no: 318
offset: 724
1r。 w ln set(0.00sec)
用上述同样的方法定位到页318,偏移量为724的位置,得到如下结果
04f82d00000000002d000160000000032040
04f82e084000001480110048000000101030131
04f82f0000b00048000000103013102d4000000
整理后得到:
02 fc
#下一个unco1og的开始位置
Oc
#undo1og类型, TRX UNDO UFD DEL REC为13
00
t undo no
+t table id
00
info bits
0000003204e0
#t rec trx id
84000001480110
#rec回滚指针
04
#主键长度
80000001
#主键值
# update vector约数量
03
# update vector列b的编号
01
# update vector列的长度
# update vector列的值,这里是1
000b
#接下去部分占用的字节
00
#列的位置
04
#列的长度
80000001
#列的值
03
#列的长度http:/blog.csdnnet/jiongyi11
5
3167幸事务
#列的值
02d4
#undo1og开始位置的偏移量
上面的例子是更新一个非主键值,若更新的对象是一个主键值,那么其产生的undo
log完全不同,如
nysyl> ROLLbACK
Query OK, 1 row affected (0.00 sec)
mysql> UPDATe t SET a=2 WHERe a=li
Rows matched: 1 Changed: l Warnings: o
mysql> SeleCt FROM information schema.INNCDB TRX UNDO
->ORDER BY undo rec no\G:
trx id: 320F
rsec id: 11
undo rec nc: 0
undo rec Lype: TRX UNDO DEL MARK REC
size: 37
space
0
page no: 324
offset: 492
tk44da+AakA+AkkAAd4AAAA肉2,x。内青六h★青言★青贲古★★★★★★★★★★
txx id: 320F
eg id: 11
undo ec no: 1
undo rec type:TRⅩUNDO工 NSERT REC
e:12
space: 0
page no: 33
offset: 272
2 rows ir set (0.00 sec)
可以看到, update主键的操作其实分两步完成。首先将原主键记录标记为已删除,
因此需要产生一个类型为 TRX UNDO DEL MARK REC的 undo log,之后插入一条
新的记录,因此需要产生一个类型为 TRX UNDO INSERT REC的 undo log。undo
rec_n显示了产生日志的步骤。对 undo log不再详细进行分析,相关内容和之前介绍的
并无不同。
总之, InnoSQL数据库提供的关于undo信息的数据字典表可以帮助DBA和开发人
员更好地了解当前各个事务产生的undo信息。http://blog.csdn.net/jiongyi1
6I
72蓼务的现317争
7.2.3 purge
delete和 update操作可能并不直接删除原有的数据。例如,对上一小节所产生的表t
执行如下的SQL话句
DELETE FROM t AHERE a=l
表t上列a有聚集索引,列b上有辅助索引。对于上述的 delete操作,通过前面关
于 undo log的介绍已经知道仅是将主键列等于1的记录 delete flag设置为1,记录并没有
被删除,即记录还是存在于B树中。其次,对辅助索引上a等于1,b等于1的记录同
样没有做任何处理,甚至没有产生 undo log。而真正删除这行记录的操作其实被“延时”
了,最终在 purge操作中完成
purge用于最终完成dlte和 update操作。这样设计是因为 InnoDB存储引擎支持
MVCC,所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行,
故 InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过 purge来
进行判断。若该行记录已不被任何其他事务引用,那么就可以进行真正的 delete操作。
可见, purge操作是清理之前的 delete和 update操作,将上述操作“最终”完成。而实
际执行的操作为 delete操作,清理之前行记录的版本。
在前一个小节中已经介绍过,为了节省存储空间, InnoDB存储引擎的 undo log设
计是这样的:一个贞上允许多个事务的 undo log存在。虽然这不代表事务在全局过程中
提交的顺序,但是后面的事务产生的 undo log总在最后。此外, InnoDB存储引擎还有
一个 history列表,它根据事务提交的顺序,将 undo log进行链接。如下面的一种情况:
在图7-17的例子中, history list表示按照事务提交的顺序将 undo log进行组织。在
InnoDB存储引擎的设计中,先提交的事务总在尾端。 undo page存放了 undo log,由于
可以重用,因此一个 undo page中可能存放了多个不同事务的 undo log. trx5的灰色阴影
表示该 undo log还被其他事务引用
在执行 purge的过程中, InnoDB存储引擎首先从 history list中找到第一个需要被
清理的记录,这里为trx1,清理之后 InnoDB存储引擎会在trx1的 undo log所在的页中
继续寻找是否存在可以被清理的记录,这里会找到事务tx3,接着找到trx5,但是发现
trx5被其他事务所引用而不能清理,故去再次去 history list中查找,发现这时最尾端的
记录为tx2,接着找到trx2所在的页,然后依次再把事务trx6、trx4的记录进行清理。http://blog.csdn.net/jiongyi1
5
318第7幸事务
由于 undo page2中所有的页都被清理了,因此该 undo page可以被重闭。y
你
History list
Irx
trx
trxs
trx
t
t
trol
trx2
tx5
trx
tx7
x4
undo pagel
undo page2
图7-17 unda log与 history列表的关系
InnoDB存储引擎这种先从 history list中找 undo log,然后再从 undo page中找undo
log的设计模式是为了避免大量的随机读取操作,从而提高 purge的效率。
全局动态参数 innodb purge batch size用来设置每次 purge操作需要清理的undo
page数量。在 InnoDB12之前,该参数的默认值为20。而从12版本开始,该参数的默
认值为300。通常来说,该参数设置得越大,每次回收的 undo page也就越多,这样可供
重用的 undo page就越多,减少了磁盘存储空间与分配的开销。不过,若该参数设置得
太大,则每次需要purg处理更多的 undo pagc,从而导致CPU和磁盘IO过于集中于对
undo log的处理,使性能下降。因此对该参数的调整需要由有经验的DBA来操作,并且
需要长期观察数据库的运行的状态。正如官方的 MySQL数据库手册所说的,普通用户
不需要调整该参数。
当 InnodB存储引擎的压力非常大时,并不能高效地进行 purge操作。那么 history
ist长度会变得越来越长。全局动态参数 innodb_max purge lag用来控制 history list的
长度,若长度大于该参数时,其会“延缓”DML的操作。该参数默认值为0,表示不对
history list做任何限制。当大于0时,就会延缓DML的操作,其延缓的算法为:
delay -((length(history list)-innodb max purge lag)*100-5http:/blog.csdnnet/jiongyi11
51.6
7.2享务的实现319
deyg单位是毫秒。此外,需要特别注意的是, delay的对象是行,不是争
个DML操作。例如当一个 update操作需要更新5行数据时,每行数据的操作都会被
delay,故总的延时时间为5* delay。而 delay的统计会在每一次 purge操作完成后,重新
进行计算。
InnoDB12版本引入了新的全局动态参数 innodb max purge lag delay,其用来控制
delay的最大毫秒数。也就是当上述计算得到的 delay值大于该参数时,将 delay设置为
innodb max purge lag delay,避免由于 purge操作缓慢导致其他SQL线程出现无限制的
等待
7.2. 4 group commit
若事务为非只读事务,则每次事务提交时需要进行一次 fsync操作,以此保证重做
日志都已经写人磁盘。当数据库发生宕机时,可以通过重做日志进行恢复。虽然固态硬
盘的出现提高了磁盘的性能,然而磁盘的 fsync性能是有限的。为了提高磁盘 fsync的效
率,当前数据库都提供了 group commit的功能,即一次fync可以刷新确保多个事务日
志被写人文件。对于 InnoDB存储引擎来说,事务提交时会进行两个阶段的操作:
1)修改内存中事务对应的信息,并且将日志写入重做日志缓冲。
2〕调用 fsync将确保日志都从重做日志缓冲写入磁盘。
步骤2)相对步骤1)是一个较慢的过程,这是因为存储引擎需要与磁盘打交道
但当有事务进行这个过程时,其他事务可以进行步骤1)的操作,正在提交的事物完成
提交操作后,再次进行步骤2)时,可以将多个事务的重做日志通过一次sync刷新到磁
盘,这样就大大地减少了磁盘的压力,从而提高了数据库的整体性能。对于写人或更新
较为频繁的操作, group commit的效果尤为明显。
然而在 InnoDB1,2版本之前,在开启二进制日志后, InnoDB存储引擎的 group
commit功能会失效,从而导致性能的下降。并且在线环境多使用 replication环境,因此
二进制日志的选项基本都为开启状态,因此这个问题尤为显著
导致这个问题的原因是在开启二进制日志后,为了保证存储引擎层中的事务和二进
制日志的一致性,二者之间使用了两阶段事务,其步骤如下:
1)当事务提交时 InnoDB存储引擎进行 prepare操作http://blog.csdn.net/jiongyi1
FI
320第7幸事
务
2) MySQL数据库上层写入二进制日志。
3) InnoDB存储引擎层将日志写人重做日志文件。
a)修改内存中事务对应的信息,并且将日志写人重做日志缓冲。
b)调用 fsync将确保日志都从重做日志缓冲写入磁盘
旦步骤2)中的操作完成,就确保了事务的提交,即使在执行步骤3)时数据库
发生了宕机。此外需要注意的是,每个步骤都需要进行一次 fsync操作才能保证上下两
层数据的一致性。步骤2)的 fsync由参数sync_ binlog控制,步骤3)的 fsync由参数
innodb flush log at trx commit控制。因此上述整个过程如图7-18所示。
Session
Server
Binary Log
Engine
COMMIT
prepare
OK
write
OK
sync
OK
commit
OK
OK
图7-18开启二进制日志后 InnoDB存储引擎的提交过程
为了保证 MySQL数据库上层二进制日志的写人顺序和 InnoDB层的事务提交顺序
致, MySQL数据库内部使用了 prepare commit mutex这个锁。但是在启用这个锁之
后,步骤3)中的步骤a)步不可以在其他事务执行步骤b)时进行,从而导致了 group
cmmt失效。
然而,为什么需要保证 MYSQL数据库上层二进制日志的写入顺序和 InnoDB层
的事务提交顺序一致呢?这时因为备份及恢复的需要,例如通过工具 xtrabackup或者
backup进行备份,并用来建立 replication,如图7-19所示。
可以看到若通过在线备份进行数据库恢复来重新建立 replication,事务Tl的数据会
产生丢失。因为在 InnoDB存储引擎层会检测事务T3在上下两层都完成了提交,不需要
再进行恢复。因此通过锁 prepare commit mutex以串行的方式来保证顺序性,然而这会http:/blog.csdnnet/jiongyi11
5.A
72事务的实现32l
拼吾
使 group commit无法生效,如图7-20所示。
TI
T2
Binary Log
InnoDB
Prepare
Prepare
Prepare
Write a 100
Write (a 200
Write( 300
Commit
Commit
----4-n- line backup taken…………l-……-…-
Commit
图7-19 InnoDB存储引擎层事务提交的顺序与 MySQL数据库上层的二进制日志不同
T
Binary Log
InnoDB
Prepare
Write 100
Commit
Prepare
Write a 300
On-line Backup Ta
Commit
P
repare
write (Q 200
图7-20通过锁 prepare commit mutex保证 InnoDB存储引擎层事务提交与 MySQL
数据库上层的二进制日志写人的顺序性
这个问题最早在2010年的 MySQL数据库大会中提出, Facebook My SQL技术组,
Percona公司都提出过解决方案。最后由 MariaDB数据库的开发人员 Kristian Nielsen完http:/blog.csdnnet/jiongyi11
322郭7幸事齐
部拼吾爱墨
成了最终的“完美”解决方案。在这种情况下,不但 MySQL数据库上层的进制日志
写人是 group commit的, InnoDB存储引擎层也是 group commit的。此外还移除了原先
的锁 prepare commit mutex,从而大大提高了数据库的整体性。 MySQL56采用了类似
的实现方式,并将其称为 Binary Log Group Commit(BLGC)
MySQL5.BLGC的实现方式是将事务提交的过程分为几个步骤来完成,如图7-21
所示。
图7-2] MySQL56BLGC的实现方式
在 MySQL数据库上层进行提交时首先按顺序将其放入一个队列中,队列中的第一
个事务称为 leader,其他事务称为 follower, leader控制着 follower的行为。BLGC的步
骤分为以下三个阶段
口 Flush阶段,将每个事务的二进制日志写入内存中。
Sync阶段,将内存中的二进制日志刷新到磁盘,若队列中有多个事务,那么仅
次 fsync操作就完成了二进制志的写人,这就是BLGC。
口 Commit阶段, leader根据顺序调用存储引擎层事务的提交, InnoDB存储引擎本
就支持 group commit,因此修复了原先由于锁 prepare commit mutex导致 group
cOmmit失效的问题。
当有一组事务在进行 Commit阶段时,其他新事物可以进行 Flush阶段,从而使
group commit不断生效。当然 group commit的效果由队列中事务的数量决定,若每次
队列中仅有一个事务,那么可能效果和之前差不多,甚至会更差。但当提交的事务越多
时, group commit的效果越明显,数据库性能的提升也就越大。
参数 binlog max flush queue time用来控制 Flush阶段中等待的时间,即使之前的
组事务完成提交,当前一组的事务也不马上进入Sync阶段,而是至少需要等待一段
时间。这样做的好处是 group commit的事务数量更多,然而这也可能会导致事务的响应
时间变慢。该参数的默认值为O,且推荐设置依然为0。除非用户的 MySQL数据库系统
巾有着大量的连接(如100个连接),并且不断地在进行事务的写入或更新操作。http://blog.csdn.net/jiongyi1
5
73事务控病句323
部拼没
7.3事务控制语句
在 MySQL命令行的默认设置下,事务都是自动提交( auto commit)的,即执
行SQL语句后就会马上执行 COMMIT操作。因此要显式地开启一个事务需使用命令
BEGIN、 START TRANSACTION,或者执行命令 SET AUTOCOMMIT=0,禁用当前会
话的自动提交。每个数据库厂商自动提交的设置都不相同,每个DBA或开发人员需要
非常明白这一点,这对之后的SQL编程会有非凡的意义,因此用户不能以之前的经验来
判断 MySQL数据库的运行方式。在具体介绍其含义之前,先来看看用户可以使用哪些
事务控制语句
口 START TRANSACTION|BEGN:显式地开启一个事务。
口 COMMIT:要想使用这个语句的最简形式,只需发出 COMMIT。也可以更详细
些,写为 COMMIT WORK,不过这二者几乎是等价的。 COMMIT会提交事务,
并使得已对数据库做的所有修改成为永久性的。
口 ROLLBACK:要想使用这个语句的最简形式,只需发出 ROLLBACK。同样地,
也可以写为 ROLLBACK WORK,但是二者几乎是等价的。回滚会结束用户的事
务,并撤销正在进行的所有未提交的修改
SAVEPOINT identifier: SAVEPOINT允许在事务中创建一个保存点,一个事务
中可以有多个 SAVEPOINT。
口 RELEASE SAVEPOINT identifier:删除一个事务的保存点,当没有一个保存点执
行这句语句时,会抛出一个异常。
口 ROLLBACK TO[ SAVEPOINT] identifier:这个语句与 SAVEPOINT命令一起使用。
可以把事务回滚到标记点,而不回滚在此标记点之前的任何工作。例如可以发出
两条 UPDATE语句,后面跟一个 SAVEPOINT,然后又是两条 DELETE语句。如
果执行 DELETE语句期间出现了某种异常情况,并且捕获到这个异常,同时发出
了 ROLLBACK TO SAVEPOINT命令,事务就会凹滚到指定的 SAVEPOINT,撤
销 DELETE完成的所有工作,而 UPDATE语句完成的工作不受影响。
日 SET TRANSACTION:这个语句用来设置事务的隔离级别。 InnoDB存储引
擎提供的事务隔离级别有: READ UNCOMMITTED、 READ COMMITTED、
REPEATABLE READ、 SERIALIZABLE。http://blog.csdnnet/jiongyi1
BI
324第7幸事务
部拼没
START TRANSACTION、BEGN语句都可以在 MySQL命令行下显式地开启一余
事务。但是在存储过程中, MySQL数据库的分析器会自动将BEGN识别为 BEGIN…
END,因此在存储过程中只能使用 START TRANSACTION语句来开启一个事务。
COMMIT和 COMMIT WORK语句基本是一致的,都是用来提交事务。不同之处在
于 COMMIT WORK用来控制事务结束后的行为是CHAN还是 RELEASE的。如果是
CHAIN方式,那么事务就变成了链事务。
用户可以通过参数 completion type来进行控制,该参数默认为0,表示没有任何
操作。在这种设置下 COMMIT和 COMMIT WORK是完全等价的。当参数 completion
type的值为1时, COMMIT WORK等同于 COMMIT AND CHAIN,表示马上自动开启
一个相同隔离级别的事务,如:
mysc l> CREATE TABLE t a INT, PRIMARY KEY (a)ENGINE=INNODB
Query OK, 0 rows affected (0.00 sec)
mysql> SELEcT @2autocommit\G;
★★货★t★大★x齿★*害★★★★★★*★1。rW丈★★文★文★★★★★★★★女★★女★安太★★★
eeautocommit: 1
row in set (0.00 sec)
mysq> SFT recompletion type=l;
Query oK, 0 rows affected (0.00 sec)
mysql>BEGIN;
Query OK,o rows affected (0.00 sec)
mysql> INSERT INTo t SELECT 1;
Query Ok, 1 row affected (0.00 sec
Records: 1 Duplicates: 0 Warnings: 0
mysql> COMMIT WORK i
Query OK, o rows affected (0.01 sec)
mysql> INSERT INTo t SELECT 2;
Query OK, I row affected (0.20 sec)
Records: 1 Duplicates: 0 warnings:0
mysql> INSERT INTO t SELECT 2;
ERROR 1062(23000) Duplicate entry 12 for key ' PRIMARY
mysl> ROLLBACK;http://blog.csdn.net/jiongyi1
5
7.3事务控制语的325
Query OK, o rows affected (0.00 sec)
异注意回滚之后只有1这个记录,而没有2这个记录
mysql>sElECt ERaM t\G
k走**★*★k★★★责★★★★★食★★r。w★實★★實丈寅★实★★★责建★灾★★实★
1 row in set (oo0 sec)
在这个示例中我们设置 completion type为1,第一次通过 COMMIT WORK来插入
1这个记录。之后插入记录2时我们并没有用BEGN(或者 START TRANSACTION)
来显式地开启一个事务,之后再插入一条重复的记录2就会抛出异常。接着执行
ROLLBACK操作,最后发现只有1这一个记录,2并没有被插入。因为 completion type
为1时, COMMIT WORK会自动开启一个链事务,第二条 INSERT INTO t SELECT2语
句是在同一个事务内的,因此回滚后2这条记录并没有被插入表t中。
参数 completion type为2时, COMMIT WORK等同于 COMMIT AND RELEASE。
在事务提交后会自动断开与服务器的连接,如:
mysql> SET recompletion type-2;
Query OK, 0 rows affected (0.00 sec)
mysql> BEGIN:
Query OK, 0 rows affected (0.00 sec)
mysql> INSERT INto t SELECT 3;
Query OK, 1 row a=fected (0. co sec)
Records: 1 Duplicates: 0 Warnings: o
mysql> COMMI T WORK i
Query Ok, a rows affected (0.01 sec)
mysql> SELECT @@version\G;
ERROR 2006 (HYOOO): MySQL server has gone away
No connection. Tying to reconnect
Connection id:
54
Current database: test
★南★★★★实★实★★★★★★★★★★卖1,row★★★★★★★★*★★★★*★★肉南★★古女女★
eversion: 5.1.45-l0g
1 row in set (0. Do sec)
通过上面的示例可以发现,当将参数 completion type设置为2时, COMMIT WORKhttp:/blog.csdnnet/jiongyi11
5.
326第7章事务
部新
后用户再执行语句 SELECT@@ version会出现 ERROR2006(HY000: MySQLServer
has gone away的错误。抛出该异常的原因是当前会话已经在上次执行 COMMIT WORK
语句后与服务器断开了连接。
ROLLBACK和 ROLLBACK WORK与 COMMIT和 COMMIT WORK的工作一样
这里不再进行赘述。
SAVEPOⅠNT记录了一个保存点,可以通过 ROLLBACK TO SAVEPOINT来回滚到
某个保存点,但是如果回滚到一个不存在的保存点,会抛出异常:
mysqL> BEGIN;
Query OK, 0 rows affected (0oC sec)
mysql> ROLLBACK TO SAVEPOINT tl;
ERROR 1305(42000]: SAVEPOINT tl does not exist
InnoDB存储引擎中的事务都是原子的,这说明下述两种情况:构成事务的每条语句
都会提交(成为永久),或者所有语句都回滚。这种保护还延伸到单个的语句。一条语
句要么完全成功,要么完全回滚(注意,这里说的是语句回滚)。因此一条语句失败并
抛出异常时,并不会导致先前已经执行的语句自动回滚。所有的执行都会得到保留,必
须由用户自己来决定是否对其进行提交或回滚的操作。如:
mysql> CREATE TAbLE t (a INT, PRIMARY KEY (a))ENGINE-INNODB
Query ok,0 rows affected (0.00 sec)
mysqL> BEGINF
Query OR,0 rows affected (0.00 sec)
mysql> INSERT INto t sELECT 1
Query OK, 1 row affected (C.00 sec)
Records: 1 Duplicates: Warnings: 0
mysql> INSERT INTo t sEleCt 1
ERROR 1062 (23000): Duplicate entry ' l' for key 'PRIMARY'
mysql> SELECT FROM t\Gi
★青常害**青*★★★★★★南★★★★★1.x○w★贲★太★南★★k**★★★★★★★★★★★★实
A
1r。 w in set〔0.00sec)
可以看到,插入第二记录1时,因为重复的关系抛出了1062的错误,但是数据库并http://blog.csdn.net/jiongyi1
6
73事办拉制衙句327
没有进行自动回滚,这时事务仍需要用户显式地运行 COMMIT或 ROLLBACK命会阻
另一个容易犯的错误是 ROLLBACK TO SAVEPOINT,虽然有 ROLLBACK,但其
并不是真正地结束一个事务,因此即使执行了 ROLLBACK TO SAVEPOINT,之后也需
要显式地运行 COMMIT或 ROLLBACK命令。
mysql> CREAtE tAble t a Int, PRIMARY KEY (a))ENGINE=INNODB
Query oK, 0 rows affected (0.Do sec)
mysql> BeGIN;
Query OK, o rows affected (0. 00 sec)
mysql> INSERT INTo t sElECT 1:
Query oK, l row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0
mysql> SAvEPOint tl
Query OK, o rows affected (0.00 sec)
mysql> INSERT INTo t SELECT 2;
Query oK, 1 row affected (0.00 sec)
Records: 1 Duplicates: o Warnings: o
mysql> SAVEPOINT t2
Query oKr 0 rows a=fected (0.00 sec)
mysqL> RELEASE SAVEPOINT tl;
Cuery Ok, c rows affected (0.00 sec)
mysql> INSERT INto t SELECt 2;
ERROR 1062(23000): Duplicate entry '2 for key 'PRIMARY.
mysql> ROLLBACK TO SAVEPOINT t2:
Query oK, o rows affected (0.00 sec)
mysql> SELECT FRoM t;
11
2
2r。 ws in seE(0.00sec)http://blog.csdn.net/jiongyi1
BI
3287事务
mysql>ROLLBACK;
你邮
Query Ok, 0 rowe affected (0.00 sec)
mysql> sElECT FROM t;
Empry set (0.00 sec
可以看到,在上面的例子中,虽然在发生重复错误后用户通过 ROLLBACK
TO SAVEPOINT2命令回滚到了保存点t,但是事务此时没有结束。再运行命令
ROLLBACK后,事务才会完整地回滚。这里再一次提醒, ROLLBACK TO SAVEPOINT
命令并不真正地结束事务。
7.4隐式提交的SQL语句
以下这些SQL语句会产生一个隐式的提交操作,即执行完这些语句后,会有一个隐
式的 COMMIT操作。
口DDL语句: ALTER DATABASE. UPGRADE DATA DIRECTORY NAME,
ALTER EVENT, ALTER PROCEDURE, ALTER TABLE, ALTER VIEW
CREATE DATABASE, CREATE EVENT, CREATE INDEX, CREATE
PROCEDURE, CREATE TABLE, CREATE TRIGGER, CREATE VIEW
DROP DATABASE, DROP EVENT, DROP INDEX, DROP PROCEDURE
DROP TABLE, DROP TRIGGER, DROP VIEW, RENAME TABLE
TRUNCATE TABLE。
口用来隐式地修改 MySQL架构的操作: CREATE USER、 DROP USER、 GRANT
RENAME USER、 REVOKE、 SET PASSWORD。
口管理语句: ANALYZE TABLE、 CACHE INDEX、 CHECK TABLE、 LOAD INDEX
INTO CACHE、 OPTIMIZE TABLE、 REPAIR TABLE。
注意我发现 Microsoft SQL Server的数据库管理员或开发人员往往忽视对于
DDL语句的隐式提交搡作,因为在 Microsoft SQL Server数据库中,即使是
DDL也是可以回滚的。这和 InnoDB存储引擎、 Oracle这些数据库完全不同。
另外需要注意的是, TRUNCATE TABLE语句是DDL,因此虽然和对整张表执行http:/blog.csdnnet/jiongyi11
5I.
75对于事务操作的统329争
DELETE的结果是一样的,但它是不能被回滚的(这又是和 Microsoft SQL Server数据
不同的地方)
mysql> SELECT FRM t\G;
女女女女+安女★*如★★★★言大古大古*六1.〓。w*大★★★★★★★★★专★★x失*****来
a:1
专★女方女六★★青★专★★★其光*★★肯*★2,row*★★★★★★★★★★★★x**量*★k東★
2 rows in set (0.00 sec)
mySa_> BEGIN:
Query OK, 0 rcws affected (0.01 sec)
mysql> TRUNCATE TABLE t
Query OK, 0 rcws affected (0.00 sec)
mysql> ROLLBACKi
Query oK, o rows affected (0.00 sec)
mysql, SElECT*FROM t
cpty set (0.00 sec!
7.5对于事务操作的统计
由于 InnoDB存储引擎是支持事务的,因此 InnODB存储引擎的应用需要在考虑每秒
请求数( Question Per Second,QPS)的同时,应该关注每秒事务处理的能力( Transaction
Per second,TPS)。
计算TPS的方法是( com commit+com rollback)fime。但是利用这种方法进行
计算的前提是:所有的事务必须都是显式提交的,如果存在隐式地提交和回滚(默认
autocommit=1),不会计算到 com commit和 com rollback变量中。如:
lysyl> SHOW GLOBAL STATUS LIKe 'com commit\G:
★实害责★★★头古★★★★★古肯青计青古南1,工。w计南★★内向南★★如★青★★归★★实女★
variable name: Com commit
Value: 5
1 row in se=(0.o0 sec)
mysql> INSERT INTo t SELECT 3:
Query oK, 1 row affected (0.00 sec
Records: 1 Duplicates: Warnings: Dhttp:/blog.csdnnet/jiongyi11
5.4
0第7幸事务
mysql> SELECT FROM t\G;
★★★★★青丈丈★女★责★★★★★食★言★★x★1.rOw*言★言言★★言言★★青★工青言t實
请古南青★责古古★古诸去出责安专★☆★皆*;2.row青***责安吉青卖声专★☆皆审★★★
a:2
3. row
a
3 rows in set (Co0 sec)
mysqL> SHOW GLOBAL STATUS LIKe 'ccm commit\G;
青真害有青宽育害读言害离贵★*害肯★1.￥。H★實實實★贵青★★★食★宽★★★★文★★★皆★
variable name: Com commit
Value: 5
l row in set (0.00 sec)
MySQL数据库中另外还有两个参数 handler commit和 handler rollback用于事务的
统计操作。但是我注意到这两个参数在 My SQL5.1中可以很好地用来统计 InnoDB存储
引擎显式和隐式的事务提交操作,但是在 InnoDB Plugin中这两个参数的表现有些“怪
异”,并不能很好地统计事务的次数。所以,如果用户的程序都是显式控制事务的提交
和回滚,那么可以通过 com commit和 com rollback进行统计。如果不是,那么情况就
显得有些复杂。
76事务的隔离级别
令人惊讶的是,大部分数据库系统都没有提供真正的隔离性,最初或许是因为
系统实现者并没有真正理解这些问题。如今这些问题已经弄清楚了,但是数据库实
现者在正确性和性能之间做了妥协。ISO和 ANIS SQL标准制定了四种事务隔离级别
的标准,但是很少有数据库厂商遵循这些标准。比如 Oracle数据库就不支持READ
UNCOMMITTED和 REPEATABLE READ的事务隔离级别。
SQL标准定义的四个隔离级别为:
日 READ UNCOMMITTED
口 READ COMMITTED
口 REPEATABLE READ
口 SERIALIZABLEhttp://blog.csdn.net/jiongyi1
5.
76*务的隔离级别3
READ UNCOMMITTED称为浏览访问( browse access),仅仅针对事务而言的
READ COMMITTED称为游标稳定( cursor stability)。 REPEATABLE READ是29999
的隔离,没有幻读的保护。 SERIALIZABLE称为隔离,或3°的隔离。SQL和SQL2标
准的默认事务隔离级别是 SERIALIZABLE。
InnoDB存储引擎默认支持的隔离级别是 REPEATABLE READ,但是与标准SQL
不同的是, InnoDB存储引擎在 REPEATABLE READ事务隔离级别下,使用Next-Key
Lok锁的算法,因此避免幻读的产生。这与其他数据库系统(如 Microsoft SQL Server
数据库)是不同的。所以说, InnoDB存储引擎在默认的 REPEATABLE READ的事务隔
离级别下已经能完全保证事务的隔离性要求,即达到SQL标准的 SERIALIZABLE隔离
级別。
隔离级别越低,事务请求的锁越少或保持锁的时间就越短。这也是为什么大多数数
据库系统默认的事务隔离级别是 READ COMMITTED。
据了解,大部分的用户质疑 SERIALIZABLE隔离级别带来的性能问题,但是根
据 Jim Gray在《 Transaction Processing》一书中指出,两者的开销几乎是一样的,甚至
SERIALIZABLE可能更优!!因此在 InnoDB存储引擎中选择 REPEATABLE READ的事
务隔离级别并不会有任何性能的损失。同样地,即使使用 READ COMMITTED的隔离
级别,用户也不会得到性能的大幅度提升。
在 InnoDB存储引擎中,可以使用以下命令来设置当前会话或全局的事务隔离级别:
SET [GLOBAL I SESSION]TRANSACTION ISOLATION LEVEL
READ UNCOMMITTED
READ COMMITTED
I REPEATABLE READ
SERIALIZABLE
如果想在 MySQL数据库启动时就设置事务的默认隔离级别,那就需要修改 MySQL
的配置文件,在[ mysqld]中添加如下行
[mysqld]
transaction-isolation READ-COMMITTED
查看当前会话的事务隔离级别,可以使用:
mysql>SELECT G@tx isolation\Ghttp:/blog.csdnnet/jiongyi11
5
332第7章事齐
★★★古★★凼★★★大古★★★★片★★★★★★1.row★★*★*★★★青*★★★责青★肯★*★★★★
eatx isolation: REPEATABLE-READ
1 row in set (0. 01 sec)
查看全局的事务隔离级别,可以使用:
mysql>SELECT eeglobaltx isolation\G:
丈文女文★★★★文★文大★★★★★★★★★★★★1.xow*★*★卖★★卖青★★女出卖害
g@global tx isolation: RE PEATABLE-READ
1r。 w in set(0.00sec)
在 SERIALIABLE的事务隔离级别, InnoDB存储引擎会对每个 SELECT语句后
自动加上 LOCK IN SHARE MODE,即为毎个读取操作加一个共享锁。因此在这个事
务隔离级别下,读占用了锁,对一致性的非锁定读不再予以支持。这时,事务隔离级
别 SERIALIZABLE符合数据库理论上的要求,即事务是wel- formed的,并且是two
phrased的。有兴趣的读者可进一步研究。
因为 Innodb存储引擎在 REPEATABLE READ隔离级别下就可以达到3°的隔离,
因此一般不在本地事务中使用 SERIALIABLE的隔离级别。 SERIALIABLE的事务隔离
级别主要用于 InnoDB存储引擎的分布式事务
在 READ COMMITTED的事务隔离级别下,除了唯一性的约束检查及外键约束的
检查需要 gap lock, InnoDB存储引擎不会使用 gap lock的锁算法。但是使用这个事务隔
离级别需要注意一些问题。首先,在 MYSQL5,1中, READ COMMITTED事务隔离级
别默认只能工作在 replication(复制)二进制日志为ROW的格式下。如果二进制日志工
作在默认的 STATEMENT下,则会出现如下的错误:
mysql> CREATE TABLE a
->h INt PRIMARY KEY (h)
〕 ENGINE= INNODE
Query OK, 0 rows affected (0.0l sec)
mysql>seT G@tx isolation='READ-COMMITTED'
Query OK, o rows affected (0.00 sec)
MySql> SELECT Gtx isolation\G:
★★肯★古肯冀★熏★真六★★★★古古★★
Wt定史定实灾丈★青肃责★★责★★责★★责★★★★
atx isolation: REPEATABLE-READ
1 row in set (0.0C sec)
mysqL> BEGIN;http:/blog.csdnnet/jiongyi11
5I.
76事齐的隔离蚁别33
Query oK 0 rows affected (o,o0 sec
mysql>INSERT Into a SELECT
ERROR 1598 ( HY000): Binary logging not possible. Message: Transaction level
READ-COMMITTED in InnoDB is not safe for binlog mode STATEMEN'T
在 MySQL50版本以前,在不支持ROW格式的二进制日志时,也许有人知道通过
将参数 innodb locks unsafe for binlog设置为1可以在二进制日志为 STATEMENT下使
用 READ COMMITTED的事务隔离级别
mysql> SEIcr eversion\G
★★青★★★★★★★★责★★★★★★★青大★★★★1.r。w青★★青文★★★★★★★★大★★★大内内古大★肖★
g@version: 5.0.77-log
1 row in set (0.0d sec!
mysql> SHOW VARIABLES LIKE innodb locks unsafe for binlog\G;
宵育實言害青言宽常赏青言害言青青青;言1.Y。W宴害实宽實囊定★★;★★★★★
Variable name: innodb locks unsafe for binlog
value: oN
1 row in set (0.00 secy
rusal>sHT的t1soat1on="REaD-coM士TTED"
Query oK, o rows affected (0.00 sec
MySqL> BEGIN:
Query oK, o rows affected (0.00 sec?
mysql> INsert Into a select 1:
Query OK,o rows affected (0.00 seck
mysql> COMMIT;
Query OK,0r。 ws affected(0·00sec
mysq> SELECT FROⅣaG
★★实史灾★★安卖安实安★★★*1。rw背★★★★★典★★青★★为★★★六★★★★舟★★
★★★★责★★★青安安皆★读★★责2,row★★★★★★★★★★t★★★★大★实★幽出责光幽
吉★古★★★★★★★★★★★冒★★★★胄★★
3
★★★★★★★★★★★肯★詈★★計★胄中曹
b:4
★★★★★★大大古大★★古古古★青青青青★*4.工ew★★★★★责★★★★太★★★★★★★★南★★★★
b:5
4 rows in set (0.00 sec)http:/blog.csdnnet/jiongyi11
5I
334第7幸亨务
接着在mase.开启一个会话A执行如下事务,并且不要提交:季令
Sessi。rA。 n master
mysql BEGINi
Query OK, 0 rows affected (0.00 sec)
mysql> dELETE FROM a NHERE b<=5i
Query OK, 4 rows affected (0.01 secy
同样,在 master上开启另一个会话B,执行如下事务,并且提交
Sessio b on master
mysql>BEGIN:
Query oK, o rows affected (0.00 sec)
mysql> InseRt into a SELECT 3;
Query ok,o rows affected (0.01 sec)
mysql> COMMIT'i
Query oK, 0 rows affected (0.00 sec)
接着会话A提交,并查看表a中的数据:
f Session a on master
mysql> COMMIT;
Query OK;0r。 ws affected《0.00sec)
my sql> SELECT FROM a\G;
★责★★★青贵★★★★★★贵★★貴★★★★★★1.Yow★★*★★★★*★★★★★★★★内★★★★★★★★
但是在 slave上看到的结果却是:
Slave
mysql> SELECT FROM a;
Empty set (0.00 sec)
可以看到,数据产生了不一致。导致这个问题发生的原因有两点
日在 READ COMMITTED事务隔离级别下,事务没有使用 gap lock进行锁定,因
此用户在会话B中可以在小于等于5的范围内插人一条记录;
日 STATEMENT格式记录的是 master上产生的SQL语句,因此在 master服务器上
执行的顺序为先删后插,但是在 STATEMENT格式中记录的却是先插后删,逻辑
顺序上产生了不一致。http://blog.csdn.net/jiongyi1
5
77分布式亨务335
要避免主从不一致的间题,只需解决上述问题中的一个就能保证数据的同步了
使用 READ REPEATABLE的事务隔离级别可以避免上述第一种情况的发生,也就避免
了 master和 slave数据不一致问题的产生。
在 MySQL5版本之后,因为支持了ROW格式的二进制日志记录格式,避免了
第二种情况的发生,所以可以放心使用 READ COMMITTED的事务隔离级别。但即使
不使用 READ COMMITTED的事务隔离级别,也应该考虑将二进制日志的格式更换成
ROW,因为这个格式记录的是行的变更,而不是简单的SQL语句,所以可以避免一些
不同步现象的产生,进一步保证数据的同步。 InnoDB存储引擎的创始人 Heikkituuri也
在hp:∥ bugs. mysql. com/bug php?d=33210这个帖子中建议使用Row格式的二进制
日志。
77分布式事务
7.71 My SQL数据库分布式事务
InnoDB存储引擎提供了对XA事务的支持,并通过XA事务来支持分布式事务的实
现。分布式事务指的是允许多个独立的事务资源( transactional resources)参与到一个全
局的事务中。事务资源通常是关系型数据库系统,但也可以是其他类型的资源。全局事
务要求在其中的所有参与的事务要么都提交,要么都回滚,这对于事务原有的ACID要
求又有了提高。另外,在使用分布式事务时, InnoDB存储引擎的事务隔离级别必须设置
为 SERIALIZABLE
XA事务允许不同数据库之间的分布式事务,如一台服务器是 MySQL数据库的,另
台是 Oracle数据库的,又可能还有一台服务器是 SQL Server数据库的,只要参与在
全局事务中的每个节点都支持XA事务。分布式事务可能在银行系统的转账中比较常见,
如用户 David需要从上海转10000元到北京的用户 Mariah的银行卡中:
f BankeShanghai
UPDATE account sET money =money 10000 WHERE user='David'
BankeBeijing
UPDATE account SET money money 10000 WhERe user='Mariah'i
在这种情况下,一定需要使用分布式事务来保证数据的安全。如果发生的操作不http://blog.csdn.net/jiongyi1
5
336第7幸事务
能全部提交或回滚,那么任何一个结点出现问题都会导致严重的结果。要么是Dav
的账户被扣款,但是 Mariah没收到,又或者是Davd的账户没有扣款, Mariah却收到
钱了
XA事务由一个或多个资源管理器( Resource Managers)、一个事务管理器
( Transaction Manager)以及一个应用程序( Application Program)组成。
口资源管理器:提供访问事务资源的方法。通常一个数据库就是一个资源管理器
口事务管理器:协调参与全局事务中的各个事务。需要和参与全局事务的所有资源
管理器进行通信。
口应用程序:定义事务的边界,指定全局事务中的操作。
在 MySQL数据库的分布式事务中,资源管理器就是 MySQL数据库,事务管理器
为连接 MySQL服务器的客户端。图722显示了一个分布式事务的模型
Application Program (Ap)
INSERTUPDTE
DELETE
SELECT
Transaction Manager
Resource Manager
(TM)
(RMs
Two-Phase Commit
图7-22分布式事务模型
分布式事务使用两段式提交( two-phase commit)的方式。在第一阶段,所有参与
全局事务的节点都开始准备( PREPARE),告诉事务管理器它们准备好提交了。在第二
阶段,事务管理器告诉资游管理器执行 ROLLBACK还是 COMMIT。如果任何一个节点
显示不能提交,则所有的节点都被告知需要回滚。可见与本地事务不同的是,分布式事
务需要多一次的 PREPARE操作,待收到所有节点的同意信息后,再进行 COMMIT或是
ROLLBACK操作。
MySQL数据库XA事务的SQL语法如下:
XA [START I BEGINI xid [JCIN I RESUME]http:/blog.csdnnet/jiongyi11
7.7分布式享务337
XA END xid [ SUSPEND FOR MIGRATEJ
XA PREPARE xid
XA COMMIT xid [ONE PHASE]
XA ROllBACK xid
XA RECOVER
在单个节点上运行XA事务的例子:
mysql> XA STArt a'i
Query OK, o rows affected (0.00 sec)
mysql> INSERT INTO z SELECT 1l;
Query oK, 1 row affected (o, oo sec)
Records: 1 Duplicates: C Warnings: 0
mysql> XA End;
Query OK, 0 rows affected (0.00 sec)
mysql> XA. PREPare 'a'i
Query ok,o rows affected (0.05 sec)
mysl> XA. RECOVER\G:
★安★★★★青★★★★★责南★★★★★1.yow★★★★★★★★★★★★★★★内★★★★女★★*冒
formatIO: 1
grid length: 1
equal length: o
data: a
l row in set (0.00 sec)
mysql> XA COMMIT a'i
Query OK, 0 rows affected (0.05 sec)
在单个节点上运行分布式事务没有太大的实际意义,但是要在 MySQL数据库的命
令下演示多个节点参与的分布式事务也是行不通的。通常来说,都是通过编程语言来
完成分布式事务的操作的。当前Java的JTA( Java Transaction aPi)可以很好地支持
MySQL的分布式事务,需要使用分布式事务应该认真参考其API。下面的一个示例显示
了如何使用JTA来调用 MySQL的分布式事务,就是前面所举例的银行转账的例子,代
码如下,仅供参考:http://blog.csdn.net/jiongyi1
5
338第7章事务
import java. sql Connection;
import javax, sqlXAConnection;
mport javax. transaction xa.*i
import com mysql jdbc jdbc, optional. MysqlXADataSource;
ort java.sq1.★;
class Myxid implements xid
Public int formatIdi
Public byte grid[]i
public byte bqual[]
Public MyXid()[
public Myxid (int formatIc, byte grid[l, byte bqual[]
this formatio fcrmatid
this grid grid;
this, equal = equal
public int getFormatId()
xe七 urn formatIo
public byte[] getBranchQualifier(
raturn quali
public byte[] getGlcbalTransactionId(
return atrid:
Public class xa demo
Public static MysqlXADatasourcc GctDataSource
string connstring,
string userhttp:/blog.csdnnet/jiongyi11
51.6
7.7分布式襄务339
string passwd)(
tryi
MysclXADataSource ds new MysqlXAData Source (i
ds. seturliconnstring)i
ds. setUser (user)i
ds. setPassword(passwd
return dsi
catch(Exception e)i
System. out. println(e tostring ()i
return null
public atatic void main(String[] args) t
String connS-ringl =#jdbc: mysl://192.168.24,43: 3306/bank shanghai"i
String connstring2 ="idbc: mysql: //192.168.24.166: 3306/bank
beijing
try t
MysqlXADataSource csl
GetDatasource(connStringl,"peter,12345")
MysglXADataSource cs2
GetDataSource(connstring2, david12345)i
XAConnection xaconnl dsl getxAConnection()i
XARe source xaResl xaConnl. getXARe source ()i
Connection connI = xaConnl get Connection()i
Statement stmt s connl. createstatement(i
xAConnection xaconn2 ds2 getxAConnection()i
XAResource xaRes2 =xaConn2. getXARe source()i
Connection conn2 =xaConn2 getConnection()
Statement stmt2 conn2 createstatement()i
Xid xidl new Myxid(
100
new byte[]【0x01},
lew byte[][0x021)i
Xid xid2= new Myxid〔
100
new byte[]1]
new byte [][0x121);
tryI
xaResl. start(xidl xAre source. IMNOFLAGShttp:/blog.csdnnet/jiongyi11
340弟7幸事务
stmt. execute(
器
UPDATE account SET money money 10000
WHERE user一"avid!
;
xaResl. end(xidl, XAResource, TMSUCCESS);
xaRes2. start (xidi, XAResource. TMOF'LAGS);
stmt2 execute(
UPDATE account SET money money+ 10000
WHERE user='mariahTif
xaRes2, end(xid2, xAResource. TMSUCCESS):
int ret2 xaRes2 prepare(xid2)i
int retl xaResl prepare(xidi
工E【工et1== XAResource,XAOK
兵x曰七2== XAResource,KAoK)
xaResl, commit(xidl, false)
xaRes2. commit(xid2, false)
catch(Exception el i
e printstackTrace()
catch〔 Exception e
System.out-printInIe, tostring(1)i
通过参数 innodb support xa可以查看是否启用了XA事务的支持(默认为oN)
mysql> SHOW VARIABLES LIKE innodb support xa\G:
★★★声★★★央★★南★内为青★青★★青*1,rOW★★★★★★★★★★★女★★★内大★★★虞★肃害熏
Variable name: innodb support xa
va⊥ue:ON
1 row in set【0,01scc)
772内部XA事务
之前讨论的分布式事务是外部事务,即资源管理器是 MySQL数据库本身。在
MySQL数据库中还存在另外一种分布式事务,其在存储引擎与插件之间,又或者在存http:/blog.csdnnet/jiongyi11
51.6
7.8不好的事务341
部挤吾
储引擎与存储引擎之间,称之为内部XA事务。
最为常见的内部XA事务存在于 binlog与 InnoDe存储引擎之间。由于复制的需要,
因此目前绝大多数的数据库都开启了 binlog功能。在事务提交时,先写二进制日志,再
写 InnoDB存储引擎的重做日志。对上述两个操作的要求也是原子的,即二进制日志和
重做口志必须同时写入。若二进制日志先写了,而在写入 InnoDB存储引擎时发生了宕
机,那么 slave可能会接收到 master传过去的二进制日志并执行,最终导致了主从不
致的情况。如图7-23所示。
在图7-23中,如果执行完①、②后在步骤③之前 MySQL数据库发生了岩
机,则会发生主从不一致的情况。为了解决这个问题, MySQL数据库在 binlog与
InnodB存储引擎之间采用XA事务。当事务提交时, InnoDB存储引擎会先做一个
PREPARE操作,将事务的xd写人,接着进行二进制日志的写入,如图7-24所示。
如果在 InnodB存储引擎提交前, MySQL数据库宕机了,那么 MySQL数据库在重
启后会先检查准备的UXID事务是否已经提交,若没有,则在存储引擎层再进行一次
提交操作。
Master事务提交
slave
beware
Master事务提交
slave
relay log
,,
write binlog
clay lo
write binlog
disk
innodb write
innodb write
redo log
disk
redo log
图723宕机导致 replication主从不一致的情况
图724 MySQL数据库通过内部XA
事务保证主从数据一致
7.8不好的事务习惯
7.8.1在循环中提交
开发人员非常喜欢在循环中进行事务的提交,下面是他们可能常写的一个存储
过程:http://blog.csdn.net/jiongyi1
BI
342某7享亨多
部拼没
CREATE PROCEDURE load(count INT UNSIGNED)
BEGIN
DECLARE S INT UNSIGNED DEFAULT 1F
DECLARE C CHAR(80)CEFAULT REPEAT(a, 80)
WHILE S < count Do
INSERT INTO tI SELECT NULL, Ci
COMMIT:
SET S =5+l
END WE工LE
END
其实,在上述的例子中,是否加上提交命令 COMMIT并不关键。因为 InnoDB存储
引擎默认为自动提交,所以在上述的存储过程中去掉 COMMIT,结果其实是完全一样
的。这也是另一个容易被开发人员忽视的问题:
CREATE PROCEDUR load (count INT UNS IGNED)
BEGIN
DECLARE S INT UNSIGNED DEFAULT 1
DECLARE C CHAR(80) DEFAULT REPEAT(a,80):
WHILE S<= count Do
INSERT INTO tl SELECT NULL, ci
SET3·3+1;
END WHILE;
END:
不论上面哪个存储过程都存在一个问题,当发生错误时,数据库会停留在一个未知
的位置。例如,用户需要插入10000条记录,但是在插入5000条时,发生了错误,这
时前5000条记录已经存放在数据库中,那应该怎么处理呢?另一个问题是性能问题,
上面两个存储过程都不会比下面的存储过程load3快,因为下面的存储过程将所有的
NSErT都放在一个事务中:
CREATE PROCEDURE load3 (count INT UNS I GNED)
BEGIN
DEClARE S INT UNSIGNED DEFAULT 1
DECLARE G CHAR (80) dEFAULT RePeAT('a,80)
START TRANSACTION;
WHILE s < coun Do
INSERT INTO tl SELECT NULLC
SET S=S+i:
END WIITI民
CoMMIT;
END;http:/blog.csdnnet/jiongyi11
5I.
8不好的事务惯343
拼吾
比较这3个存储过程的执行时间
召擦器
mysql> CAlL load1!10000)
Query oκ,0 IoNs a￡ fated(1in3.158ec)
mysql> TRUNCATE TABle tli
Query OK, o rows affected (0.05 sec
mysql> CALL load2, 10000)
Query oKr 1 row affected (1 min 1.69 sec)
mysql> TRUNCATE TABLE tli
Query oK, 0 rows affected (0.05 sec
mysql> CALL load3:10000)i
Query oK, 0 rows affected (0.63 sec
显然,第三种方法要快得多!这是因为每一次提交都要写一次重做日志,存储过程
load1和load2实际写了10000次重做日志文件,而对于存储过程load3来说,实际只写了
1次。可以对笫二个存储过程lad的调用进行调整,同样可以达到存储过程load3的性
能,如
mysql> BEGIN;
Query Ok, rows attested (Uo0 sec)
mysql> CALL load (10000)1
Query oK, 1 row affected (0.56 scc)
mysql> COMMIT
Query OK,0 rows affected (0.03 sec)
大多数程序员会使用第一种或第二种方法,有人可能不知道noDB存储引擎自动
提交的情况,另外有些人可能持有以下两种观点:首先,在他们曾经使用过的数据库
中,对事务的要求总是尽快地进行释放,不能有长时间的事务;其次,他们可能担心存
在 Oracle数据库中由于没有足够undo产生的 Snapshot Too Old的经典问题。 MySQL的
InnoDB存储引擎没有上述两个问题,因此程序员不论从何种角度出发,都不应该在一个
循环中反复进行提交操作,不论是显式的提交还是隐式的提交。
7.82使用自动提交
自动提交并不是一个好的习惯,因为这会使初级DBA容易犯错,另外还可能使http://blog.csdn.net/jiongyi1
5
3447幸事务
部拼吾
些开发人员产生错误的理解,如我们在前一小节中提到的循环提交问题。 MySQL数据库
默认设置使用自动提交( autocommit),可以使用如下语句来改变当前自动提交的方式:
mysql> set autoccmmit=0;
Query Ok, 0 rows affected (0.00 sec)
也可以使用 START TRANSACTION, BEGIN来显式地开启一个事务。在显式开启
事务后,在默认设置下(即参数 completion type等于0), MySQL会自动地执行SET
AUTOCOMMIT=0的命令,并在 COMMIT或 ROLLBACK结束一个事务后执行SET
AUTOCOMMIT=l。
另外,对于不同语言的API,自动提交是不同的。 MySQL C API默认的提交方式是
自动提交,而 MySQL Python API则会自动执行 SET AUTOCOMMIT=0,以禁用自动提
交。因此在选用不同的语言来编写数据库应用程序前,应该对连接 MySQL的AP做好
研究。
我认为,在编写应用程序开发时,最好把事务的控制权限交给开发人员,即在程
序端进行事务的开始和结束。同时,开发人员必须了解自动提交可能带来的问题。我
曾经见过很多开发人员没有意识到自动提交这个特性,等到出现错误时应用就会遇到
大麻烦。
78.3使用自动回滚
InnoDB存储引擎支持通过定义一个 HANDLER来进行自动事务的回滚操作,如在
个存储过程中发生了错误会自动对其进行回滚操作。因此我发现很多开发人员喜欢在
应用程序的存储过程中使用自动回滚操作,例如下面所示的一个存储过程
CREATE PROCEDURE sp auto rollback demo (
BEGIN
DECLARE EXIT HANDLER FOR SQLEXCEPTION ROLLBACK
START TRANSACT工oN
INSERT工 nto b SELECT1
INSERT INTO D SELECT 2
INSERT INTO D sELECt 1
⊥ NSERT IⅣ o SELECT3;
COMMIT,
END:http:/blog.csdnnet/jiongyi11
5.e
78不好的事习切345
存储过程sp_ auto rollback demo首先定义了一个ext类型的 HANDLER,当捕获到
错误时进行回滚。结构如下
mysql>SHON CREATE TABLE b\Gi
害k★赏實言宽宾窝宽宝度宽x害实實害實實1,r。W實宽害定宽定询黄责责青★t★女★
Table: b
Create Table: CREATE TABLE b(
fa int (11)NOT NUILI DEFAULT '01
PRIMARY KEY (a)
ENGINE=InnoDB DEFAUL'I CHARSETlatinl
1 row in set (0.00 sec)
因此插人第二个记录1时会发生错误,但是因为启用了自动回滚的操作,因此这个
存储过程的执行结果如下
mysql>CAL- sp auto rollback demo
Query oK, 0 rows affected(0.06 sec
mysql>SELECT
FROM h;
Empty set (0,00 sec)
看起来运行没有问题,非常正常。但是,执行 sp auto rollback demo这个存储过程
的结果到底是正确的还是错误的?对于同样的存储过程 sp auto rollback demo,为了得
到执行正确与否的结果,开发人员可能会进行这样的处理:
CREATE PROCEDURE sp auto rollback demo (
BEGIN
DECLARE EXIT HANDLER FOR SQLEXCEPTION BEGIN ROLLEACK SELECT -1: END
START TRANSACT工oN
INSERT工 NTO S SELECT1;
INSERT InTo b SELECT 2
INSERT INTo h SF.TFCT 1
INSERT INTO b SELECT 3
CoMM_1:
SELECT 1
ENDi
当发生错误时,先回滚然后返回-1,表示运行有错误。运行正常返回值1。因此这
次运行的结果就会变成:
mysql>CALL sp auto rollback demo (\G:
许许青★内青大★★★青大青赏害★黄发★大★★1,y。w★**皆走★★★青为古☆★http://blog.csdn.net/jiongyi1
5
346第7章事办
1:-1
1 row in set (0.04 sec)
mysql>SELECT FROM b;
Empty set (0.00 sec)
看起来用户可以得到运行是否准确的信息。但问题还没有最终解决,对于开发人员
来说,重要的不仅是知道发生了错误,而是发生了什么样的错误。因此自动回滚存在这
样的一个问题。
习惯使用自动回滚的人大多是以前使用 Microsoft SQL Server数据库的开发人员。在
Microsoft SQL Server数据库中,可以使用 SET XABORT ON来自动回滚一个事务。但
是 Microsoft SQL Server数据库不仅会自动回滚当前的事务,还会抛出异常,开发人员可
以捕获到这个异常。因此, Microsoft SQL Server数据库和 MySQL数据库在这方面是有
所不同的。
就像之前小节中所讲到的,对事务的 BEGIN、 COMMIT和 ROLLBACK操作应该
交给程序端来完成,存储过程需要完成的只是一个逻辑的操作,即对逻辑进行封装。下
面演示用 Python语言编写的程序调用一个存储过程 sp rollback demo,这里的存储过
程 sp rollback demo和之前的存储过程 sp auto rollback demo在逻辑上完成的内容大
致相同:
CREATE PROCEDURE sp rollback demo (
BEGIN
inSeRt int b SELECT 1
工 NSERT工 nrc b SELECT2;
INSERT INTO b seleCt 1
INSERT InTo b SELECT 3:
ENDI
和 sp auto rollback demo存储过程不同的是,在 sp rollback demo存储过程中去掉
了对于事务的控制语句,将这些操作都交由程序来完成。接着来看 test demo.py的程序
源代码:
#! /usr/bin/env python
encoding=utf-8
import MysQLdbhttp:/blog.csdnnet/jiongyi11
51.6
79长事务347
Conn-
MysQLdb, connect(host=192.168.8.7",user=root", passwd=xx,db="test")
CuE
conn. Curser
cur, execute "set autocommit=O)
cur, execute("CALI sp rollback demo")
cur. execute("COMMIT")
except Exception,e:
cur. execute(ROLlBACK"]
print. e
观察运行 test demo. py这个程序的结果:
IrootCnineyouo-43 J python test demo. py
tarting rollback
(1062," Duplicate entry l for key ' PRIMARY
在程序中控制事务的好处是,用户可以得知发生错误的原因。如在上述这个例子中,
我们知道是因为发生了1062这个错误,错误的提示内容是 Duplicate entry!l, for key
PRIMARY',即发生了主键重复的错误。然后可以根据发生的原因来进一步调试程序。
79长事务
长事务 Long- Lived Transactions),顾名思义,就是执行时间较长的事务。比如,对
于银行系统的数据库,每过一个阶段可能需要更新对应账户的利息。如果对应账号的数
量非常大,例如对有1亿用户的表 account,需要执行下列语句:
UPDATE account
SET account total account total t (1 t interest ratel
这时这个事务可能需要非常长的时间来完成。可能需要1个小时,也可能需要4、5
个小时,这取决于数据库的硬件配置。DBA和开发人员本身能做的事情非常少。然而,由
于事务ACID的特性,这个操作被封装在一个事务中完成。这就产生了一个问题,在执行
过程中,当数据库或操作系统、硬件等发生问题时,重新开始事务的代价变得不可接受。
数据库需要回滚所有已经发生的变化,而这个过程可能比产生这些变化的时间还要长。因
此,对于长事务的问题,有时可以通过转化为小批量 mini batch)的事务来进行处理。当http:/blog.csdnnet/jiongyi11
5L.
348第7亨齐
事务发生错误时,只需要回滚一部分数据,然后接着上次已完成的事务继续进行令
例如,对于前面讨论的银行利息计算问题,我们可以通过分解为小批量事务来完
成,下面给出的是伪代码,既可以通过程序完成,也可以通过存储过程完成
void Compute Interest (double interest rate)(
long last account done, max account no, log size;
int batch size =100000:
EXEC SQL SELECT COUNT(*】工NTo1。 g size FROM batchcontext;
if SQLCODE =0 II log size ==0 )
EXEC SQL DROP TABLE IF EXISTS batchcontexti
EXEC SQL CREATE TABLE batchcontext last account done BIGINT )i
Last acc。 unt dcne=0
INSERT INTo batchcontext SELECT o
else
EXEC SQL SELECT last account no
into last account done
FROM batchcentexti
EXEC SQL SELECT COUNT〈*)工 NTo max a≈ count no
FROM account TOC.K TN SHARF. MODE.
WHIlE last account no max account no )I
EXEC SQL START TRANSACTIONi
EXEC SQL oPDATE account
SET account total account total *(l+interest rate )i
WHere account no
betWeeN last account no
And last account no t batch size
EXEC SOL UPDATE batchcontext
SET last account done =last accourt done batch size;
EXEC SQL COMMIT WORK i
last account done last account done batch size
上述代码将一个需要处理1亿用户的大事务分解为每次处理10万用户的小事务,http:/blog.csdnnet/jiongyi11
EI
710~小结349
通过批量处理小事务来完成大事务的逻辑。每完成一个小事务,将完成的结果存放在
batchcontext表中,表示已完成批量事务的最大账号ID。若事务在运行过程中产生问题,
需要重做事务,可以从这个已完成的最大事务DD继续进行批量的小事务,这样重新开
启事务的代价就显得比较低,也更容易让用户接受。 batchcontext表的另外一个好处是,
在长事务的执行过程中,用户可以知道现在大概已经执行到了哪个阶段。比如一共有1
亿条的记录,现在表 batchcontext中最大的账号mD为4000万,也就是说这个大事务大
概完成了40%的工作
这里还有一个小地方需要注意,在从表 account中取得 max account no时,人为地
加上了一个共享锁,以保证在事务的处理过程中,没有其他的事务可以来更新表中的数
据,这是有意义的,并且也是非常有必要的操作。
7.10小结
在这一章中我们了解了 InnoDB存储引擎管理事务的许多方面。了解了事务如何工
作以及如何使用事务,这在任何数据库中对于正确实现应用都是必要的。此外,事务是
数据库区别于文件系统的一个关键特性。
事务必须遵循ACID特性,即 Atomicity(原子性)、 Consistency(一致性)、 solation
(隔离性)和 Durability(持久性)。隔离性通过第6章介绍过的锁来完成;原子性、一致
性、隔离性通过redo和undo来完成。通过对redo和undo的了解,可以进一步明白事
务的工作原理以及如何更好地使用事务。接着我们讲到了 InnoDB存储引擎支持的四个
事务隔离级别,知道了 InnoDB存储引擎的默认事务隔离级别是 REPEATABLE READ
的,不同于SQL标准对于事务隔离级别的要求, InnoDB存储引擎在 REPEATABLE
READ隔离级别下就可以达到3°的隔离要求。
本章最后讲解了操作事务的SQL语句以及怎样在应用程序中正确使用事务。在
默认配置下, MySQL数据库总是自动提交的如果不知道这点,可能会带来非常
不好的结果。此外,在应用程序中,最好的做法是把事务的 START TRANSACTION、
COMMIT、 ROLLBACK操作交给程序端来完成,而不是在存储过程内完成。在完整
了解了 InnoDB存储引擎事务机制后,相信你可以开发出一个很好的企业级 My SQL
InnoDB数据库应用了。http://blog.csdn.net/jiongyi1
BI
部拼吾费
你盛
第8章备份与恢复
对于DBA来说,数据库的备份与恢复是一项最基本的操作与工作。在意外情况下
(如服务器宕机、磁盘损坏、RAID卡损坏等)要保证数据不丢失,或者是最小程度地丢
失,每个DBA应该每时每刻关心所负责的数据库备份情况。
本章主要介绍对 InnodB存储引擎的备份,应该知道 MySQL数据库提供的大多数
工具(如 mysqldump、 backup、 replication)都能很好地完成备份的工作,当然也可以
通过第三方的一些工具来完成,如 xtrabacup、LVM快照备份等。DBA应该根据自己的
业务要求,设计出损失最小、对于数据库影响最小的备份策略。
8.1备份与恢复概述
可以根据不同的类型来划分备份的方法。根据备份的方法不同可以将备份分为:
口 Hot Backup(热备)
口 Cold Backup(冷备)
口 Warm Backup(温备
Hot Back叩是指数据库运行中直接备份,对正在运行的数据库操作没有任何的影
响。这种方式在 MySQL官方手册中称为 Online backup(在线备份)。 Cold Backup是指
备份操作是在数据库停止的情况下,这种备份最为简单,一般只需要复制相关的数据库
物理文件即可。这种方式在 MySQL官方手册中称为 Offline Backup(离线备份)。Warm
Backup备份同样是在数据库运行中进行的,但是会对当前数据库的操作有所影响,如加
个全局读锁以保证备份数据的一致性。
按照备份后文件的内容,备份又可以分为:
口逻辑备份
口裸文件备份
在 MySQL数据库中,逻辑备份是指备份出的文件内容是可读的,一般是文本http:/blog.csdnnet/jiongyi11
8!各份与恢复甕述35
文件。内容一般是由一条条SQL语句,或者是表内实际数据组成。如 mysqldump和
SELECT* INTO OUTFILE的方法。这类方法的好处是可以观察导出文件的内容,一般适
用于数据库的升级、迁移等工作。但其缺点是恢复所需要的时间往往较长。
裸文件备份是指复制数据库的物理文件,既可以是在数据库运行中的复制(如
backup、 xtrabackup这类工具),也可以是在数据库停止运行时直接的数据文件复制。
这类备份的恢复时间往往较逻辑备份短很多
若按照备份数据库的内容来分,备份又可以分为:
口完全备份
口增量备份
日志备份
完仝备份是指对数据库进行一个完整的备份。增量备份是指在上次完全备份的基础
上,对于更改的数据进行备份。日志备份主要是指对 MySQL数据库二进制日志的备份,
通过对一个完全备份进行二进制日志的重做( replay)来完成数据库的 point-in-time的恢
复工作。 MySQL数据库复制( replication)的原理就是异步实时地将二进制日志重做传
送并应用到从( slave/standby)数据库
对于 MySQL数据厍来说,官方没有提供真正的增量备份的方法,大部分是通过二
进制日志完成增量备份的工作。这种备份较之真正的增量备份来说,效率还是很低的
假设有一个100GB的数据库,要通过二进制日志完成备份,可能同一个页需要执行多次
的SQL语句完成重做的工作。但是对于真正的增量各份来说,只需要记录当前每贞最后
的检查点的LSN,如果大于之前全备时的LSN,则备份该页,否则不用备份,这大大加
快了备份的速度和恢复的时间,同时这也是 xtrabackup工具增量备份的原理。
此外还需要理解数据库备份的一致性,这种备份要求在备份的时候数据在这一时间
点上是一致的。举例来说,在一个网络游戏中有一个玩家购买了道具,这个事务的过程
是:先扣除相应的金钱,然后向其装备表中插入道具,确保扣费和得到道具是互相一致
的。否则,在恢复时,可能出现金钱被扣除了而装备丢失的问题。
对于 InnoDB存储引擎来说,因为其支持MVCC功能,因此实现一致的备份比铰
简单。用户可以先开启一个事务,然后导出一组相关的表,最后提交。当然用户的事务
隔离级别必须设置为 REPEATABLE READ,这样的做法就可以给出一个完美的一致性
备份。然而这个方法的前提是需要用户正确地设计应用程序。对于上述的购买道具的过http:/blog.csdnnet/jiongyi11
352算8章备纷与恢复
程,不可以分为两个事务来完成,如一个完成扣费,一个完成道具的购买。若备份时
发生在这两者之间,则由于逻辑设计的问题,导致备份出的数据依然不是一致的。
对于 mysqldump备份工具来说,可以通过添加- - single-transaction选项获得IoDB
存储引擎的一致性备份,原理和之前所说的相同。需要了解的是,这时的备份是在一个
执行时间很长的事务中完成的。另外,对于 InnoDB存储引擎的备份,务必加上- single
transaction的选项(虽然是 mysqldump的一个可选选项,但是我找不出任何不加的理由)
冋时我建议毎个公可要根据自己的备份策略编写一个备份的应用程序,这个程序
可以方便地设置备份的方法及监控备份的结果,并且通过第三方接口实时地通知DBA,
这样才能真正地做到24×7的备份监控。久游网开发过一套DAO( Database admin
Online)系统,这套系统完全由DBA开发完成,整个平台用 Python语言编写,Web操
作界面采用 Django。通过这个系统DBA可以方便地对几百台 MySQL数据库服务器进
行备份,同时查看备份完成后备份文件的状态。之后DBA又对其进行了扩展,不仅可
以完成备份的工作,也可以实时监控数据库的状态、系统的状态和硬件的状态,当发生
问题时,通过飞信接口在第一时间以短信的方式告知DBA。
最后,任何时候都需要做好远程异地备份,也就是容灾的防范。只是同一机房的两
台服务器的备份是远远不够的。我曾经遇到的情况是,公司在2008年的汶川地震中发
生一个机房可能被淹的的情况,这时远程异地备份显得就至关重要了
82冷备
对于 InnoDB存储引擎的冷备非常简单,只需要备份 MySQL数据库的fm文件,共
享表空间文件,独立表空间文件(*ibd),重做日志文件。另外建议定期备份 MySQL数
据库的配置文件my.cnf,这样有利于恢复的操作。
通常DBA会写一个脚本来进行冷备的操作,DBA可能还会对备份完的数据库进行
打包和压缩,这都并不是难事。关键在于不要遗漏原本需要备份的物理文件,如共享表
空间和重做日志文件,少了这些文件可能数据库都无法启动。另外一种经常发生的情况
是由于磁盘空间已满而导致的备份失败,DBA可能习惯性地认为运行脚本的备份是没有
问题的,少了检验的机制。
正如前面所说的,在同一台机器上对数据库进行冷备是远远不够的,至少还需要将http:/blog.csdnnet/jiongyi11
51.6
8.3逻抨份353
部拼吾
本地产生的备份存放到一台远程的服务器中,确保不会因为本地数据库的宕和而影响铄
份文件的使用。
冷备的优点是:
口备份简单,只要复制相关文件即可
口备份文件易于在不同操作系统,不同 MySQL版本上进行恢复。
口恢复相当简单,只需要把文件恢复到指定位置即可。
口恢复速度快,不需要执行任何SQI语句,也不需要重建索引。
冷备的缺点是:
口 InnoDb存储引擎冷备的文件通常比逻辑文件大很多,因为表空间中存放着很多
其他的数据,如undo段,插人缓冲等信息
口冷备也不总是可以轻易地跨平台。操作系统、 MySQL的版本、文件大小写敏感
和浮点数格式都会成为问题。
8.3逻辑备份
8.3.1 mysqldump
mysqldump备份工具最初由 Igor Romanenko编写完成,通常用来完成转存(dmp)
数据库的备份及不同数据库之间的移植,如从MyQL低版本数据库升级到 MySQL高
版本数据库,又或者从 MySQL数据库移植到 Oracle、 Microsoft SQL Server数据库等。
mysqldump的语法如下
shell>mysqldump [arguments] >file name
如果想要备份所有的数据库,可以使用-1 atabases选项:
shell>mysqldump --all-catabases >dump. sql
如果想要备份指定的数据库,可以使用- databases选项
shell>mysq-dump --catabases dbl db2 db 3 >dump. sql
如果想要对test这个架构进行备份,可以使用如下语句:
Irootexen-server ]t mysqldump -single-transaction test >test backup sqlhttp://blog.csdnnet/jiongyi1
5
354郭8字份与茨复
部拼雳
上述操作产生了一个对test架构的备份,使用- -single-transaction选项来保证备份的
致性。备份出的 test backup.sq是文本文件,通过文本查看命令cat就可以得到文件的
内容:
[root@xen-server attest backup, sql
MY SQL dump 10.13 Distrib 5.5+-m2, for unknown-linux-gnu (x86 64)
Host:1。 calmest
Da tabase: test
Server version
5.5.1-m2-1og
- Table structure for table 'a'
DROP TABLE IF EXISTS·a
/*40101 set saved cs client
character set client */i
/*!40101 SET character set client s utf8 *
CREATE TAELE ' a'
'b int(11)NOT NULL DEFAULT I0r
PRIMARY KEY【"b")
ENG工NE=工 nnoDB DEFAULT CHARSET=1atin1;
/*!40101 seT character set client @ saved cs client *
Dumping data for table a
LOCK TABLEs 'a WRITE:
/*! 40000 ALTER TAbLE 'a. DISABLE KEYS +
INSERT INto a VALUES (1),(2)(4)(5)i
*!40000 ALTER TABLE 'a ENABLE KEYs *
UNLOCK TABLES
rable structure for table 1z.
DROP TABLE IF EXISTS
/*!40101 SET saved cs client
@@character set client *
/*!40101 SET character set client utf8 */
CREATE TABLE 2(http://blog.csdnnet/jiongyi1
15.6
8.3逻辑份355
部拼没
a int(11)DEFAULT NULL
ENGINE=InnoDB DEFAULT CHARSET-lasinli
/*!40101 SET character set client @saved cs client */i
Dumping data for table
LOCK TABLES Z WRITES
/*!40000 ALTER TABLE 'Z DISABLE KEYS *
INSERT INTO 1Z. VALUES (1)(1)i
/*!4000C ALTER TABLE Z ENABLE KEYS */
UNLOCK TABLES;
Dump cornpleted on 2010-08-0313: 36: 17
可以看到,备份出的文件内容就是表结构和数据,所有这些都是用SQL语句方式表
示。文件升始和结束的注释部分是用来设置 MySQL数据库的各项参数,一般用来使还
原工作更有效和准确地进行。之后的部分先是 CREATE TABLE语句,接着就是 INSERT
的SQL语句了。
mysqldump的参数选项很多,可以通过使川 mysqldump-help命令来查看所有的参数,
有些参数有缩写形式,如-lock- ables的缩写形式-。这里列举一些比较重要的参数。
single- transaction:在备份开始前,先执行 START TRANSACTION命令,以
此来获得备份的一致性,当前该参数只对 InnoDB存储引擎有效。当启用该参数
并进行备份时,确保没有其他任何的DDL语句执行,因为一致性读并不能隔离
DDL操作。
口- clock-tables(-41):在备份中,依次锁住每个架构下的所有表。一般用于 MyISAM
存储引擎,当备份时只能对数据库进行读取操作,不过备份依然可以保证一致
性。对于 InnoDB有储引擎,不需要使用该参数,用- single-transaction即可。并
且- -lock -tables和- single- transaction是互斥( exclusive)的,不能同时使用。如
果用户的 MySQL数据库中,既有 MyIsAM存储引擎的表,又有 InnoDB存储
引擎的表,那么这时用户的选择只有-ock- tables了。此外,正如前画所说的那
样,-lock- tables选项是依次对每个架构中的表上锁的,因此只能保证每个架构下http:/blog.csdnnet/jiongyi11
5
356葬8幸备份与恢复
表备份的一致性,而不能保证所有架构下表的一致性。
口-lck- - all-tables(-x):在备份过程中,对所有架构中的所有表上锁。这个可以避
免之前说的-ck- tables参数不能同时锁住所有表的问题。
口-ad-drop- database:在 CREATE DATABASE前先运行 DROP DATABASE。这个
参数需要和- all-databases或者- databases选项一起使用。在默认情况下,导出
的文本文件中并不会有 CREATE DATABASE,除非指定了这个参数,因此可能
会看到如下的内容:
Irootaxen-server -]f mysqldump --single-transaction --add-drop-database
-databases test >test backup, sql
[rootexen-server ]t cat test backup sql
MySQL dump 10.13 Distrib 5.5.1-m2, for unknawn-linux-gnu (x86 64)
Current database: test'
*!40000 DROP Dλ hAS工EB工sTs"七t!内/
CREATE DATABASE /*132312 IF NOT EXISTS*/ 'test/*!40100 DEFAULT CHARACTER SET
latin */:
USE test
口- master-data[= value]:通过该参数产生的备份转存文件主要用来建立一个
replication。当 value的值为1时,转存文件中记录 CHANGE MASTER语句。当
value的值为2时, CHANGE MASTER语句被写出SQL注释。在默认情况下,
value
的值为空。当 value值为1时,在备份文件中会看到
Irootexen-server ]f mysqldump --single-transaction --add-drop-database
mastcr-data-1 --databases test >test backup sql
Irootexen-server x]t cat test backup. scl
MysQL dump 10.13 Distrib 5.5.1-m2, for unknown-linux-gnu (x86 64)
Host:1。 calmest
Database: test
server version
5.5.1-m2-1og
4·http:/blog.csdnnet/jiongyi11
5I.A
8.3逻辑畚份357
Position to start replication or point-in-time recovery from
CHANGE MASTER TO MASTER LOG FILE='xen-server-bin 000006 MASTER LOG P09=8095:
当 value为2时,在备份文件中会看到 CHANGE MASTER语句被注释了:
Irootexen-server t mysqldump --single-transaction --add-drop-database
-mastcr-data-2 --databases test >test backup sq
[root exen-server -]f cat test backup. sql
MysQI dump 10.13 Distrib 5.5.1-m2, for unknown-linux-gnu (x86 64)
Hcst:1。 calmest
Database: tes=
一一
一一一一一一
server version
5.5.1-m2-1og
Position to start replication or point-in-time recovery from
- master -data会自动忽略-lock- tables选项。如果没有使用- single-
transaction
选
项,则会自动使用-ock- all-tables选项。
口- events(-E):备份事件调度器。
口- routines(-R):备份存储过程和函数
口- -triggers:备份触发器。
口-hex-blob:将 BINARY、 VARBINARY、BLOG和BIT列类型备份为十六进制的
格式。 mysqldump导出的文件一般是文本文件,但是如果导出的数据中有上述这
些类型,在文本文件模式下可能有些字符不可见,若添加-hex-blob选项,结果
会以十六进制的方式显示,如:
[rootaxen-server
) mysqldump
single--ransaction --add-drop-database
-master-data2 --no-autocommit --databases test3> test3 backup sgl
.rootexer-server t cat test3 backup sql
MysQL dump 10.13 Distrib 5. 5.1-m2, for unknown -linux-gru (x86 64)http://blog.csdn.net/jiongyi1
5.
3588亨寄分与恢复
部拼吾
Host: localhost
Database: test3
Server version
5.5.1-m2-1og
L。 CK TABLES"a" WRITE;
/*!40000 ALTER TABLE 'a1 DISABLE KEYS */i
setautocommit=0:
INSERT INTO a VALUES (0x61000000000000000000)i
/*! 40000 ALTER TABLe 'a. ENABLE KEYs */
UNLOCK TABLES
可以看到,这里用0x6100000000000六进制的格式来导出数据。
tab=path(- T path):产生TAB分割的数据文件。对于每张表, mysqldump创
建一个包含 CREATE TABLE语句的 table name. sa!文件,和包含数据的tbl
name, txt文件。可以使用- fields-terminated-by=…,- -fields- enclosed-by=…,-flds
optionally-enclosed-b
y=.,- fields-escaped-by=…,- -lines-terminated-by=.来改变默
认的分割符、换行符等。如
[rootexen-server test]# mysqldump --single-transaction --adc-drop-database
-tab="/usr/local/mysql/data/test"test
【r。c@xen- server test]#1s-h
total 244K
w-rw----l mysql mysql 8.4K Jul 21 16: 02 a trm
rw-rN
1 mysql mysql 96K Jul 22 17: =8 a ibd
rw-r--r--l root root 1. 3K Aug 3 15: 36 a sql
rw-rw-rw-1 mysql mysql 8 Aug 315: 36a.txt
w----1 mysqlmysql 65 Jul 17 15: 54dbopt
rw-rw---- 1 mysql mysql 8.4K Aug 217:22 zfrm
1 mysql mysql 96K Aug 2 17: 22 z ibd
rw-r--r-- 1 rootroot 1, 3K Aug 3 15: 36 2, sql
-rw-rw-rw-l mysql mysql 4 Aug 3 15:36z.txt
Server version
5.5.1-m2-1og
/*40101 SET EOT.D CHARACTER SFT CITENT=0@CHARACTER SET CITENT */A
/*!40101 SET EoLD CHARACTER SET RESULTS=eECHARACTER SET RESULTS *
/*!40101 SET COLD COLLATION CONNECTION=@@COLLATION CONNECTIoN *
/*!40101 SET NAMES utf8 */:
/*!40103SET@OLDT工 ME ZONE=@园 TIME ZONE*/;
*!40103 SET TIME20NE=1+00:00"*
/*!40101 SEt @OLD SQL MODE=G2SQL MODE, SQL MODE='.*/;
/*!40111 SET EOLD SQL NOTES=eeSQL NOTES, SQL NOTES=0 */ihttp://blog.csdn.net/jiongyi1
5
83辽辑份359
部拼雳
你郾盛
Table structure for table a'
DROP TABLE IF EXISTS a
/* 40101 SeT saved cs client
charact是 r set client★
/*!40101 SET character set client utf8 */i
CREATE TABLE a(
'b. int(11)NOT NULL DEFAULT 0
PRIMARY KEY (b'
s ENGINE=InnoDB DEFAULT CHArSET-latinli
/*!40101 SEt character set client saved cs client */i
/*!40103 SET TIME ZONE=@OLD TIME ZoNE *
/*!40101 SET SQL MODE=GOLD SQL MCDE *
/*!40101 SET CHARACTER SET CLIENT=gOLD CHARACTER SET CLIENT *
/*!40101 SET CHARACTER SET RESULTS=COLD CHARACTER SET RESULTS *
/* 40101 SET COLLATION CONNECTION=@OLD CoLLATION CONNECTION +
/* 40111 SET SQL NOTES=COLD SQL NOTES *
Dump completed on 2010-08-03 15: 36: 56
[rootexen-server test]+ cata.txt
我发现大多数DBA喜欢用 SELECT. INTO OUTFILE的方式来导出一张表,但是通
过 mysqldump一样可以完成工作,而且可以一次完成多张表的导出,并且实现导出数据
的一致性
日- where=" where condition’(-w" where condition'):导出给定条件的数据。如
导出b架构下的表a,并且表a的数据大于2
[rootexen-server bin]# mysqldump --single-transaction --where=b>2+ test a>
scI
[rootGxen-server bin]# cat a sql
My sQL dump 10.13 Distrib 5.5.1-m2, fcr unknown-linux-gnu (x86 64)
Host:1。 calmest
Database: testhttp:/blog.csdnnet/jiongyi11
5
360第8幸奇份与恢复
Server version
5.5.1-m2-1oq
Dumping data for table a
HERE: 5>2
LOCK TABlES 'a WRITE:
/*! 40000 ALTER TABLE 'a DISABLE KEYs *
INSERT INTO a vAlves (4)(5)i
/*! 40000 ALTER TABle 'a! ENABLE KEys */i
UNLOCK TABLE S
/*!40103 SET TIME ZONE=@OLD TIME ZoNe *
8. 3. 2 SELECT INTO OUTFILE
SELECTINTO评句也是一种逻辑备份的方法,更准确地说是导出一张表中的数
据。 SELECT.INTO的语法如下:
SELECT [column 1],[column 2]
NTO
OUTFILE file name
[FIELDS I COLUMNS)
C TERMINATED BY 'string1
[OPT IONALLY] ENCLOSED BY 'char'I
〔 ESCAPED BY"char']
ILINES
「 STARTING BY strIng"]
[TERMINATED BY string.
FROM TABLE WHERE
其中 FIELDS[ TERMINATED BY 'string]表示每个列的分隔符,[[ OPTIONALLY]
ENCLOSED BY'char']表示对于字符串的包含符,[ ESCAPED BY·cha]表示转义
符。[ STARTING BY' string1]表示每行的开始符号, TERMINATED BY' string!表示每
行的结束符号。如果没有指定任何的 FIELDS和 LINES的选项,默认使用以下的设置
FIELDS TERMINATED BY ' \t ENCLOSED BY ESCAPED BY 1\\
LINES TERMINATED BY .\n. STARTING BY Ihttp:/blog.csdnnet/jiongyi11
51.6
83逻备份361
file name表示导出的文件,但文件所在的路径的权限必须是mg.p
mysq的否
则 MySQL会报没有权限导出:
mysql> select into outfile /root/a. txt 'from ai
ERROR 1 (HYC00):Can't create/write to file /raot/a. txt Errcode: 13)
若已经存在该文件,则同样会报错:
[rootexen-server It mysql test -e "select into outfile /home/mysql/a.txts'
fields terminated by 'r
i from aF
ERROR 1086 (HY000, at line 1: File /home/mysql/a, txt already exists
查看通过 SELECT INTO导出的表a文件:
mysql> select into outfile /home/mysql/a. txt. from ai
Query OK,3 rows affected (0.02 sec)
mysqL> quit
B
[root@xen-server -l cat /home/mysql/a.txt
b
可以发现,默认导出的文件是以TAB进行列分割的,如果想要使用其他分割符,如
“,”,则可以使用 FIELDS TERMINATED BY' string'选项,如:
[rootexen-server mysql test -e select into outfile '/home/mysql/a,txt
fields terminated by. from a";
[root@xen-server -] cat /home/mysql/a.txt
2,b
3,c
在 Window平台下,由于换行符是“lrhn”,因此在导出时可能需要指定 LINES
TERMINATED BY选项,如
Irootexen-servermysq1l mysql test -e"select into outfile ' /home/mysql/a.txt
fields terminated by lines terminated by '\r\n from a"
[roctexen-servermysql]# od -c a,txt
00000001
\r 11 2
b \r \
0000017http://blog.csdn.net/jiongyi1
BL
362笫8幸备份与恢复
83.3逻辑备份的恢复
mysqldump的恢复操作比较简单,因为备份的文件就是导出的SQL语句,一般只需
要执行这个文件就可以了,可以通过以下的方法
[root@xen-server -]# mysql -uroot -p <test backup sq1
Enter password:
如果在导出时包含了创建和删除数据库的SQL语句,那必须确保删除架构时,架构
目录下没有其他与数据库相关的文件,否则可能会得到以下的错误:
mysql> drop database testi
ERROR 1010 (HY000): Error dropping database (can't rmdir ./test errno: 39)
因为逻辑备份的文件是由SQL语句组成的,也可以通过 SOURCE命令来执行导出
的逻辑备份文件,如下
mysql> source /home/mysql/test backupsqli
Query Okr o rows affected (.00 sec)
Query Okr o rows affected (0.00 sec)
Query OK, rows affected (C.00 sec)
Query OK 5 rows affected (do0 sec)
通过 mysqldump可以恢复数据库,但是经常发生的个问题是, mysqldump可以导
出存储过程、导出触发器、导出事件、导出数据,但是却不能导出视图。因此,如果用
户的数据库中还使用了视图,那么在用 mysqldump备份完数据库后还需要导出视图的定
义,或者备份视图定义的frm文件,并在恢复时进行导入,这样才能保证 mysqldump数
据库的完全恢复。
8 3 4 LOAD DATA INFILE
若通过 mysqldump-tab,或者通过 SELECT INTO OUTFILE导出的数据需要恢复,
这时可以通过命令 LOAD DATA INFILE来进行导人。 LOAD DATA INFILE的语法如下
LOAD DATA INTO TABLE a IGNORE 1 LINES INFILE '/home/mysql/a,txt'http://blog.csdn.net/jiongyi1
5
8.3逻轷畚份363
[REPLACE I IGNORE J
督你图函令
INTO ABLE tbl name
CHARACTER SET charset name]
[[FIELDS I COLUMNS F
I TERMINATED BY string]
[[OPT-ONALLY] ENCLOSED BY tchar t
「 ESCAPED BY"char
[LINES
[STARTING BY 'string]
ITERM-NATED BY string]
[IGNORE number LINES
《 cof name or user var,-)
[SET coI name= expr,.I
要对服务器文件使用 LOAD DATA INFILE,必须拥有FILE权。其中对于导入格式
的选项和之前介绍的 SELECT INTO OUTFILE命令完全一样。 IGNORE number LiNeS
选项可以忽略导人的前几行。下面显示一个用 LOAD DATA INFILE命令导人文件的示
例,并忽略第一行的导入:
mysql> load data infile ' /home/mysql/a. txt into table a:
Query Ok 3 rows affected (0.00 sec)
Records: 3 Deleted: 0 Skipped: 0 Warnings: 0
为了加快 InnoDB存储引擎的导入,可能希望导入过程忽略对外键的检查,因此可
以使用如下方式:
mysqL>sET foreign key checks=0;
Query OK, a rows affected (0.00 sec)
mysql>LOAD DATA INFILE ' /home/mysql/a. txt! INTO TABLE a:
Query OK 4 rows affected (0.00 sec)
Records: 4 Deleted: c Skipped 0 Warnings: 0
mysql>s]r foreign key checks=l:
Query oK, o rows affected (0.00 sec)
另外可以针对指定的列进行导入,如将数据导入列a、b,而c列等于a、b列之和:
mysql>CREATE TABLE b(
>a Int
>b INT
>C INTIhttp:/blog.csdnnet/jiongyi11
5.6
364第8幸客份与荧复
器研
PRIMARY KEY (a)
擦器
ENGINE一工nnDB
Query OK, 0 rows affected (0. o1 sec)
mysql>LOAD DAIA INFILE /home/mysql/atxti
SINTO TAELE b FIELDS TERMINATED BY ,(a,b)
SET C-atb
Query Ok 4 rcws affected (a.0l sec)
Records: 4 Deleted: o Skipped: 0 Warnings: 0
mys->SELECT FROM b
t一
2356
l+11
5
5
11
4 rows in set (0.o0 sec)
8.3.5 mysqlimport
mysqlimport是 MySQL数据库提供的一个命令行程序,从本质上来说,是LOAD
DATA INFILE的命令接口,而且大多数的选项都和 LOAD DATA INFILE语法相同。其
语法格式如下:
she11> mysqlimport[。pt⊥ons! db name teκ tfile1[ textfi1e2.]
和 LOAD DATA INFILE不同的是, mysqlimport命令可以用来导入多张表。并且通
过- user-thread参数并发地导入不同的文件。这里的并发是指并发导人多个文件,而不
是指 mysqlimport可以并发地导人一个文件,这是有明显区别的。此外,通常来说并发
地对同一张表进行导入,其效果一般都不会比串行的方式好。下面通过 mysqlimport并
发地导人2张表
trootaxen-servermysq1]# mysqlimport --use-threads=2 test /home/mysql/t, txt
home/mysql/s.txt
cest.s: Recorcs: 5000000 Deleted: o Skipped: 0 Warnings: 0
test. t: Records: 5000000 Deleted: 0 Skipped: 0 Warnings: 0
如果在上述命令的运行过程中,查看 MySQL的数据库线程列表,应该可以看到类http:/blog.csdnnet/jiongyi11
8.3逻抨鲁份365
似如下内容:
mysql>SHOW FULL PROCESSIIST\G
★★★★★走虫走曲
★★
★★★女★1.rw★★★为★★★★★☆★女安★安★皆安★安k★安丧
Id:46
User: rep
Host:www.dao.com1028
db NULl
Command: Binlog Dump
Time:37651
State: Master has sent all binlog to slave: waiting for binlog to be updated
Info: NUll
★★★★★★★★★★青★★★害大内内大★内★+★大2.工ow青★青肯大青古大有★古青肃古青青青★内★★方★★青
Id:77
UseX:r。ot
Host: localhost
db:tes乜
Command: Query
e
state: NULL
Info: show full processlist
大★★★肯★★★★★★★言片言青大★★青南★青★来3,ow南★*★★★曾*★肯大★★★★★★★女女女女
Id:83
o七
Host;⊥ localhost
db: test
Command: Query
Time: 3
State: NULL
Info: OAD DATA INFILE'/home/mysq1/ttt!工 NHO TABLE"t! IGNORE0工工NEs
★★★★★★★★★★实实★★★所★★★背洲★青*4,xW内南★★★南南如★★★★★*★★★k★★★★★大★大
Id:84
User: root
Host: localhost
db: test
Command: Query
Til
state: NULL
Ino: LOAD DATA INFIIE'/home/mygg1/a.tt’INyo四ABE"a!工GoRE0iNs
4 rows in set (0.00 sec)
可以看到 mysqlimport实际上是同时执行了两句 LOAD DTA INFILE并发地导入
数据。http://blog.csdn.net/jiongyi1
5
366第8章备份与恢复
84二进制日志备份与恢复
二进制日志非常关键,用户可以通过它完成 point-In-time的恢复工作。 MySQL数据
库的 replication同样需要二进制日志。在默认情况下并不启用二进制日志,要使用二进
制日志首先必须启用它。如在配置文件中进行设置
〔mysc1d
log-bin-mysql-bin
在324节中已经阐述过,对于 InnoDB存储引擎只简单启用二进制日志是不够的,
还需要启用一些其他参数来保证最为安全和正确地记录二进制日志,因此对于 InnoDB
存储引擎,推荐的二进制日志的服务器配置应该是:
[mysql
⊥。g-bin- mysql-bin
sync binlog =1
innodb support xa =1
在备份二进制日志文件前,可以通过 FLUSH LOGS命令来生成一个新的二进制日
志文件,然后备份之前的二进制日志。
要恢复二进制日志也是非常简单的,通过 mysqlbinlog即可。 mysqlbinlog的使用方
法如下
shell>mysqlbinlog [options] log file
例如要还原 binlog000001可以使用如下命令:
shell>mysqlbinlog binlog. 0000001 I mysql-uroot -p test
如果需要恢复多个二进制日志文件,最正确的做法应该是同时恢复多个二进制日志
文件,而不是一个一个地恢复,如
shell>mysqlbinlog binlog. [0-10]* 1 mysql -u root -p test
也可以先通过 mysqlbinlog命令导出到一个文件,然后再通过 SOURCE命令来导
入,这种做法的好处是可以对导出的文件进行修改后再导入,如
shell>mysqlbinlog binlog. 000001 >/tmp/statements sql
she11>mysqlbinlog binlog.000002 >>/tmp/statements, sql
shell>mysql -u root -p -e "source /tmp/statements sql
start- position和- -stop-positior选项可以用米指定从二进制目志的某个偏移量来进http:/blog.csdnnet/jiongyi11
85熟备367
行恢复,这样可以跳过某些不正确的语句,如:
shell>mysqlbinlog--start-poaition-107856 binlog, 0000001 I mysql-uroot -p test
- start-datetime和- stop-datetime选项可以用来指定从二进制日志的某个时间点来进
行恢复,用法和- -start-position和- stop-position选项基本相同。
85热备
8.5.1 backup
Backup是 InnoDB存储引擎官方提供的热备工具,可以同时备份 MyISAM存储引
擎和 InnoDB存储引擎表。对于IoDB存储引擎表其备份工作原理如下
1)记录备份开始时, InnoDB存储引擎重做日志文件检查点的LSN。
2)复制共享表空间文件以及独立表空间文件。
3)记录复制完表空间文件后, InnoDB存储引擎重做日志文件检查点的LSN
4)复制在备份时产生的重做日志。
对于事务的数据库,如 Microsoft SQL Server数据库和 Oracle数据库,热备的原理
大致和上述相同。可以发现,在备份期间不会对数据库本身有任何影响,所做的操作
只是复制数据库文件,因此任何对数据库的操作都是允许的,不会阻塞任何操作。故
backup的优点如下:
口在线备份,不阻塞任何的SQL语句。
备份性能好,备份的实质是复制数据库文件和重做日志文件。
口支持压缩备份,通过选项,可以支持不同级别的压缩。
口跨平台支持, backup可以运行在 Linux、 Windows以及主流的UNX系统平台上。
backup对 InnoDB存储引擎表的恢复步骤为:
口恢复表空间文件。
口应用重做日志文件。
backup提供了一种高性能的热备方式,是 InnoDe存储引擎备份的首选方式。不过
它是收费软件,并非免费的软件。好在开源的魅力就在于社区的力量, Percona公司给用
户带来了开源、免费的 Xtrabackup热备工具,它实现所有 backup的功能,并且扩展支http://blog.csdn.net/jiongyi1
5
368第8幸备份与惔复
持了真正的增量备份功能。因此,更好的选择是使用 XtraBackup来完成热备的作参
8.5.2 XtraBackup
Xtra Backup备份工具是由 Percona公司开发的开源热备工具。支持 MySQL5.0以上
的版本。Ⅹ tra Backup在GPLv2开源下发布,官网地址是:htps:/ launchpad. net/percona
xtrabackup
xtrabackup命令的使用方法如下:
xtrabackup--backup I --prepare [OPTIONS I
xtrabackup命令的可选参数如下:
(The defaults options should be given as the first argument)
Print-defaults
彐上 ints the progra" s argument1$ and exit,
-no-defaults
Don't read the default options from any fi
de faults-file=
Read the default options from this file
defau⊥ts-eXta-fi1e=
Read this file after the global options files have been
read
-target-dir=
The destination directory for backups
-backup
Make a backup of a mysql instance
-stats
calculate the statistic of the datadir (it is recommended
you take mysqld offline)
Prepare
Prepare a backup so you can start mysql server with your
restore
-exp。rt
Create files to import to another database after it has been
prepared
print -paran
Print the parameters of mysqld that you will need for a
forcopyback
-use-memoLy-
This value is used instead of buffer pool size
suspend-at-end
Creates a file called xtrabackup suspended and waits until
the user deletes that file at the end of the backup
throttle=
(use with --backup) Limits the Io operations (pairs of reads
and writes)per second to the values set here
log-strearm
outputs the contents of the xtrabackup logfile to stdout
incremental-lsn- (use with --backup)Copy only .ibd pages newer than the
specified Lsn high:°w
##ATTENTION##: checkpoint lsn *must* be used. Be Careful!
incremental-basedir= (use with --backup) Copy only . ibd pages newer than
the existing backup at the specified directory
-incremental-dir=
(use with --prepare) Apply .delta files and logfiles
located in the specified directoryhttp://blog.csdn.net/jiongyi1
5
85热备3069
部拼没
tablesename
Regular Expression list of table names to be backed up
--create-ib-1oqfile (NOT CURRENTLY IMPLEMENTED) will create ib logfileaft
e
a --prepare
## If you want to create ib logfile* only re-execute this
c。 mmand using the same option.##普
catadir=name
Path to the database root
tmpdir=name
Path for temporary files. Several paths may be specified
as a colon ( separated string
If you specify multiple paths they are used round-robin
如果用户要做一个完全备份,可以执行如下命令:
#./xtrabackup --backup
/xtrabackup ver alpha-02 for 5.0.75 unknown-linux-gnu (x86 64
>>log scanned up to (0 1009910580)
Copying ./ibdatal
to /home/kinoyasu/ xtrabackup work/rysql-5075/innobase/xtrabackup/tmp2/ibdatal
done
Copying ./ tpcc/stock ibd
to /home/kinoyasu/xtrabackup_ work/mysql-5075/inncbase/xtrabackup/tmp2/tpcc/
st。ck。ibd
done
Copying ,/tpcc/new orders, ibd
to /home/kinoyasu/xtrabackup work/mysql-50. 75/innobase/xtrabackup/tmp2/tpcc/
neW5rde工s,ibd
done
Copying ./tscc/history, ibd
home/kinoyasu/xtrabackup work/mysql-5.0.75/innobase/xtrabackup/tmp2/tpcc.
history
one
Copying /tpcc/customer ibd
to /home/kinoyaau/xtrabackuF_work/mysq1-50 75/innobase/xtrabackup/tmp2/tpcc/
customer ibd
>>log scanned up to (0 1010561109)
done
Copying ./tpcc/district. ibd
to /home/xinoyasu/xtrabackup_work/nmysyl-50 75/innobase/xtrabackup/tmp2/tpcc/
district. ibd
卓●ne
Copying ./tpcc/item ibd
to /home/kinoyasu/xtrabackup_work/mysq1-5,.75/innobase/xtrabackup/tmp2/tpcc/
ltem ibd
4 done
Copying ./tpcc/order line, ibdhttp:/blog.csdnnet/jiongyi11
5
370第8幸备份与茯复
挤吾
to / home/kinoyasu/xtrabackup work/mysq1-5075/innobase/xtrabackup/tmp2/tpcc
order line, ibd
>>log scanned up to (0 1012047066
Copying ,/tpcc/orders. ibd
to /home/kinoyasu/xtrabackup work/mysql-5075innobase/xtrabackup/tmp2/ tpcc/
orders. ibd
done
Copying ./tpcc/warehouse ibd
to /home/kinoyasu/xtrabackup work/mysql-50.75/innobase /xtrabackup/tmp/tpcc/
warehouse. lbd
done
>>log scanned up to (0 1014592707)
Stopping log copying thread
Transaction log of lsn (0 1009910580)to (o 1014592707)was copied
可以看到在开始备份时, xtrabackup首先记录了重做日志的位置,在上述示例中为
(01009910580)。然后对备份的 InnoDB存储引擎表的物理文件,即共享表空间和独立
表空间进行copy操作,这里可以看到输出有 Copying…to…。最后记录备份完成后的重
做日志位置(01014592707)
853 XtraBackup实现增量备份
MyS。L数据库本身提供的工具并不支持真正的增量备份,更准确地说,二进制
日志的恢复应该是 point-In-time的恢复而不是增量备份。而 XtraBackup工具支持对于
InnoDB存储引擎的增量备份,其工作原理如下:
1)首选完成一个全备,并记录下此时检查点的LSN。
2)在进行增量备份时,比较表空间中每个页的LSN是否大于上次备份时的LSN,
如果是,则备份该页,同时记录当前检查点的LSN。
因此 Xtra Backup的备份和恢复的过程大致如下:
〔fu11 backup)
F ./xtrabackup --backup
target-dir=/backup/base
(incremental backup)
4./xtrabackup -backup --tarqet-dir=/backup/delta
incremental-basedir=/
backup/basehttp:/blog.csdnnet/jiongyi11
5I
85热备371
(prepare)
f./xtrabackup --prepare --target-dir=/backup,base
tapply incremental backup
t ./xtrabackup --prepare --target-dir=/backup/base --incremental-dir=/backup/
delta
在上述过程中,首先将全部文件备份到/ backup/base目录下,增量备份产生的文件
备份到 backup/ delta。在恢复过程中,首先指定全备的路径,然后将增量的备份应用于
该完全备份。以下显示了一个完整的增量备份过程:
f ./xtrabackup --backup
/xtrabackup ver bcta-04 far 5.0.75 unknown-linux-gnu (x86 64)
>>log scanned up to (0 378161500
The latest check point (for incremental):0: 377883685
=使用这个LsN
>>log scanned up to 0 379294296
topping log copying thread
Transaction log of lsn(0377883685)to(0 379294296)was copied
imust do --prepare before the each incremental backup)
t ./xtrabackup--prepare
4.xtrabackup --backup --incremental=0: 377883685
incremental backup from 0: 377883685 is enabled
/xtrabackup Ver beta-C4 for 5.0. 75 unknown-iinux-gn (x86 64)
>>log scanned up to (0 379708047)
Copying ./ibdatal
to /rome /kinoyasu/ xtrabackup work/mysq1-5075/innobase/xtrabackup/tmp dift/
ibdatal, delta
done
The latest check point (for incremental]: 0:379438233'
<====下一个增量备份开
始的LSN
>>log scanned up tc (0 380663549)
opping log copying thread
Transaction log of lsn (0 379438233)to (0 380663549) was copiedhttp://blog.csdn.net/jiongyi1
6I
372弟8奇份与恢复
部拼没
86快照备份
你
MySQL数据库本身并不支持快照功能,因此快照备份是指通过文件系统支持的
快照功能对数据库进行备份。备份的前提是将所有数据库文件放在同一文件分区中,
然后对该分区进行快照操作。支持快照功能的文件系统和设备包括 FreeBSD的UFS
文件系统, Solaris的ZFS文件系统, GNULinux的逻辑管理器( Logical Volume
Manager,LVM)等。这里以LVM为例进行介绍,UFS和ZFS的快照实现大致和
LVM相似。
LVM是 LINUX系统下对磁盘分区进行管理的一种机制。IVM在硬盘和分区之上建
立一个逻辑层,来提高磁盘分区管理的灵活性。管理员可以通过IVM系统轻松管理磁
盘分区,例如,将若干个磁盘分区连接为一个整块的卷组( /olume Group),形成一个
存储池。管理员可以在卷组上随意创建逻辑卷( Logical Volumes),并进一步在逻辑卷上
创建文件系统。管理员通过IVM可以方便地调整卷组的大小,并且可以对磁盘存储按
照组的方式进行命名、管理和分配。简单地说,用户可以通过LWM由物理块设备(如
硬盘等)创建物理卷,由一个或多个物埋卷创建卷组,最后从卷组中创建任意个逻辑卷
(不超过卷组大小),如图8-1所示。
Logical volumes
Increate
Volume giroup
vgcreate
picrate
Block devices
图8-1LVM工作原理
图82显示了由多块磁盘组成的逻辑卷L0http://blog.csdnnet/jiongyi1
5
86快照壽份373争
physical disk O
physical disk 1
physical disk
/devhhdal
/dev/hda2/dev/hda3 /dev/hda4
fdevhdb
fdev/hdd
VGO
LVO
free spa
图8-2物理到逻辑卷的映射
通过 redisplay命令查看系统中有哪些卷组,如:
[rootenh124-98 *]# vgdisplay
Volume group
g Name
rep
system ID
Format
I vm2
Metadata areas
Metadata Sequence No 1873
VG Access
read/write
VG status
resizable
MAX LV
Cur LV
Open lv
0310
Max pv
Cur pv
1
Act pv
vG size
260.77GB
PE Size
4,00MB
Total pe
66758
Alloc Pe / Size
66560260.00GB
Free pe size
198/792.00MB
vGUU工ID
MQJiye-j4NN-LbzG-F3CQ-UdTU-fo9D-RRfXDS
redisplay命令的输出结果显示当前系统有一个rep的卷组,大小为26077GB,该卷
组访问权限是read/wite等。命令 display可以用来查看当前系统中有哪些逻辑卷:
[rootenN124-98 -]t lvdisplay
Logical volume.---
LV Name
/dev/rep/repdata
VG Name
reP
LV UUID
7tolDt-seKZ-ChpY-QMXC-WaFD-zXAl-MRbofK
LV Write Access
read/write
Lv snapshot status source of
/dev/rep/dho datasnapshot100805143507 [active
/dev /rep/dho datasnapshot100805163504 [activelhttp://blog.csdn.net/jiongyi1
5
3y4第8幸容份与恢复
LvS七a七us
available
open
VSi艺e
100,00GB
Current le
25600
Segments
1
Allocation
inherit
Read ahead sectors
auto
currently set t。256
Block device
253:0
Logical volu
LV Name
/dev/ rep/cho datasnapshat100805143507
VG Name
rep
LⅴUULD
fSSXzh-IBnZ-aZIn-eP03-b7pk-CPJN-SxUktE
Lv Wrlte Access
read。n1y
LV snapshot status
active destination for /dev/rep/repdata
Lv Status
available
open
Ly Size
100.00GB
Current le
25600
con-table size
80.00GB
coN=table le
20480
Allocated to snapshot 0, 13%
Snapshot chunk size
4.00KB
Segment
1
AL1cati。n
inherit
Re己 d ahead sectors
a1t●
currently set to
256
Block device
253:1
Logical volume
IY Name
/dev/rep/dho datasnapshot100805163504
VG Name
rep
LⅴUUID
3B9NP1-qWVG-pfJY-Bdgm-DIdD-dUMu-s2L6qJ
LW￥ ite ccess
read only
Lv snapshot status
active destination for /dev/rep/repdata
LvS七atus
available
open
Lv Size
100.00GB
Current le
25600
CoW一tab1 e s126
80.00GB
coW一tab1eLE
20480
Allocated to snapshot 0.029
Snapshot chunk size
4.00KBhttp:/blog.csdnnet/jiongyi11
5.6
86快照备份375
拼要翻
Segments
召盛
Allocation
inherit
Read ahead sectors
auto
currently set to
256
Block device
253:4
可以看到,一共有3个逻辑卷,都属于卷组rep,每个逻辑卷的大小都是100GB
/ dev/rep/ repdata这个逻辑卷有两个只读快照,并且当前都是激活状态的
LVM使用了写时复制( Copy-on- write)技术来创建快照。当创建一个快照时,仅复
制原始卷中数据的元数据( meta data),并不会有数据的物理操作,因此快照的创建过
程是非常快的。当快照创建完成,原始卷上有写操作时,快照会跟踪原始卷块的改变,
将要改变的数据在改变之前复制到快照预留的空间里,因此这个原理的实现叫做写时复
制。而对于快照的读取操作,如果读取的数据块是创建数据来源卷
快照区域
快照后没有修改过的,那么会将读操作直接重定向到原
始卷上,如果要读取的是已经修改过的块,则将读取保
存在快照中该块在原始卷上改变之前的数据。因此,采
用写吋复制机制保证了读取快照时得到的数据与快照创
ABCD
B
建时一致。
图8-3显示了LVM的快照读取,可见B区块被修
改了,因此历史数据放入了快照区域。读取快照数据
快照读取
时,A、C、D块还是从原有卷中读取,而B块就需要
从快照读取了。
图83LM快照读取
命令 Increate可以用来创建一个快照,- permission r表示创建的快照是只读的:
Irootenh119-215 data]t lvcreate --size 100G --snapshot --permission r-n
daLasnldpshiuL /dev/rep/repdata
Logical volume datasnapshot"created
在快照制作完成后可以用 Display命令查看,输出中的 COw-table size字段表示该
快照最大的空间大小, Allocated to snapshot字段表示该快照目前空间的使用状况:
Croot@*]t Ivdisplay
Logical volume
Lv Name
/dev/rep/aho datasnapshot100805163504
VG Name
rephttp://blog.csdn.net/jiongyi1
5I
376第8章畚份与恢复
LV UUID
3B9NPl-qWVG-pfJY-Bdgm-DIdD-dUMu-s2L6qJ
你
Lv write Access
read only
Lv snapshot status
active destination for /dev/rep/repdata
L status
available
排⊙pen
Lv Size
100.00GB
Current le
25600
coN一 table size
80.00GB
CN一 table le
20480
ALL。 cated to snapshot
0.04皆
Snapshot chunk size
4.00KB
Segments
Allocation
inherit
Read ahead sectors
auto
currently set to
256
Block device
253:4
可以看到,当前快照只使用0.04%的空间。快照在最初创建时总是很小,当数据来源
卷的数据不断被修改时,这些数据库才会放人快照空间,这时快照的大小才会慢慢增大。
用LVM快照备份 InnoDB存储引擎表相当简单,只要把与 InnoDB存储引擎相关的
文件如共享表空间、独立表空间、重做日志文件等放在同一个逻辑卷中,然后对这个逻
辑卷做快照备份即可。
在对 InnoDB存储引擎文件做快照时,数据库无须关闭,即可以进行在线备份。虽
然此时数据库中可能还有任务需要往磁盘上写数据,但这不会妨碍备份的正确性。因为
InnoDB存储引擎是事务安全的引擎,在下次恢复时,数据库会自动检查表空间中页的状
态,并决定是否应用重做日志,恢复就好像数据库被意外重启了。
8.7复制
87.1复制的工作原理
复制( replication)是 MySQL数据库提供的一种高可用高性能的解决方案,一般用
来建立大型的应用。总体来说, replication的工作原理分为以下3个步骤:
)主服务器( master)把数据更改记录到二进制日志( binlog)中。
2)从服务器( slave)把主服务器的二进制日志复制到自己的中继日志( relay log)中。
3)从服务器重做中继日志中的日志,把更改应用到自己的数据库上,以达到数据http:/blog.csdnnet/jiongyi11
51.6
8.7`复制377
研安兽
的最终一致性。
复制的工作原理并不复杂,其实就是一个完全备份加上二进制日志备份的还原。不同
的是这个二进制日志的还原操作基本上实时在进行中。这里特别需要注意的是,复制不是
完全实时地进行同步,而是异步实时。这中间存在主从服务器之间的执行延时,如果主服
务器的压力很大,则可能导致主从服务器延时较大。复制的工作原理如图8-4所示。
Q线程
主服务器
从服务器
数据
更改
日志传送
SQL线程
写入
读取
二进制
日志
中继日志
图84 MySQL数据库的复制工作原理
从服务器有2个线程,一个是IO线程,负责读取主服务器的二进制日志,并将其
保存为中继日志;另一个是SQL线程,复制执行中继日志。 MySQL40版本之前,从服
务器只有1个线程,既负责读取二进制日志,又负责执行二进制日志中的SQL语句。这
种方式不符合高性能的要求,目前已淘汰。因此如果查看一个从服务器的状态,应该可
以看到类似如下内容:
mysql>SHOW FULL PROCESSLIST\G:
大内六内有青肯青害★常★背害害實害害1,r。w★★★★★女★★★★★★★★★★★★★★★实★★★
Id: 1
User: system user
Hos t
db: NULL
Command: Connect
Time: 6501
state: Waiting for master to send eventhttp://blog.csdn.net/jiongyi1
5
378第8亨备份与茯复
Info: NULL
★卖女*★女★女女★黄★★★★青安安言密實2,yw實★★★★★★
★责北克★流责责黄真賁
Id: 2
User: system user
Host
d
NULL
Command: Connect
Time: 0
state: Has read all relay log; waiting for the slave I/o thread to update it
Info: NULL
★★★★★★★★★★★★如★由知南★★严★妯★*3,Y。w★★★★★★★★★★★★★★南*★★南★★★
Id:206
User;Y。。t
Host:1。ca1host
db: NULL
Command: Query
Time: 0
state: NULL
Info: SHOW FULL PROCESSLIST
3r。 ws in set【0.00sec】
可以看到ID为1的线程就是IO线程,目前的状态是等待主服务器发送二进制日
志。ID为2的线程是SQL线程,负责读取中继日志并执行。目前的状态是已读取所有
的中继日志,等待中继日志被IO线程更新
在 replication的主服务器上应该可以看到一个线程负责发送二进制日志,类似内容
如下:
mysql>SHOW FULL PROCESSLIST\G;
★★★六青青青六★大★青肉★★**65,工ow★方轰太囊飞太太★★南★★为★★★★
Id:26541
User: rep
Ho3t:192.168.190.98:39549
d: NULL
d: Binlog Dump
Time: 6857
state: Has sent all binlog to slave waiting for binlog to be updated
Inf。:NULL
之前已经说过 MySQL的复制是异步实时的,并非完全的主从同步。若用户要想得知
当前的延迟,可以通过命令 SHOW SLAVE STATUS和 SHOW MASTER STATUS得知,如:http://blog.csdn.net/jiongyi1
51.
8.7制379
拼帮爱
mysql>SHOW SLAVE STATUS\G;
★★★★★★★安灾★安夹★★★★来★★★央★丈夹*1.row★★★出★片古片★古青hhhh古中中
slave Io state: Waiting for master to send event
Master host:192,168.190,10
Mas七 er User;re
Master Port: 3306
Connect Retry: 62
Master Log File: mysql-bin. 000007
Read Master Log Pos: 555176471
Relay Log File: gamcdb-relay-bin.000048
Relay Log Pos: 224355889
Relay Master Log File: wysql-bin000507
Slave Io Running: Yes
Slave SQL Running
Y
G s
Replicate Do DB:
Rep1 lcate工 gnore DB:
plicate Do Table
Replicate Ignore Table:
Replicate wild Do Table
Replicate wild Ignore Table: mysql,3,DBA.3
Last errno: o
Last error
Skip counter: 0
Exec Master Log Pos: 555176471
Relay log Space: 224356045
Until Condition: None
Unt立工 Lcg Fi⊥e
Until Log Pos: 0
Master ssL Allowed: No
Master ssl CA File
Master SsL Ca Path
Master ssl cert
Master ssl cipher:
Master ssl key:
Seconds Behind Master: 0
Master SsL Verify Server cert: No
Last Io Errno: o
Last io error:
Last SqL Errno: 0
Last SQL Error:
1 row in set (0.00 sec)
通过 SHOW SLAVE STATUS命令可以观察当前复制的运行状态,一些主要的变量http://blog.csdn.net/jiongyi1
6I
380第8章备份与恢复
拼哪
如表8-1所示。
图函令
表8-1 SHOW SLAVE STATUS的主要变量
变量
说明
Slave Io State
显示当前I线程的状态,上述状态显示的是等待主服务发送二进制日志
显示当前同步的主服务器的二进制日志,上述显示当前同步的是主服务器的mysq
Master Log File
bin000007
显示当前同步到主服务器上二进制日志的偏移量位置,单位是字节。上述的示例
Read Master Log_ Pos|显示当前同步到 mysql-bir0.00090515471偏移量位置,即已经同步了 mysql
bin00007这个二进制日志中529MB(555176471/024/1024)的内容
Relay Master Log File
当前中继日志同步的二进制日志
Relay log file
显示当前写入的中继H志
Relay log pos
显示当前执行到中继日志的偏移量位置
Slave Io Running
从服务器中IO线程的运行状态,YES表示运行正常
Slave SQL Running
从服务器中SQL线程的运行状态,YES表示运行正常
表示同步到主服务器的二进制日志偏移量的位置。( Read Master Log Pos·Exec
Exec Master Log Pos| Master Log Pos)可以表示当前SQL线程运行的延时,单位是字节。上述例子显示当
前主从服务器是完全同步的
命令 SHOW MASTER STATUS可以用来查看主服务器中二进制日志的状态,如:
mysql>SHON MASTER STATUS\G;
★★★★常★★★★青青★★青★青青背黄青青★★;1.row**★★★★青★青青六古古★古★内★青★
Eile: rysql-bin.0C3007
Position: 606181078
B:n1oaD。DB:
Binlog Ignore de:
l row in set (0.01 sec)
可以看到,当前二进制日志记录了偏移量606181078的位置,该值减去这一时间点
时从服务器上的 Read Master Log Pos,就可以得知I/o线程的延时。
对于一个优秀的 My SQL数据库复制的监控,用户不应该仅仅监控从服务器上IO
线程和SQL线程运行得是否正常,同时也应该监控从服务器和主服务器之间的延迟,确
保从服务器上的数据库总是尽可能地接近于主服务器上数据库的状态。
87.2快照+复制的备份架构
复制可以用来作为备份,但功能不仅限于备份,其主要功能如下
口数据分布。由于 MySQL数据库提供的复制并不需要很大的带宽要求,因此可以
在不同的数据中心之间实现数据的复制。http:/blog.csdnnet/jiongyi11
51.6
87文制381争
口读取的负载平衡。通过建立多个从服务器,可将读取平均地分布到这些从服务
器中,并且减少了主服务器的压力。一般通过DNS的 Round- Robin和 Linux的
LVs功能都可以实现负载平衡。
口数据库备份。复制对备份很有帮助,但是从服务器不是备份,不能完全代替备份
口高可用性和故障转秽。通过复制建立的从服务器有助于故障转移,减少故障的停
机时间和恢复时间。
可见,复制的设计不是简简单单用来备份的,并且只是用复制来进行备份是远远不
够的。假设当前应用采用了主从的复制架构,从服务器作为备份。这时,一个初级DBA
执行了误操作,如 DROP DATABASE或 DROP TABLE,这时从服务器也跟着运行了
这时用户怎样从服务器进行恢复呢?
因此,一个比较好的方法是通过对从服务器上的数据库所在分区做快照,以此来避
免误操作对复制造成影响。当发生主服务器上的误操作时,只需要将从服务器上的快照
进行恢复,然后再根据二进制日志进行 point-in-time的恢复即可。因此快照+复制的备
份架构如图8-5所示。
IO线程
快照
主服务器
从服务器
快照
数据
SQL线程
更改
日志传送
写入
读取
二进制
日志
中继日志
图8-5快照+复制的备份架构
还有一些其他的方法来调整复制,比如采用延时复制,即间歇性地开启从服务器上
的同步,保证大约一小时的延时。这的确也是一个方法,只是数据库在高峰和非高峰期
间每小时产生的二进制日志量是不同的,用户很难精准地控制。另外,这种方法也不能http://blog.csdn.net/jiongyi1
6I
382茅8幸备分与恢复
部拼吾
完全起到对误操作的防范作用。
此外,建议在从服务上启用read-only选项,这样能保证从服务器上的数据仅与主服
务器进行同步,避免其他线程修改数据。如
[mysql]
read-only
在启用read-ony选项后,如果操作从服务器的用户没有 SUPER权限,则对从服务
器进行任何的修改操作会抛出一个错误,如:
ycl>INSERT INTC Z SELECT 2:
ERROR 1290 (HY000): The MySQI server is running with the --read-only option so
it cannot execute this statement
8.8小结
本章中介绍了不同的备份类型,并介绍了 MySQL数据库常用的一些备份方式。同
时主要介绍了对于 InnoDB存储引擎表的备份。不管是 mysqldump还是 xtrabackup工
具,都可以对 InnoDB存储引擎表进行很好的在线热备工作。最后,介绍了复制,通过
快照和复制技术的结合,可以保证用户得到一个异步实时的在线 MySQL备份解决方案http:/blog.csdnnet/jiongyi11
51.6
第9章性能调优
性能优化不是一项简单的工作,但也不是复杂的难事,关键在于对 InnodB存储引
擎特性的了解。如果之前各章的内容读者已经完全理解并掌握了,那就应该基本掌握了
如何使 InnoDB存储引擎更好地工作。本章将从以下几个方面集中讲解 InnoDB存储引擎
的性能问题:
口选择合适的CPU
口内存的重要性
口硬盘对数据库性能的影响
口合理地设置RAID
口操作系统的选择也很重要
口不同文件系统对数据库的影响
口选择合适的基准测试工具
91选择合适的cPU
用户首先需要清楚当前数据库的应用类型。一般而言,可分为两大类:OLTP
( Online Transaction Processing,在线事务处理)和OLAP( Online Analytical
Processing,在线分析处理)。这是两种截然不同的数据库应用。OLAP多用在数据仓
库或数据集市中,一般需要执行复杂的SQL语句来进行查询:OLTP多用在日常的事
物处理应用中,如银行交易、在线商品交易、Blog、网终游戏等应用。相对于OLAP,
数据库的容量较小
InnoDB存储引擎一般都应用于OLTP的数据库应用,这种应用的特点如下
口用户操作的并发量大
口事务处理的时间一般比较短
口查询的语句较为简单,一般都走索引http:/blog.csdnnet/jiongyi11
3849幸性館碉优
口复杂的查询较少
可以看出,OLTP的数据库应用本身对CPU的要求并不是很高,因为复杂的奎询可
能需要执行比较、排序、连接等非常耗CPU的操作,这些操作在OLTP的数据厍应用中
较少发生。因此,可以说OLAP是CPU密集型的操作,而OLTP是IO密集型的操作。
建议在采购设备时,将更多的注意力放在提高IO的配置上。
此外,为了获得更多内存的支持,用户采购的CPU必须支持64位,否则无法
支持64位操作系统的安装。因此,为新的应用选择64位的CPU是必要的前提。现
在4核的CPU已经非常普遍,如今Int和AMD又相继推出了8核的CPU,将来
随着操作系统的升级我们还可能看到128核的CPU,这都需要数据库更好地对其提
供支持。
从 InnoDB存储引擎的设计架构上来看,其主要的后台操作都是在一个单独的
master thread中完成的,因此并不能很好地支持多核的应用。当然,开源社区已经通过
多种方法来改变这种局面,而 InnoDB1,0版本在各种测试下已经显示出对多核CPU的
处理性能的支持有∫极大的提高,而 InnoDB12版本又支持多个 purge线程,以及将刷
新操作从 master thread中分离出来。因此,若用户的CPU攴持多核, InnoDB的版本应
该选择11或更高版本。另外,如果CPU是多核的,可以通过修改参数 innodb read io
threads和 innodb write io threads来增大IO的线程,这样也能更充分有效地利用CPU
的多核性能。
在当前的 MySQL数据库版本中,一条SQL查询语句只能在一个CPU中工作,
并不支持多CPU的处理。OLTP的数据库应用操作一般都很简单,因此对OLTP应
用的影响并不是很大。但是,多个CPU或多核CPU对处理大并发量的请求还是会有
帮助
92内存的重要性
内存的大小是最能直接反映数据库的性能。通过之前各个章节的介绍,已经了解到
InnoDB存储引擎既缓存数据,又缓存索引,并且将它们缓存于一个很大的缓冲池中,即
InnoDB Buffer Pool。因此,内存的大小直接影响了数据库的性能。 Percona公司的CTO
Vadim对此做了一次测试,以此反映内存的重要性,结果如图9-1所示。http:/blog.csdnnet/jiongyi11
5.e
92内存的重要性385
sysbench oltp, 80mIn rows (18GB data
增图强
2500
2250
2000
1750
1500
1250
令 RAID L0
1000
750
500
250
810121416182022
Buffer pool (memory ),GB
图9-1不同内存容量下 InnoDE存储引擎的性能表现
在上述测试中,数据和索引总大小为18GB,然后将缓冲池的大小分别设为2GB
4GB、6GB、8GB、l0GB、12GB、14GB、16GB、l8GB、20GB、22GB,再进行 sysbench
的测试。可以发现,随着缓冲池的增大,测试结果TPs( Transaction per second)会线性增
长。当缓冲池增大到20GB和22GB时,数据库的性能有了极大的提高,因为这时缓冲池
的大小已经大于数据文件本身的大小,所有对数据文件的操作都可以在内存中进行。因此
这时的性能应该是最优的,再调大缓冲池并不能再提高数据库的性能
所以,应该在开发应用前预估“活跃”数据库的大小是多少,并以此确定数据库服
务器内存的大小。当然,要使用更多的内存还必须使用64位的操作系统。
如何判断当前数据库的内存是否已经达到瓶颈了呢?可以通过查看当前服务器的状
态,比较物理磁盘的读取和内存读取的比例来判断缓冲池的命中率,通常 InnoDB存储
引擎的缓冲池的命中率不应该小于99%,如
mysql>SHIOW GLOBAL STAUTS LIKE 'innodb%\G
害卖责★自★青★★青青青下青青食1.r。W卖★★★为★★★★★t★★大x★★★由★★★★★★★
Variable name: Innodb buffer pool read ahead
Value: 0http://blog.csdn.net/jiongyi1
FI
3806第9章性能调优
★女女★★★★女★★太女★*★鲨次古★古青古★★★*2.x。w肉★★南★★★★★实★★★★史★★★★★★★★★★
Variable name Innodb buffer pool read ahead evicted
Value: 0
★★古女肃★★★大大★★大★大*★★★★★★★★3.rOW★*★★肃★*★*★★*★★*★★南★★★★*
Variable name: Innodb buffer pool read request.
Va1ue:167051313
★责★燕离声声古玄言古肯古古大肯大★
W★★内内肉内内★古古古内内古青;古青★★★
Variable name: Innodb buffer pool reads
va1ue:129236
大★★★★★★★★★女★女安★块★★请*★*5,工w青幽南青南青南有南南青南南南内市古
Variable name: Innodb data pending reads
al
女★★责★★★★★旋★★发★★读★★★青★★★青6.工。w肃内囊卖★★★★★★青★责南内数青t责
Variable name: Innodb data read
va1ue:2135642112
★丈丈女丈★★★走责安★★安青★责青责曹★7。wt责★
★古★★背★★★★★★曹★肯古肯责
variable name: Innodb data
ds
Value: 130309
★★青★★★★★★★★★★★★★★★责★★
★★★★★★★责實★★★熏★★★★
Variable name: Innodb pages read
Va1ue:130215
★★★★★★★★★9.r。w
variable name: Innodb rows read
Va1ue:17651085
9 rows ir set (0.00 sec)
上述参数的具体含义如表9-1所示
表91当前服务器的状态参数
参数
说明
Innodb buffer pool reads
表示从物理磁盘读取页的次数
Innodb buffer pool read ahead
预读的次数
预读的页,但是没有被读取就从缓冲池中被替换的页的数量,一般
Innodb buffer pool read ahead evicted
用来判断预读的效率
Innodb buffer pool rcad requests
从缓冲池中读取页的次数
Innodb data read
总共读人的字节数
Innodb data reads
发起读取请求的次数,每次读取可能需要读取多个页
以下公式可以计算各种对缓冲池的操作:
缓冲池命中率
Innodb_buffer_pool_read_requests
(Innodb_buffer_poolread_requests+Innodb__buffer-pool_read_ahead+innodb_buffer_pool_reads
平均每次读取的字节数
Innodb data read
Innodb data readhttp:/blog.csdnnet/jiongyi11
51.A
93硬盘对数据库性能的影响387
挤号发
从上面的例子看,缓冲池命中率=167051313/(167051313+129236+0)992800
即使缓冲池的大小已经大于数据库文件的大小,这也并不意味着没有磁盘操作。数
据库的缓冲池只是一个用来存放热点的区域,后台的线程还负责将脏页异步地写入到磁
盘。此外,每次事务提交时还需要将日志写人重做日志文件。
9.3硬盘对数据库性能的影响
931传统机械硬盘
当前大多数数据库使用的都是传统的机槭硬盘。机械硬盘的技术目前已非常成熟,
在服务器领域一般使用SAS或SATA接口的硬盘。服务器机械硬盘开始向小型化转型
目前大部分使用25寸的SAS机械硬盘。
机械硬盘有两个重要的指标:一个是寻道时间,另一个是转速。当前服务器机械硬
盘的寻道时间已经能够达到3ms,转速为15000RPM( rotate per minute)。传统杌械硬盘
最大的问題在于读写磁头,读写磁头的设计使硬盘可以不再像磁带一样,只能进行顺序
访问,而是可以随机访问。但是,机械硬盘的访问需要耗费长时间的磁头旋转和定位来
查找,因此顺序访间的速度要远高于随机访问。传统关系数据库的很多设计也都是在尽
量充分地利用顺序访问的特性。
通常来说,可以将多块机械硬盘组成RAID来提高数据库的性能,也可以将数据文
件分布在不同硬盘上来达到访问负载的均衡。
932固态硬盘
固态硬盘,更准确地说是基于闪存的固态硬盘,是近几年出现的一种新的存储设
备,其内部由闪存( Flash Memory)组成。因为闪存的低延迟性、低功耗,以及防震性,
闪存设备已在移动设备上得到了广泛的应用。企业级应用一般使用固态硬盘,通过并联
多块闪存来进一步提高数据传输的吞吐量。传统的存储服务提供商EMC公司已经开始
提供基于闪存的固态硬盘的TB级别存储解决方案。数据库厂商 Oracle公司最近也开始
提供绑定固态硬盘的 Exadata服务器。http://blog.csdn.net/jiongyi1
6I
3889萝性能调优
不同于传统的机械硬盘,闪存是一个完全的电子设备,没有传统机械硬盘的读写磁
头。因此,固态硬盘不需要像传统机械硬盘一样,需要耗费大量时间的磁头旋转和定位
来查找数据,所以固态硬盘可以提供一致的随机访问时间。固态硬盘这种对数据的快速
读写和定位特性是值得研究的。
另一方面,闪存中的数据是不可以更新的,只能通过扇区( sector)的覆盖重写,而在
覆盖重写之前,需要执行非常耗时的擦除( erase)操作。擦除操作不能在所含数据的扇区
上完成,而需要在删除整个被称为擦除块的基础上完成,这个擦除块的尺寸大于扇区的大
小,通常为128KB或者256KB。此外,每个擦除块有擦写次数的限制。已经有一些算法来
解决这个问题。但是对于数据库应用,需要认真考虑固态硬盘在写入方面存在的问题。
因为存在上述写入方面的问题,闪存提供的读写速度是非对称的。读取速度要远快
于写人的速度,因此对于固态硬盘在数据库中的应用,应该好好利用其读取的性能,避
免过多的写入操作。
图92显示了一个双通道的固态硬盘架构,通过支持4路的闪存交叉存储来降低固态
硬盘的访问延时,同时增大并发的读写操作。通过进一步增加通道的数量,固态硬盘的
性能可以线性地提高,例如我们常见的 Intel x2M固态硬盘就是10通道的固态硬盘
ARMT
Flash
Flash Memory
x16
x16 Memory
Host
SRAN
Controller
WF
Controller
Flash Memory
x32
X32
ost
Flash Memory
Flash
x16]Memory
X16
Controller
X32
Flash Memory
SRAM
图9-2双通道的固态硬盘架构
由于闪存是一个完全的电子设备,没有读写磁头等移动部件,因此固态硬盘有着
铰低的访问延时。当主机发布一个读写请求时,固态硬盘的控制器会把IO命令从逻辑
地址映射成实际的物理地址,写操作还需要修改相应的映射表信息。算上这些额外的开http:/blog.csdnnet/jiongyi11
5.6
94合理地设置RAD389
销,固态硬盘的访问延时一般小于01ms左右。图9-3显示了传统机械硬盘、呐内存、
态硬盘的随机访问延时之间的比较。
Random Access Time (ms)
Memory 0.01
25 SAS Disk酸|3.63
SSD3005
SSD20.
SSD1 0.07
图9-3固态硬盘和传统杌械硬盘随机访问延时的比较
对于固态硬盘在 InnoDB存储引擎中的优化,可以增加 innodb_ 10 capacity变量的值
达到充分利用固态硬盘带来的高IOPS特性。不过这需要用户根据自己的应用进行有针
对性的调整。在 InnoSQL及InDB12版本中,可以选择关闭邻接页的刷新,同样可以
为数据库的性能带来一定效果的提升。
此外,还可以使用 InnOSQL开发的L2 Cache解决方案,该解决方案可以充分利用
固态硬盘的超高速随机读取性能,在内缓冲池和传统存储层之间建立一层基于闪存固
态硬盘的二级缓冲池,以此来扩充缓冲池的容量,提高数据库的性能。与基于磁盘的固
态硬盘 Cache类似的解决方案还有 Facebook flash cache和 bcache,只不过它们是基于
通用文件系统的,对 InnoDB存储引擎本身的优化较少。
94合理地设置RAD
94.1RA|D类型
RAID( Redundant Array of Independent Disks,独立磁盘冗余数组)的基本思想就是
把多个相对便宜的硬盘组合起来,成为一个磁盘数组,使性能达到甚至超过一个价格昂
贵、容量巨大的硬盘。由于将多个硬盘组合成为一个逻辑扇区,RAID看起来就像一个
单独的硬盘或逻辑存储单元,因此操作系统只会把它当作一个硬盘
RAID的作用是:
口增强数据集成度http://blog.csdn.net/jiongyi1
5.
3909幸性能调优
口增强容错功能
口增加处理量或容量
根据不同磁盘的组合方式,常见的RAID组合方式可分为RAID0、RAID1、RAID5
RAID10和RAID50等。
RAID0:将多个磁盘合并成一个大的磁盘,不会有冗余,并行IO,速度最快
RAID0亦称为带区集,它将多个磁盘并列起来,使之成为一个大磁盘,如图94所示。
在存放数据时,其将数据按磁盘的个数进行分段,同时将这些数据写进这些盘中。所
以,在所有的级别中,RAID0的速度是最快的。但是RAID0没有
RAID O
冗余功能,如果一个磁盘(物理)损坏,则所有的数据都会丢失。K
理论上,多磁盘的效能就等丁(单一磁盘效能)×(磁盘数),但飞A飞A
A
实际上受限于总线O瓶颈及其他因素的影响,RAID效能会随边A
LA6
A%
际递减。也就是说,假设一个磁盘的效能是50MB/s,两个磁盘的
RAID0效能约96MBs,三个磁盘的RAID0也许是130MR/而不是
150MB/so
Disk c
Disk l
RA|D1:两组以上的N个磁盘相互作为镜像(如图95所示),图94RAID0结构
在一些多线程操作系统中能有很好的读取速度,但写入速度略有降低。除非拥有相同数
据的主磁盘与镜像同时损坏,否则只要一个磁盘正常即可维持运作,可靠性最高。RAID
1就是镜像,其原理为在主硬盘上存放数据的同时也在镜像硬盘上写
RAID I
相同的数据。当主硬盘(物理)损坏时,镜像硬盘则代替主硬盘的工
作。因为有镜像硬盘做数据备份,所以RADI的数据安全性在所有下人a
的RAID级别上来说是最好的。但是,无论用多少磁盘作为RAID1,A
A33
A3
A4
仅算一个磁盘的容量,是所有RAID中磁盘利用率最低的一个级别。
RAD5:是一种存储性能、数据安全和存储成本兼顾的存储解
决方案。它使用的是 Disk Striping(硬盘分区)技术。RAID5至少Dsk0 Disk l
需要三个硬盘,RAID5不对存储的数据进行备份,而是把数据和相图95RAID1结构
对应的奇偶校验信息存储到组成RAID5的各个磁盘上,并且奇偶校验信息和相对应的
数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据发生损坏后,利用剩下的数
据和相应的奇偶校验信息去恢复被损坏的数据。RAID5可以理解为是RAID0和RAID
1的折中方案。RAID5可以为系统提供数据安全保障,但保障程度要比镜像低而磁盘http://blog.csdn.net/jiongyi1
5
94合理地设置RAD391
空间利用率要比镜像高。 RAID S具有和RAD0相近似的数据读取速度,只是多盛
奇偶校验信息,写入数据的速度相当慢,若使用 Write Back可以让性能改善不少。同时,
由于多个数据对应一个奇偶校验信息,RAID5的
RAID 5
磁盘空间利用率要比RAID1高,存储成本相对较
低。RAID5的结构如图9-6所示。
A下A2
BI
B
Bp
B3
RAD10和RAD01:RAD10是先镜像再ccka2
&Dp
DⅠ
sD2
D3
分区数据,将所有硬盘分为两组,视为RAID0的
最低组合,然后将这两组各自视为RAID1运作
RAID10有着不错的读取速度,而且拥有比 Raid Disk0Dk1Dk2Ds3
0更高的数据保护性。RAID01则与RAID10的
图96RAID5结构
程序相反,先分区再将数据镜射到两组硬盘。RAID01将所有的硬盘分为两组,变成
RAID I的最低组合,而将两组硬盘各自视为RAID0运作。RAID01比RAID10有着更
快的读写速度,不过也多了一些会让整个硬盘组停止运转的几率,因为只要同一组的硬
盘全部损毁,RAID01就会停止运作,而RAID10可以在牺牲RAID0的优势下正常运
作。RAID10巧妙地利用了RAID0的速度及RAID1的安全(保护)两种特性,它的
缺点是需要较多的硬盘,因为至少必须拥有四个以上的偶数硬盘才能使用。RAID10和
RAID01的结构如图97所示
RAID 10
RAID OI
RAID O
RAID 1
RAID I
RAID 1
RAID O
RAID O
A
SAI
、A5
A6
A
SA8
8
AT
A7今
图9-7RAID10和RAID01结构
RAD50:RAID50也被称为镜像阵列条带,由至少六块硬盘组成,像RAID0
样,数据被分区成条带,在同一时间内向多块磁盘写入;像RAID5一样,也是以数http:/blog.csdnnet/jiongyi11
51.6
3929章性能调优
据的校验位来保证数据的安全,且校验条带均匀分布在各个磁盘上,其目的在于提高
RAID5的读写性能
RAID 50
RAID O
RAID 5
RAID 5
RAID S
a2
A3
A4 A-par:A5
A6
Bpar
B2
B3
B4
B5
B6
DI
D2
D-par
D4 D-pa
DS
DE
D-Dar
s E1 E-par
E
ES E-par E6
DiskDisk 1 Disk 2 Disk 3 Disk 4 Disk 5 Disk 6 Disk 7 Disk 8
图98RAID50结构
对于数据库应用来说,RAID10是最好的选择,它同时兼顾了RAID1和RAID0的
特性。但是,当一个磁盘失效时,性能可能会受到很大的影响,因为条带( strip)会成
为瓶颈。我曾在生产环境下遇到过的情况是,两台负载基本相同的数据库,一台正常的
服务器磁盘O负载为20%左右,而另一台服务器IO负载却高达90%
942 RAID Write Back功能
RAID Write Back功能是指RAm控制器能够将写人的数据放入自身的缓存中,并把
它们安排到后面再执行。这样做的好处是,不用等待物理磁盘实际写入的完成,因此写入
变得更快了。对于数据库来说,这显得十分重要。例如,对重做日志的写入,在将 sync
binlog设为1的情况下二进制日志的写人、脏页的刷新等都可以使性能得到明显的提升。
但是,当操作系统或数据库关机时, Write Back功能可能会破坏数据库的数据。这
是由于已经写人的数据库可能还在RAID卡的缓存中,数据可能并没有完全写入磁盘,
而这时故障发生了。为了解决这个问题,目前大部分的硬件RAID卡都提供了电池备份
单元(BBU, Battery Backup Unit),因此可以放心地开启 Write back的功能。不过我发
现每台服务器的出厂设置都不相同,应该将RAID设置要求告知服务器提供商,开启http:/blog.csdnnet/jiongyi11
5I.
94今理地设罡RAD393
些认为需要的参数。
如果没有启用 Write back功能,那么在RAID卡设置中显示的就是
Write Through
Write Through没有缓冲写人,因此写入性能可能不是很好,但它却是最安全的写人。
即使用户开启了 Write back功能,RAID卡也可能只是在 Write Through模式下工作。
这是因为安全使用 Write back的前提是RAD卡有电池备份单元。为了确保电池的有效
性,RAID卡会定期检查电池状态,并在电池电量不足时对其进行充电,在充电的这段
时间内会将 Write Back功能切换为最为安全的 Write Through
用户可以在没有电池备份单元的情况下强制启用 Write Back功能,也可以在电池充
电时强制使用 Write back功能,只是写入是不安全的。用户应该非常确信这点,否则不
应该在没有电池备份单元的情况下启用 Write Back
可以通过插入20W的记录来比较 Write Back和 Write Through的性能差异:
mysql>CREATE TABLE t a CHAR(2))Engine=InnoDB;
Query Ok, 0 rows affected (ooc sec)
mysql>DELIMITER /
mysqL>
mysqL>CREATE PROCEDURE P()
>BEGIN
>DEClARE V INT
->SET V=O:
->WHILE V<20000C DO
->iNSERTINto t vAlUES (aa)
>5ETv=v+1;
一> END WHILE
>END
Query OK,0r。 ws affected【0.12sec
mysql>DELIMITER
首先创建一个向表t插人20W记录的存储过程,并在 Write Back和 Write Through
的设置下分别进行测试,最终测试结果如表92所示。
表92 Write Back和 Write Through的性能对比测试结果
RAD卡设置
时间
Write back
3秒
Write Throug
31分钟
Write Through with innodb flush log at trx commit=0
68http:/blog.csdnnet/jiongyi11
394笫9幸性能调优
由于批量插入不是在一个事务中完成的,而是直接用命令CALP来运行的,因此
数据库实际执行了20W次的事务。很明显可以看到,在 Write back模式下执行时间只需
要43秒,而在 Write Through模式下执行时间需要31分钟,大约有40多倍的差距。
当然,在 Write Through模式下,通过将参数 innodb fush log at trx commit设置为
0也可以提高执行存储过程P的性能,这时只需要68秒了。因为,在此设置下,重做日
志的写人不是发生在每次事务提交时,而是发生在后台 master线程每秒钟自动刷新的时
候,因此减少了物理磁盘的写人请求,所以执行速度也可以有明显的提高
943RAD配置工具
对RAID卡进行配置可以在服务器启动时进入一个类似于BIoS的配置界面,然后
再对其进行各种设置。此外,很多厂商都开发了各种操作系统下的软件对RAID进行配
置,如果用户使用的是LS公司生产提供的RAID卡,则可以使用 MegaLI工具来进行
配置。
MegaCLⅠ为多个操作系统提供了支持,对 Windows操作系统还提供了GUI界面
的配置环境,因此相对来说比较简单。这里主要介绍命令行下 MegaLi的使用,在
Windows下同样可以使用命令 MegaCLI.exe。
使用 MegaCLI查看RAID卡的信息
Ircotexen-server +]# /opt/MegaRAI D/Megacli/MegaCl164-AdpAllInfo -aO
Adapter +O
〓〓
二〓二二〓出出〓〓〓〓〓〓〓〓〓〓〓〓〓〓
Versions
二二二二二三三!
Product Name MegaRAID SAS 8708ELP
Serial no
P012233608
FW Package Build: 9.0.1-0030
HW Configuratio
二二二二二三三出出出出出
SAs Address
500605b000d1e180
BBU
Present
Alarm
Presenthttp://blog.csdn.net/jiongyi1
5
94合狸地置RA395
部拼没
NVRAM
Present
serial Debugger Present
Memory
Present
Flash
Present
Memory size
256T
TEM
Absent
Default settings
Thy polarity
Phy Polaritysplit
:240
Background Rate
30
stripe size
64kB
Flush Time
4 seconds
W五teEo1cy
Read e。]iey
None
Cache When bbu Bad
Disabled
Cached工
N
SMART Mode
Mode
Aldrin disable
Ye
Coercion mode
1GB
ZCR Config
Unknown
Dirty led Shows Drive Activity No
BIos Continue on err。r
No
sp⊥nD。wnM。de
None
Allowed Device Type
SAS/SATA Mix
Allow Mix in Enclosure
Ye
Allow HDD SAS/SATA Mix in VD
t Y
AllOw SSD SAS/SATA Mix in vD
No
Allow HDD/SSD Mix in VD
N
A⊥1 OW SATA in Cluster
N
Max Chained enclosures
3
Disab⊥ectr1-R
Yes
Enable Web BIos
Yes
Direct PD Mapping
B工 OS Enumerate vds
Yes
Restore Hot Spare on Insertion
Expose Enclosure Devices
Yes
Maintain PD Fail History
Yes
Disable Puncturing
NO
Zero based Enclosure Enumeration
PreBoot ClI Enabled
LED SH。 w Drive Activity
N
Cluster Disable
Yeshttp:/blog.csdnnet/jiongyi11
EL
396第9性能调优
sAs Disable
No
Auto detect Backplane Enable
SGPIO/i2C SEP
Use FDE Only
No
Enable led Header
N
Delay during POST
由于排版的原因,这里只列出了输出的一小部分。通过上述命令可以看到RAD卡的
一些硬件设置,如这块RAID卡的型号是 MegaRAID SAS8708ELP,缓存大小是256MB
还可以看到一些默认的配置,如默认启用的 Write Policy为WB( Write back)等。
MegaCL还可以用来查看当前物理磁盘的信息,如:
Irootexen-server -]f /opt/MegaRAID/MegaCli/MegaCli64-PDList -aALL
Adapter #O
Enclosure Device ID: 252
s⊥ ot Number:0
Device Id: 8
Sequence Number: 2
Media Error Count: 0
other error count: 0
Predictive failure count: 0
Last Predictive Failure Event seg Number: 0
Pd TyPe: SAS
Raw size: 279,396 GB !0x22ecb25c Sectors]
Non Coerced size: 278.896 GB [Cx22dch25c Sectors l
Coerced size: 278,464 GB [0x22cee000 Sectors]
Firnware state: Online
SAs Address(0): 0x5000c5000f353b55
SAs Address(1): 0xO
Connected Port Number: 0(path0)
Inquiry Data: SEAGATE ST3300655SS
00023LM5MGZZ
FDE Capable: Not capable
FDE Enable: Disable
Secured: Unsecured
Locked: Unlocked
Foreign state: None
Device speed: Unknown
Link Speed: Unknown
Media Type: Hard Disk Device
可以看到当前使用的磁盘型号是 SEAGATE ST330065可以从这个型号继续找到http://blog.csdn.net/jiongyi1
BI
95操作系统的速择397争
部拼没
这个硬盘的具体信息,如在希捷官网htp:/ discountechnology. com/ Seagate-ST3300655589
SAS-Hard-Drive上可以知道这块硬盘大小是35寸的,转速为15000,硬盘的 Cache为
16MB,随机读取的寻道时间是3.5毫秒,随机写人的寻道时间是40毫秒等。
此外,还可以通过下面的命令来查看是否开启了 Write Back功能:
[rootexen-server -]l /opt/MegaRAID/Megacli/MegaCl164-LDGetPrcp -Cache -LAll
aAll
Adapter 0-VD 0(target id: 0): Cache Policy: writeBack, ReadAheadNone Direct. No
Write cache if bad BBu
Adapter 0-vD 1(target id: 1): Cache Policy: WriteBack ReadAheadNone, Direct, No
Write cache if bad bbu
Eκ it code:0x00
通过上面的结果可以发现当前开启了RAID卡的 Write back功能,并且当BBU有
问题时或在充电时禁用 Write back功能。此外,这里还显示了不需要启用RAID卡的预
读功能,写入方式为直接写入。
通过下面的命令可以对当前的写入策略进行调整
#/opt/ MegaRAID/Megacli/MegaCcli64 -LDSetPropWB -LALL -aALL
/。pt/ MegaRAID/ Megac1立/ Megac1i64- LDSetProp种-LALL-aALL
特别需要注意地是,当RAID卡的写入策略从 Write back切换为 Write Through时,
该更改立即生效。然而从 Write Through切换为 Write back时,必须重启服务器才能使
其生效。
9.5操作系统的选择
Linux是 MySQL数据库服务器中最常使用的操作系统。与其他操作系统不同的是
Linuκ有着众多的发行版本,每个用户的偏好可能不尽相同。然而在将 Linux操作系统
作为数据库服务器时需要考虑更多的是操作系统的稳定性,而不是新特性。
除了 Linux操作系统外, FreeBSD也是另一个常见的优秀操作系统。之前版本的
FreeBSD对MysαL数据库支持得不是很好,需要选择单独的线程库进行手动编译,
但是新版本的 FreeBSD对 My SQL数据库的支持已经好了很多,直接下载二进制安装
包即可。http:/blog.csdnnet/jiongyi11
5L.A
398第9幸性能谓优
拼吾爱
S是非常不错的操作系统,之前是基于SARC硬件的操作系统+喝
移植到了X86平台上。 Solaris是高性能、高可靠性的操作系统,同时其提供的ZFS文
件系统非常适合 MySQL的数据库应用。如果需要,用户可以尝试它的开源版本Open
Solaris
Windows操作系统在 MySQL数据库应用中也非常普及。也有公司喜欢在开发环境
下使用 Windows版本的 MySQL数据库,而在正式生产环境下选择使用 Linux操作系
统。这本身没有什么问题,但问题通常存在于文件系统大小写敏感对应用程序的影响。
在 Windows操作系统下表名不区分大小写,而 Linux操作系统却是大小写致感的,这点
在开发阶段需要特别注意。
4G内存在当前已经非常普遍了,即使是桌面用户也开始使用8G的内存。为了可以
更好地使用大于4G的内存容量,用户必须使用64位的操作系统,上述介绍的这些操作
系统都提供了64位的版本。此外,使用64位的操作系统还必须使用64位的软件。这
听上去像是句废话,但是我曾多次看到32位的 MySQL数据库安装在64位的系统上,
导致不能充分发挥64位操作系统的内存寻址能力。
96不同的文件系统对数据库性能的影响
每个操作系统都默认支持一种文件系统并推荐用户使用,如 Windows默认支持
NTFS, Solaris默认支持ZFS。而对于 Linux这样的操作系统,不同发行版本默认支持
的文件系统各不相同,有的默认支持EXT3,有的是 ReiserFs,有的是EXT4,有的是
XFS
虽然不同特性的文件系统有很多,但是在实际使用过程中从未感觉到文件系统的
性能差异有多大。网上有多个关于XFS文件系统的“神话”,认为其是多么地适合数据
库应用,性能较之EXT3有极大的提升。但是在实际测试和使用后发现,它的性能和
EXT3在整体上没有大的差距。因此,DBA首先应该把更多的注意力放到数据库上,而
不是纠结于文件系统。
文件系统可提供的功能也许是DBA需要关注的,例如zFS文件系统本身就可以支
持快照,因此就不需要LVM这样的逻辑卷管理工具。此外,可能还需要知道 mount的
参数,这些参数在每个文件系统中可能有所不同http:/blog.csdnnet/jiongyi11
5I.
97选择合适的基准测减工具39
97选择合适的基准测试工具
基准测试工具可以用来对数据库或操作系统调优后的性能进行对比。 MySQL数据
库本身提供了一些比较优秀的工具,这里将介绍另外两款更为优秀和常用的基准测试工
具: sysbench和 mysql- tpcc
9.7.1 sysbench
sysbench是一个模块化的、跨平台的多线程基准测试工具,主要用于测试各种不同
系统参数下的数据库负载情况。它主要包括以下几种测试方式
口CPU性能
口磁盘IO性能
口调度程序性能
口内存分配及传输速度
口 POSIX线程性能
口数据库OLTP基准测试
sysbench的数据库OLTP测试支持 MySQL、 PostgreSQL和 Oracle。日前 sysbench
主要用于 Linux操作系统,开源社区已经将 sysbench移植到 Windows,并支持对
Microsoft SQL Server数据库的测试。
sysbench的官网地址是:httb:/ sysbench, ourceforge,net,可以从该地址下载最新版
本的 sysbench T具,然后进行编译和安装。此外,有些 Linux操作系统发行版本,如
RED HAT,本身可能已经提供了 sysbench的安装包,直接安装即可
sysbench可以通过不同的参数设置来进行不同项目的测试,使用方法如下:
[rootexen-server -]t sysbench
Missing required command argument
Usage:
sysbench [general-options]..--test-<test-name> [test-opticnsl., command
General options
num-threads=N
number of threads to use [1]
max-requests=N
limit for total number of requests [10000
-max-time=N
limit for total execution time in seconds [0]
-thread-stack-size=sIZe size of stack per thread [32K]http:/blog.csdnnet/jiongyi11
EI
00第9亨性能谓优
init-rng=[onoff]
itialize random number generator [off
-test=STRING
test tc run
以
-debug=[on loff]
print more debugging info [offl
validate=[nlet纟」
perform validation checks where possible [off]
-help= [on ioffl
print help and exit
version= [on lofE]
print version and exit
Compiled-in tests:
fileid- File I/◎test
CPU performance test
memory Memory functions speed test
thread
Threads subsystem performance test
mutex Mutex performance test
oltp -oLTP test
Commands: prepare run cleanup help version
See ' sysbench --test=<name> helpfor a list of options for each test
对于 InnoDB存储引擎的数据库应用来说,用户可能更关心磁盘和OITP的性能,因
此主要测试 fileid和ol这两个项目。对于磁盘的测试, sysbench提供了以下的测试选项:
Lroocexen-server *]i syshench --testfileio help
sysbench 0.4. 10: multi-threaded system evaluation benchmark
fileid options
-file-num=N
number of files to create [128
file-block-size=N
block size to use in all Io operations [16384
fille-total-size-5IZE
total size of files to create [2G1
--file-test-ncde=STRING
test mode (segwr, segrewr, segrd, rndrd, rndwr,
endow k
-file-io-mode=STRING
file operations mode I sync async fastmmap, slowmmmap
[sync]
file-extra-flags=STRING additional flags to use on opening files
[sync, async direct [
file-fsync-freg=N
d。 fsync() after this number。 f reque3ta(0
don 't use fsync()) [100]
file-fsync-all=[on]
do fsync( after each write operation [offl
file-fsync-end=[on loff]
do fsync( at the end cf test [on]
--file-fsync-modeESTRING
which method to use for synchronization (fsync
fdatasync〔 Esync]
file-merged-requests=N
merge at most this number of Io requests if
possible (0- don't merge)[OI
file-rw-ratio=N
reads/writes ratio for combined test [1.5]http://blog.csdn.net/jiongyi1
5
97选拆合适的基准测工具401多
各个参数的含义如下
口-fle-mum,生成测试文件的数量,默认为128。
口- file-block-size,测试期间文件块的大小,如果想知道磁盘针对 InnODB存储引
擎进行的测试,可以将其设置为16384,即 InnoDB存储引擎页的大小。默认为
16384
口-fle-totl-size,每个文件的大小,默认为2GB。
口-file- test-mode,文件测试模式,包含 sewn(顺序写)、 segreto(顺序读写)、
send(顺序读)、mdrd(随机读)、mdwr(随机写)和mndw(随机读写)
口-fle-io-mode,文件操作的模式,同步还是异步,或者是选择MMAP(map映射)
模式。默认为同步。
口-file- extra-fags,打开文件时的选项,这是与API相关的参数。
fle- fsync-freq,执行 fsync函数的频率。 fsync主要是同步磁盘文件,因为可能
有系统和磁盘缓冲的关系。
口-file- fsync-all每执行完一次写操作,就执行一次fync。默认为of
口-file- fsync-end,在测试结束时,执行 fsync。默认为on
口-fle- fsync-mode,文件同步函数的选择,同样是和AP相关的参数,由于多个操
作系统对 fdatasync支持的不同,因此不建议使用 fdatasync。默认为 fsync
口-fle- rw-ratio,测试时的读写比例,默认是2:1
sysbench的 fileid测试需要经过 prepare、mn和 cleanup三个阶段。 prepare是准备阶
段,生产需要的测试文件,rn是实际测试阶段, cleanup是清理测试产生的文件。例如
进行16个文件、总大小2GB的fleo测试:
[rootexen-server ssd] syshench --test=fileic --file-num=16 --file-total-size=2G
Prepare
sysbench 0.4.10: multi-threaded system evaluation benchmark
16 files, 131072Kb each, 2048Mb total
Creating files for the test
接着在相应的目录下就会产生16个文件,因为总大小是2GB,所以每个文件的大
小应该是128MB
[rootexen-server ssd]t ls -lh
total 2Ghttp:/blog.csdnnet/jiongyi11
402多9幸性能调优
1 root root 128M Aug 12 10: 42 test file. 0
1 root root 128M Aug 12 10: 42 test file. 1
1 root root 128M Aug 12 10: 42 test file. 10
--1 rootroot 128M Aug 12 10: 42 test file,ll
1 root root 128M Aug 12 10: 42 test file. 12
rH-
1 root root 128M Aug 12 10: 42 test file, 13
w=·
l root root 128M Aug 1210: 42 test file. 14
rw-
1 rootroot 128M Aug 12 10: 42 test file. 15
rw-------l root root 128M Aug 12 10: 42 test file. 2
Lw
1 root root 128M Aug 12 10: 42 test file. 3
1 root root 128M Aug 12 10: 42 test file. 4
l root root 128M Aug 12 10: 42 test file. 5
1 root root 128M Aug 12 10: 42 test file. 6
rw--m---1 root root 128M Aug 12 10: 42 test file. 7
1 rootroot 12BM Aug 1210: 42 test file, s
--1 root root 128M Aug 12 10: 42 test file. 9
接着就可以基于这些文件进行测试了。下面是在16个线程下的随机读取性能:
rootexen-server ssd]# sysbench --test-fileio --file-total-size=2G --file-test-
mode-rndrd --mmax-time-180 --max-requests-100000000 --num-threads-16 --init-rng-on
file-num=16 --file-extra-flags=direct --file-fsync-freg=0 --file-block-size=16384 run
上述测试的最大随机读取请求是100000000次,如果在180秒内不能完成,测试
即结束。测试结束后可以看到如下的测试结果
[rootexen-server ssd] sysbench --test=fileio --file-total-size=2G --file-test-
mode=rndrd --max-time=180 --max-requests=100000000 --num-threads-16 --init-rng=on
-file-num=16 --file-extra-flags=direct --file-fsync-freq=0 --file-block-size=16384 run
cyabench 0 4.10: multi-threaded system evaluation benchmark
Running the test with following options:
Number of threads: 16
Initializing random number generator from timer
Extra file open flags: 16384
16 files, 128M each
2Gb total file size
Block size 16kb
Number of random requests for random IO: 100000000
Read/Write ratio for combined random Io test: 1.50
Calling fsync() at the end cf test, Enabled.
Using synchronous I/o mode
Doing random read test
Threads started!http://blog.csdn.net/jiongyi1
SI.
97逃择合适的基准涮战具403
Time limit exceeded, exiting
(last message repeated 15 times)
one
Opcrations per formed: 619908 Read, 0 Write, o other =619908 Total
Read 9. 459Gb Written ob Total transferred 9.459G (53 81Mb/sec)
3443.85 Reques=s/sec executed
Test execution summary:
total time
180,044s
total number cf events
61990s
total time taken by event execution: 2878.0750
per-request statistics:
Iln.
C. 42ms
avg:
4.64ms
na∵
27.30ns
approx. 95 percentile
,13ms
Thread s fairness
events (avg/stddev)
38744,2500/1C2,69
execution time (avg/stddev): 179. 8797/0.Cd
可以看到随机读取的性能为5381MB/s,随机读的IOFS为3443.85。测试的硬盘是
固态硬盘,因此随机读取的性能较为强劲。此外还可以看到每次请求的一些具体数据,
如最大值、最小值、平均值等。
测试结束后,记得要执行 cleanup,确保测试产生的文件都已删除:
[rootexen-server ssd]t syshench -test=fileio --file-num=16 --file-total-size=2G
cleanup
sysbench 0.4.10: multi-threaded system evaluation benchmark
Removing test files
可能用户需要测试随机读、随机写、随机读写、顺序写、顺序读等所有这些模式,
并且还可能需要测试不同的线程和不同文件块下磁盘的性能表现,这时可能需要类似如
下的脚木来帮用户自动完成这些测试:
#!/bin/sh
set -u
set -x
set -e
for size in 8G 64G: do
for mode in seqrd seqrw rndrd rndwr rndrw: do
for 5lksize in 409616384 dohttp:/blog.csdnnet/jiongyi11
5I.A
404笫9章性能调优
拼安
sysbench --test=fieio --file-num=64 --file-total-size=ssize prepare
for threads in 148: do
echo"回≡〓 testing$b1 ksize in thread s threads"
echa PARAMS Ssize Smode sthreads sblksize>sysbench-size-ssize-mode-smode
threads-sthreads-blksz-sblksize
for i ir 1 23i do
sysbench --testfileio --file-total-size=Ssize --file-test-mode-Smode\
--max-time=180 --nax-requests=100000000 --num-threads=sthreads --init-rng=on
-file-num=64 --file-extra-flags=direct
ile-fsync-freq=0 --file-block-
size=Sblksize run
tee -a sysbench-size-ssize-mode-Smode-threads-sthreads-blksz-sblksize 2>61
done
d。e
s ysbench --test-fiLeio --file-total-size-ssize cleanup
done
done
done
对于 MySQL数据库的OLTP测试,和flio一样需要经历 prepare、rn和 cleanup
阶段。 prepare阶段会根据选项产生一张指定行数的表,默认表在 sbtest架构下,表名为
sbtest( sysbench默认生成表的存储引擎为 InnoDB)。例如创建一张8000W的表:
[rootexen-server - ]t sysbench --test-oltp --oltp-table-size= 80000000 --db-
driver=mysa
-mysql-socket=/tmp/mysql. sock --mysql-user=root prepare
sysbench 0.4,10: multi-threaded system evaluation benchmark
creating table 'sbtest
Creating 80000000 records in table 'sbtest
接着就可以根据产生的表进行olt的测试:
sysbench --testscltp --oltp-table-size=80000000 --oltp-read-only=off --init
rng=on --num-threads-16 --max -requests=0 --oltp-dist-type=uniform --max-time=3600
-imlysql-user=root
mmlysql-socket=/tp/mysl, sock --db-driver-mysgl run >res
用户可将测试结果放人到了文件res中,查看res可得类似如下结果:
sysbench 0.4.10: multi-threaded system evaluation benchmark
WARNING: Preparing of "BEGIN" is unsupported. using emulation
(last message repeated 15 times)
Running the test with following options:
Number or thredds: 16
Initializing random number generator from timer
Doing olTP testhttp://blog.csdn.net/jiongyi1
5
97选挥合适的基准测成具405
部拼没
Running mixed OLTP test
Using Uniform distribution
你
Using "BEGIN" or starting transactions
Using auto inc on the id column
Threads started!
Time limit exceeded, exiting
(last message reFeated 15 times
Done
Oltp test statistics
queries performed:
read
5043324
write
2158330
other
963332
t⊙ta1:
C64986
七 ransact。ns;
431666【119.90 per sec.
deadlocks
(0.00 per sec.
read/write requests:
8201654(227B.07per
other operations:
863332(239,B0 per sec.)
rest execution summary:
t→ta1七ime:
3600.26723
total number of even=s
431666
total time taken by event execution: 57598.5965
per-request statistics:
nln
6.84ms
avg
133.43ms
max t
7155.61ms
approx. 95 percentile:
325.34ms
Threads fairness
events avg/stddev ):
26979.1250/64.14
execution time (avg/stddev): 3599 9123/0.05
结果中罗列出了测试时很多操作的详细信息, transactions代表了测试结果的评
判标准,即TPS,上述测试的结果是1199。用户可以对数据库进行调优后再运行
sysbench的OLTP测试,看看TPS是否有所提高。注意, sysbench的测试只是基准测试,
并不代表实际生产环境下的性能指标。
9.7. 2 mysql-tpcc
TPC( Transaction Processing Performance Counci,事务处理性能协会)是一个用来http://blog.csdn.net/jiongyi1
5.
406躬9性能调优
备拼雳
评价大型数据库系统软硬件性能的非盈利组织。TPCC是TPC协会制定的,用来测试典
型的复杂OLTP(在线事务处理)系统的性能。目前在学术界和工业界普遍用TPCC
来评价OLTP应用的性能。
TPCC用3NF(第三范式)虚拟实现了一家仓库销售供应商公司,拥有一批分布
在不同地方的仓库和地区分公司。当公司业务扩大时,将建立新的仓库和地区分公司
通常每个仓库供货覆盖10家地区分公司,每个地区分公司服务3000名客户。公司共有
100000种商品,分别储在各个仓库中。该系统包含了库存管理、销售、分发产品、
付款、订单查询等一系列操作,一共包含了9个基本关系,基本关系如图99所示。
回以,四比
3MW(11)
d_ id TINYpNT()
命hC1)
多 iSMAILI6
l今 w_ -mA YARCHAR
dw jd SHLLINT()
9h.6dTeMj
s quanity mATlIN『[6
Q w_rect.1 VARCHAR(20) fed_name VARCHAR(10)
◆ h w sMAllL
;d01HR24
φhddT
Eos. a. (2 CHAP(24)
ow cty YAROAR(2o
edrt_:vaR【20
wh w.dsMAUINT[G
os.d 03cHARc24)
ow sate CHAR(2)
4e9d_cty VAROHARIX) itoh dat+ DATET哐
9s_dt_01 CHAR(24)
◆WxQR(9
od state OA
分 h amount DEcIMA62)
:9s_dg_0sCHAR(24
全 w ta DECEMALO42)
I +d Ap OAR(9
h dita VARCHA〔24)
tos_t_06 CHAR(24)
ow. ytd DECEMAL(2.2)
&d tax DECIMAL(4, 2)
rameses
分sd0aHMR(24)
od_ ytd DECIMAL(I2, 2)
9s_da_0B CHAR(24)
pdr。dmt)
2s.dst_ 09 CHAR(2)
分510HAR21
Os_yd DECIMAL(3. 0,
>C.MN(II
osorder_ ant SMALLINT(S)
cdd tINYInt()
stnoke<rt SHLLINT6:
坪 SmaLITE(5}
令 s d-ta 4AROMR(50)
oc_firs YARCAR(16)
M级
命 c mdde CHAR{2)
i。owr:l)
9c LH VARCHAR(L6
创 d M TINYIN(4
o w d SMLNT(6)
伞csre2 ARCHAR(2O
o nmber trinity
命 c.cY VARCHAR2
◆dLT
a d INT11
会cte口ARC
iLdD】
oimjwt(11
以向rw别ML(6
o d i TINYINT(4)
i ocin dHaR(9)
o d devery d DATETIME
&t_phone CHAR<16)
:oiname VARCHAR(24)
G-W_ sMALLTNT(6)
Dotrice DECIMAL.5. 2)
令 d etty TINYINT(+
◆NNT1l
9<sne DATETwE
φ d amount DEC(6.2
9o entry. d DATETIME
心 data VArchAr
心 ddt ratHAR2
n care N NIh(q)!L÷cc№mEMT20
t÷ o d o TIN DMT(4
oc_discount DECiMA(4-2)
。 kota TinYinT4
会 bawe DECIM"〔u2)
CECIMAL(R2 2)
oc_delvery_cnt SMALLNT(6)
c dia TEXT
a_n diNt(I)
?_jTININT(
ho w_idsMAILET(6)
图99TPCC基本关系图
TPCC的性能度量单位是tpmC,tpm是 transaction per minute的缩写,C代表TPC
的C基准测试。该值越大,代表事务处理的性能越高。http://blog.csdn.net/jiongyi1
BI
97逃择合适的基准涮浓县407
tpcc-mysql是开源的TPCC测试工具,该测试工具完全遵守TPCC的标准。棋
官方网站为:htp:/ code launchpad. net/~ percona-dev/ perconatools/tpc- mysql。之前
tpcc- mysql主要工作在 Linux操作系统上,我已经将其移植到了 Windows平台,可以
在htp:/ode.google.com/p/davd-mysql-tools/downloads/list下载到Windows版本的
tpcc-mysql
tpcc- mysql由以下两个工具组成。
口tpcc_load:根据仓库数量,生成9张表中的数据。
口tpce_ start::根据不同选项进行TPCC测试。
tpcc load命令的使用方法如下:
[rootexen-server w]f tp c lvad
★★肃青★★★★★内叱青★★★★★★★★★★★★★★★堂★★火★☆旋★
★★#寺#easy#群番"PC- c Data loader太
言言青古古★出青肯皆★亢青言富青宫言青寓實★★★★★★★★★★★
usage: Pee_ ludd [server] [DB] [user] [pass] [warehouse l
OR
tpcc_1∞ad【 server][DB][user][pass][ warehouse【part][nin_wh1「 max wh
parti: 1=ITEMS 2=WAREHOUSE 3=CUSTOMER 4=ORDERS
各参数的意义如下:
口 sErver,导入的 MySQL服务器IP。
口DB,导入的数据库。
日user, MySQL的用户名。
口pass, MySQL的密码。
口 warehouse,要生产的仓库数量。
如果用 tpcc load工具创建100个仓库的数据库tpc,可以这样:
root@xen-server tpcc-mysql]# mysql tpcc<create table sql
[root@xen-server tpcc-mysql]# mysql tpcc<add fkey idx. sql
Irootexen-server tpcc-mysqlf tpcc load 127.0.0.1 tpcc2 root xxxxxx 100
★太胄宽齿重啬“音女☆★★★★★★背青南青青虻★窗★青★
*翟#easy##TPC- c Data loader★
★★青★贤青★古食食★★南
★丈大青★肯★霁霁阳曹實實實囊货
<Parameters>
[server: 127.0.0.1http:/blog.csdnnet/jiongyi11
51.6
08第9亨性能裯疣
L DBname]: tpcc2
[user: root
督里令
Ipass]:
[warehouse]: 100
TPCC Data load started
Loading Item
,,,,,,5000
看中·····,··■
,,。..,..10000
15000
(略)
DATA LOADING COMPLETED SUCCESSFULLY
tpcc_star命令的使用方法如下:
[rootexen-server ] tpcc start
★實實★责食★★★出食南★★★言★★★★责實★★★★★责實货责食责
如★*##easy#|#TPC- c Load generator**
★责★责★量★声★★黄★★★★责责黄责★★★★貴★畫貴★黄★
usage: tpcc start server] [DD] [user [pass] [warehouse! [connection] [rampup
Measure]
相关参数的作用如下;
口 connection,测试时的线程数量。
口 rampup,热身时间,单位秒,这段时间的操作不计入统计信息。
口 measure,测试时间,单位秒
使用ψ pcc start进行16个线程的测试,热身时间为10分钟,测试时间为20分钟,
如下
Irootaxen-server -]t tpcc start 127.0.0.1 tpcc root xxxxXx 100 16 600 1200
★古古★肯古肯肯肯★★古肯詈計胄胄旾青密★計密出古古去啬责★
★★普普#easy#TPC-CL。 ad generator*★★
密卖★出幽密南洳出曹☆出皆世亡
<Parameters>
server]:127.0.0.1
DBname]: tpcc
luser]: root
paaa!;xκxxxX
[ warehouse]: 100
[connection:: 16
[rampup]: 600 (sec.k
[measure!: 1200 (sec.http://blog.csdn.net/jiongyi1
5
97选择合道的基准测斌壬尽49感鄂
在测试的时候用户或许会在终端上看到类似如下的输出:
你
RAMP- UP TIME(1sec·}
MEASURING START
10,624(0〕:0,4,624(0):0,2,62(0):0.2,63(0):0.6;62(0):0.8
20,990(0):0,2,988(0):0.2,98(0):0.2,99(0):0.4;98(0):0.6
30,1435(0):0.2r1436(0):0.2,144(0):0.2,143(0):0.2,144(0):04
40,1736(0):0.2,1739(0):0.2,174(0):0.2,174(0):0.2;174(0):0.4
50,2041(0):0.2,2044(0);0,2,204(0);0.2,204(0);0,2,207(0);0,2
60,2195(0):0.2,2193(0):0.2,220(0):0.2,2210):0.2,218(0):0.2
70,2332(0):0.2r2335(0):0.2,233(0):0,2,23240):0,2,234(0):Q.2
80,2408(0):0.2;2401(0):0.2,241(0):0.2,239(0):0.2,241(0):0.2
90,2473(0):0.2,2476(0):0.2,247(0):0.2,250(0):0.2,248(0):0.2
100,2350(0):0.2,2347(0):0.2,235(0):0.2,233(0):0.2,235(0):0.2
这些信息是每10秒TPCC测试的结果数据,TPCC测试一共测试5个模块,分
别是 New Order、 Payment、 Order- Status、 Delivery、 Stock-Level。第一个值即为New
Order,这也是TPCC测试结果的一个重要考量标准 New Order per10 Second(每十秒
订单处理能力),可以将测试时所有的数据组成一张折线图或散点图,观察 InnoDB存储
引擎每10秒的性能表现,如图9-10所示。
TPCC
I400
L200
1000
800
-4 RAIDIO
400
200
3l619112115118121124127130133136139142145148151154l157160163l661691
2 9-10 New Order Per 10 Second
而 tpcc load最后结束时产生的tpmC也是通过 New Order per10 Second来进行
的,首先求出 New Order per10 Second的平均值,然后乘以6,得到的就是最终的
tpmchttp://blog.csdn.net/jiongyi1
5
410第9性能调优
者会
<Constraint check>(all must he [ok])
[transaction percentage]
Payment:43·4日8【>=43.08)IOK]
Order-Status: 4.35(>=4.0%)[OK
De1 lvery:4,35号(>=4,0)[OK]
Stock-Level: 4.35(>=4.0%)[OK
response time (at least 908 passed)]
New-crder: 99.72 [OK
Payment:99.95专[OK
order-Status: 99.939 [OK]
Delivery: 100.00% [OK]
Stock-Level: 10000g [OK]
<TpmC>
7949.942c
98小结
在这一章中我们根据 InnoDB存储引擎的应用特点对CPU、内存、硬盘、固态硬
盘、RA⑩D卡做了详细的介绍,相信只有通过理解 InnoDB存储引擎的应用场合和范围才
能更好地对其进行调优。最后,介绍了两个在Lnux操作系统平台下常用的基准测试工
具 sysbench和tpco-mysq,借助这两个工具可以更有效地得知当前系统的负载承受能力,
以及对 MySQL数据库的调优结果进行分析。http://blog.csdn.net/jiongyi1
6I
部拼没
第10章 InnoDB存储引擎源代码的编译和调试
InnoDB存储引擎是开源的,这意味着用户可以获得其源代码并查看内部的具体实
现。任何时候Why都比What重要,通过研究源代码可以更好地理解数据库是如何工
作的,从而知道如何使数据库更好地为你工作。如果你有一定的编程能力,完全可以对
InnoDB存储引擎进行扩展,开发出新的功能模块来更好地支持数据库应用。
10.1获取 InnoDB存储引擎源代码
InnoDB存储引擎的源代码被包含在 MySQL数据库的源代码中,在 MySQL的官方
网站上下载 MYSQL数据库的源代码即可,如图10-1所示
MYSQL Community Server 5.1. 49
Source code
SassE s intg Enlerwrisu Server ver.11
5.1:9
22n
(Architecture Eadepeiiderit). RPM Package
动my5:1,211,
!:!4=1E935Ee5,93运
KdH名 oracle Fntprprisptinux5
5
2078
onload
(Architecture [ndependent), RPM Package
iw-o. comm. 4 3.i 42 :. A:. re Pe:
SuSE Linux Enterprise Server 1O(Architecture
22.GN
Download
Independent), RPM Package
15G-corcaans-5
M5:A2ed7::『a?1s9238“39
Generic linux (olite 2. 1)(Architeclure
5,t49
22M
Iridescent】,风PM护cka9e
54:F
:5}7”,和出贴”了3已
SuSE L inux Enterprise Server 9(Arthitecture
220M
independen】RMa(knqe
M::2=1=:467t形品出石d1a35
Red Hal A Oracle Enterpise Linux -t
LM
(Archiecture Iadepemdeni) RPM Package
已空n5143·1.1ey÷rp
:!;团'曾】2冫“《二当"
Red Hat Fntarpnisey t inux (Ardlui er tirn
22.D
InEloPinoonE】HPp豳k
5:如:E5比三h44于“题6
Generic linex(Architecture Independent)
5,
geHl
图10-1 MySQL源代码下载
白链接为:ht:∥www.mysqlcom/downloads./mysqlhttp:/blog.csdnnet/jiongyi11
51.6
412第加0幸加mDB存儲引孥源代吗的编币忒
可以看到,这里有不同操作系统下的源代码可供下载,一般只需下载 Genetic
Linux的版本即可。通过 MySQL官网首页的 Download链接可以迅速地找到GA版
本的下载,但是如果想要下载目前正在开发的 MySQL版本,如 MySQL5.5.5(现在
是 milestone的版本,离GA版本还有很长的开发时间),用户可能在官网找了很久
都找不到链接,这时只要把下载的链接从www换到dev即可,如htt:!dev. mysql
com/ downloads/ mysql,在这里就可以找到开发中的 MySQL版本的源代码了,如
图10-2所示。
GghefaiNy Avante (GA) Reas+ Deweispnent Recasts
MySQL Community server 5.5.5 m3
弓eee!Pa!ft
I iuuz-Cemeric 2G(Architecture Independant
555
210M
RPM Padzi世
5.5!.25m
MD5:36思里95⊥742225了5252e4
SusE Linux Interprise Server ve.1:
21.45
(Architcdltir'ey Inde elidletir) HPM Package
…5.5…:的e!1:2)
Hw Hol是 Oral EateRprise L奚5
5.5,5
21
Architecture independert).记趴acka
555A1,5MC
H:1s73“he:376"1b3fe
Sust Linux Eaterprise Server 10 (Architcclute
:.
Download
dependent), HpM package
的w5四2:∷a)
5:354::42e“25:23255
ed Hat a Qrade Enterprise LInux 4
,55
Arctiitecttre Independent), RPM ockngie
的 CQL E5.5,m:,sn"
H5!i=63·23:6255t2u514e
Generic Linux(Architecture Independent),
5.5.5
18M
Compressed TAR ArchivE
"a5.:r
ML;::“n号可的于“p3f吧19平
图102 MySQL开发中版本的源代码下载
单击“Download”下载标签后可以进入到下载页面,当然,有mysql.com账号的用户
可以进行登录, MySQL官方提供了大量的镜像用来分流下载,用户可以根据所在的位置
选择下载速度最快的地址。中国用户一般可以在“Asia”这里镜像下载,如图10-3所示。
如果下载的文件是 tar. gz结尾的文件,可以通过 Linux的tar命令, Windows的
WinRAR工具来进行解压,解压后得到一个文件夹,其中包含了 MySQL数据库的所有
源代码。源代码的结构如图104所示
所有存储引擎的源代码都被放在 storage的文件夹下,其源代码结构如图10-5所示。http://blog.csdn.net/jiongyi1
BI
10.2 InnoDe源代码结构43
Asi
邮盛
Hosting, :srael
!"p
JAST,Japd「
HTTPFTP
9: Internet Initative lapan inc, Janan
Http Ftp
d Lanete university of Management Sciancas, pakistan
HTFP FTP
Kvunc Hee Unversity Linus User Group, Republ of Korea
HTTO p
ezNetworku1g SoF tions Pte. Lt. SIn spore
HtTP FTP
a mirror. tw(T'atw an Mirre: ),Taiwan
Http Ftp
L Providence University Taivan
HIFR FTP
Natioral Taiw an Un ver sity, Taiwan
HTP FfP
National Sun Yat Sen university, Tanan
TIP FTP
a Computer Center, shu- Te University/ Kanhs ng, Taiwan
图10-3 MYSQL亚洲下载镜像
可以看到所有存储引擎的源代码都在这里,文件夹名一般就是存储引擎的名称,如
archive、 blackhole、csv、 federated、heap、 imdb2i、 nisar、 innobase。从 MySQL55
版本开始, InnoDB Plugin已经作为默认的 InnoDB存储引擎版本,而在 MySQL51的源
代码中,应该可以看到两个版本的 InnoDB存储引擎源代码,如图10-6所示。
可以看到有 innobase和 innodb plugin两个文件夹, innobase文件夹是旧的 InnoDB
存储引擎的源代码, innodb plugin文件夹是 InnoDB Plugin存储引擎的源代码。如果想
将 InnoDB Plugin直接静态编译到 MySQL数据库中,那么需要删除 innobase文件夹,再
将 innodb_ plugin文件夹重命名为 innobase
102 InnoDB源代码结构
进人 InnoDB存储引擎的源代码文件夹,应该可以看到如图10-7所示的源代码结构
下面介绍一些主要文件夹内的源代码的具体作用。
口btr:B+树的实现。
口buf:缓冲池的实现,包括LRU算法, Flush刷新算法等。
口dict: InnoDB存储引擎中内存数据字典的实现。
口dyn: InnoDB存储引擎中动态数组的实现。
口fl: InnoDB存储引擎中文件数据结构以及对文件的一些操作。
口邸:可以理解为 file space,即对 InnoDB存储引擎物理文件的管理,如页、区、段等。
口ha:哈希算法的实现。http:/blog.csdnnet/jiongyi11
51.6
4l4郭10章loDB存儲引擎源代吗的编译和调试
i BUILD
L archive
elient
1: blackhole
cmake
4, CMakefiles
8 cmd- line-utils
i federated
s btr
can
d buf
iN ibmdb2i
data
。c5
m
i dyn
e extra
include
ttyisammrg
↓ perfschem
f
R is
e Makefile. am
L libmysqld
Makefile. in
h
L services
handler
man
图10-5存储引擎源
k ibut
s mysql-test
代码文件夹
is inc
Packaging
3i plugin
LE archive
Hem
E pstack
black。e
mtr
regex
品验款
mysql-test
scripts
is example
.E federated
3 page
LAc heap
yu sql-commen
imdb
nn。ba5e
read
dr storage
innodb ply
ning
t row
i support - files
testE
A sync
ic unittest
Makefile.am
r wn
Makefile. in
mysql_storage_engine. cmake
图10-4 My SQL源代码
图10-6 MySQL5.1存储
图10-7 InnoDB存储引擎源
目录结构
引擎目录结构
代码的文件夹结构
口 handler:继承于 MySQL的 handler,插件式存储引擎的实现
口ibuf:插人缓冲的实现
口 include: InnoDB将头文件(h,ic)文件都统一放在这个文件夹下。
口lock: InnoDB存储引擎锁的实现,如S锁、Ⅹ锁,以及定义锁的一系列算法。
口log:日志缓冲和重组日志文件的实现。对重组日志感兴趣的应该好好阅读该源代码。
口mem:辅助缓冲池的实现,用来申请一些数据结构的内存
口mtr:事务的底层实现。
口os:封装一些对于操作系统的操作。http:/blog.csdnnet/jiongyi11
103MQL5,版本2和调试 InnoDB源焦吗415争
page
页的实现
你器
口row:对于各种类型行数据的操作。
口srv:对于 InnoDB存储引擎参数的设计。
口sync: InnoDB存储引擎互斥量( Mutex)的实现
口thr: InnoDB储存引擎封装的可移植的线程库。
口trx:事务的实现。
口ut:工具类。
10.3 MySQL51版本编译和调试 InnoDB源代码
10.3.1 Windows下的调试
在 Windows平台下,可以通过 Visual studion2003、205和2008开发工具对
MySQL的源代码进行编译和调试。在此之前,用户需要预先安装如下的工具。
口CMake:可以从htt:/www.cmake.org下载。
口 bison:可以从htp:/ gnuwin32. sourceforge. net/packages/ bison htm下载
安装之后还需要通过 configure. js这个命令进行配置:
C: workdir>win\configure is options
options比较重要的选项如下:
口 WITH INNOBASE STORAGE ENGINE,支持 InnoDB存储引擎。
口 WITH PARTITION STORAGE ENGINE,分区支持。
口 WITH ARCHIVE STORAGE ENGⅠNE,支持 Archive存储引擎。
口 WITH BLACKHOLE STORAGE ENGINE,支持 Blackhole存储引擎
口wITH_ EXAMPLE_ STORAGE ENGINE,支持 Example存储引擎,这个存
储引擎是展示给开发人员的,用户可以从这个存储引擎开始构建自已的存储
引擎。
口 WITH FEDERATED STORAGE_ENGⅠNE,支持 Federated存储引擎。
口 WITH NDBCLUSTER STORAGE ENGINE,支持 NDB Cluster存储引擎。
如果我们只是比较关心 InnoDB存储引擎,可以这样进行设置,如图10-8所示。http:/blog.csdnnet/jiongyi11
46加0加oDB弁储引源代玛的编择和忒
部拼吾
CAMndowswylem32\mexr
,1eC气号,,,”m2a1E
检BsEx1OHC上H;H} HsI 1 HULR I1…y
F*,jecE-4)5,h5-13
图10-8 configure. js配置
之后可以根据用户使用的是 isual studio2005还是 Visual studio2008在win文件下
运行 build-ysx.bat文件来生成 Visual studio的工程文件。buld-vs8.bat表示 Visual Studio
2005, build-vs8x64bat表示需要编译64位的 MySQL数据库。例如,我们需要在32位
的操作系统下使用 Visual studio2008进行调试工作,可以使用如下命令:
D: \Project\mysql-55.5-m3>win\build-vs9bat
Check for working C compiler: C:/Program Files/Microsoft visual Studio 9.0/
Vc/b⊥n/c⊥,eXe
heck for working c compiler: C: /Prograin Files/Microsoft visual Studio 9.0/
VC/bin/cl.exe
w。rks
Detecting c compiler ABI inf
Detecting c compiler AbI info - done
Check for working CxX compiler: C: /Program Files/Microsoft visual Studio 9.0/
vC/bin/cl. exe
Check for working CXX compiler: C: /Program Files/Microsoft visual Studio 9,0/
VC/bin/cl. exe - works
Detecting cXx compiler Abi info
Detecting cxX compiler ABI info- done
Check size of void来
Check size of void * - done
SIZEOF VCIDP=4
Looking for include files HAVE CXXABI H
Looking for include files HAVE CXXABI H -not found
Looking for include files HAVE NDIR H
Looking for include files HAVE NDIR H -not found.
Looking for include files HAVE SYS NDIR H
Looking for include files HAVE sYs NDIR H not found
Looking f。rinc1 ude files HAVE ASM TERME工TSH
Looking for include files HAVE ASM TERMBITS H -nc- found
Looking for include files HAVE TERMBITS H
Looking for include files HAVE TERMBITS H not found
Looking for include files HAVE VIS H
Looking for include files HAVE VIS H not found
Looking重 or inc】 ude files HAVE WCHAR Hhttp://blog.csdn.net/jiongyi1
I
103MkoL5版本城和式加n0DB源码417争
部拼吾
Looking for include files HAVE WCHAR H -found
Looking for include files HAVE WCTYPE H
冷能
Looking for include files HAVE WCTYPE H - fcund
Looking for include files HAVE XFS XFS H
Looking for include files HAVE XES XES- nct found.
Looking for include files CMAKE HAVE PTHREAD H
Looking for include files CMAKE HAVE PTHREAD H- not. found
Found threads: TRUE
Looking for pthread rwlockattr setkind np
Looking for pthread rwlockattr setkind np- not found
Performing Test HAVE SOCKADDR IN SIN LEN
Per forming Test HAVE SOCKADDR IN SIN LEN Failed
Performing Test HAVE SOCKADDR ING SING LEN
Performing Test HAVE SOCKADDR IN6 SIN6 LEN Failed
Cannot find wix 3, installer project will not be generated
Configuring done
Generating done
Build files have been written to: D: /Project/mysql-5.5-5-m3
这样就生成了 MySQL. sIn的工程文件,打开这个工程文件并将myqd这个项目设
置为默认的启动项就可以进行 MySQL的编译和调试了。
之后的编译,断点的设置和调试与在 isual studio下操作一般的程序没有什么区别,
图10-9演示了对 InnoDB存储引擎的 master thread进行调试。
看票“
真:!含P
票物的们”亦,,卫加“:2是
心》t产·3
:“,业
pn:”通!
i wtrs
的品吧lLH□L1区
1:1:“nB:.“
1w1可“F示产啊
dalou
ribaldry
rrr,uy2的hBkk
s今记
k
T气
中;行的!4曾为
命c,雷力
4:数看线雀中1减想
图10-9调试 master threadhttp:/blog.csdnnet/jiongyi11
418笫10幸mnoD存储引擎源代码的编译和调试
10.32 Linux下的调试
Linux下的调试通常使用 Eclipse。对于其他类UNx的操作系统,如 Solaris
FreeBSD、MAC同样可以使用 Eclipse进行调试。首先到ht!/ww: eclipse.org
downloads,/下载并安装 Eclipse IDE for C/C++ Developers。然后,解压 MySQL源代码到
指定目录,如解压到/ root/workspace/mysq1555-m3,接着运行如下命令产生Make文
件, Eclipse会使用产生的这些Mak文件:
rootexen-server mysql-5.5.5-m31# BUILD/compile-amd64-debug-max-no-ndb -c
BULD下有很多 compile文件,用户可以从中选择所需要的文件。本书编译
的平台是64位的 Linux系统,并且我希望可以进行 Debug,因此选择了 compile
amd64- debug-max- no-ndb文件。注意-c选项,这个选项只生产Make文件,不进行
编译
接着打开 Eclipse,新建一个C++的项目,如图10-10所示。
E New Project
5e亡aw|zard
Create a new C++ project
wizard
e General
CC↓
L=CPr。ec
E C++Project3
D E Cvs
t
Next
Cancel
图10-10新建一个C++项目
为项目取个名字,如这里的项日名为 mysql555,并选择一个空的项目,如
图10-11所示。http://blog.csdn.net/jiongyi1
5.
1D3MSQL5版本航和测试m0DB源代要
拼者
C++ Project
Create C++ project of selected type
Project name: mys4553--
v: Use default location
L
PoNCE TYDA
Toolchain
k Executable
hue scc
Hello wond C++ prolect
P Static Library
D Makefile projo
y: Show project types anc tooichairs only if they are supparted on the platorm
⑨
j cancel
FInISh
图10-11选择空项目
选择 Finish按钮后,可以看到新产生的一个空项目,如图10-12所示
eE“5 ouRce F『cqe5 ch un roacE Mind°w即
n出·心·⑤·····:·÷::1
a! dEbe
cEw契
口:EBM;园1:日日
e,l瓦des
k iaap/444a 1
A44】1/别t
pardi.<cxt64h前
b", Sfoc dAnc九de
mv* s: OConee 5、p< s:"Cal Herarchy y ear…、
cd[myq5。53
自 uttu of configurat:on tug ror project”55予
Noth Lng to build for project 1555
my555
图10-12新建的C++项目http:/blog.csdnnet/jiongyi11
5L
420第0章moDB存储引乎源代码的编译和碉忒
留研考
之后选择左边的 Project Explorer,,右击项目 mysql555,选择新建文件夹,将文
件夹/ oot/workspace/mysq-555-m3导到工程,如图10-13所示。
New Folder
F。Ider
Create a new folder resource
Enter or select the parent folder:
mysql.5_5-5
Folder name:i myscl-5.5.5-m3
s Advanced
M Link to folder in the file system
/root/w/rmysql-55.5-m3
Browse.
Variables
Cancel
Finish
图10-13选择文件夹
导入文件夹后再右击项目名 mysql555,选择项目属性,在C/C++ Build选项这里
进行设置,需要将 Build directory选择为源代码所在路径,如图10-14所示。
编译配置完后,程序就会自动开始执行编译工作了,如图10-15所示。
上述的这个过程只是编译的过程,换句话说,编译完后就产生了 mysqld这样的执行
文件。如果想要进行调试,我们还需要在Debg这里进行如下的配置,如图10-16所示。
另外如果需耍配置一些额外的参数,需要切换到 Arguments选项,如图10-17
所示。http://blog.csdn.net/jiongyi1
6I
103MsQL5版本编译和调武lmDB源代吗421争
部拼没
Cc++ Buld
ResourCe
Builders
Configuraton: i Debug Acuve
p C/C++ General
EBuHlder Settings!@Behaviour
Project References
Builder----
Refactoring History
Cx!a!tm! turoe
Aun/Debug setting
Budder type
P Task Repositor
v use defaut bulld courland
W幽上翼t
BuHd command::m1 3t,m
----------------------------
1+m当1=1
Maker de generation
a Generate Makefes automatically
Build locatior---------1-9-"----,--
Build directory: is (workspace_lot: mysql_5_55/mysql-555-m3)..
如中
workspace.:Ale system. variables> ,r
Restore nefa!M
?
Cancel
OK
图10-14编译配置
BE5oumR4c国减5 ch Bu BpcE Window
·::圍”···””·0··,5i7
2争 Debug
FoCT Exp其
Bcu嚣M;:°日
日
Buong workspace:(+5s1
图10-15执行编译http://blog.csdn.net/jiongyi1
BI
422第10幸加mDB夺储引源代码的和得试
部拼吾
Debug Configuraton的
cra看,m仙,晶ndrE。 nfquratiens
M入4mm: Environmens w Deb吗gym、一
Name: my_5-5_5 Debug
urce:rEfresh: i Common
y cC/C++ ApplIcaton
c汇C+ t Attach to Applic
mysql._5
c. CIC++ Postmortem Debugger
Build configuraton ' Deb
e Launch Group
cC+即 pplication
i my5ql-5.5.5-m3/scl'mysqld
L Search Project. Towse
E Connect process Input ouput to a teirrilnal
: Using standard Create Process Launcher Select
Apply
R
FHer matched505敢em5
Close
Debug
图10-16 Debug配置
Debug
reate, menade, and run configur.。n
Name: imy5q1_ Debug
C Main el Arguments Ermvironment$ Debugger Source g- Refresh: ECommon
PsCC↓+ APplcatIon
Program argument5
user=root
E CK++ Attach to Application
. datadir= /root/workspaceAmysql55.5-mJ/in/data
e s: C/c++ Postmortem Debugger
5oke= mp/mysql.s心k
uage=noot/ pace/mysql5.53-In3'sqlsh
Launch Grol甲p
variables
Warking dir ectory-…
中物护界界
5{中画Ce。Cy以
Use default
一气,,啊国气增气一,里出它一如正写
using standard cn碱时FoEe55 Launcher:S世
Fiter matched s of 5 items
图10-17调试参数
之后就可以设置断点,进行调试工作了,这和一般的程序并没有什么不同,如图10-18
所示http:/blog.csdnnet/jiongyi11
5I.
104 cmake方式编译和调试lODB存错引季423
多市yq555y中955m刻式0bB/c重即等冷
Tle Edr source Refact Hawlgate Search Bun groect w
可ved1Spe即pm的、B对:
钋De∞跬
fl Vanos .a Breakpoints A. wr Expressiom:群Repr断MduA
到以以说3)5我计”“m水myq55m3mnsv/wrwc(m!
耍23"申ed4)0x00031为20J7
≡2cre})0000031206d30ad
b -4 T ead [18)(Suspended
Ted【19!( Suspended
x
t iryn th reads ctiveISRV MASTER]+i:
E orem h
n「粗「
e me'nOftemh
syncosyric h
5 sN main thread op into .. serving kenet ntext
a tholos h
b
bus晶t1;
log Io
stat
aut stat, n_page
t吧夏夏e(贮r1eL■【e是1
pAPan h
nur a: tha start 511:EG iCIS
old activity coun:=sn-c tivity. count
u:你xex:I玩et
日 Console I Tasks:Pms:OE黑ea所aE贴rer軒o;C副e
a:逊图咎::“
isnot: Creating foreig key constraint system tables
nno:F4re3gnky≤ anserIna 51:tt山碧cr通ted
100816161·32 innot:1.115t
16: 43: 3] (Note! Event schouler: Loaded o + t
version:5.5
03:13 HOtei /root/workspace/mysql. 5.5-a/sqt/msqtd: heady far connections
一+—
-++++++m7
品b
sTar Insert
图10-18用 Eclipse进行调试
104 cmake方式编译和调试 InnoDB存储引擎
ySQL数据库从5.5版本开始可以直接通过命令 cmake生成对应的MyQL工程
文件,例如在 Mac OSX操作系统下,用户可以直接通过下列命令产生 xcode对应的
MySQL T程文件:
cd mysgl-xxx
mkdir bld
cd bld
cmake
G Xcode
上述命令在 MySQL源码文件夹下创建了bd文件夹,接着通过命令cmak产生对
应xode的工程文件,之后在文件夹下就能看到工程文件 MySQL. xcodeproj,双击该文
件就能对 MySQL数据库和 InnoDB存储引擎进行编译,如图10-19所示。http:/blog.csdnnet/jiongyi11
51.6
424箕0章 nodE存儲引学源代码的编邙和凋忒
研者翻
MYSQL.xcodeproj.t srvosMvc
A. My Mac
Running amrysqld: ALL- BUILD
题!增
serie
Creakeainte
vewy
organizer
hinn
syt
nowin:
taoic
srvDsrv.5
面x8三↓出4酶)间m精)别钟))Nm,总
2
srv n threads己 ctIve【 SRV. MASTER]+
ThPzd 1
cam, apple. main-thread
mutex exit(&kernet mutex)
T I Thread 2
题0
240:: oop:
1. thread. start
x下札x↓市中电中事中产比木本中本不不杰木冰车冰木啦冰一大中十产F
四2 tread 32ar
ihen there is database activity by users
ercte in this
+sf Thread 3
)i Thread 4
srv main. threac-op_inio = reserving keret mutex
。T剂5
bur get total stat(Sbuf stat?;
toui
n_ios_very_old log_sys-n1og_ios but_statn_poges_read
4Thd西
but_statn_pages written:
:
nut ex enter( u"cx)
t H Thread 3
上Thed8
/x Store the wser activity counter at the start of this top A/
old activity.count srv activity count*
t Thread 9
215
natex exlt【kne1,tex);
题Thr器
* H THnead 11
if( sry force recovery >= SRY_ FORCE№ BACKGR0ip】【:h2bm
u Thread 12
A goto suspend thread;
ts Thread 13
we run tine! f ILUwlry tocp app uxisldtely ante per secund
when there Is Catalase act! ty i
tt Thread 15
n:is srv_Iastlog_flush_time tire(NuLL];
m
Y* sleep for I second on entrying the foc Loop below the first tic. */
next itr time g ut time ms(>+ 1000:
8.,野r4=.…1.<1日:+4+1.「
四非2, myoid i Thread2; G srv master thread
图 buf stat ouf_pool_stat
M srv_force recovery =(lint)o
圈圳ok- lock Inval E*brei4n
图10-19 Mac osx操作系统下通过 xcode对 MySQL进行编译
总之, cmake大大简化了编译 MySQL效据库的难度。更多关于 cmake的参数及说
明可见 MySQL官方手册说明。
105小结
MySQL数据库和 InnoDB存储引擎都是开源的,我们可以通过常用的开发工具
如 visual studio、 Eclipse对其进行编译和调试,以此来更好地了解数据库内部运行机
制。有能力的开发人员可以进一步扩展数据库的功能,这就是开源的魅力,这在 Oracle
Microsoft SQL Server、DB2等商业数据库中是永远不可能发生的。